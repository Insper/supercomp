
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://insper.github.io/supercomp/aulas/aula21/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Revisão - SuperComputação - 2026/1</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/printing.css">
    
      <link rel="stylesheet" href="../../css/extra.css">
    
      <link rel="stylesheet" href="../../css/equipe.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue-gray" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#revisao" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="SuperComputação - 2026/1" class="md-header__button md-logo" aria-label="SuperComputação - 2026/1" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SuperComputação - 2026/1
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Revisão
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/insper/supercomp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    SuperComp
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../sobre/" class="md-tabs__link">
        
  
  
    
  
  Burocracias

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../aula01/" class="md-tabs__link">
          
  
  
  Aulas

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../teoria/slides/" class="md-tabs__link">
          
  
  
  Suporte

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="SuperComputação - 2026/1" class="md-nav__button md-logo" aria-label="SuperComputação - 2026/1" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    SuperComputação - 2026/1
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/insper/supercomp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    SuperComp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sobre/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Burocracias
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Aulas
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Aulas
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aula01/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aula 01 - Introdução e Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aula02/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aula 02 - Cluster Franky
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aula03/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aula 03 - STD, Vector e Tiling
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Suporte
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Suporte
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../teoria/slides/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Slides das aulas
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../teoria/aula01/compilar-executar-C%2B%2B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aula 01
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../teoria/aula02/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aula 02
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../teoria/aula03/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aula 03
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../teoria/comandos/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Útil
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../teoria/permissoes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Permissões
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#sistemas-de-hpc" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sistemas de HPC
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sistemas de HPC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#carregar-os-modulos" class="md-nav__link">
    <span class="md-ellipsis">
      
        Carregar os modulos
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diretorio-scratch" class="md-nav__link">
    <span class="md-ellipsis">
      
        Diretório Scratch
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#informacoes-uteis-sobre-os-recursos-do-sistema" class="md-nav__link">
    <span class="md-ellipsis">
      
        Informações úteis sobre os recursos do sistema
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="revisao">Revisão<a class="headerlink" href="#revisao" title="Permanent link">&para;</a></h1>
<h2 id="sistemas-de-hpc">Sistemas de HPC<a class="headerlink" href="#sistemas-de-hpc" title="Permanent link">&para;</a></h2>
<p>O paralelismo em GPU se diferencia do paralelismo em CPU de várias formas, uma delas está na maneira como solicitamos recursos para o SLURM, primeiro de tudo é importante considerar que não é possível compartilhar o hardware da GPU com outros usuários, uma vez que a GPU é alocada para o seu job, só você terá acesso a GPU, desta forma, você pode alocar completamente a GPU, e esta é um boa prática, aproveitar o máximo possível o potencial da GPU. Para fazer a solicitação de GPU via slurm você precisa:</p>
<h3 id="carregar-os-modulos">Carregar os modulos<a class="headerlink" href="#carregar-os-modulos" title="Permanent link">&para;</a></h3>
<p>Um sistema de HPC pode ter várias versões de drivers e módulos, é importante prestar atenção em qual versão do modulo você precisa trabalhar para garantir compatibilidade de drivers, para verificar a lista de módulos e drivers disponíveis para uma determinada instalação, utilize o comando:</p>
<p><div class="highlight"><pre><span></span><code>module<span class="w"> </span>avail<span class="w"> </span>cuda
</code></pre></div>
Neste exemplo, filtramos a busca por <code>cuda</code>, desta forma, podemos visualizar todos os módulos e drivers disponíveis com esta interface</p>
<p><img alt="alt text" src="image.png" /></p>
<p>Observando as opções disponíveis do cuda, verificamos que a instalação mais atualizada é a <code>cuda/12.6_sequana</code>, então vamos carregar ela no ambiente</p>
<div class="highlight"><pre><span></span><code>module<span class="w"> </span>load<span class="w"> </span>cuda/12.6_sequana<span class="w"> </span>
</code></pre></div>
<p>Uma vez carregado o módulo, é possível utilizar as ferramentas desta instalação em todo o ambiente, inclusive nos nós de computação.</p>
<h3 id="diretorio-scratch">Diretório Scratch<a class="headerlink" href="#diretorio-scratch" title="Permanent link">&para;</a></h3>
<p>Assim que você conecta no Santos Dumont via SSH, usando algo como:</p>
<div class="highlight"><pre><span></span><code>ssh<span class="w"> </span>-o<span class="w"> </span><span class="nv">MACs</span><span class="o">=</span>hmac-sha2-256<span class="w"> </span>seu_usuario@login.sdumont.lncc.br
</code></pre></div>
<p>Você cairá na pasta de projeto dentro do nó de login do Santos Dumont, com o comando <code>pwd</code>, é possível verificar o caminho do diretório que você está, que deverá ser algo como:</p>
<div class="highlight"><pre><span></span><code>/prj/insperhpc/seu_usuario
</code></pre></div>
<p>O diretório de trabalho é o <code>SCRATCH</code>, somente neste ambiente os nós de computação terão acesso aos seus códigos e aos seus binários, então, logo que carregar os módulos necessários, troque para o diretório de trabalho:</p>
<div class="highlight"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>/scratch/insperhpc/seu_usuario<span class="w">    </span>
</code></pre></div>
<p>Neste ambiente você pode clonar seus repositórios, organizar suas pastas, submeter seus jobs...</p>
<h3 id="informacoes-uteis-sobre-os-recursos-do-sistema">Informações úteis sobre os recursos do sistema<a class="headerlink" href="#informacoes-uteis-sobre-os-recursos-do-sistema" title="Permanent link">&para;</a></h3>
<p>Para saber quais são as filas disponíveis para o seu usuário em um ambiente de HPC, você pode usar o seguinte comando:</p>
<div class="highlight"><pre><span></span><code>sacctmgr<span class="w"> </span>list<span class="w"> </span>user<span class="w"> </span><span class="nv">$USER</span><span class="w"> </span>-s<span class="w"> </span><span class="nv">format</span><span class="o">=</span>partition%20,MaxJobs,MaxSubmit,MaxNodes,MaxCPUs,MaxWall
</code></pre></div>
<p>No caso do Santos Dumont, você deve ver algo como:
<div class="highlight"><pre><span></span><code><span class="w">           </span>Partition<span class="w"> </span>MaxJobs<span class="w"> </span>MaxSubmit<span class="w"> </span>MaxNodes<span class="w">  </span>MaxCPUs<span class="w">     </span>MaxWall
--------------------<span class="w"> </span>-------<span class="w"> </span>---------<span class="w"> </span>--------<span class="w"> </span>--------<span class="w"> </span>-----------
<span class="w">     </span>sequana_cpu_dev<span class="w">       </span><span class="m">1</span><span class="w">         </span><span class="m">1</span><span class="w">        </span><span class="m">4</span><span class="w">      </span><span class="m">192</span><span class="w">    </span><span class="m">00</span>:20:00
<span class="w">         </span>sequana_gpu<span class="w">       </span><span class="m">4</span><span class="w">        </span><span class="m">24</span><span class="w">       </span><span class="m">24</span><span class="w">     </span><span class="m">1152</span><span class="w">  </span><span class="m">4</span>-00:00:00
<span class="w">     </span>sequana_gpu_dev<span class="w">       </span><span class="m">1</span><span class="w">         </span><span class="m">1</span><span class="w">        </span><span class="m">4</span><span class="w">      </span><span class="m">192</span><span class="w">    </span><span class="m">00</span>:20:00
</code></pre></div></p>
<p><strong>Partition</strong></p>
<p>É a “fila” do SLURM, o espaço do cluster onde seu job vai rodar.
Cada partição tem características próprias: hardware específico, limites, prioridades.</p>
<p>No Santos Dumont:</p>
<ul>
<li><strong>sequana_cpu_dev</strong>: CPUs para desenvolvimento rápido (jobs curtos).</li>
<li><strong>sequana_gpu</strong>: GPUs para produção (jobs longos, pesados).</li>
<li><strong>sequana_gpu_dev</strong>: GPUs para desenvolvimento (jobs curtos).</li>
</ul>
<h1 id="maxjobs"><strong>MaxJobs</strong><a class="headerlink" href="#maxjobs" title="Permanent link">&para;</a></h1>
<p>Número máximo de <strong>jobs simultâneos em execução</strong> que você, pode ter naquela partição.</p>
<ul>
<li><code>1</code> significa que você só pode rodar um job por vez na partição. </li>
<li><code>4</code> significa que você pode ter até quatro jobs rodando ao mesmo tempo.</li>
</ul>
<p><strong>Exemplo:</strong>
Em <code>sequana_gpu_dev</code>, se você tentar rodar dois jobs simultâneos, o segundo fica na fila como <em>pending</em> esperando o primeiro terminar.</p>
<p><strong>MaxSubmit</strong></p>
<p>Número máximo de <strong>jobs pendentes ou rodando</strong> que você pode <strong>enviar</strong> para uma fila.</p>
<p>É o limite de quantas submissões o SLURM aceita de você.</p>
<ul>
<li>Em dev (<code>sequana_cpu_dev</code>): <code>1</code>
  Só um job enviado por vez.</li>
<li>Em produção (<code>sequana_gpu</code>): <code>24</code>
  Você pode enviar 24 jobs para a fila se quiser.</li>
</ul>
<p><strong>MaxNodes</strong></p>
<p>Quantos nós você pode reservar <strong>por job</strong> nessa partição.</p>
<ul>
<li><code>4</code> significa que seu job pode ocupar até 4 nós simultâneos.</li>
<li>Se você tentar usar <code>--nodes=8</code> dentro dessa partição, o SLURM rejeita.</li>
</ul>
<p><strong>MaxCPUs</strong></p>
<p>Número máximo de CPUs que você pode alocar <strong>por job</strong>.</p>
<p>Essa conta geralmente é:</p>
<div class="highlight"><pre><span></span><code>MaxNodes × CPUs_por_nó = MaxCPUs
</code></pre></div>
<ul>
<li><code>sequana_cpu_dev</code>: 4 nós × 48 CPUs = 192 CPUs</li>
<li><code>sequana_gpu_dev</code>: 4 nós × 48 CPUs = 192 CPUs</li>
<li><code>sequana_gpu</code>: 24 nós × 48 CPUs = 1152 CPUs</li>
</ul>
<p>Isso não significa que você <em>vai</em> usar tudo, mas esse é o limite superior permitido para sua submissão.</p>
<p><strong>MaxWall</strong></p>
<p>O tempo máximo de <strong>duração</strong> que um job pode ter antes de ser morto.</p>
<p>Valores:</p>
<ul>
<li><code>00:20:00</code> significa 20 minutos.</li>
<li><code>4-00:00:00</code> significa 4 dias.</li>
</ul>
<h3 id="para-saber-detalhes-sobre-o-hardware-disponivel-em-cada-fila">Para saber detalhes sobre o hardware disponível em cada fila<a class="headerlink" href="#para-saber-detalhes-sobre-o-hardware-disponivel-em-cada-fila" title="Permanent link">&para;</a></h3>
<p>Usamos o comando</p>
<div class="highlight"><pre><span></span><code>scontrol<span class="w"> </span>show<span class="w"> </span>partition<span class="w"> </span>sequana_gpu_dev
</code></pre></div>
<p>Para saber informações detalhadas sobre o hardware disponível em determinada fila</p>
<div class="highlight"><pre><span></span><code><span class="nv">PartitionName</span><span class="o">=</span>sequana_gpu_dev
<span class="w">   </span><span class="nv">AllowGroups</span><span class="o">=</span>ALL<span class="w"> </span><span class="nv">AllowAccounts</span><span class="o">=</span>ALL<span class="w"> </span><span class="nv">AllowQos</span><span class="o">=</span>ALL
<span class="w">   </span><span class="nv">AllocNodes</span><span class="o">=</span>ALL<span class="w"> </span><span class="nv">Default</span><span class="o">=</span>NO<span class="w"> </span><span class="nv">QoS</span><span class="o">=</span>defaultgpu
<span class="w">   </span><span class="nv">DefaultTime</span><span class="o">=</span><span class="m">00</span>:20:00<span class="w"> </span><span class="nv">DisableRootJobs</span><span class="o">=</span>NO<span class="w"> </span><span class="nv">ExclusiveUser</span><span class="o">=</span>NO<span class="w"> </span><span class="nv">GraceTime</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="nv">Hidden</span><span class="o">=</span>NO
<span class="w">   </span><span class="nv">MaxNodes</span><span class="o">=</span>UNLIMITED<span class="w"> </span><span class="nv">MaxTime</span><span class="o">=</span>UNLIMITED<span class="w"> </span><span class="nv">MinNodes</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="nv">LLN</span><span class="o">=</span>NO<span class="w"> </span><span class="nv">MaxCPUsPerNode</span><span class="o">=</span>UNLIMITED<span class="w"> </span><span class="nv">MaxCPUsPerSocket</span><span class="o">=</span>UNLIMITED
<span class="w">   </span><span class="nv">Nodes</span><span class="o">=</span>sdumont<span class="o">[</span><span class="m">8029</span>-8055,8060-8083,8085-8091,8093-8095<span class="o">]</span>
<span class="w">   </span><span class="nv">PriorityJobFactor</span><span class="o">=</span><span class="m">40</span><span class="w"> </span><span class="nv">PriorityTier</span><span class="o">=</span><span class="m">40</span><span class="w"> </span><span class="nv">RootOnly</span><span class="o">=</span>NO<span class="w"> </span><span class="nv">ReqResv</span><span class="o">=</span>NO<span class="w"> </span><span class="nv">OverSubscribe</span><span class="o">=</span>NO
<span class="w">   </span><span class="nv">OverTimeLimit</span><span class="o">=</span>NONE<span class="w"> </span><span class="nv">PreemptMode</span><span class="o">=</span>OFF
<span class="w">   </span><span class="nv">State</span><span class="o">=</span>UP<span class="w"> </span><span class="nv">TotalCPUs</span><span class="o">=</span><span class="m">2928</span><span class="w"> </span><span class="nv">TotalNodes</span><span class="o">=</span><span class="m">61</span><span class="w"> </span><span class="nv">SelectTypeParameters</span><span class="o">=</span>NONE
<span class="w">   </span><span class="nv">JobDefaults</span><span class="o">=</span><span class="nv">DefCpuPerGPU</span><span class="o">=</span><span class="m">12</span>,DefMemPerGPU<span class="o">=</span><span class="m">94000</span>
<span class="w">   </span><span class="nv">DefMemPerCPU</span><span class="o">=</span><span class="m">8000</span><span class="w"> </span><span class="nv">MaxMemPerNode</span><span class="o">=</span>UNLIMITED
<span class="w">   </span><span class="nv">TRES</span><span class="o">=</span><span class="nv">cpu</span><span class="o">=</span><span class="m">2928</span>,mem<span class="o">=</span>22875G,node<span class="o">=</span><span class="m">61</span>,billing<span class="o">=</span><span class="m">2928</span>,gres/gpu<span class="o">=</span><span class="m">244</span>
</code></pre></div>
<p>De forma resumida, a sequana_gpu e a sequana_gpu_dev tem essas características:</p>
<table>
<thead>
<tr>
<th>Fila</th>
<th>Nós</th>
<th>CPUs Totais</th>
<th>GPUs Totais</th>
<th>Memória Total</th>
<th>CPUs por GPU (default)</th>
<th>Memória por GPU (default)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>sequana_gpu_dev</strong></td>
<td>61</td>
<td>2928</td>
<td>244</td>
<td>22.8 TB</td>
<td>12 CPUs/GPU</td>
<td>94 GB/GPU</td>
</tr>
<tr>
<td><strong>sequana_gpu</strong></td>
<td>87</td>
<td>4176</td>
<td>348</td>
<td>32.6 TB</td>
<td>12 CPUs/GPU</td>
<td>94 GB/GPU</td>
</tr>
</tbody>
</table>
<p>Ambas as filas são de GPU's V100 com 32 GB de VRAM.</p>
<h3 id="submetendo-um-job-com-suporte-a-gpu">Submetendo um job com suporte a GPU<a class="headerlink" href="#submetendo-um-job-com-suporte-a-gpu" title="Permanent link">&para;</a></h3>
<p>Considerando as informações sobre filas disponíveis e as configurações de hardware de cada fila, você pode submeter o seu job de duas formas diferentes:</p>
<h3 id="comando-srun">Comando srun<a class="headerlink" href="#comando-srun" title="Permanent link">&para;</a></h3>
<p>Com o srun, você pode solicitar um terminal para executar o seu job de forma rápida, você pode ou não, salvar o output desta execução, se quiser salvar o output, faça a submissão do job desta forma:</p>
<div class="highlight"><pre><span></span><code>srun<span class="w"> </span>--partition<span class="o">=</span>sequana_gpu_dev<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>--output<span class="o">=</span>saida.txt<span class="w"> </span>./seu_binario
</code></pre></div>
<p>Esse comando pede ao SLURM que execute imediatamente um programa dentro da partição <code>sequana_gpu_dev</code>, reservando uma GPU, e salvando todo o output em <code>saida.txt</code>.</p>
<p><strong><code>srun</code></strong></p>
<p>É o comando do SLURM usado para executar jobs interativos ou iniciar processos paralelos dentro de alocações já existentes.</p>
<ul>
<li>Se a partição tiver recurso livre, ele roda agora.</li>
<li>Se não tiver, seu comando fica <em>pending</em> até conseguir GPU.</li>
</ul>
<p><strong><code>--partition=sequana_gpu_dev</code></strong></p>
<p>Define em qual fila você quer rodar.</p>
<p><code>sequana_gpu_dev</code> é a fila de GPUs, com tempo máximo de 20 minutos.</p>
<p>Se você rodasse na <code>sequana_gpu</code>, poderia usar jobs longos, mas com maior concorrência.</p>
<p><strong><code>--gres=gpu:1</code></strong></p>
<p>Aqui você está dizendo:</p>
<p>“Reserve <strong>1 GPU</strong> para mim”.</p>
<p>Se você colocar <code>--gres=gpu:4</code>, estaria pedindo quatro GPUs.</p>
<p><strong><code>--output=saida.txt</code></strong></p>
<p>Tudo o que normalmente apareceria no seu terminal é redirecionado para um arquivo.</p>
<p>Se não colocar esse parâmetro, o output aparece diretamente no terminal.</p>
<h3 id="comando-sbatch">Comando sbatch<a class="headerlink" href="#comando-sbatch" title="Permanent link">&para;</a></h3>
<p>Se você precisa executar um código que vai ficar rodando sem a sua supervisão, é melhor usar o sbatch, pois o sbatch executa em background.</p>
<p>Um sbatch direto ao ponto para executar um código em GPU seria assim:</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=exemplo_gpu</span>
<span class="c1">#SBATCH --output=saida_%j.txt</span>
<span class="c1">#SBATCH --time=00:10:00</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --partition=sequana_gpu_dev</span>
<span class="c1">#SBATCH --mem=1G                  </span>


module<span class="w"> </span>load<span class="w"> </span>cuda/12.6_sequana

./seu_binario
</code></pre></div>
<h2 id="passando-um-codigo-sequencial-em-cpu-para-gpu-usando-cuda">Passando um código sequencial em CPU para GPU usando CUDA<a class="headerlink" href="#passando-um-codigo-sequencial-em-cpu-para-gpu-usando-cuda" title="Permanent link">&para;</a></h2>
<p>Vamos começar com um programa C++ simples que soma os elementos de dois arrays, cada um com um milhão de elementos.</p>
<div class="highlight"><pre><span></span><code><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>

<span class="c1">// function to add the elements of two arrays</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">&lt;&lt;</span><span class="mi">20</span><span class="p">;</span><span class="w"> </span><span class="c1">// 1M elements</span>

<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">float</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">float</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>

<span class="w">  </span><span class="c1">// initialize x and y arrays on the host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">;</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run kernel on 1M elements on the CPU</span>
<span class="w">  </span><span class="n">add</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Check for errors (all values should be 3.0f)</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">maxError</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">maxError</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmax</span><span class="p">(</span><span class="n">maxError</span><span class="p">,</span><span class="w"> </span><span class="n">fabs</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="mf">-3.0f</span><span class="p">));</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Max error: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">maxError</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Free memory</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="p">[]</span><span class="w"> </span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="k">delete</span><span class="w"> </span><span class="p">[]</span><span class="w"> </span><span class="n">y</span><span class="p">;</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>Primeiro, compile e execute esse programa C++. Coloque o código acima em um arquivo e salve como <strong>add.cpp</strong>, e então compile com o compilador C++. 
<div class="highlight"><pre><span></span><code>g++ add.cpp -o add
</code></pre></div></p>
<p>Depois execute:</p>
<div class="highlight"><pre><span></span><code>./add
Max error: 0.000000
</code></pre></div>
<p>Para passa esse código para a GPU, primeiro, precisa transformar a função <strong>add</strong> em uma função que a GPU pode executar, chamada de <em>kernel</em> em CUDA. Para fazer isso, é preciso adicionar o especificador <strong>global</strong> à função, o que diz ao compilador CUDA C++ que essa é uma função que roda na GPU e pode ser chamada a partir de código da CPU.</p>
<div class="highlight"><pre><span></span><code><span class="c1">// Kernel function to add the elements of two arrays</span>
<span class="n">__global__</span>
<span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">sum</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">sum</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div>
<p>Essa função <strong><strong>global</strong></strong> é conhecida como kernel CUDA e roda na GPU. Código que roda na GPU é frequentemente chamado de <em>device code</em>, enquanto código que roda na CPU é chamado de <em>host code</em>.</p>
<p>Para computar na GPU, precisa alocar memória acessível pela GPU. <strong>Unified Memory</strong> (Memória Unificada) no CUDA facilita isso ao fornecer um único espaço de memória acessível por todas as GPUs e CPUs do sistema. Para alocar dados em memória unificada, da pra usar o <strong>cudaMallocManaged()</strong>, que retorna um ponteiro acessível tanto pelo host (CPU) quanto pelo device (GPU). Para liberar os dados, basta passar o ponteiro para <strong>cudaFree()</strong>.</p>
<div class="highlight"><pre><span></span><code><span class="c1">// Allocate Unified Memory -- accessible from CPU or GPU</span>
<span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">sum</span><span class="p">;</span>
<span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="p">...</span>

<span class="c1">// Free memory</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>
</code></pre></div>
<p>Lançamentos de kernel CUDA são especificados usando a sintaxe com três sinais de maior: <strong>&lt;&lt;&lt; &gt;&gt;&gt;</strong>. Só preciso adicioná-la na chamada de <strong>add</strong> antes da lista de parâmetros.</p>
<div class="highlight"><pre><span></span><code>add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(N, sum, x, y);
</code></pre></div>
<p>Essa linha lança <strong>uma thread</strong> da GPU para executar <strong>add()</strong>.</p>
<p>Só falta mais uma coisa: preciso que a CPU espere até que o kernel esteja terminado antes de acessar os resultados (porque lançamentos de kernel CUDA não bloqueiam a thread da CPU que o chamou). Para isso, basta chamar <strong>cudaDeviceSynchronize()</strong> antes de fazer a verificação final de erro na CPU.</p>
<p>O código completo:
<div class="highlight"><pre><span></span><code><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;math.h&gt;</span>

<span class="c1">// Kernel function to add the elements of two arrays</span>
<span class="n">__global__</span>
<span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">&lt;&lt;</span><span class="mi">20</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Allocate Unified Memory – accessible from CPU or GPU</span>
<span class="w">  </span><span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">  </span><span class="c1">// initialize x and y arrays on the host</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">;</span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Run kernel on 1M elements on the GPU</span>
<span class="w">  </span><span class="n">add</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Wait for GPU to finish before accessing on host</span>
<span class="w">  </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// Check for errors (all values should be 3.0f)</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">maxError</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">maxError</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmax</span><span class="p">(</span><span class="n">maxError</span><span class="p">,</span><span class="w"> </span><span class="n">fabs</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="mf">-3.0f</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Max error: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">maxError</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Free memory</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
<span class="w">  </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></p>
<p>Arquivos CUDA têm a extensão <strong>.cu</strong>. Então salve esse código em um arquivo chamado <strong>add.cu</strong> e compile com o <strong>nvcc</strong>, o compilador CUDA C++.</p>
<div class="highlight"><pre><span></span><code>nvcc add.cu -o add_cuda
./add_cuda
Max error: 0.000000
</code></pre></div>
<p>Isso é apenas o primeiro passo, porque da forma como está, esse kernel só funciona para <strong>uma única thread</strong>. </p>
<p>Nos próximos passos é importante entender como gerenciar memória adequadamente, como funciona a divisão lógica dentro da GPU e, para implementações mais complexas, é legal entender como programar de forma assíncrona. O material sobre os próximos passos estão disponíveis nas aulas anteriores.</p>
<p>Referência:
<a href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/">https://developer.nvidia.com/blog/even-easier-introduction-cuda/</a></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tabs", "content.code.copy"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.0.0/js-yaml.min.js"></script>
      
        <script src="../../js/markdown-enhancer.js"></script>
      
        <script src="../../js/slides.js"></script>
      
    
  </body>
</html>