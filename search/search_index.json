{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SuperComputa\u00e7\u00e3o","text":"<p>Bem-vindo ao curso de SuperComputa\u00e7\u00e3o 2025/2!</p> <p>Essa p\u00e1gina cont\u00e9m os materiais de apoio para o curso de SuperComputa\u00e7\u00e3o do Insper.</p> <p>Hor\u00e1rios das Aulas</p> <p>Aulas:</p> <p>Segunda -&gt; 16h30 -- 18h30</p> <p>Sexta -&gt; 14h15 -- 16h15</p> <p>Atendimento:</p> <p>Segunda -&gt; 18h30 -- 20h00</p>"},{"location":"#estrutura-do-curso","title":"Estrutura do Curso","text":"<p>O curso \u00e9 estruturado da seguinte forma:</p> <p>Estrutura do Curso</p> <ol> <li>Programa\u00e7\u00e3o paralela e distribu\u00edda em CPU</li> <li>Projeto 1</li> <li>Programa\u00e7\u00e3o paralela e distribu\u00edda em GPU</li> <li>Projeto 2</li> </ol>"},{"location":"#objetivos-de-aprendizagem","title":"Objetivos de aprendizagem","text":"<p>No Insper, cada disciplina \u00e9 guiada por objetivos de aprendizagem. Para evoluir na mat\u00e9ria e ser aprovado, \u00e9 essencial que voc\u00ea atinja esses objetivos. Todos os conte\u00fados, atividades e projetos est\u00e3o conectados diretamente a esses objetivos.  Voc\u00ea pode consultar o detalhamento completo do curso neste link.</p> <p>Notas</p> <ul> <li>Atividades - 15%.</li> <li>Projeto 1 - 10%</li> <li>Avalia\u00e7\u00e3o Intermedi\u00e1ria - 25%</li> <li>Projeto 2 - 20%</li> <li>Avalia\u00e7\u00e3o Final - 30%</li> </ul>"},{"location":"#equipe","title":"Equipe","text":"<p>Equipe atual</p> <ul> <li> L\u00edcia Sales Professora</li> <li> Ana Laiz Ninja</li> <li> Victor Cordeiro T\u00e9cnico do lab.</li> </ul>"},{"location":"sobre/","title":"Burocracias","text":"<p>Hor\u00e1rios</p> <p>Aulas:</p> <p>Segunda -&gt; 16h30 -- 18h30</p> <p>Sexta -&gt; 14h15 -- 16h15</p> <p>Atendimento:</p> <p>Segunda -&gt; 18h30 -- 20h00</p> Objetivos de Aprendizagem <p>Ao final da disciplina, o estudante ser\u00e1 capaz de:</p> <p>Obj 1. Desenvolver algoritmos usando recursos de computa\u00e7\u00e3o paralela e distribu\u00edda para obter ganhos de desempenho na aplica\u00e7\u00e3o final.</p> <p>Obj 2. Aplicar estruturas l\u00f3gicas de computa\u00e7\u00e3o distribu\u00edda no desenvolvimento de algoritmos multitarefa.</p> <p>Obj 3. Usar GPGPU (General-Purpose computing on Graphics Processing Units) para computa\u00e7\u00e3o num\u00e9rica e comparar seu desempenho com solu\u00e7\u00f5es baseadas em CPU.</p> <p>Obj 4. Planejar e projetar sistemas de computa\u00e7\u00e3o de alto desempenho, considerando aspectos de hardware, escalabilidade, e aloca\u00e7\u00e3o de recursos.</p> <p>Obj 5. Analisar a complexidade de algoritmos paralelos e a efici\u00eancia de implementa\u00e7\u00f5es espec\u00edficas, identificando as m\u00e9tricas de desempenho mais adequadas para essa an\u00e1lise.</p> <p>Obj 6. Aplicar recursos espec\u00edficos de sistemas operacionais (como escalonadores, controle de threads e gerenciamento de mem\u00f3ria) para melhorar o desempenho de algoritmos.</p> <p>Obj 7. Desenvolver aplica\u00e7\u00f5es que utilizam protocolos otimizados para paraleliza\u00e7\u00e3o, como MPI, OpenMP e CUDA.</p> Plano de Aulas - Supercomputa\u00e7\u00e3o (2025.2) Data Aula T\u00f3picos Abordados Atividades 11/ago (seg) Aula 01 Problemas de HPC; mapa de mem\u00f3ria; Python \u00d7 C++; desempenho; objetivos da disciplina; passagem de argumentos; recursos de C++ Transcri\u00e7\u00e3o de c\u00f3digos Python para C++; compara\u00e7\u00e3o de desempenho entre linguagens. 15/ago (sex) Aula 02 Sistemas de HPC; rede, hardware, filas, jobs; SLURM; clusters no Brasil e no mundo Testes com SLURM no Cluster Franky; compara\u00e7\u00e3o de desempenho em diferentes filas. 18/ago (seg) Aula 03 Hierarquia de mem\u00f3ria (L1, L2, L3); t\u00e9cnica de tiling (fateamento em blocos); localidade espacial e temporal Aplicar tiling para melhorar uso de cache; reorganizar estruturas de dados para melhor localidade. 22/ago (sex) Aula 04 Aleatoriedade, heur\u00edsticas, aloca\u00e7\u00e3o de mem\u00f3ria Ajustes em heur\u00edsticas, estrutura de dados e uso eficiente da mem\u00f3ria. 25/ago (seg) Aula 05 Paralelismo em CPU; threads; cores; OpenMP; vari\u00e1veis privadas e compartilhadas; scheduling Paralelismo com OpenMP; compartilhamento entre threads; efeitos do scheduler. 29/ago (sex) Aula 06 Efeitos colaterais do paralelismo; race conditions; depend\u00eancias; recurs\u00e3o Estudo de caso: mapear problemas, levantar hip\u00f3teses de otimiza\u00e7\u00e3o e comparar desempenho. 01/set (seg) Aula 07 Mem\u00f3ria distribu\u00edda; comunica\u00e7\u00e3o com MPI; ponto-a-ponto e coletiva; grupos e comunicadores Paralelismo com MPI; comunica\u00e7\u00e3o entre n\u00f3s. 05/set (sex) Aula 08 Estrat\u00e9gias h\u00edbridas MPI + OpenMP Estudo de caso com MPI + OpenMP; identifica\u00e7\u00e3o de gargalos e poss\u00edveis otimiza\u00e7\u00f5es. 08/set (seg) Aula 09 Apresenta\u00e7\u00e3o do Projeto \u2013 Minera\u00e7\u00e3o de criptomoedas em CPU Aula est\u00fadio. 12/set (sex) Aula 10 Discuss\u00e3o sobre exerc\u00edcios de t\u00e9cnicas de otimiza\u00e7\u00e3o e aplica\u00e7\u00e3o de paralelismo/distribui\u00e7\u00e3o em CPU Resolu\u00e7\u00e3o de exerc\u00edcios preparat\u00f3rios para a Prova Intermedi\u00e1ria. 15/set (seg) Aula 11 Aula est\u00fadio Suporte ao desenvolvimento do Projeto 1; discuss\u00e3o sobre exerc\u00edcios para a Prova Intermedi\u00e1ria. 19/set (sex) Aula 12 Aula est\u00fadio Suporte ao desenvolvimento do Projeto 1; discuss\u00e3o sobre exerc\u00edcios para a Prova Intermedi\u00e1ria. 22/set (seg) Aula 13 Aula est\u00fadio Ajustes finais no Projeto 1 \u2013 Minera\u00e7\u00e3o de criptomoedas em CPU. 26/set (sex) Aula 14 Prova Intermedi\u00e1ria Avalia\u00e7\u00e3o dos conte\u00fados at\u00e9 Estrat\u00e9gias h\u00edbridas MPI + OpenMP. 29/set (seg) Aula 15 Prova Intermedi\u00e1ria Avalia\u00e7\u00e3o dos conte\u00fados at\u00e9 Estrat\u00e9gias h\u00edbridas MPI + OpenMP. 06/out (seg) Aula 16 CURSO NVIDIA \u2013 CUDA CURSO NVIDIA \u2013 CUDA. 10/out (sex) Aula 17 CURSO NVIDIA \u2013 CUDA CURSO NVIDIA \u2013 CUDA. 13/out (seg) Aula 18 Profiling em GPU; an\u00e1lise de diverg\u00eancias; uso de mem\u00f3ria em ambientes HPC Atividade pr\u00e1tica no ambiente de HPC Santos Dumont. 17/out (sex) Aula 19 Histogramming; data race em GPU; atomic; throughput Estudo de caso; visualiza\u00e7\u00e3o de data race e throughput em ambientes de HPC. 20/out (seg) Aula 20 T\u00e9cnicas stencil; convolu\u00e7\u00e3o; tile boundaries; agendamento de threads Atividade pr\u00e1tica sobre tiling, agendamento de threads e stencil para convolu\u00e7\u00e3o em GPU/HPC. 24/out (sex) Aula 21 Estabilidade num\u00e9rica; ponto flutuante; controle de erro Aula expositiva; estudo de caso; visualiza\u00e7\u00e3o de estabilidade num\u00e9rica e controle de erros. 27/out (seg) Aula 22 Estrat\u00e9gias h\u00edbridas com MPI + CUDA; gerenciamento de dados Atividade pr\u00e1tica sobre programa\u00e7\u00e3o distribu\u00edda em GPU para ambientes de HPC. 31/out (sex) Aula 23 Lan\u00e7amento do Projeto 2 \u2013 Minera\u00e7\u00e3o de criptomoedas em GPU Discuss\u00e3o sobre t\u00e9cnicas de otimiza\u00e7\u00e3o vistas no curso e aplica\u00e7\u00f5es no projeto. 03/nov (seg) Aula 24 Aula est\u00fadio Suporte ao Projeto 2 \u2013 Minera\u00e7\u00e3o de criptomoedas em GPU. 07/nov (sex) Aula 25 Aula est\u00fadio Suporte ao Projeto 2 \u2013 Minera\u00e7\u00e3o de criptomoedas em GPU. 10/nov (seg) Aula 26 Aula est\u00fadio Ajustes finais no Projeto 2. 14/nov (sex) Aula 27 Devolutiva do Projeto 2; exerc\u00edcios de prepara\u00e7\u00e3o para Avalia\u00e7\u00e3o Final Revis\u00e3o pr\u00e1tica. 17/nov (seg) Aula 28 Avalia\u00e7\u00e3o Final Avalia\u00e7\u00e3o Final. 24/nov (seg) Aula 29 Avalia\u00e7\u00e3o Final Encerramento e avalia\u00e7\u00e3o final. Atividades (Individual) 15% Percentual de Atividades Conceito Com Participa\u00e7\u00e3o Volunt\u00e1ria 50% C C+ 70% B B+ 90% A A+ Projeto 1 (Grupo) 10% Projeto 2 (Individual) 20% <p>Projeto Minerador em GPU  Neste projeto, o foco \u00e9 explorar o uso de paralelismo e estrat\u00e9gias de otimiza\u00e7\u00e3o em GPU para maximizar o desempenho computacional.</p> <p>Objetivos principais:</p> <ul> <li> <p>Executar o projeto utilizando o sistema de HPC SDumont, do LNCC;</p> </li> <li> <p>Implementar estrat\u00e9gias de paralelismo e distribui\u00e7\u00e3o em GPUs;</p> </li> <li> <p>Aumentar a dificuldade da minera\u00e7\u00e3o (n\u00famero de zeros);</p> </li> <li> <p>Comparar desempenho, efici\u00eancia e consumo de recursos entre as vers\u00f5es CPU e GPU;</p> </li> </ul>"},{"location":"sobre/#mineracao-de-criptomoedas-em-cpu","title":"Minera\u00e7\u00e3o de criptomoedas em CPU","text":"<p>Este projeto consiste na implementa\u00e7\u00e3o e otimiza\u00e7\u00e3o de um minerador de criptomoedas que roda em CPU. Aplicando t\u00e9cnicas de paralelismo para melhorar desempenho no cluster Franky. A dificuldade da minera\u00e7\u00e3o \u00e9 ajustada pela quantidade de zeros no hash, aumentando o desafio computacional conforme otimizimos a aplica\u00e7\u00e3o.</p> Rubrica Crit\u00e9rios T\u00e9cnicos C Executa o c\u00f3digo minerador ass\u00edncrono no cluster Franky com dificuldade **5 zeros e pelo menos 5 gera\u00e7\u00f5es diferentes de async_gen`. B Executa o c\u00f3digo minerador ass\u00edncrono no cluster Franky com dificuldade 6 zeros e pelo menos 5 gera\u00e7\u00f5es diferentes de <code>async_gen</code>; utiliza paralelismo ou distribui\u00e7\u00e3o do c\u00f3digo em CPU. A Executa o c\u00f3digo minerador ass\u00edncrono no cluster Franky com dificuldade 7 zeros e pelo menos 5 gera\u00e7\u00f5es diferentes de <code>async_gen</code>; realiza paraleliza\u00e7\u00e3o e distribui\u00e7\u00e3o do c\u00f3digo em CPU."},{"location":"sobre/#entrega","title":"Entrega","text":"<p>C\u00f3digo-fonte funcional, comentado e documentado. Relat\u00f3rio t\u00e9cnico com: </p> <ul> <li>Diagn\u00f3stico dos gargalos;</li> <li>Proposta de otimiza\u00e7\u00e3o;</li> <li>Hip\u00f3tese de melhoria;</li> <li>Implementa\u00e7\u00e3o da hip\u00f3tese;</li> <li>Compara\u00e7\u00e3o de desempenho;</li> <li>Discuss\u00e3o dos resultados.</li> </ul>"},{"location":"sobre/#bonus-por-qualidade","title":"B\u00f4nus por Qualidade","text":"Conceito Base Com B\u00f4nus C C+ B B+ A A+"},{"location":"sobre/#rubrica-de-avaliacao","title":"R\u00fabrica de Avalia\u00e7\u00e3o","text":"N\u00edvel Crit\u00e9rios T\u00e9cnicos Complexidade Computacional Esperado R\u00fabrica C Parte da otimiza\u00e7\u00e3o realizada em CPU e parte implementada em GPU, executada no SDumont 7 zeros R\u00fabrica B Paralelismo e distribui\u00e7\u00e3o em CPU, com parte da otimiza\u00e7\u00e3o feita em GPU, utilizando o SDumont 8 zeros R\u00fabrica A Paralelismo e distribui\u00e7\u00e3o focados principalmente em GPU, com tarefas simples executadas em CPU, utilizando o sistema SDumont 9 zeros"},{"location":"sobre/#entrega_1","title":"Entrega","text":"<p>C\u00f3digo-fonte funcional, comentado e documentado. Relat\u00f3rio t\u00e9cnico com: </p> <ul> <li>Diagn\u00f3stico dos gargalos;</li> <li>Proposta de otimiza\u00e7\u00e3o;</li> <li>Hip\u00f3tese de melhoria;</li> <li>Implementa\u00e7\u00e3o da hip\u00f3tese;</li> <li>Compara\u00e7\u00e3o de desempenho;</li> <li>Discuss\u00e3o dos resultados.</li> </ul>"},{"location":"sobre/#bonus-por-qualidade_1","title":"B\u00f4nus por Qualidade","text":"Conceito Base Com B\u00f4nus C C+ B B+ A A+"},{"location":"Exercicios/aula01/aula01/","title":"Aula 01 e 02 Otimiza\u00e7\u00f5es basicas","text":""},{"location":"Exercicios/aula01/aula01/#questao-1-classificacao-de-problemas-em-hpc-teorica","title":"Quest\u00e3o 1 \u2014 Classifica\u00e7\u00e3o de problemas em HPC (Te\u00f3rica)","text":"<p>Tipo: m\u00faltipla escolha (m\u00faltiplas corretas) Enunciado: Classifique cada cen\u00e1rio como Grande (G), Intensivo (I) ou Combo (C).</p> <p>a) Treinar um modelo com bilh\u00f5es de par\u00e2metros, mas com dataset moderado. b) Processar todos os frames de c\u00e2meras de uma cidade por 30 dias. c) Resolver simula\u00e7\u00f5es de mec\u00e2nica dos fluidos 3D com malha fina para um avi\u00e3o. d) Indexar petabytes de logs e calcular m\u00e9tricas em janelas de tempo curtas.  </p> <p>Recaptulando... \u201cGrandes\u201d se refere a um conjunto de dados muito grande, \u201cIntensivos\u201d se refere a algoritimos demorados, resolu\u00e7\u00e3o complexa de equa\u00e7\u00f5es, etc.. e \u201cCombo\u201d s\u00e3o as duas caracter\u00edsticas juntas. </p> Ver a resposta <p>Gabarito: a) I (Intensivo) b) G (Grande) c) I (Intensivo) d) C (Combo)</p> <p>Por qu\u00ea? - a) Treinar um modelo com bilh\u00f5es de par\u00e2metros \u00e9 Intensivo, o dataset sendo moderado, n\u00e3o \u00e9 cr\u00edtico ent\u00e3o excluimos a op\u00e7\u00e3o de Combo. - b) Volume massivo de dados \u21d2 Grande. - c) CFD 3D com malha fina \u00e9 cl\u00e1ssico Intensivo. - d) Petabytes + m\u00e9tricas em janelas curtas \u21d2 Combo.</p>"},{"location":"Exercicios/aula01/aula01/#questao-2-geracao-de-dados-aleatorios-em-c","title":"Quest\u00e3o 2 \u2014 Gera\u00e7\u00e3o de dados aleat\u00f3rios em C++","text":"<p>Enunciado: Complete a fun\u00e7\u00e3o <code>gerar_leituras</code> para criar um vetor de tamanho <code>N</code> contendo valores <code>double</code> aleat\u00f3rios entre 12.0 e 189.98, usando <code>std::vector</code>, <code>std::mt19937</code> e <code>std::uniform_real_distribution</code>.</p> <pre><code>// =========================================\n// Fun\u00e7\u00e3o para gerar um vetor com valores aleat\u00f3rios\n// =========================================\nvector&lt;double&gt; gerar_leituras(size_t tamanho) {\n    // TODO: Criar um vetor de tamanho `tamanho`\n    // TODO: Criar gerador de n\u00fameros aleat\u00f3rios com seed fixa (ex: 42)\n    // TODO: Definir distribui\u00e7\u00e3o entre 12.0 e 189.98\n    // TODO: Preencher o vetor com n\u00fameros aleat\u00f3rios\n\n    return {}; // Substitua pelo vetor preenchido\n}\n</code></pre> Ver a resposta <pre><code>#include &lt;vector&gt;\n#include &lt;random&gt;\nusing std::vector;\n\n// =========================================\n// Fun\u00e7\u00e3o para gerar leituras aleat\u00f3rias\n// Preenche o vetor passado por refer\u00eancia\n// =========================================\nvoid gerar_leituras_ref(vector&lt;double&gt;&amp; v) {\n    // Criamos o gerador Mersenne Twister com seed fixa\n    std::mt19937 gen(42);\n\n    // Distribui\u00e7\u00e3o uniforme no intervalo [12.0, 189.98]\n    std::uniform_real_distribution&lt;double&gt; dist(12.0, 189.98);\n\n    // Percorremos o vetor pelo \u00edndice (sem auto)\n    for (size_t i = 0; i &lt; v.size(); i++) {\n        v[i] = dist(gen);  // gera n\u00famero e armazena direto no vetor\n    }\n}\n</code></pre>"},{"location":"Exercicios/aula01/aula01/#questao-3-media-movel-por-valor-e-por-referencia","title":"Quest\u00e3o 3 \u2014 M\u00e9dia m\u00f3vel por valor e por refer\u00eancia","text":"<p>Enunciado: Implemente as duas vers\u00f5es abaixo da m\u00e9dia m\u00f3vel simples com janela <code>K</code>:  </p> <p>(a) recebendo os dados por valor (b) recebendo os dados por refer\u00eancia constante  </p> <pre><code>// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por valor)\n// =========================================\nvector&lt;double&gt; media_movel_por_valor(vector&lt;double&gt; dados, size_t K) {\n    // TODO: Usar soma inicial dos K primeiros elementos\n    // TODO: Atualizar soma a cada passo removendo o primeiro e adicionando o pr\u00f3ximo\n    // TODO: Retornar vetor com m\u00e9dias\n    return {};\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por refer\u00eancia)\n// =========================================\nvector&lt;double&gt; media_movel_por_referencia(const vector&lt;double&gt;&amp; dados, size_t K) {\n    // TODO: Mesma l\u00f3gica da vers\u00e3o por valor\n    // TODO: N\u00e3o copiar o vetor original\n    return {};\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;vector&gt;\nusing std::vector;\n\n// =====================================================\n// (a) Fun\u00e7\u00e3o que recebe o vetor por VALOR\n//     \u2192 Uma c\u00f3pia de 'dados' \u00e9 criada dentro da fun\u00e7\u00e3o.\n//     \u2192 Essa c\u00f3pia aumenta custo de mem\u00f3ria/tempo se\n//       o vetor for muito grande.\n// =====================================================\nvector&lt;double&gt; media_movel_por_valor(vector&lt;double&gt; dados, size_t K) {\n    const size_t N = dados.size();\n\n    // Se a janela for inv\u00e1lida, retorna vetor vazio\n    if (K == 0 || K &gt; N) return {};\n\n    // Vetor de sa\u00edda que conter\u00e1 as m\u00e9dias\n    vector&lt;double&gt; medias;\n\n    // Calcula a soma inicial dos K primeiros elementos\n    double soma = 0.0;\n    for (size_t i = 0; i &lt; K; i++) {\n        soma += dados[i];\n    }\n    medias.push_back(soma / K); // primeira m\u00e9dia\n\n    // Desliza a janela: remove o elemento que saiu\n    // e adiciona o pr\u00f3ximo elemento\n    for (size_t i = K; i &lt; N; i++) {\n        soma += dados[i] - dados[i - K];\n        medias.push_back(soma / K);\n    }\n\n    // Retorna o vetor de m\u00e9dias\n    return medias;\n}\n\n// =====================================================\n// (b) Fun\u00e7\u00e3o que recebe o vetor por REFER\u00caNCIA CONST\n//     \u2192 N\u00e3o h\u00e1 c\u00f3pia: a fun\u00e7\u00e3o acessa o mesmo vetor.\n//     \u2192 Mais eficiente em mem\u00f3ria e tempo.\n//     \u2192 'const' garante que a fun\u00e7\u00e3o N\u00c3O altera os dados.\n// =====================================================\nvector&lt;double&gt; media_movel_por_referencia(const vector&lt;double&gt;&amp; dados, size_t K) {\n    const size_t N = dados.size();\n\n    // Se a janela for inv\u00e1lida, retorna vetor vazio\n    if (K == 0 || K &gt; N) return {};\n\n    // Vetor de sa\u00edda que conter\u00e1 as m\u00e9dias\n    vector&lt;double&gt; medias;\n\n    // Calcula a soma inicial dos K primeiros elementos\n    double soma = 0.0;\n    for (size_t i = 0; i &lt; K; i++) {\n        soma += dados[i];\n    }\n    medias.push_back(soma / K);\n\n    // Desliza a janela e calcula as m\u00e9dias seguintes\n    for (size_t i = K; i &lt; N; i++) {\n        soma += dados[i] - dados[i - K];\n        medias.push_back(soma / K);\n    }\n\n    // Retorna o vetor de m\u00e9dias\n    return medias;\n}\n</code></pre>"},{"location":"Exercicios/aula01/aula01/#questao-4-media-movel-por-ponteiro","title":"Quest\u00e3o 4 \u2014 M\u00e9dia m\u00f3vel por ponteiro","text":"<p>Enunciado: Implemente a fun\u00e7\u00e3o <code>media_movel_por_ponteiro</code> que recebe um ponteiro para <code>double</code> (<code>const double*</code>) e calcula a m\u00e9dia m\u00f3vel com aritm\u00e9tica de ponteiros. Retorne o vetor de m\u00e9dias.</p> <pre><code>// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por ponteiro)\n// =========================================\nvector&lt;double&gt; media_movel_por_ponteiro(const double* ptr, size_t N, size_t K) {\n    // TODO: Implementar usando aritm\u00e9tica de ponteiros\n    // Exemplo: *(ptr + i) acessa o elemento i\n    return {};\n}\n</code></pre> ver resposta <pre><code>#include &lt;vector&gt;\nusing std::vector;\n\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel usando ponteiros\nvector&lt;double&gt; media_movel_por_ponteiro(const double* ptr, size_t N, size_t K) {\n    // Verifica se o ponteiro \u00e9 v\u00e1lido e se a janela K faz sentido\n    if (!ptr || K == 0 || K &gt; N) return {};\n\n    vector&lt;double&gt; medias;      // vetor que vai guardar os resultados\n    double soma = 0.0;          // acumulador da soma da janela\n\n    // Calcula a soma inicial dos K primeiros elementos\n    for (size_t i = 0; i &lt; K; i++) {\n        soma += *(ptr + i);     // *(ptr + i) \u00e9 o mesmo que ptr[i]\n    }\n    medias.push_back(soma / K); // primeira m\u00e9dia\n\n    // Desliza a janela at\u00e9 o final\n    for (size_t i = K; i &lt; N; i++) {\n        soma += *(ptr + i) - *(ptr + i - K); // atualiza a soma\n        medias.push_back(soma / K);          // guarda a m\u00e9dia\n    }\n\n    return medias; // retorna o vetor de m\u00e9dias\n}\n</code></pre>"},{"location":"Exercicios/aula03/aula03/","title":"Aula 03 Otimiza\u00e7\u00f5es no uso da mem\u00f3ria","text":""},{"location":"Exercicios/aula03/aula03/#questao-1-teorica-hierarquia-de-memoria-e-localidade","title":"Quest\u00e3o 1 \u2014 Te\u00f3rica (Hierarquia de Mem\u00f3ria e Localidade)","text":"<p>Tipo: m\u00faltipla escolha (m\u00faltiplas corretas) Enunciado: Sobre a hierarquia de mem\u00f3ria (L1, L2, L3, RAM) e os princ\u00edpios de localidade:  </p> <p>a) L1 \u00e9 a mem\u00f3ria cache mais r\u00e1pida, por\u00e9m \u00e9 a maior. b) O princ\u00edpio da localidade temporal sugere que dados acessados recentemente provavelmente ser\u00e3o acessados novamente em breve. c) O princ\u00edpio da localidade espacial sugere que percorrer um vetor de 3 dimens\u00f5es varrendo coluna por coluna em um la\u00e7o for encadeado \u00e9 a forma mais eficiente. d) Se um loop acessa elementos distantes no vetor (p. ex., <code>array[i*1000]</code>), isso prejudica a localidade espacial.  </p> Ver a resposta <ul> <li> <p>a) Incorreta. L1 \u00e9 realmente a mais r\u00e1pida, mas n\u00e3o \u00e9 a maior. Entre caches, a maior costuma ser a L3; em geral, a RAM \u00e9 muito maior, mas bem mais lenta.</p> </li> <li> <p>b) Correta. Esse \u00e9 o conceito cl\u00e1ssico de localidade temporal: reutilizar dados acessados h\u00e1 pouco tempo.</p> </li> <li> <p>c) Incorreta. Isso fere o princ\u00edpio da localidade espacial, porque os dados s\u00e3o armazenados em ordem de linhas na mem\u00f3ria (RAM e caches). Se percorrermos coluna por coluna, os acessos n\u00e3o ser\u00e3o cont\u00edguos. O correto seria percorrer linha por linha para aproveitar os blocos que j\u00e1 est\u00e3o em cache.</p> </li> <li> <p>d) Correta. Pular elementos gera desperd\u00edcio de cache, porque v\u00e1rias posi\u00e7\u00f5es carregadas n\u00e3o ser\u00e3o usadas. Al\u00e9m disso, h\u00e1 overhead de instru\u00e7\u00f5es para calcular o \u00edndice distante, em vez de simplesmente incrementar o endere\u00e7o cont\u00edguo.</p> </li> </ul>"},{"location":"Exercicios/aula03/aula03/#questao-2-versao-ingenua-calculo-de-produto-vetorial","title":"Quest\u00e3o 2 \u2014 Vers\u00e3o Ing\u00eanua (C\u00e1lculo de Produto Vetorial)","text":"<p>Enunciado: Implemente uma fun\u00e7\u00e3o que recebe dois vetores <code>A</code> e <code>B</code> de tamanho <code>N</code> e calcula o vetor <code>C</code>, onde:  </p>  C[i] = \\sum_{k=0}^{N-1} A[i] \\times B[k]  <p>ou seja, cada posi\u00e7\u00e3o de <code>C</code> \u00e9 a soma do produto de <code>A[i]</code> com todos os elementos de <code>B</code>. Depois, compile o programa e rode no cluster com SLURM utilizando a fila express.  </p> <pre><code>void produtoIngenuo(vector&lt;double&gt;&amp; A, vector&lt;double&gt;&amp; B, vector&lt;double&gt;&amp; C, int N) {\n    // TODO: loop i\n    // TODO: loop k\n    // TODO: C[i] += A[i] * B[k];\n}\n</code></pre> Ver resposta <p>Explica\u00e7\u00e3o:</p> <p>O loop externo (<code>i</code>) percorre todos os elementos de <code>A</code> e <code>C</code>. O loop interno (<code>k</code>) percorre todos os elementos de <code>B</code>. Essa \u00e9 a vers\u00e3o ing\u00eanua, porque sempre percorremos <code>B</code> inteiro para cada <code>i</code>. Localidade temporal: cada <code>A[i]</code> \u00e9 reutilizado N vezes. Localidade espacial: <code>B[k]</code> \u00e9 percorrido de forma sequencial, o que \u00e9 bom para cache.  </p> <pre><code>#include &lt;vector&gt;\nusing std::vector;\n\n// Implementa\u00e7\u00e3o ing\u00eanua do c\u00e1lculo\nvoid produtoIngenuo(vector&lt;double&gt;&amp; A, vector&lt;double&gt;&amp; B, vector&lt;double&gt;&amp; C, int N) {\n    // Percorre cada posi\u00e7\u00e3o do vetor C\n    for (int i = 0; i &lt; N; i++) {\n        C[i] = 0.0; // inicializa C[i] em zero\n\n        // Para cada A[i], percorre todo o vetor B\n        for (int k = 0; k &lt; N; k++) {\n            C[i] += A[i] * B[k]; // acumula o produto\n        }\n    }\n}\n</code></pre> <p>Exemplo de script <code>run.slurm</code> para rodar no cluster:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=produtoIngenuo   # nome do job\n#SBATCH --output=saida.out          # arquivo de sa\u00edda\n#SBATCH --partition=express         # fila express\n#SBATCH --nodes=1                   # 1 n\u00f3\n#SBATCH --ntasks=1                  # 1 tarefa\n#SBATCH --mem=2G\n#SBATCH --time=00:05:00             # tempo 5 min\n\n./produtoIngenuo\n</code></pre>"},{"location":"Exercicios/aula03/aula03/#questao-3-versao-com-tiling-multiplicacao-de-blocos-de-vetores","title":"Quest\u00e3o 3 \u2014 Vers\u00e3o com Tiling (Multiplica\u00e7\u00e3o de Blocos de Vetores)","text":"<p>Enunciado: Agora implemente uma vers\u00e3o com tiling: - Divida o vetor <code>B</code> em blocos de tamanho <code>Bsize</code>. - Para cada <code>A[i]</code>, some os produtos em blocos de <code>B</code> antes de acumular no resultado <code>C[i]</code>. - Compare o desempenho com a vers\u00e3o ing\u00eanua usando SLURM.  </p> <pre><code>void produtoTiling(vector&lt;double&gt;&amp; A, vector&lt;double&gt;&amp; B, vector&lt;double&gt;&amp; C, int N, int Bsize) {\n    // TODO: loop externo sobre blocos de B\n    // TODO: loop i sobre elementos de A\n    // TODO: loop k dentro do bloco de B\n}\n</code></pre> Ver Resposta <p>Usando a cache L2 lat\u00eancia menor que RAM e a L3 capacidade bem maior que L1. Deixe margem para A, C e demais dados. Uma boa heur\u00edstica \u00e9 usar 60%\u201375% da L2 para o bloco de <code>B</code>.</p> <p>Ganhos sobre a vers\u00e3o ing\u00eanua: - Acesso espacial cont\u00edguo a <code>B</code> dentro do bloco. - Maior chance de vetoriza\u00e7\u00e3o no la\u00e7o de <code>i</code>.  </p> <pre><code>#include &lt;vector&gt;\n#include &lt;algorithm&gt;\nusing namespace std;\n\n// ======================================================\n// Fun\u00e7\u00e3o: produtoTiling\n// Objetivo: calcular C[i] = soma_k ( A[i] * B[k] )\n// Estrat\u00e9gia: TILING (processar B em blocos cont\u00edguos)\n//   - Varremos B em blocos [kk, kend)\n//   - Para cada bloco de B, atualizamos todos os C[i]\n// Benef\u00edcio: melhor reuso temporal/espacial de B (cache), reduzindo misses\n// ======================================================\nvoid produtoTiling(vector&lt;double&gt;&amp; A, vector&lt;double&gt;&amp; B, vector&lt;double&gt;&amp; C, int N, int Bsize) {\n    // Inicializa C uma \u00fanica vez\n    for (int i = 0; i &lt; N; i++) {\n        C[i] = 0.0;\n    }\n\n    // Loop externo: percorre B em blocos de tamanho Bsize\n    for (int kk = 0; kk &lt; N; kk += Bsize) {\n        // Limite do bloco (cuida da \"sobra\" no final)\n        int kend = min(kk + Bsize, N);\n\n        // Para cada elemento de A (e C correspondente)...\n        for (int i = 0; i &lt; N; i++) {\n            // ...percorrermos APENAS o bloco atual de B\n            for (int k = kk; k &lt; kend; k++) {\n                // A[i] * B[k] contribui para C[i]\n                C[i] += A[i] * B[k];\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"Exercicios/aula03/aula03/#questao-4-reordenacao-de-loops-flags-de-otimizacao","title":"Quest\u00e3o 4 \u2014 Reordena\u00e7\u00e3o de Loops + Flags de Otimiza\u00e7\u00e3o","text":"<p>Enunciado: Implemente a vers\u00e3o reordenada: - Para cada <code>k</code>, carregue uma c\u00f3pia tempor\u00e1ria de <code>B[k]</code> em cache. - Depois percorra todos os elementos de <code>A</code> para atualizar <code>C[i]</code>. - Qual a flag de compila\u00e7\u00e3o que resulta no bin\u00e1rio mais eficiente?  </p> <pre><code>void produtoReordenado(vector&lt;double&gt;&amp; A, vector&lt;double&gt;&amp; B, vector&lt;double&gt;&amp; C, int N) {\n    // TODO: loop k\n    // TODO: armazenar tempB = B[k]\n    // TODO: loop i \u2192 C[i] += A[i] * tempB\n}\n</code></pre> Ver Resposta <p>Usando a cache L2 lat\u00eancia menor que RAM e a L3 capacidade bem maior que L1. Deixe margem para A, C e demais dados. Uma boa heur\u00edstica \u00e9 usar 60%\u201375% da L2 para o bloco de <code>B</code>.</p> <p>Ganhos sobre a vers\u00e3o ing\u00eanua: - Reuso temporal forte de <code>B[k]</code> e de <code>tempB</code>. - Acesso espacial cont\u00edguo a <code>B</code> dentro do bloco. - Maior chance de vetoriza\u00e7\u00e3o no la\u00e7o de <code>i</code>.  </p> <pre><code>#include &lt;vector&gt;\nusing std::vector;\n\n// TILING + HOIST:\n// - Varremos B em BLOCOS cont\u00edguos (tiles) que caibam na CACHE L2.\n// - Para cada k do bloco, copiamos B[k] para tempB.\n// - Em seguida, percorremos todos os i e atualizamos C[i] usando A[i] * tempB.\n//\n// Vantagens:\n// Garantimos que a fatia do bloco B que ser\u00e1 utilizada est\u00e1 na L2 (bom reuso temporal).\n// Loop interno (em i) costuma vetorizar bem e tem \u00f3timo acesso cont\u00edguo a A e C.\nvoid produtoTilingHoistB(vector&lt;double&gt;&amp; A, vector&lt;double&gt;&amp; B, vector&lt;double&gt;&amp; C, int N, int Bsize) {\n    // Inicializa C uma \u00fanica vez\n    for (int i = 0; i &lt; N; i++) {\n        C[i] = 0.0;\n    }\n\n    // Varre B em blocos [start, end)\n    for (int start = 0; start &lt; N; start += Bsize) {\n        int end = (start + Bsize &lt; N) ? (start + Bsize) : N;\n\n        // Para cada elemento do bloco de B...\n        for (int k = start; k &lt; end; k++) {\n            // tempor\u00e1rio de B[k]: carrega uma vez e reutiliza\n            double tempB = B[k];\n\n            // Atualiza todos os C[i] com esse B[k]\n            for (int i = 0; i &lt; N; i++) {\n                C[i] += A[i] * tempB;\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"Exercicios/aula04/aula04/","title":"Aula 04 Otimiza\u00e7\u00e3o de Estrat\u00e9gias e Heur\u00edsticas","text":""},{"location":"Exercicios/aula04/aula04/#questao-1-teorica-heuristicas-e-aleatoriedade","title":"Quest\u00e3o 1 \u2014 Te\u00f3rica (Heur\u00edsticas e Aleatoriedade)","text":"<p>Tipo: m\u00faltipla escolha (m\u00faltiplas corretas) Enunciado: Sobre heur\u00edsticas com aleatoriedade em problemas de otimiza\u00e7\u00e3o:  </p> <p>a) Uma heur\u00edstica sempre garante encontrar a solu\u00e7\u00e3o \u00f3tima. b) O uso de aleatoriedade pode ajudar a escapar de m\u00ednimos locais. c) Estrat\u00e9gias puramente determin\u00edsticas podem explorar repetidamente as mesmas regi\u00f5es do espa\u00e7o de busca. d) Uma heur\u00edstica aleat\u00f3ria nunca pode ser menos eficiente que uma busca determin\u00edstica.  </p> Ver resposta <p>a) Incorreta. Heur\u00edsticas n\u00e3o garantem a solu\u00e7\u00e3o \u00f3tima, mas sim uma boa solu\u00e7\u00e3o em tempo razo\u00e1vel. </p> <p>b) Correta. T\u00e9cnicas como Algoritmos Gen\u00e9ticos usam aleatoriedade justamente para evitar que a busca fique presa em solu\u00e7\u00f5es sub\u00f3timas.</p> <p>c) Correta. Sem varia\u00e7\u00e3o aleat\u00f3ria, a busca pode focar em regi\u00f5es j\u00e1 visitadas, perdendo diversidade na explora\u00e7\u00e3o.</p> <p>d) Incorreta. O uso de aleatoriedade n\u00e3o garante efici\u00eancia. Pode inclusive aumentar o custo (mais itera\u00e7\u00f5es, solu\u00e7\u00f5es piores) se mal calibrada. A efici\u00eancia depende da implementa\u00e7\u00e3o.</p>"},{"location":"Exercicios/aula04/aula04/#questao-2-busca-linear-vs-aleatoria-em-vetor","title":"Quest\u00e3o 2 \u2014 Busca linear vs aleat\u00f3ria em vetor","text":"<p>Enunciado: Implemente duas fun\u00e7\u00f5es para encontrar um valor <code>alvo</code> em um vetor:  </p> <ul> <li>Vers\u00e3o linear: percorre o vetor de <code>0</code> at\u00e9 <code>N-1</code>.  </li> <li>Vers\u00e3o aleat\u00f3ria: sorteia \u00edndices aleat\u00f3rios at\u00e9 encontrar o alvo (ou at\u00e9 <code>maxTentativas</code>).  </li> </ul> <p>Depois: - Compile no cluster. - Crie um script SLURM para rodar ambas vers\u00f5es. - Compare o tempo e n\u00famero de tentativas de cada abordagem.  </p> <pre><code>int busca_linear(const std::vector&lt;int&gt;&amp; v, int alvo);\nint busca_aleatoria(const std::vector&lt;int&gt;&amp; v, int alvo, unsigned long long maxTentativas);\n</code></pre> Ver resposta <p><code>busca_linear</code> percorre sequencialmente \u2192 excelente localidade espacial. <code>busca_aleatoria</code> tem acessos aleat\u00f3rios \u2192 pouca localidade, alta vari\u00e2ncia; pode repetir \u00edndices.  Com o vetor <code>v[i]=i</code>, a linear encontra r\u00e1pido (especialmente se <code>alvo</code> for pequeno); a aleat\u00f3ria pode demorar mesmo com alvo \u201cpr\u00f3ximo\u201d.  </p> <pre><code>#include &lt;vector&gt;\n#include &lt;random&gt;\n\n// ---------------------------------------------------------\n// Fun\u00e7\u00e3o: busca_linear\n// Objetivo: procurar o valor 'alvo' de forma sequencial\n// Estrat\u00e9gia: percorre o vetor do in\u00edcio ao fim (\u00edndices 0..N-1)\n// ---------------------------------------------------------\nint busca_linear(const std::vector&lt;int&gt;&amp; v, int alvo) {\n    // Percorre todos os elementos do vetor\n    for (size_t i = 0; i &lt; v.size(); i++) {\n        // Se encontrou o alvo, retorna o \u00edndice\n        if (v[i] == alvo) return (int)i;\n    }\n    // Se chegou at\u00e9 aqui, o alvo n\u00e3o existe no vetor\n    return -1;\n}\n\n// ---------------------------------------------------------\n// Fun\u00e7\u00e3o: busca_aleatoria\n// Objetivo: procurar o valor 'alvo' de forma aleat\u00f3ria\n// Estrat\u00e9gia: sorteia \u00edndices ao acaso at\u00e9 achar o alvo\n// ou at\u00e9 atingir o limite de tentativas (maxTentativas).\n// ---------------------------------------------------------\nint busca_aleatoria(const std::vector&lt;int&gt;&amp; v, int alvo, unsigned long long maxTentativas) {\n    // Caso o vetor esteja vazio, n\u00e3o h\u00e1 o que buscar\n    if (v.empty()) return -1;\n\n    // Gerador de n\u00fameros aleat\u00f3rios\n    std::random_device rd;        // fonte de entropia (pode variar a cada execu\u00e7\u00e3o)\n    std::mt19937 gen(rd());       // gerador pseudo-aleat\u00f3rio (Mersenne Twister)\n    std::uniform_int_distribution&lt;size_t&gt; dist(0, v.size() - 1); \n    // distribui\u00e7\u00e3o uniforme de \u00edndices v\u00e1lidos [0, N-1]\n\n    // Tenta encontrar o alvo at\u00e9 atingir o n\u00famero m\u00e1ximo de tentativas\n    for (unsigned long long t = 0; t &lt; maxTentativas; t++) {\n        size_t idx = dist(gen);   // sorteia um \u00edndice v\u00e1lido\n        if (v[idx] == alvo) {\n            // se encontrou, retorna o \u00edndice\n            return (int)idx;\n        }\n    }\n    // Se n\u00e3o encontrou dentro do limite de tentativas, retorna -1\n    return -1;\n}\n</code></pre> <p>Script SLURM</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=busca            # nome do job\n#SBATCH --output=busca.%j.txt       # sa\u00edda em arquivo\n#SBATCH --time=00:05:00             # tempo limite\n#SBATCH --nodes=1                   # 1 n\u00f3\n#SBATCH --ntasks=1                  # 1 tarefa\n#SBATCH --cpus-per-task=1           # 1 CPU\n#SBATCH --partition=express         # ou 'normal', se preferir\n#SBATCH --mem=1GB                   # mem\u00f3ria\n\necho \"=== Rodada 1: N=1e6 alvo=500000 maxTent=1e6 seed=42 ===\"\n./busca 1000000 500000 1000000 42\necho \"=======================================================\"\n\necho \"=== Rodada 2: N=1e6 alvo=10 maxTent=1e6 seed=123 ===\"\n./busca 1000000 10 1000000 123\necho \"====================================================\"\n\necho \"=== Rodada 3: N=1e6 alvo=999999 maxTent=1e6 seed=777 ===\"\n./busca 1000000 999999 1000000 777\necho \"=======================================================\"\n\necho \"=== Rodada 4: N=1e6 alvo=37 (usa N/2) maxTent=1e6 seed=2025 ===\"\n./busca 1000000 37 1000000 2025\necho \"=============================================================\"\n</code></pre>"},{"location":"Exercicios/aula04/aula04/#questao-3-estrategia-hibrida-busca-sequencial-aleatoria","title":"Quest\u00e3o 3 \u2014 Estrat\u00e9gia h\u00edbrida (busca sequencial + aleat\u00f3ria)","text":"<p>Enunciado: Implemente uma fun\u00e7\u00e3o que: - Primeiro verifica os K primeiros elementos do vetor sequencialmente. - Se n\u00e3o encontrar, passa a buscar usando \u00edndices aleat\u00f3rios at\u00e9 <code>maxTentativas</code>.  </p> <p>Depois: - Compile e rode no cluster com SLURM. - Compare os resultados com as fun\u00e7\u00f5es da Quest\u00e3o 2.  </p> <pre><code>int busca_hibrida(const std::vector&lt;int&gt;&amp; v, int alvo, int K, unsigned long long maxTentativas);\n</code></pre> Ver resposta <pre><code>#include &lt;vector&gt;\n#include &lt;random&gt;\n\n// ---------------------------------------------------------\n// Fun\u00e7\u00e3o: busca_hibrida\n// Objetivo: combinar duas estrat\u00e9gias de busca:\n//   (1) varre sequencialmente os K primeiros elementos (bom p/ localidade)\n//   (2) se n\u00e3o achar, usa tentativas aleat\u00f3rias at\u00e9 maxTentativas\n//\n// Quando \u00e9 \u00fatil?\n// - Se o alvo tem maior probabilidade de estar no in\u00edcio do vetor,\n//   a parte sequencial encontra r\u00e1pido.\n// - Caso contr\u00e1rio, a fase aleat\u00f3ria pode \"acertar\" em elementos distantes\n//   sem percorrer todo o vetor sequencialmente.\n// ---------------------------------------------------------\nint busca_hibrida(const std::vector&lt;int&gt;&amp; v, int alvo, int K, unsigned long long maxTentativas) {\n    // -------- Parte 1: busca sequencial nos primeiros K elementos --------\n    // Varre de 0 at\u00e9 K-1 (limitando tamb\u00e9m pelo tamanho do vetor).\n    // Vantagem: acesso cont\u00edguo \u2192 melhor localidade de mem\u00f3ria.\n    for (int i = 0; i &lt; K &amp;&amp; i &lt; (int)v.size(); i++) {\n        if (v[i] == alvo) return i;  // achou no prefixo\n    }\n\n    // -------- Parte 2: busca aleat\u00f3ria no vetor inteiro --------\n    // Observa\u00e7\u00e3o: esta vers\u00e3o sorteia em [0, N-1]. Em muitos casos,\n    // restringir a [K, N-1] faz mais sentido (evita repetir o prefixo j\u00e1 checado).\n    if (v.empty()) return -1;        // vetor vazio \u2192 n\u00e3o h\u00e1 o que buscar\n\n    // Geradores para sorteio de \u00edndices v\u00e1lidos\n    std::random_device rd;           // fonte de entropia (n\u00e3o determin\u00edstica)\n    std::mt19937 gen(rd());          // PRNG (Mersenne Twister)\n    std::uniform_int_distribution&lt;size_t&gt; dist(0, v.size() - 1); // sorteia 0..N-1\n\n    // Tenta at\u00e9 atingir o limite de tentativas aleat\u00f3rias\n    for (unsigned long long t = 0; t &lt; maxTentativas; t++) {\n        size_t idx = dist(gen);      // sorteia um \u00edndice\n        if (v[idx] == alvo) {        // compara com o alvo\n            return (int)idx;         // achou durante a fase aleat\u00f3ria\n        }\n    }\n\n    // N\u00e3o encontrou nem na parte sequencial, nem na aleat\u00f3ria\n    return -1;\n}\n</code></pre>"},{"location":"Exercicios/aula04/aula04/#questao-4-heuristica-com-pre-filtro","title":"Quest\u00e3o 4 \u2014 Heur\u00edstica com pr\u00e9-filtro","text":"<p>Enunciado: Implemente uma fun\u00e7\u00e3o de busca que usa uma heur\u00edstica simples de pr\u00e9-filtro: - Antes de acessar <code>v[i]</code>, s\u00f3 considere o \u00edndice se <code>i % 2 == 0</code> (ou seja, s\u00f3 olha posi\u00e7\u00f5es pares). - Se n\u00e3o encontrar ap\u00f3s <code>maxTentativas</code>, fa\u00e7a busca linear completa como fallback.  </p> <p>Depois: - Compile e rode no cluster com SLURM. - Compare desempenho e n\u00famero de acessos com as vers\u00f5es anteriores.  </p> <pre><code>int busca_com_filtro(const std::vector&lt;int&gt;&amp; v, int alvo, unsigned long long maxTentativas);\n</code></pre> Ver resposta <p>A busca aleat\u00f3ria \u00e9 restrita a \u00edndices pares, tentando reduzir acessos. Caso n\u00e3o encontre dentro de <code>maxTentativas</code>, entra uma busca linear  O pr\u00e9-filtro pode ser vantajoso se h\u00e1 maior probabilidade de o alvo estar em posi\u00e7\u00f5es pares. Por\u00e9m, pode desperdi\u00e7ar tentativas (\u00edndices \u00edmpares descartados) e no pior caso cair na busca linear.</p> <pre><code>#include &lt;vector&gt;\n#include &lt;random&gt;\n\nint busca_com_filtro(const std::vector&lt;int&gt;&amp; v, int alvo, unsigned long long maxTentativas) {\n    if (v.empty()) return -1;\n    std::random_device rd;\n    std::mt19937 gen(rd());\n    std::uniform_int_distribution&lt;size_t&gt; dist(0, v.size() - 1);\n\n    // Heur\u00edstica: s\u00f3 verifica \u00edndices pares\n    for (unsigned long long t = 0; t &lt; maxTentativas; t++) {\n        size_t idx = dist(gen);\n        if (idx % 2 != 0) continue;       // ignora \u00edndices \u00edmpares\n        if (v[idx] == alvo) return (int)idx;\n    }\n\n    // Fallback: se n\u00e3o achou, faz busca linear completa\n    for (size_t i = 0; i &lt; v.size(); i++) {\n        if (v[i] == alvo) return (int)i;\n    }\n    return -1; // n\u00e3o encontrado\n}\n</code></pre>"},{"location":"Exercicios/aula05/aula05/","title":"Prova \u2014 Paralelismo com OpenMP","text":""},{"location":"Exercicios/aula05/aula05/#questao-1-teorica-dependencia-de-dados-e-paralelismo","title":"Quest\u00e3o 1 \u2014 Te\u00f3rica (Depend\u00eancia de dados e paralelismo)","text":"<p>Enunciado: Explique por que um loop com depend\u00eancia entre itera\u00e7\u00f5es n\u00e3o pode ser paralelizado ingenuamente com OpenMP. - D\u00ea um exemplo de um loop n\u00e3o paraleliz\u00e1vel por depend\u00eancia. - D\u00ea um exemplo de um loop paraleliz\u00e1vel (independente). - Explique como a escolha do escalonamento (<code>static</code>, <code>dynamic</code>, <code>guided</code>) pode influenciar no desempenho mesmo quando n\u00e3o h\u00e1 depend\u00eancias.  </p> Ver resposta <ol> <li>Depend\u00eancia de dados vs paraleliza\u00e7\u00e3o Um loop s\u00f3 pode ser paralelizado com OpenMP se cada itera\u00e7\u00e3o puder ser executada de forma independente.  </li> </ol> <p>Exemplo n\u00e3o paraleliz\u00e1vel: </p> <pre><code>for (int i = 1; i &lt; N; i++) {\n    A[i] = A[i-1] + 1;  // depend\u00eancia de dado em A[i-1]\n}\n</code></pre> <p>Exemplo paraleliz\u00e1vel: </p> <pre><code>for (int i = 0; i &lt; N; i++) {\n    B[i] = C[i] * 2;    // cada i usa apenas sua pr\u00f3pria posi\u00e7\u00e3o\n}\n</code></pre> <ol> <li>Influ\u00eancia do escalonamento no desempenho Mesmo sem depend\u00eancias, a forma de dividir o trabalho entre threads afeta o desempenho:  <ul> <li><code>static</code>: divide itera\u00e7\u00f5es em blocos fixos \u2192 bom quando o custo por itera\u00e7\u00e3o \u00e9 uniforme.  </li> <li><code>dynamic</code>: atribui novas itera\u00e7\u00f5es \u00e0s threads que terminam mais cedo \u2192 melhor para cargas desbalanceadas, mas tem overhead maior.  </li> <li><code>guided</code>: semelhante ao <code>dynamic</code>, mas blocos v\u00e3o diminuindo de tamanho \u2192 equil\u00edbrio entre overhead e adaptabilidade. Al\u00e9m disso, podemos usar <code>schedule(static, tamanho_do_bloco)</code> para aplicar tiling: quebramos o loop em blocos que caibam na mem\u00f3ria cache, melhorando o aproveitamento da hierarquia de mem\u00f3ria. Assim, a escolha do escalonamento pode minimizar tempo de espera entre threads, evitar subutiliza\u00e7\u00e3o da cache e melhorar o uso do cluster.  </li> </ul> </li> </ol>"},{"location":"Exercicios/aula05/aula05/#questao-2-normalizacao-de-vetor-com-openmp","title":"Quest\u00e3o 2 \u2014 Normaliza\u00e7\u00e3o de vetor com OpenMP","text":"<p>Enunciado: Implemente em C++ um programa que normaliza um vetor <code>a</code> em <code>b</code>, de forma que:  </p> <p><code>b[i] = a[i] / max(a)</code></p> <ul> <li>Paralelize a busca de <code>max(a)</code> com redu\u00e7\u00e3o.  </li> <li>Paralelize o c\u00e1lculo de <code>b[i]</code> com <code>#pragma omp parallel for</code>.  </li> <li>Compare os tempos de execu\u00e7\u00e3o com <code>OMP_SCHEDULE=static</code>, <code>dynamic</code> e <code>guided</code>.  </li> </ul> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n    int N = (argc &gt; 1 ? std::stoi(argv[1]) : 10000000);\n\n    std::vector&lt;float&gt; a(N), b(N);\n\n    // TODO: inicializar vetor a com n\u00fameros aleat\u00f3rios em [0,1)\n\n    float max_val = 0.0f;\n\n    double t0 = omp_get_wtime();\n\n    // TODO: paralelizar busca do m\u00e1ximo usando redu\u00e7\u00e3o\n\n    double t1 = omp_get_wtime();\n\n    // TODO: paralelizar c\u00e1lculo de b[i] = a[i] / max_val\n\n    double t2 = omp_get_wtime();\n\n    std::cout &lt;&lt; \"Tempo max = \" &lt;&lt; (t1 - t0) &lt;&lt; \"s\\n\";\n    std::cout &lt;&lt; \"Tempo normaliza\u00e7\u00e3o = \" &lt;&lt; (t2 - t1) &lt;&lt; \"s\\n\";\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n    // Tamanho do vetor: pode ser passado na linha de comando\n    int N = (argc &gt; 1 ? std::stoi(argv[1]) : 10000000);\n\n    // Vetores de entrada (a) e sa\u00edda (b)\n    std::vector&lt;float&gt; a(N), b(N);\n\n    // Gera\u00e7\u00e3o reprodut\u00edvel de valores em a \u2208 [0,1)\n    std::mt19937 rng(123);\n    std::uniform_real_distribution&lt;&gt; U(0.0, 1.0);\n    for (int i = 0; i &lt; N; i++) {\n        a[i] = static_cast&lt;float&gt;(U(rng));\n    }\n\n    float max_val = 0.0f;\n\n    double t0 = omp_get_wtime();\n\n    // ------------------------------------------------------------------\n    // PARTE 1: Encontrar o m\u00e1ximo com OpenMP + redu\u00e7\u00e3o\n    //\n    // - Cada thread calcula um m\u00e1ximo local e o OpenMP combina (reduction)\n    //   usando o operador 'max', evitando condi\u00e7\u00f5es de corrida.\n    // - 'parallel for' distribui as itera\u00e7\u00f5es i entre as threads.\n    // ------------------------------------------------------------------\n    #pragma omp parallel for reduction(max:max_val)\n    for (int i = 0; i &lt; N; i++) {\n        if (a[i] &gt; max_val) {\n            max_val = a[i];\n        }\n    }\n\n    double t1 = omp_get_wtime();\n\n    // ------------------------------------------------------------------\n    // PARTE 2: Normaliza\u00e7\u00e3o em paralelo\n    //\n    // - Cada itera\u00e7\u00e3o \u00e9 independente (n\u00e3o h\u00e1 depend\u00eancia entre i's),\n    //   ent\u00e3o o 'parallel for' \u00e9 naturalmente seguro e escal\u00e1vel.\n    // - Acesso sequencial a a[i] e b[i] \u2192 boa localidade de cache.\n    // ------------------------------------------------------------------\n    #pragma omp parallel for\n    for (int i = 0; i &lt; N; i++) {\n        b[i] = a[i] / max_val;\n    }\n\n    double t2 = omp_get_wtime();\n\n    std::cout &lt;&lt; \"Tempo max = \" &lt;&lt; (t1 - t0) &lt;&lt; \"s\\n\";\n    std::cout &lt;&lt; \"Tempo normalizacao = \" &lt;&lt; (t2 - t1) &lt;&lt; \"s\\n\";\n}\n</code></pre>"},{"location":"Exercicios/aula05/aula05/#questao-3-contagem-de-elementos-pares","title":"Quest\u00e3o 3 \u2014 Contagem de elementos pares","text":"<p>Enunciado: Implemente uma fun\u00e7\u00e3o que conta quantos elementos pares existem em um vetor de inteiros. - Paralelize com <code>#pragma omp parallel for reduction(+:contador)</code>. - Varie <code>OMP_NUM_THREADS</code> em {1, 2, 4, 8}. - Compare resultados com <code>schedule(static,4)</code> e <code>schedule(dynamic,4)</code>.  </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n    int N = (argc &gt; 1 ? std::stoi(argv[1]) : 10000000);\n\n    std::vector&lt;int&gt; v(N);\n\n    // TODO: inicializar vetor v com n\u00fameros inteiros aleat\u00f3rios\n\n    long long contador = 0;\n\n    double t0 = omp_get_wtime();\n\n    // TODO: paralelizar contagem de pares com redu\u00e7\u00e3o\n\n    double t1 = omp_get_wtime();\n\n    std::cout &lt;&lt; \"Total pares = \" &lt;&lt; contador &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Tempo = \" &lt;&lt; (t1 - t0) &lt;&lt; \"s\\n\";\n}\n</code></pre> Ver implementa\u00e7\u00e3o <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n    // Tamanho do vetor (padr\u00e3o: 10 milh\u00f5es). Pode ser passado via linha de comando.\n    int N = (argc &gt; 1 ? std::stoi(argv[1]) : 10000000);\n\n    // Vetor de inteiros a ser analisado\n    std::vector&lt;int&gt; v(N);\n\n    // Gera\u00e7\u00e3o reprodut\u00edvel de dados inteiros uniformes em [0, 1000]\n    std::mt19937 rng(123);\n    std::uniform_int_distribution&lt;int&gt; U(0, 1000);\n    for (int i = 0; i &lt; N; i++) {\n        v[i] = U(rng);\n    }\n\n    // Contador global de elementos pares (tipo largo para evitar overflow)\n    long long contador = 0;\n\n    double t0 = omp_get_wtime();\n\n    // ------------------------------------------------------------------\n    // Contagem de pares paralelizada\n    //\n    // - 'parallel for' distribui as itera\u00e7\u00f5es entre as threads.\n    // - 'reduction(+:contador)' cria um contador local por thread e\n    //    no final soma tudo no 'contador' global.\n    // - Cada itera\u00e7\u00e3o \u00e9 independente (n\u00e3o h\u00e1 depend\u00eancias entre i's).\n    // ------------------------------------------------------------------\n    #pragma omp parallel for reduction(+:contador)\n    for (int i = 0; i &lt; N; i++) {\n        if (v[i] % 2 == 0) {\n            contador++;  // soma no acumulador local da thread\n        }\n    }\n\n    double t1 = omp_get_wtime();\n\n    std::cout &lt;&lt; \"Total pares = \" &lt;&lt; contador &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Tempo = \" &lt;&lt; (t1 - t0) &lt;&lt; \"s\\n\";\n}\n</code></pre>"},{"location":"Exercicios/aula05/aula05/#questao-4-convolucao-1d-com-openmp","title":"Quest\u00e3o 4 \u2014 Convolu\u00e7\u00e3o 1D com OpenMP","text":"<p>Enunciado: Implemente uma convolu\u00e7\u00e3o 1D de um vetor <code>a</code> (N elementos) com um kernel fixo de tamanho <code>K</code>.  </p>  c[i] = \\sum_{j=0}^{K-1} a[i+j] \\cdot kernel[j]  <ul> <li>Paralelize o loop externo (<code>i</code>).  </li> <li>Varie <code>OMP_NUM_THREADS</code> em {2, 4, 8, 16}.  </li> <li>Qual o menor custo de hardware para o melhor beneficio de desempenho?</li> </ul> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n    int N = (argc &gt; 1 ? std::stoi(argv[1]) : 1000000);\n    int K = 5; // tamanho do kernel\n\n    std::vector&lt;float&gt; a(N, 1.0f), kernel(K, 0.2f), c(N-K+1, 0.0f);\n\n    double t0 = omp_get_wtime();\n\n    // TODO: paralelizar o loop externo da convolu\u00e7\u00e3o 1D\n    for (int i = 0; i &lt; N - K + 1; i++) {\n        float soma = 0.0f;\n        for (int j = 0; j &lt; K; j++) {\n            soma += a[i + j] * kernel[j];\n        }\n        c[i] = soma;\n    }\n\n    double t1 = omp_get_wtime();\n\n    std::cout &lt;&lt; \"Tempo convolu\u00e7\u00e3o = \" &lt;&lt; (t1 - t0) &lt;&lt; \"s\\n\";\n}\n</code></pre> Ver Implementa\u00e7\u00e3o <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n    // Tamanho do vetor de entrada (default: 1 milh\u00e3o). Pode ser passado na linha de comando.\n    int N = (argc &gt; 1 ? std::stoi(argv[1]) : 1000000);\n    int K = 5; // tamanho do kernel (filtro convolucional)\n\n    // Vetor de entrada 'a' preenchido com 1.0\n    std::vector&lt;float&gt; a(N, 1.0f);\n    // Kernel de tamanho K preenchido com 0.2 (simples m\u00e9dia m\u00f3vel de 5 pontos)\n    std::vector&lt;float&gt; kernel(K, 0.2f);\n    // Vetor de sa\u00edda 'c' com tamanho (N-K+1), inicializado em 0.0\n    std::vector&lt;float&gt; c(N-K+1, 0.0f);\n\n    double t0 = omp_get_wtime();\n\n    // ------------------------------------------------------------------\n    // Convolu\u00e7\u00e3o paralelizada\n    //\n    // - 'parallel for' distribui as itera\u00e7\u00f5es de i (posi\u00e7\u00f5es da sa\u00edda) entre threads.\n    // - Cada itera\u00e7\u00e3o calcula c[i] = soma(a[i..i+K-1] * kernel[0..K-1]).\n    // - As itera\u00e7\u00f5es s\u00e3o independentes \u2192 n\u00e3o h\u00e1 depend\u00eancia entre diferentes c[i].\n    // - Isso torna o loop um bom candidato para paralelismo com OpenMP.\n    // ------------------------------------------------------------------\n    #pragma omp parallel for\n    for (int i = 0; i &lt; N - K + 1; i++) {\n        float soma = 0.0f;\n        // loop interno: acumula o produto de K elementos\n        for (int j = 0; j &lt; K; j++) {\n            soma += a[i + j] * kernel[j];\n        }\n        c[i] = soma; // resultado da convolu\u00e7\u00e3o no ponto i\n    }\n\n    double t1 = omp_get_wtime();\n\n    std::cout &lt;&lt; \"Tempo convolu\u00e7\u00e3o = \" &lt;&lt; (t1 - t0) &lt;&lt; \"s\\n\";\n}\n</code></pre>"},{"location":"Exercicios/aula06/aula06/","title":"Prova \u2014 Efeitos Colaterais do Paralelismo em OpenMP","text":""},{"location":"Exercicios/aula06/aula06/#questao-1-teorica-race-condition-e-dependencia-de-dados","title":"Quest\u00e3o 1 \u2014 Te\u00f3rica (Race condition e depend\u00eancia de dados)","text":"<p>Enunciado: a) Explique com suas palavras o que \u00e9 uma condi\u00e7\u00e3o de corrida em um programa paralelo. b) Por que um loop que acumula resultados em uma mesma vari\u00e1vel global \u00e9 vulner\u00e1vel a esse problema? c) D\u00ea um exemplo de loop que n\u00e3o pode ser paralelizado por depender de valores calculados em itera\u00e7\u00f5es anteriores. d) O que significa \u201creformular o algoritmo\u201d para eliminar uma depend\u00eancia? Cite um exemplo.  </p> Ver respostas <p>a) \u00c9 quando duas ou mais threads acessam a mesma vari\u00e1vel compartilhada simultaneamente, e pelo menos uma delas altera o valor. </p> <p>b) Um loop em paralelo que escreve em uma \u00fanica vari\u00e1vel global cria acessos concorrentes de v\u00e1rias threads. Diferentes threads podem sobrescrever valores, perdendo opera\u00e7\u00f5es.</p> <p>c) Loops em que cada itera\u00e7\u00e3o depende do valor produzido pela itera\u00e7\u00e3o anterior. Ex.: c\u00e1lculo de s\u00e9ries recursivas, onde <code>A[i]</code> usa <code>A[i-1]</code>.  </p> <p>d) \u00c9 alterar a forma de c\u00e1lculo para remover depend\u00eancias entre itera\u00e7\u00f5es e permitir paralelismo.  </p>"},{"location":"Exercicios/aula06/aula06/#questao-2-media-de-vetor-com-e-sem-reducao-openmp","title":"Quest\u00e3o 2 \u2014 M\u00e9dia de vetor com e sem redu\u00e7\u00e3o (OpenMP)","text":"<p>Enunciado: Implemente em C++ duas vers\u00f5es de um programa que calcula a m\u00e9dia dos valores em um vetor: 1. Vers\u00e3o ing\u00eanua (errada): paralelize o loop de soma sem usar redu\u00e7\u00e3o. 2. Vers\u00e3o corrigida: use <code>reduction(+:soma)</code> para evitar condi\u00e7\u00e3o de corrida. Encontre o melhor custo de hardware para o melhor benef\u00edcio de tempo   </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;omp.h&gt;\n\nint main() {\n    int N = 1000000;\n    std::vector&lt;float&gt; v(N);\n\n    std::mt19937 rng(123);\n    std::uniform_real_distribution&lt;&gt; dist(0.0, 1.0);\n    for (int i = 0; i &lt; N; i++) v[i] = dist(rng);\n\n    double soma = 0.0;\n\n    // TODO: vers\u00e3o ing\u00eanua paralelizada sem redu\u00e7\u00e3o (vai dar erro num\u00e9rico)\n\n    // TODO: vers\u00e3o corrigida usando reduction\n    // #pragma omp parallel for reduction(+:soma)\n\n    double media = soma / N;\n    std::cout &lt;&lt; \"Media = \" &lt;&lt; media &lt;&lt; \"\\n\";\n}\n</code></pre> Ver implementa\u00e7\u00e3o <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;omp.h&gt;\n\nint main() {\n    int N = 1000000;\n    std::vector&lt;float&gt; v(N);\n\n    std::mt19937 rng(123);\n    std::uniform_real_distribution&lt;&gt; dist(0.0, 1.0);\n    for (int i = 0; i &lt; N; i++) v[i] = dist(rng);\n\n    double soma = 0.0;\n\n    // Vers\u00e3o errada (sem reduction, resultado inconsistente)\n    #pragma omp parallel for\n    for (int i = 0; i &lt; N; i++) {\n        soma += v[i];\n    }\n    std::cout &lt;&lt; \"[Errada] Media = \" &lt;&lt; soma / N &lt;&lt; \"\\n\";\n\n    soma = 0.0;\n    // Vers\u00e3o correta com reduction\n    #pragma omp parallel for reduction(+:soma)\n    for (int i = 0; i &lt; N; i++) {\n        soma += v[i];\n    }\n    std::cout &lt;&lt; \"[Correta] Media = \" &lt;&lt; soma / N &lt;&lt; \"\\n\";\n}\n</code></pre>"},{"location":"Exercicios/aula06/aula06/#questao-3-prefixo-acumulado-dependencia-de-dados","title":"Quest\u00e3o 3 \u2014 Prefixo acumulado (depend\u00eancia de dados)","text":"<p>Enunciado: O programa abaixo calcula o prefixo acumulado (<code>p[i] = p[i-1] + a[i]</code>), que possui depend\u00eancia sequencial.  </p> <p>a) Explique por que a vers\u00e3o abaixo n\u00e3o pode ser paralelizada diretamente. b) Reescreva o algoritmo de forma paraleliz\u00e1vel, eliminando a depend\u00eancia.  </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;omp.h&gt;\n\nint main() {\n    int N = 20;\n    std::vector&lt;int&gt; a(N), p(N);\n\n    for (int i = 0; i &lt; N; i++) a[i] = 1;\n\n    // Vers\u00e3o com depend\u00eancia\n    p[0] = a[0];\n    for (int i = 1; i &lt; N; i++) {\n        p[i] = p[i-1] + a[i];  // depende do anterior\n    }\n\n    // TODO: vers\u00e3o reformulada paraleliz\u00e1vel\n    // dica: perceba que o resultado \u00e9 uma progress\u00e3o\n\n    for (int i = 0; i &lt; N; i++) std::cout &lt;&lt; p[i] &lt;&lt; \" \";\n}\n</code></pre> Ver resposta <p>a) O loop tem depend\u00eancia entre itera\u00e7\u00f5es, para calcular p[i] \u00e9 obrigat\u00f3rio conhecer p[i-1] j\u00e1 calculado. Se voc\u00ea colocar #pragma omp parallel for nesse loop, threads diferentes tentariam computar p[i] e p[i-1] ao mesmo tempo, violando a ordem necess\u00e1ria; o resultado fica incorreto</p> <p>b) Como o programa define a[i] = 1 para todo i, ent\u00e3o o prefixo acumulado vira uma progress\u00e3o:</p> <p>p[i] = 1 + 1 + \u2026 + 1 (i+1 vezes) = i + 1.</p> <p>Logo podemos paralelizar calculando diretamente a f\u00f3rmula fechada:</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;omp.h&gt;\n\nint main() {\n    int N = 20;\n    std::vector&lt;int&gt; a(N), p(N);\n\n    for (int i = 0; i &lt; N; i++) a[i] = 1;\n\n    // Vers\u00e3o reformulada (progress\u00e3o) \u2014 V\u00c1LIDA porque a[i] = 1 para todo i\n    #pragma omp parallel for\n    for (int i = 0; i &lt; N; i++) {\n        // Como a[i]=1, p[i] = (i+1)*1\n        p[i] = (i + 1) * a[0];  // eliminada a depend\u00eancia (f\u00f3rmula fechada)\n    }\n\n    for (int i = 0; i &lt; N; i++) std::cout &lt;&lt; p[i] &lt;&lt; \" \";\n    std::cout &lt;&lt; \"\\n\";\n}\n</code></pre>"},{"location":"Exercicios/aula06/aula06/#questao-4-recursao-paralela-em-arvore-binaria-tasks","title":"Quest\u00e3o 4 \u2014 Recurs\u00e3o paralela em \u00e1rvore bin\u00e1ria (tasks)","text":"<p>Enunciado: Considere uma \u00e1rvore bin\u00e1ria em que cada n\u00f3 cont\u00e9m um n\u00famero inteiro. Desejamos calcular a soma de todos os n\u00f3s da \u00e1rvore.  </p> <p>Matematicamente, se <code>raiz</code> \u00e9 o n\u00f3 atual:  </p> <p><code>S(raiz) = valor(raiz) + S(filho_esq) + S(filho_dir)</code></p> <p>Tarefa: - Implemente uma fun\u00e7\u00e3o recursiva <code>soma_arvore</code> que use OpenMP tasks para calcular a soma:   - Uma task para o filho esquerdo   - Uma task para o filho direito   - Use <code>taskwait</code> para sincronizar.  </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;omp.h&gt;\n\nstruct No {\n    int valor;\n    No* esq;\n    No* dir;\n    No(int v) : valor(v), esq(nullptr), dir(nullptr) {}\n};\n\n// TODO: implementar soma_arvore recursiva com tasks\nint soma_arvore(No* raiz) {\n    if (!raiz) return 0;\n    int soma_esq = 0, soma_dir = 0;\n\n    // #pragma omp task shared(soma_esq)\n    // soma_esq = soma_arvore(raiz-&gt;esq);\n\n    // #pragma omp task shared(soma_dir)\n    // soma_dir = soma_arvore(raiz-&gt;dir);\n\n    // #pragma omp taskwait\n\n    return raiz-&gt;valor + soma_esq + soma_dir;\n}\n\nint main() {\n    // exemplo: \u00e1rvore pequena\n    No* raiz = new No(1);\n    raiz-&gt;esq = new No(2);\n    raiz-&gt;dir = new No(3);\n    raiz-&gt;esq-&gt;esq = new No(4);\n    raiz-&gt;esq-&gt;dir = new No(5);\n\n    double t0 = omp_get_wtime();\n    int soma = soma_arvore(raiz);\n    double t1 = omp_get_wtime();\n\n    std::cout &lt;&lt; \"Soma dos n\u00f3s = \" &lt;&lt; soma &lt;&lt; \" tempo = \" &lt;&lt; (t1 - t0) &lt;&lt; \"s\\n\";\n}\n</code></pre> Ver Implementa\u00e7\u00e3o <pre><code>#include &lt;iostream&gt;\n#include &lt;omp.h&gt;\n\n// N\u00f3 b\u00e1sico de \u00e1rvore bin\u00e1ria\nstruct No {\n    int valor;\n    No* esq;\n    No* dir;\n    No(int v) : valor(v), esq(nullptr), dir(nullptr) {}\n};\n\n// -------------------------------------------------------------\n// soma_arvore: soma os valores de todos os n\u00f3s de uma \u00e1rvore.\n// Estrat\u00e9gia paralela: criar TAREFAS (OpenMP tasks) para cada\n// sub\u00e1rvore esquerda e direita.\n// -------------------------------------------------------------\nint soma_arvore(No* raiz) {\n    // Caso base da recurs\u00e3o: \u00e1rvore vazia soma 0 (execu\u00e7\u00e3o sequencial)\n    if (!raiz) return 0;\n\n    int soma_esq = 0, soma_dir = 0;\n\n    // Cria uma TAREFA para computar a soma da sub\u00e1rvore ESQUERDA.\n    // 'shared(soma_esq)' permite que a tarefa escreva no escopo atual.\n    // Observa\u00e7\u00e3o: cada tarefa escreve em uma vari\u00e1vel distinta \u2192 sem corrida.\n    #pragma omp task shared(soma_esq)\n    soma_esq = soma_arvore(raiz-&gt;esq);\n\n    // Cria outra TAREFA para a sub\u00e1rvore DIREITA.\n    #pragma omp task shared(soma_dir)\n    soma_dir = soma_arvore(raiz-&gt;dir);\n\n    // Sincroniza\u00e7\u00e3o: espera as DUAS tarefas terminarem antes de somar.\n    // Sem taskwait, poder\u00edamos retornar antes das subtarefas conclu\u00edrem.\n    #pragma omp taskwait\n    return raiz-&gt;valor + soma_esq + soma_dir;\n}\n\nint main() {\n    // Monta uma arvorezinha de exemplo\n    No* raiz = new No(1);\n    raiz-&gt;esq = new No(2);\n    raiz-&gt;dir = new No(3);\n    raiz-&gt;esq-&gt;esq = new No(4);\n    raiz-&gt;esq-&gt;dir = new No(5);\n\n    double t0 = omp_get_wtime();\n    int soma = 0;\n\n    // Regi\u00e3o paralela: cria o time de threads.\n    #pragma omp parallel\n    {\n        // single: apenas UMA thread entra na chamada inicial.\n        // A partir daqui, as tarefas criadas recursivamente poder\u00e3o\n        // ser executadas por QUALQUER thread do time.\n        #pragma omp single\n        soma = soma_arvore(raiz);\n    }\n    double t1 = omp_get_wtime();\n\n    std::cout &lt;&lt; \"Soma dos n\u00f3s = \" &lt;&lt; soma &lt;&lt; \" tempo = \" &lt;&lt; (t1 - t0) &lt;&lt; \"s\\n\";\n}\n</code></pre> <p>Perguntas adicionais: a) O que acontece com o tempo de execu\u00e7\u00e3o se a \u00e1rvore for muito pequena? b) Por que criar muitas tasks pequenas pode ser pior do que calcular de forma sequencial?  </p> Ver Respostas <p>a)O tempo tende a piorar ou empatar com o sequencial, porque o overhead de paralelismo (criar regi\u00e3o paralela, criar/agendar/sincronizar tasks, work-stealing, barreiras) pode ser maior que o trabalho \u00fatil (somar poucos n\u00f3s). Em \u00e1rvores pequenas, n\u00e3o h\u00e1 trabalho suficiente para \u201ccompensar\u201d o custo de paralelizar.</p> <p>b) Cada <code>#pragma omp task</code> tem custo de cria\u00e7\u00e3o, enfileiramento e agendamento. Se o trabalho \u00e9 min\u00fasculo, voc\u00ea gasta mais tempo organizando do que trabalhando.</p>"},{"location":"Exercicios/aula07/aula07/","title":"Prova \u2014 Programa\u00e7\u00e3o Distribu\u00edda com MPI","text":""},{"location":"Exercicios/aula07/aula07/#questao-1-teorica-conceitos-fundamentais-de-mpi","title":"Quest\u00e3o 1 \u2014 Te\u00f3rica (Conceitos fundamentais de MPI)","text":"<p>Enunciado: a) Diferencie paralelismo com mem\u00f3ria compartilhada e paralelismo com mem\u00f3ria distribu\u00edda. b) Explique o que \u00e9 um rank no contexto do MPI e como ele \u00e9 utilizado em comunica\u00e7\u00f5es. c) Cite uma vantagem e uma desvantagem de usar comunica\u00e7\u00e3o coletiva (ex.: <code>MPI_Bcast</code>, <code>MPI_Reduce</code>) em compara\u00e7\u00e3o com v\u00e1rias chamadas ponto a ponto (<code>MPI_Send</code>/<code>MPI_Recv</code>). d) O que acontece se dois processos MPI tentarem executar <code>MPI_Send</code> um para o outro sem <code>MPI_Recv</code> correspondente?  </p> Ver Resposta <p>a) No paralelismo com mem\u00f3ria compartilhada (como no OpenMP), todas as threads acessam a mesma regi\u00e3o de mem\u00f3ria. Isso facilita a troca de dados. J\u00e1 no paralelismo com mem\u00f3ria distribu\u00edda (como no MPI), a comunica\u00e7\u00e3o \u00e9 feita por troca expl\u00edcita de mensagens. </p> <p>b) Rank em MPI O rank \u00e9 o identificador \u00fanico de cada processo dentro de um comunicador MPI, geralmente numerado de <code>0</code> at\u00e9 <code>size-1</code>. Ele \u00e9 usado para diferenciar processos e definir o papel de cada um durante a execu\u00e7\u00e3o. </p> <p>c) Comunica\u00e7\u00e3o coletiva vs. ponto a ponto Uma vantagem das comunica\u00e7\u00f5es coletivas \u00e9 a simplicidade de implementa\u00e7\u00e3o, pois a biblioteca MPI j\u00e1 otimiza a troca de dados internamente, evitando que o programador tenha de escrever m\u00faltiplos <code>MPI_Send</code> e <code>MPI_Recv</code>. A desvantagem \u00e9 o overhead, todos os processos precisam participar da opera\u00e7\u00e3o coletiva ao mesmo tempo, o que pode causar esperas desnecess\u00e1rias se algum processo atrasar. J\u00e1 a comunica\u00e7\u00e3o ponto a ponto d\u00e1 mais flexibilidade, e controle dos processos e trocas de mensagens.</p> <p>d) Dois processos executando apenas <code>MPI_Send</code> Se dois processos chamarem <code>MPI_Send</code> simultaneamente um para o outro sem que haja chamadas correspondentes de <code>MPI_Recv</code>, o programa pode entrar em deadlock. Isso acontece porque cada processo fica esperando o envio ser conclu\u00eddo, mas n\u00e3o h\u00e1 recep\u00e7\u00e3o ativa para liberar os dados. Para evitar isso, \u00e9 importante garantir que um processo envie enquanto o outro recebe.</p>"},{"location":"Exercicios/aula07/aula07/#questao-2-broadcast-manual-vs-mpi_bcast","title":"Quest\u00e3o 2 \u2014 Broadcast manual vs MPI_Bcast","text":"<p>Enunciado: Implemente duas vers\u00f5es para distribuir um mesmo valor inteiro a todos os processos:  </p> <ol> <li>Vers\u00e3o manual: o <code>rank 0</code> envia o valor individualmente para cada outro processo usando <code>MPI_Send</code>.  </li> <li>Vers\u00e3o coletiva: use <code>MPI_Bcast</code> para o mesmo objetivo.  </li> </ol> <p>Compare os tempos de execu\u00e7\u00e3o \u00e0 medida que o n\u00famero de processos aumenta.  </p> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int valor;\n    if (rank == 0) {\n        valor = 42;\n        // TODO: enviar valor manualmente com MPI_Send\n    } else {\n        // TODO: receber valor com MPI_Recv\n    }\n\n    std::cout &lt;&lt; \"[Manual] Processo \" &lt;&lt; rank &lt;&lt; \" recebeu valor = \" &lt;&lt; valor &lt;&lt; \"\\n\";\n\n    // TODO: implementar vers\u00e3o com MPI_Bcast\n\n    std::cout &lt;&lt; \"[Bcast] Processo \" &lt;&lt; rank &lt;&lt; \" recebeu valor = \" &lt;&lt; valor &lt;&lt; \"\\n\";\n\n    MPI_Finalize();\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int valor;\n    if (rank == 0) {\n        valor = 42;\n        // vers\u00e3o manual\n        for (int dest = 1; dest &lt; size; dest++) {\n            MPI_Send(&amp;valor, 1, MPI_INT, dest, 0, MPI_COMM_WORLD);\n        }\n    } else {\n        MPI_Recv(&amp;valor, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    }\n    std::cout &lt;&lt; \"[Manual] Processo \" &lt;&lt; rank &lt;&lt; \" recebeu valor = \" &lt;&lt; valor &lt;&lt; \"\\n\";\n\n    // vers\u00e3o com MPI_Bcast\n    if (rank == 0) valor = 99;\n    MPI_Bcast(&amp;valor, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    std::cout &lt;&lt; \"[Bcast] Processo \" &lt;&lt; rank &lt;&lt; \" recebeu valor = \" &lt;&lt; valor &lt;&lt; \"\\n\";\n\n    MPI_Finalize();\n}\n</code></pre>"},{"location":"Exercicios/aula07/aula07/#questao-3-reducao-manual-vs-mpi_reduce","title":"Quest\u00e3o 3 \u2014 Redu\u00e7\u00e3o manual vs MPI_Reduce","text":"<p>Enunciado: Implemente a soma de inteiros distribu\u00eddos entre os processos de duas formas:  </p> <ol> <li>Vers\u00e3o manual: cada processo envia seu valor ao <code>rank 0</code>, que acumula.  </li> <li>Vers\u00e3o coletiva: use <code>MPI_Reduce</code> para calcular a soma diretamente.  </li> </ol> <p>Verifique se os resultados s\u00e3o iguais.  </p> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int meu_valor = rank + 1; // cada processo tem um valor diferente\n    int soma = 0;\n\n    if (rank == 0) {\n        soma = meu_valor;\n        // TODO: receber valores dos outros processos com MPI_Recv e acumular\n    } else {\n        // TODO: enviar valor ao processo 0 com MPI_Send\n    }\n\n    if (rank == 0) {\n        std::cout &lt;&lt; \"[Manual] Soma total = \" &lt;&lt; soma &lt;&lt; \"\\n\";\n    }\n\n    // TODO: implementar vers\u00e3o com MPI_Reduce\n\n    if (rank == 0) {\n        std::cout &lt;&lt; \"[Reduce] Soma total = \" &lt;&lt; soma &lt;&lt; \"\\n\";\n    }\n\n    MPI_Finalize();\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int meu_valor = rank + 1; // s\u00f3 para ter valores diferentes\n    int soma = 0;\n\n    if (rank == 0) {\n        soma = meu_valor;\n        for (int src = 1; src &lt; size; src++) {\n            int temp;\n            MPI_Recv(&amp;temp, 1, MPI_INT, src, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n            soma += temp;\n        }\n        std::cout &lt;&lt; \"[Manual] Soma total = \" &lt;&lt; soma &lt;&lt; \"\\n\";\n    } else {\n        MPI_Send(&amp;meu_valor, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n\n    // vers\u00e3o com MPI_Reduce\n    int soma_reduce = 0;\n    MPI_Reduce(&amp;meu_valor, &amp;soma_reduce, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    if (rank == 0) {\n        std::cout &lt;&lt; \"[Reduce] Soma total = \" &lt;&lt; soma_reduce &lt;&lt; \"\\n\";\n    }\n\n    MPI_Finalize();\n}\n</code></pre>"},{"location":"Exercicios/aula07/aula07/#questao-4-scatter-calculo-local-gather","title":"Quest\u00e3o 4 \u2014 Scatter + c\u00e1lculo local + Gather","text":"<p>Enunciado: Implemente um programa que divide um vetor de inteiros igualmente entre os processos, cada processo calcula a soma dos seus elementos, e depois os resultados s\u00e3o reunidos no processo 0:  </p> <ol> <li>Use <code>MPI_Scatter</code> para distribuir partes do vetor.  </li> <li>Cada processo calcula sua soma parcial.  </li> <li>Use <code>MPI_Gather</code> para enviar os resultados ao <code>rank 0</code>.  </li> <li>O <code>rank 0</code> calcula a soma total e imprime.  </li> </ol> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = 16;\n    std::vector&lt;int&gt; dados;\n    if (rank == 0) {\n        dados.resize(N);\n        for (int i = 0; i &lt; N; i++) dados[i] = i+1;\n    }\n\n    int tam_local = N / size;\n    std::vector&lt;int&gt; local(tam_local);\n\n    // TODO: usar MPI_Scatter para enviar partes do vetor\n\n    int soma_local = 0;\n    // TODO: calcular soma local\n\n    std::vector&lt;int&gt; somas;\n    if (rank == 0) somas.resize(size);\n\n    // TODO: usar MPI_Gather para enviar resultados locais ao rank 0\n\n    if (rank == 0) {\n        int soma_total = 0;\n        // TODO: acumular somas e imprimir resultado final\n    }\n\n    MPI_Finalize();\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = 16;\n    std::vector&lt;int&gt; dados;\n    if (rank == 0) {\n        dados.resize(N);\n        for (int i = 0; i &lt; N; i++) dados[i] = i+1;\n    }\n\n    int tam_local = N / size;\n    std::vector&lt;int&gt; local(tam_local);\n\n    MPI_Scatter(dados.data(), tam_local, MPI_INT,\n                local.data(), tam_local, MPI_INT,\n                0, MPI_COMM_WORLD);\n\n    int soma_local = 0;\n    for (int x : local) soma_local += x;\n\n    std::vector&lt;int&gt; somas;\n    if (rank == 0) somas.resize(size);\n\n    MPI_Gather(&amp;soma_local, 1, MPI_INT,\n            somas.data(), 1, MPI_INT,\n            0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        int soma_total = 0;\n        for (int s : somas) soma_total += s;\n        std::cout &lt;&lt; \"Soma total = \" &lt;&lt; soma_total &lt;&lt; \"\\n\";\n    }\n\n    MPI_Finalize();\n}\n</code></pre>"},{"location":"Exercicios/aula08/aula08/","title":"Aula 08 Otimiza\u00e7\u00f5es usando paralelismo de mem\u00f3ria local e distribu\u00edda","text":""},{"location":"Exercicios/aula08/aula08/#questao-1-teorica-mpi-openmp","title":"Quest\u00e3o 1 \u2014 Te\u00f3rica (MPI + OpenMP)","text":"<p>Enunciado: a) Explique por que faz sentido combinar MPI e OpenMP em clusters de HPC. b) Quais s\u00e3o as vantagens dessa abordagem h\u00edbrida em rela\u00e7\u00e3o a usar apenas MPI puro? c) D\u00ea um exemplo de problema em que somente OpenMP n\u00e3o seria suficiente. d) Cite uma dificuldade extra que surge ao programar em MPI+OpenMP em compara\u00e7\u00e3o com usar apenas OpenMP.  </p> Ver resposta <p>a) Os clusters HPC t\u00eam m\u00faltiplos n\u00f3s (m\u00e1quinas diferentes) e m\u00faltiplos n\u00facleos por n\u00f3 (v\u00e1rios core dentro da CPU). O MPI \u00e9 usado para comunica\u00e7\u00e3o entre n\u00f3s, O OpenMP \u00e9 usado para paralelismo dentro de cada n\u00f3, usandos as threads e a mem\u00f3ria compartilhada (L1, L2, L3 e RAM). Juntos, aproveitam ao m\u00e1ximo a hierarquia do hardware (distribu\u00eddo + compartilhado).</p> <p>b) Reduz o n\u00famero de processos MPI: menos overhead de comunica\u00e7\u00e3o entre n\u00f3s.  </p> <p>Aproveita melhor a mem\u00f3ria compartilhada dentro de cada n\u00f3, que \u00e9 mais r\u00e1pida que a troca de mensagens MPI.</p> <p>Aproveita melhor os recursos dispon\u00edveis no cluster: MPI distribui entre n\u00f3s, OpenMP paraleliza dentro de cada n\u00f3.  </p> <p>c) Problemas que n\u00e3o cabem na mem\u00f3ria de um \u00fanico n\u00f3. Exemplo: simula\u00e7\u00e3o de clima global, que precisa de terabytes de mem\u00f3ria, imposs\u00edvel em apenas um n\u00f3. Necess\u00e1rio MPI para dividir os dados entre n\u00f3s diferentes.</p> <p>d) Maior complexidade de programa\u00e7\u00e3o: o programador precisa lidar tanto com gerenciamento de threads (OpenMP) quanto com comunica\u00e7\u00e3o entre processos(MPI). Debug e balanceamento de carga ficam mais dif\u00edceis em c\u00f3digos h\u00edbridos.  </p>"},{"location":"Exercicios/aula08/aula08/#questao-2-somas-parciais-em-matriz-hibrida","title":"Quest\u00e3o 2 \u2014 Somas parciais em matriz h\u00edbrida","text":"<p>Enunciado: Implemente um programa que calcula a soma de todos os elementos de uma matriz <code>NxN</code> de forma h\u00edbrida: - O <code>rank 0</code> inicializa a matriz com valores aleat\u00f3rios. - Cada processo recebe um bloco de linhas usando <code>MPI_Scatter</code>. - Dentro de cada processo, use OpenMP para somar os elementos do seu bloco. - Combine os resultados parciais em <code>rank 0</code> com <code>MPI_Reduce</code>.  </p> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;cstdlib&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = 1024;\n    std::vector&lt;int&gt; A;\n    if (rank == 0) {\n        A.resize(N*N);\n        for (int i = 0; i &lt; N*N; i++) A[i] = rand() % 10;\n    }\n\n    // TODO: MPI_Scatter blocos de linhas\n    // TODO: soma parcial local com OpenMP\n    // TODO: MPI_Reduce para combinar resultados\n\n    MPI_Finalize();\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;mpi.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;cstdlib&gt;\n\nint main(int argc, char** argv) {\n    // Inicializa o MPI (cria o comunicador global e o ambiente de processos)\n    MPI_Init(&amp;argc, &amp;argv);\n\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);  // identificador do processo (0..size-1)\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);  // total de processos MPI\n\n    // Dimens\u00e3o da matriz NxN \n    int N = 1024;\n\n    // Apenas o rank 0 mant\u00e9m a matriz completa; os demais s\u00f3 recebem o seu peda\u00e7o\n    std::vector&lt;int&gt; A;\n    if (rank == 0) {\n        A.resize(N * N);\n        // Preenche a matriz com inteiros aleat\u00f3rios simples (0..9)\n        for (int i = 0; i &lt; N * N; i++) A[i] = rand() % 10;\n    }\n\n    // N\u00famero de linhas por processo (vers\u00e3o simples: exige N % size == 0)\n    int rows_per_proc = N / size;\n\n    // Buffer local do processo: \"rows_per_proc\" linhas por N colunas\n    std::vector&lt;int&gt; local(rows_per_proc * N);\n\n    // Distribui blocos de linhas de A (cont\u00edguas em mem\u00f3ria) para todos os processos\n    // - No rank 0: envia peda\u00e7os de A\n    // - Nos demais ranks: recebe em \"local\"\n    MPI_Scatter(\n        A.data(),                 // buffer de envio (apenas significativo no rank 0)\n        rows_per_proc * N,        // elementos enviados para CADA processo\n        MPI_INT,                  // tipo dos elementos\n        local.data(),             // buffer de recep\u00e7\u00e3o (todos os ranks)\n        rows_per_proc * N,        // elementos recebidos por processo\n        MPI_INT,                  // tipo dos elementos\n        0,                        // root (rank que envia)\n        MPI_COMM_WORLD            // comunicador\n    );\n\n    // Soma parcial local (vai acumular a soma do bloco deste processo)\n    long long soma_local = 0;\n\n    // Paraleliza a soma dentro do n\u00f3 com OpenMP:\n    // - Cada thread percorre um peda\u00e7o do vetor \"local\"\n    // - reduction(+:soma_local) evita condi\u00e7\u00e3o de corrida (cada thread tem acumulador pr\u00f3prio)\n    #pragma omp parallel for reduction(+:soma_local)\n    for (int i = 0; i &lt; rows_per_proc * N; i++) {\n        soma_local += local[i];\n    }\n\n    // Reduz (soma) todas as somas locais em \"soma_total\" no rank 0\n    long long soma_total = 0;\n    MPI_Reduce(\n        &amp;soma_local,              // dado local\n        &amp;soma_total,              // resultado no root\n        1,                        // quantidade\n        MPI_LONG_LONG,            // tipo do dado\n        MPI_SUM,                  // opera\u00e7\u00e3o de redu\u00e7\u00e3o\n        0,                        // root\n        MPI_COMM_WORLD\n    );\n\n    if (rank == 0) {\n        std::cout &lt;&lt; \"Soma total = \" &lt;&lt; soma_total &lt;&lt; std::endl;\n    }\n\n    MPI_Finalize(); // Finaliza MPI\n}\n</code></pre>"},{"location":"Exercicios/aula08/aula08/#questao-3-produto-escalar-distribuido","title":"Quest\u00e3o 3 \u2014 Produto escalar distribu\u00eddo","text":"<p>Enunciado: Implemente um programa h\u00edbrido para calcular o produto escalar entre dois vetores <code>v</code> e <code>w</code>:  </p> <p><code>s = sum(v[i] * w[i])</code> </p> <ul> <li>O <code>rank 0</code> inicializa os vetores.  </li> <li>Cada processo recebe um peda\u00e7o dos vetores via <code>MPI_Scatter</code>.  </li> <li>Dentro de cada processo, paralelize o c\u00e1lculo do produto parcial com OpenMP.  </li> <li>Use <code>MPI_Reduce</code> para reunir a soma no <code>rank 0</code>.  </li> </ul> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = 1&lt;&lt;20;\n    std::vector&lt;float&gt; v, w;\n    if (rank == 0) {\n        v.resize(N, 1.0f);\n        w.resize(N, 2.0f);\n    }\n\n    // TODO: Scatter peda\u00e7os dos vetores\n    // TODO: produto parcial com OpenMP\n    // TODO: MPI_Reduce para juntar resultados\n\n    MPI_Finalize();\n}\n</code></pre> Ver resposta"},{"location":"Exercicios/aula08/aula08/#include","title":"include","text":""},{"location":"Exercicios/aula08/aula08/#include_1","title":"include","text":""},{"location":"Exercicios/aula08/aula08/#include_2","title":"include","text":""},{"location":"Exercicios/aula08/aula08/#include_3","title":"include  <p>int main(int argc, char** argv) {     // Inicializa o ambiente MPI (processos distribu\u00eddos)     MPI_Init(&amp;argc, &amp;argv);</p> <pre><code>int rank, size;\nMPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);  // identificador do processo (0..size-1)\nMPI_Comm_size(MPI_COMM_WORLD, &amp;size);  // total de processos\n\n// Tamanho global dos vetores (2^20 ~ 1 milh\u00e3o de elementos)\nint N = 1 &lt;&lt; 20;\n\n// Apenas o rank 0 guarda os vetores completos\nstd::vector&lt;float&gt; v, w;\nif (rank == 0) {\n    v.resize(N, 1.0f);  // exemplo simples: todos 1.0\n    w.resize(N, 2.0f);  // exemplo simples: todos 2.0\n}\n\n// Particionamento simples: assume N % size == 0 (cada rank recebe o mesmo tamanho)\nint elems_per_proc = N / size;\n\n// Buffers locais (cada processo recebe um peda\u00e7o cont\u00edguo de v e w)\nstd::vector&lt;float&gt; v_local(elems_per_proc), w_local(elems_per_proc);\n\n// Distribui um peda\u00e7o de v para cada processo\nMPI_Scatter(\n    v.data(),                 // buffer origem (v\u00e1lido no rank 0)\n    elems_per_proc,           // n\u00ba de elementos enviados a cada rank\n    MPI_FLOAT,                // tipo\n    v_local.data(),           // buffer destino (todos os ranks)\n    elems_per_proc,           // n\u00ba de elementos recebidos\n    MPI_FLOAT,                // tipo\n    0, MPI_COMM_WORLD\n);\n\n// Distribui um peda\u00e7o de w para cada processo\nMPI_Scatter(\n    w.data(),\n    elems_per_proc,\n    MPI_FLOAT,\n    w_local.data(),\n    elems_per_proc,\n    MPI_FLOAT,\n    0, MPI_COMM_WORLD\n);\n\n// Soma parcial local do produto escalar desse processo\n// Observa\u00e7\u00e3o: usar 'double' para acumular reduz erro num\u00e9rico\ndouble soma_local = 0.0;\n\n// Paraleliza o la\u00e7o local com OpenMP:\n// - Cada thread processa um bloco de \u00edndices [0..elems_per_proc)\n// - reduction(+:soma_local) evita condi\u00e7\u00e3o de corrida (cada thread acumula localmente)\n#pragma omp parallel for reduction(+:soma_local)\nfor (int i = 0; i &lt; elems_per_proc; i++) {\n    soma_local += static_cast&lt;double&gt;(v_local[i]) * static_cast&lt;double&gt;(w_local[i]);\n}\n\n// Redu\u00e7\u00e3o global: soma todas as parcelas locais em 'soma_total' no rank 0\ndouble soma_total = 0.0;\nMPI_Reduce(\n    &amp;soma_local, &amp;soma_total,\n    1, MPI_DOUBLE, MPI_SUM,\n    0, MPI_COMM_WORLD\n);\n\n// Rank 0 imprime o resultado final\nif (rank == 0) {\n    std::cout &lt;&lt; \"Produto escalar = \" &lt;&lt; soma_total &lt;&lt; std::endl;\n}\n\n// Encerra o ambiente MPI\nMPI_Finalize();\n</code></pre> <p>}</p>","text":""},{"location":"Exercicios/aula08/aula08/#questao-4-filtro-1d-paralelo-com-halos","title":"Quest\u00e3o 4 \u2014 Filtro 1D paralelo com halos","text":"<p>Enunciado: Implemente um filtro de m\u00e9dia m\u00f3vel 1D sobre um vetor:  </p> <p><code>out[i] = (v[i-1] + v[i] + v[i+1]) / 3</code> </p> <ul> <li>O <code>rank 0</code> inicializa o vetor <code>v</code>.  </li> <li>O vetor \u00e9 dividido entre os processos (<code>MPI_Scatter</code>).  </li> <li>Cada processo precisa das bordas vizinhas (halos) \u2014 troque os elementos das extremidades com <code>MPI_Sendrecv</code>.  </li> <li>Paralelize o c\u00e1lculo local com OpenMP.  </li> <li>Re\u00fana o vetor final no <code>rank 0</code> com <code>MPI_Gather</code>.  </li> </ul> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = 1024;\n    std::vector&lt;float&gt; v, out;\n    if (rank == 0) {\n        v.resize(N, 1.0f);\n        out.resize(N);\n    }\n\n    // TODO: Scatter blocos do vetor\n    // TODO: troca de halos com MPI_Sendrecv\n    // TODO: c\u00e1lculo local com OpenMP\n    // TODO: MPI_Gather para juntar resultado\n\n    MPI_Finalize();\n}\n</code></pre> Ver Resposta"},{"location":"Exercicios/aula08/aula08/#include_4","title":"include","text":""},{"location":"Exercicios/aula08/aula08/#include_5","title":"include","text":""},{"location":"Exercicios/aula08/aula08/#include_6","title":"include","text":""},{"location":"Exercicios/aula08/aula08/#include_7","title":"include  <p>int main(int argc, char** argv) {     // ------------------------------------------------------------     // Inicializa\u00e7\u00e3o do MPI e descoberta de (rank, size)     // ------------------------------------------------------------     MPI_Init(&amp;argc, &amp;argv);     int rank, size;     MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); // ID do processo (0..size-1)     MPI_Comm_size(MPI_COMM_WORLD, &amp;size); // n\u00ba total de processos</p> <pre><code>// ------------------------------------------------------------\n// Dimens\u00e3o global do vetor e buffers no rank 0\n// (v inicializado, out receber\u00e1 o resultado global)\n// ------------------------------------------------------------\nint N = 1024;\nstd::vector&lt;float&gt; v, out;\nif (rank == 0) {\n    v.resize(N, 1.0f); // exemplo simples: todos 1.0\n    out.resize(N);\n}\n\n// ------------------------------------------------------------\n// Particionamento simples: assume N % size == 0\n// Cada processo recebe elems_per_proc elementos cont\u00edguos\n// ------------------------------------------------------------\nint elems_per_proc = N / size;\nstd::vector&lt;float&gt; local(elems_per_proc), local_out(elems_per_proc);\n\n// ------------------------------------------------------------\n// Distribui partes de v para todos os processos\n// (rank 0 envia; demais recebem em 'local')\n// ------------------------------------------------------------\nMPI_Scatter(v.data(), elems_per_proc, MPI_FLOAT,\n            local.data(), elems_per_proc, MPI_FLOAT,\n            0, MPI_COMM_WORLD);\n\n// ------------------------------------------------------------\n// Troca de HALOS (bordas vizinhas):\n//   - Cada processo precisa do elemento da esquerda e da direita\n//     pertencentes aos vizinhos (para computar out[i] nas extremidades).\n//   - Pol\u00edtica de borda simples: se n\u00e3o h\u00e1 vizinho, usamos o pr\u00f3prio valor.\n// ------------------------------------------------------------\nfloat left_halo  = local[0];                    // padr\u00e3o: pr\u00f3prio valor (borda)\nfloat right_halo = local[elems_per_proc - 1];   // padr\u00e3o: pr\u00f3prio valor (borda)\n\n// Envia/recebe com o vizinho \u00e0 esquerda (rank-1), se existir\nif (rank &gt; 0) {\n    MPI_Sendrecv(&amp;local[0],               1, MPI_FLOAT, rank - 1, 0,\n                &amp;left_halo,              1, MPI_FLOAT, rank - 1, 0,\n                MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n}\n// Envia/recebe com o vizinho \u00e0 direita (rank+1), se existir\nif (rank &lt; size - 1) {\n    MPI_Sendrecv(&amp;local[elems_per_proc - 1], 1, MPI_FLOAT, rank + 1, 0,\n                &amp;right_halo,                1, MPI_FLOAT, rank + 1, 0,\n                MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n}\n\n// ------------------------------------------------------------\n// C\u00e1lculo local do filtro (paralelo com OpenMP)\n//   out[i] = (v[i-1] + v[i] + v[i+1]) / 3\n//   - Para i=0 e i=\u00faltimo, usamos halos recebidos (ou pr\u00f3prio valor na borda).\n// ------------------------------------------------------------\n#pragma omp parallel for\nfor (int i = 0; i &lt; elems_per_proc; i++) {\n    float left  = (i == 0) ? left_halo : local[i - 1];\n    float right = (i == elems_per_proc - 1) ? right_halo : local[i + 1];\n    local_out[i] = (left + local[i] + right) / 3.0f;\n}\n\n// ------------------------------------------------------------\n// Re\u00fane os peda\u00e7os filtrados em 'out' no rank 0\n// ------------------------------------------------------------\nMPI_Gather(local_out.data(), elems_per_proc, MPI_FLOAT,\n        out.data(),       elems_per_proc, MPI_FLOAT,\n        0, MPI_COMM_WORLD);\n\nif (rank == 0) {\n    std::cout &lt;&lt; \"Filtro 1D conclu\u00eddo.\" &lt;&lt; std::endl;\n    // (Opcional) validar/inspecionar alguns elementos de 'out'\n    // for (int i = 0; i &lt; 10; ++i) std::cout &lt;&lt; out[i] &lt;&lt; \" \";\n    // std::cout &lt;&lt; \"\\n\";\n}\n\nMPI_Finalize();\n</code></pre> <p>}</p>","text":""},{"location":"aulas/aula01/","title":"Aula 01 - Problemas de HPC","text":"<p>Durante a aula, vimos que problemas computacionalmente complexos podem ser:</p> <ul> <li> <p>Grandes: uma quantidade de dados absurda, que n\u00e3o cabe em um computador de trabalho comum</p> </li> <li> <p>Intensivo: Realiza calculos complexos e demorados, demandando horas ou dias de processamento intensivo</p> </li> <li> <p>Combo: As vezes o problema tem as duas caracteristicas, tem uma grande quantidade de dados, demanda c\u00e1lculos intesivos.</p> </li> </ul> <p>Para resolver problemas desse tipo, precisamos fazer um bom uso do hardware, podemos come\u00e7ar usando uma linguagem de programa\u00e7\u00e3o mais eficiente e planejando melhor o nosso c\u00f3digo, usando as caracter\u00edsticas da linguagem a nosso favor.</p> <p>Conte\u00fado te\u00f3rico de apoio - Aula 01</p> <p>Eu fui legal e organizei aqui tudo aqui pra voc\u00ea!</p>"},{"location":"aulas/aula01/#atividade-01-python-x-c","title":"Atividade 01 \u2014 Python x C++","text":"<p>Voc\u00ea est\u00e1 trabalhando com sensores industriais que geram milh\u00f5es de medi\u00e7\u00f5es por dia, como temperatura, press\u00e3o e vibra\u00e7\u00e3o. Monitorar apenas a \u00faltima medi\u00e7\u00e3o n\u00e3o \u00e9 confi\u00e1vel: leituras oscilam naturalmente devido a ru\u00eddos ou pequenas flutua\u00e7\u00f5es.</p> <p>Para obter informa\u00e7\u00f5es mais est\u00e1veis e \u00fateis, usamos m\u00e9dias m\u00f3veis: ao inv\u00e9s de olhar um valor isolado, olhamos a tend\u00eancia local dos dados.</p> <p>Exemplo: Se a temperatura medida for <code>[85.1, 84.9, 85.0, 93.2, 85.1, 85.0]</code>, um \u00fanico pico (93.2) poderia gerar alarme falso. A m\u00e9dia m\u00f3vel suaviza esse ru\u00eddo.</p>"},{"location":"aulas/aula01/#desafio","title":"Desafio","text":"<p>Simular o processamento de dados de sensores, implementando o c\u00e1lculo da m\u00e9dia m\u00f3vel simples. A partir disso, comparar diferentes vers\u00f5es do c\u00f3digo para analisar os ganhos de desempenho obtidos com otimiza\u00e7\u00f5es e com o uso dos recursos da linguagem C++.</p> <p>Implementa\u00e7\u00e3o em Python <pre><code>import time\nimport random\n\n# N = 100 milh\u00f5es de leituras\nN = 100_000_000\n\n# Janela K = 10\nK = 10\n\n# Gera os dados\nstart_gen = time.time()\ndados = [random.uniform(12.0, 189.98) for _ in range(N)]\nprint(\"Tempo para gerar os dados:\", time.time() - start_gen)\n\n# Calcula m\u00e9dia m\u00f3vel\nstart_avg = time.time()\nmedia = []\nsoma = sum(dados[:K])\nmedia.append(soma / K)\n\nfor i in range(1, N - K):\n    soma = soma - dados[i - 1] + dados[i + K - 1]\n    media.append(soma / K)\n\nprint(\"Tempo para calcular m\u00e9dia m\u00f3vel:\", time.time() - start_avg)\n</code></pre></p> <ol> <li> <p>Fa\u00e7a um c\u00f3digo em c+++ que gera um vetor com <code>100000000</code> valores de leitura do tipo <code>double</code>, variando entre <code>12.0</code> e <code>189.98</code></p> </li> <li> <p>Implemente o c\u00e1lculo da m\u00e9dia m\u00f3vel simples com janela <code>k = 10</code>, ou seja:</p> </li> </ol> <p>$$    M_i = \\frac{1}{k} \\sum_{j=i}^{i+k-1} v_j    $$</p> <ol> <li>Fa\u00e7a a passagem dos dados para o c\u00e1lculo da m\u00e9dia m\u00f3vel simples de 3 formas diferentes:</li> <li>Passagem por valor</li> <li>Passagem por refer\u00eancia</li> <li> <p>Passagem por ponteiro</p> </li> <li> <p>Use <code>const</code> para garantir seguran\u00e7a e desempenho (const correctness) onde fizer sentido.</p> </li> <li> <p>Compile usando diferentes flags de otimiza\u00e7\u00e3o:</p> </li> <li> <p>Me\u00e7a e compare os tempos de execu\u00e7\u00e3o</p> </li> <li> <p>Compare com a implementa\u00e7\u00e3o em python.</p> </li> </ol> <p>Esqueleto do c\u00f3digo \u2013 <code>media.cpp</code></p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\n\n// =========================================\n// Constantes globais\n// =========================================\nconst size_t N = 100'000'000; // N\u00famero total de amostras\nconst size_t K = 10;          // Tamanho da janela da m\u00e9dia m\u00f3vel\n\n// =========================================\n// Fun\u00e7\u00e3o para gerar um vetor com valores aleat\u00f3rios\n// =========================================\nvector&lt;double&gt; gerar_leituras(size_t tamanho) {\n    // TODO: Criar um vetor de tamanho `tamanho`\n    // TODO: Criar gerador de n\u00fameros aleat\u00f3rios com seed fixa\n    // TODO: Definir distribui\u00e7\u00e3o entre 12.0 e 189.98\n    // TODO: Preencher o vetor com n\u00fameros aleat\u00f3rios\n\n    // DICA: use std::vector&lt;double&gt; e uniform_real_distribution\n\n    return {}; // Substitua pelo vetor preenchido\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por valor)\n// =========================================\nvector&lt;double&gt; media_movel_por_valor() {\n    // TODO: Calcular a m\u00e9dia m\u00f3vel simples sobre o vetor recebido por valor\n    // TODO: Retornar um vetor com os resultados\n\n    return {};\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por refer\u00eancia)\n// =========================================\nvector&lt;double&gt; media_movel_por_referencia() {\n    // TODO: Igual \u00e0 vers\u00e3o anterior, mas recebendo os dados por refer\u00eancia constante\n\n    return {};\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por ponteiro)\n// =========================================\nvector&lt;double&gt; media_movel_por_ponteiro() {\n    // TODO: Usar aritm\u00e9tica de ponteiros para calcular a m\u00e9dia m\u00f3vel\n    // TODO: Retornar um vetor com os resultados\n\n    return {};\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para medir tempo de execu\u00e7\u00e3o\n// =========================================\ntemplate &lt;typename Func, typename... Args&gt;\ndouble medir_tempo(Func funcao, Args&amp;&amp;... args) {\n    auto inicio = chrono::high_resolution_clock::now();\n    funcao(forward&lt;Args&gt;(args)...);\n    auto fim = chrono::high_resolution_clock::now();\n    chrono::duration&lt;double&gt; duracao = fim - inicio;\n    return duracao.count();\n}\n\n// =========================================\n// Fun\u00e7\u00e3o principal\n// =========================================\nint main() {\n    // Etapa 1: Gerar os dados\n    cout &lt;&lt; \"Gerando dados...\" &lt;&lt; endl;\n    vector&lt;double&gt; leituras = gerar_leituras(N);\n\n    // Etapa 2: C\u00e1lculo por valor\n    cout &lt;&lt; \"M\u00e9dia m\u00f3vel (por valor):\" &lt;&lt; endl;\n    double tempo_valor = medir_tempo(media_movel_por_valor, leituras, K);\n    cout &lt;&lt; \"\u2192 Tempo: \" &lt;&lt; tempo_valor &lt;&lt; \" s\" &lt;&lt; endl;\n\n    // Etapa 3: C\u00e1lculo por refer\u00eancia\n    cout &lt;&lt; \"M\u00e9dia m\u00f3vel (por refer\u00eancia):\" &lt;&lt; endl;\n    double tempo_ref = medir_tempo(media_movel_por_referencia, leituras, K);\n    cout &lt;&lt; \"\u2192 Tempo: \" &lt;&lt; tempo_ref &lt;&lt; \" s\" &lt;&lt; endl;\n\n    // Etapa 4: C\u00e1lculo por ponteiro\n    cout &lt;&lt; \"M\u00e9dia m\u00f3vel (por ponteiro):\" &lt;&lt; endl;\n    const double* ptr = leituras.data();\n    double tempo_ptr = medir_tempo(media_movel_por_ponteiro, ptr, N, K);\n    cout &lt;&lt; \"\u2192 Tempo: \" &lt;&lt; tempo_ptr &lt;&lt; \" s\" &lt;&lt; endl;\n\n    // Etapa 5: Compile com diferentes flags e compare os tempos\n    // Exemplo:\n    //   g++ media.cpp -o sem_otimizacao\n    //   g++ -O2 media.cpp -o otimizacao_O2\n    //   g++ -O3 media.cpp -o otimizacao_O23\n    //   g++ -Ofast media.cpp -o otimizacao_Ofast\n    return 0;\n}\n</code></pre>"},{"location":"aulas/aula01/#entrega-da-atividade-01","title":"Entrega da Atividade 01","text":"<p>No arquivo README.md do Classroom, inclua:</p> <ul> <li> <p>C\u00f3digo-fonte em C++: o programa utilizado para os testes. </p> </li> <li> <p>Tabela comparativa: com os resultados de todas as execu\u00e7\u00f5es</p> </li> <li> <p>Gr\u00e1fico comparativo: representando visualmente os resultados obtidos.</p> </li> <li> <p>An\u00e1lise de desempenho: coment\u00e1rios explicando quais fatores influenciaram o desempenho</p> </li> </ul> <p>Entrega at\u00e9 quinta 23h59 pelo link do GitHub Classroom</p> <p>Lembre-se de preencher o foruml\u00e1rio para criar o seu acesso ao Cluster Franky, ele ser\u00e1 usado a partir da pr\u00f3xima aula!</p> <p>Dica!</p> <p>Lembre-se de consultar o material dispon\u00edvel em Conte\u00fado te\u00f3rico de apoio - Aula 01</p> <p>Links \u00fateis</p> <p>Rand\u00f4micos aqui, aqui e aqui Vetores aqui e aqui Passagem de valor por refer\u00eancia - aqui e aqui Ponteiros aqui e aqui Aritim\u00e9tica de ponteiros</p>"},{"location":"aulas/aula02/","title":"Aula 02: Acessando o Cluster Franky","text":"<p>Na Atividade 2, voc\u00ea ir\u00e1 executar as implementa\u00e7\u00f5es que foram testadas na Atividade 1, mas agora no ambiente de um cluster HPC usando SLURM. O objetivo \u00e9 observar como o ambiente de cluster, com suas diferentes arquiteturas de hardware, pode impactar o desempenho das opera\u00e7\u00f5es computacionalmente intensivas que voc\u00ea j\u00e1 explorou.</p>"},{"location":"aulas/aula02/#parte-0-configurando-seu-acesso-ao-cluster-franky","title":"Parte 0: Configurando seu acesso ao Cluster Franky","text":"<p>Para ter acesso ao Cluster Franky voc\u00ea precisa configurar suas credenciais de acesso e realizar acesso remoto via SSH.</p> <p>As chaves foram enviadas para o seu email Insper, Fa\u00e7a o download da pasta completa, que cont\u00e9m os arquivos <code>id_rsa</code> (chave privada) e <code>id_rsa.pub</code> (chave p\u00fablica). Dependendo do sistema operacional que voc\u00ea utiliza, siga as instru\u00e7\u00f5es abaixo para configurar corretamente seu acesso ao cluster Franky.</p>"},{"location":"aulas/aula02/#para-macbook-ou-linux","title":"Para Macbook ou Linux:","text":"<p>Abra o terminal, navegue at\u00e9 a pasta onde a chave privada (<code>id_rsa</code>) foi baixada, mova a chave para o diret\u00f3rio <code>.ssh</code> em sua home:</p> <pre><code>mv id_rsa ~/.ssh/\n</code></pre> <p>Garanta que apenas voc\u00ea possa ler o arquivo:</p> <pre><code>chmod 400 ~/.ssh/id_rsa\n</code></pre> <p>Conecte-se ao cluster utilizando o comando SSH:</p> <p>O login \u00e9 o seu \"usuario Insper\", o endere\u00e7o de IP foi fornecido durante a aula.</p> <p><pre><code>ssh -i ~/.ssh/id_rsa login@ip_do_cluster\n</code></pre> ou</p> <pre><code>ssh login@ip_do_cluster\n</code></pre>"},{"location":"aulas/aula02/#para-windows","title":"Para Windows:","text":"<p>Usando MobaXTerm</p> <p>Baixe o MobaXterm Home Edition em: https://mobaxterm.mobatek.net/download-home-edition.html</p> <p>Execute a aplica\u00e7\u00e3o, com o MobaXterm aberto, clique em Session, depois em SSH. </p> <p>Preencha todos os campos marcados em vermelho </p> <p>Estabele\u00e7a a conex\u00e3o, se tudo der certo, voc\u00ea ver\u00e1 algo como: </p>"},{"location":"aulas/aula02/#configurar-o-vs-code-para-acesso-remoto-ao-cluster","title":"Configurar o VS Code para Acesso Remoto ao Cluster","text":"<p>Instale a Extens\u00e3o Remote - SSH:</p> <p>Abra o VS Code, v\u00e1 para a aba de extens\u00f5es (\u00edcone de quadrado no lado esquerdo). Pesquise por \"Remote - SSH\" e instale a extens\u00e3o oficial da Microsoft.</p> <p>Configurar o Acesso Remoto:</p> <p>Pressione <code>Ctrl+Shift+P</code> (ou <code>Cmd+Shift+P</code> no Mac) para abrir o painel de comandos.</p> <p>Digite <code>Remote-SSH: Add New SSH Host...</code> e selecione a op\u00e7\u00e3o.</p> <p>Insira o comando SSH para conex\u00e3o com o Franky: <pre><code>ssh -i Endere\u00e7o_da_cahve/id_rsa login@ip_do_cluster\n</code></pre> Escolha o arquivo de configura\u00e7\u00e3o padr\u00e3o (<code>~/.ssh/config</code> para Mac/Linux ou <code>C:\\Users\\seu_usuario\\.ssh\\config</code> para Windows).</p> <p>Pressione <code>Ctrl+Shift+P</code> (ou <code>Cmd+Shift+P</code> no Mac) novamente e digite <code>Remote-SSH: Connect to Host...</code>. Selecione o host configurado.</p> <p>O VS Code abrir\u00e1 uma nova janela conectada ao ambiente remoto do cluster.</p> <p></p> <p>Gerenciar Projetos Remotamente:</p> <p>Ap\u00f3s a conex\u00e3o, voc\u00ea pode abrir pastas e arquivos no cluster diretamente pelo VS Code.</p> <p>Voc\u00ea pode utilizar os recursos do VS Code, como o terminal integrado e o debug para trabalhar no cluster Franky.</p>"},{"location":"aulas/aula02/#executando-a-atividade-no-cluster-franky-usando-slurm","title":"Executando a Atividade no Cluster Franky usando SLURM","text":"<p>Um arquivo .slurm \u00e9 usado para \"lan\u00e7ar jobs\" no sistema SLURM, especificando os recursos necess\u00e1rios para a execu\u00e7\u00e3o, como mem\u00f3ria, n\u00famero de m\u00e1quinas e n\u00facleos. Nesse arquivo, tamb\u00e9m definimos como desejamos o output do execut\u00e1vel e onde o sistema pode encontrar o arquivo a ser executado. Como a equipe que gerencia o Cluster definiu que os jobs sejam lan\u00e7ados apenas da pasta SCRATCH, podemos omitir o caminho do arquivo nos nossos arquivos .slurm.</p> <p>Warning</p> <p>Quando voc\u00ea escreve um script para ser executado pelo SLURM o gerenciador de jobs SLURM interpreta <code>#SBATCH</code> como diretivas que definem como o job deve ser executado.</p>"},{"location":"aulas/aula02/#conhecendo-o-sistema","title":"Conhecendo o Sistema","text":"<p>Antes de come\u00e7ar a fazer pedidos de recursos pro SLURM, vamos conhecer os diferentes hardwares que temos dispon\u00edvel no Franky. Vamos utilizar alguns comandos de sistema operacional para ler os recursos de CPU, mem\u00f3ria e GPU dispon\u00edveis</p>"},{"location":"aulas/aula02/#comandos-utilizados","title":"Comandos utilizados","text":"<ul> <li><code>lscpu</code>: mostra detalhes da CPU (n\u00facleos, threads, mem\u00f3ria cache...)</li> <li><code>cat /proc/meminfo</code>: mostra detalhes sobre a mem\u00f3ria RAM </li> <li><code>nvidia-smi</code>: mostra detalhes de GPU, se dispon\u00edvel</li> </ul>"},{"location":"aulas/aula02/#comando-srun","title":"Comando SRUN","text":"<pre><code>srun --partition=normal --ntasks=1 --cpus-per-task=1 --mem=1G --time=00:05:00 \\\n--pty bash -c \"hostname &amp;&amp; \\\ncat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' &amp;&amp; \\\nlscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache' &amp;&amp; \\\n{ command -v nvidia-smi &amp;&gt; /dev/null &amp;&amp; nvidia-smi || echo 'nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada'; }\" \n</code></pre> <p>Voc\u00ea deve ver algo como:</p> <p></p> <p><code>srun</code></p> <p>\u00c9 o comando do SLURM usado para executar uma tarefa interativamente em um n\u00f3 do cluster.</p> <p><code>--partition=normal</code></p> <p>Indica em qual fila (parti\u00e7\u00e3o) o job ser\u00e1 executado. No seu caso, <code>normal</code> pode ser substitu\u00eddo por qualquer outra fila do sistema</p> <p><code>--ntasks=1</code></p> <p>Solicita 1 tarefa (processo). Se voc\u00ea estivesse rodando um c\u00f3digo paralelo, faz sentido trocar esse valor.</p> <p><code>--cpus-per-task=1</code></p> <p>Cada tarefa receber\u00e1 1 CPU (core). Quando estiver usando paralelismo com v\u00e1rias threads , faz sentido aumentar esse valor.</p> <p><code>--mem=1G</code></p> <p>Aloca 1 gigabyte de mem\u00f3ria RAM para essa tarefa. Se ultrapassar esse limite, o job ser\u00e1 encerrado.</p> <p><code>--time=00:05:00</code></p> <p>Define um tempo m\u00e1ximo de execu\u00e7\u00e3o de 5 minutos. Depois disso, o SLURM mata o processo automaticamente.</p> <p><code>--pty bash</code></p> <p>Solicita um terminal para o SLURM dentro do n\u00f3 de computa\u00e7\u00e3o. Interessante para fazer testes no c\u00f3digo ou realizar debugs</p> <p><code>{ command -v nvidia-smi &amp;&gt; /dev/null &amp;&amp; nvidia-smi || echo 'nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada'; }</code></p> <p>Esse trecho verifica se o comando <code>nvidia-smi</code> est\u00e1 dispon\u00edvel no sistema (ou seja, se h\u00e1 driver NVIDIA instalado e uma GPU NVIDIA acess\u00edvel).</p> <ul> <li>Se <code>nvidia-smi</code> estiver dispon\u00edvel, ele ser\u00e1 executado e mostrar\u00e1 as informa\u00e7\u00f5es da(s) GPU(s) no n\u00f3 (como nome, mem\u00f3ria, uso, driver etc).</li> <li>Se n\u00e3o estiver dispon\u00edvel (por exemplo, em n\u00f3s sem GPU ou sem driver instalado), exibir\u00e1 a mensagem:   <code>\"nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada\"</code>.</li> </ul> <p>Tip</p> <ul> <li>Em n\u00f3s CPU-only (como os da parti\u00e7\u00e3o <code>normal</code>), \u00e9 esperado que <code>nvidia-smi</code> n\u00e3o esteja presente.</li> <li>Para testar o comando em um n\u00f3 com GPU, use <code>--partition=gpu</code> ou <code>--partition=monstrao</code>  para alocar n\u00f3s com placas NVIDIA.</li> </ul> <p>O comando abaixo faz exatamente a mesma coisa, mas eu coloquei ele dentro de um shell script para ter uma formata\u00e7\u00e3o melhor no display:</p> <pre><code>srun --partition=normal --ntasks=1 --pty bash -c \\\n\"echo '=== HOSTNAME ==='; hostname; echo; \\\n echo '=== MEMORIA (GB) ==='; \\\n cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' | \\\n awk '{printf \\\"%s %.2f GB\\\\n\\\", \\$1, \\$2 / 1048576}'; \\\n echo; \\\n echo '=== CPU INFO ==='; \\\n lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\n echo '=== GPU INFO ==='; \\\n if command -v nvidia-smi &amp;&gt; /dev/null; then nvidia-smi; else echo 'nvidia-smi n\u00e3o dispon\u00edvel'; fi\"\n</code></pre> <p></p> <p>O comando <code>sinfo</code> mostra quais s\u00e3o as filas e quais s\u00e3o os status dos n\u00f3s </p> <p><pre><code>sinfo\n</code></pre> O comando abaixo mostra detalhes sobre os recursos de cada fila</p> <pre><code>scontrol show partition\n</code></pre> <p>Recomendo que voc\u00ea mude o nome da fila (partition) no comando abaixo para se ambientar no Cluster Franky e desconrir quais s\u00e3o as diferen\u00e7as entre as filas</p> <pre><code>srun --partition=normal --ntasks=1 --cpus-per-task=1 --mem=1G --time=00:05:00 \\\n     --pty bash -c \"hostname &amp;&amp; cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' &amp;&amp; lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\"\n</code></pre>"},{"location":"aulas/aula02/#atividade-02","title":"Atividade 02","text":"<p>Na aula passada n\u00f3s vimos que a linguagem importa, al\u00e9m disso, existem recursos da linguagem que tem o poder de acelerar o nosso c\u00f3digo, e mais ainda, podemos usar otimiza\u00e7\u00f5es a n\u00edvel de compila\u00e7\u00e3o para ir al\u00e9m e conseguir uma otimiza\u00e7\u00e3o ainda maior. Agora vamos executar os scripts da aula passada no Cluster Franky para verificar o quanto o hardware impacta nessa abordagem, como ser\u00e1 que ficar\u00e1 o desempenho ao executar os c\u00f3digos em diferentes arquiteturas de computadores?</p> <p>Vamos utilizar o SLURM para pedir recursos computacionais do nosso Cluster, agora que voc\u00ea ja conhece o hardware que tem em cada fila, fa\u00e7a as suas escolhas de recursos e teste o seu c\u00f3digo!</p> <p>Script SLURM para o c\u00f3digo em Python:</p> <p>media_py.slurm</p> <pre><code>#!/bin/bash\n#As instru\u00e7\u00f5es SBATCH n\u00e3o devem ser descomentadas\n\n#SBATCH --job-name=OLHA_EU\n# define o nome do job. Esse nome aparece nas listas de jobs e \u00e9 \u00fatil para identificar o job.\n\n#SBATCH --output=media_py%j.out\n# Especifica o arquivo onde a sa\u00edda padr\u00e3o (stdout) do job ser\u00e1 salva.\n\n#SBATCH --ntasks=1\n# Define o n\u00famero de tarefas que o job executar\u00e1. Neste caso, o job executa uma \u00fanica tarefa.\n\n#SBATCH --time=00:10:00\n# Define o tempo m\u00e1ximo de execu\u00e7\u00e3o para o job. Neste caso, o job tem um tempo limite de 10 minutos. Se o job exceder esse tempo, ele ser\u00e1 automaticamente encerrado.\n\n#SBATCH --partition=normal\n# Especifica a parti\u00e7\u00e3o (ou fila) onde o job ser\u00e1 submetido. Aqui.\n\ntime python3 media_movel.py\n#Executa o programa dentro do n\u00f3 de computa\u00e7\u00e3o.\n</code></pre> <p>Script SLURM para arquivos C++:</p> <p>Como o C++ \u00e9 uma linguagem que requer compila\u00e7\u00e3o, precisamos gerar o execut\u00e1vel antes de preparar o arquivo .slurm.</p> <p>Dentro da pasta SCRATCH, compile seu c\u00f3digo .cpp para gerar o bin\u00e1rio.</p> <pre><code>g++ media_movel.cpp -o sem_otimizacao\ng++ -O2 media_movel.cpp -o otimizacao_O2\ng++ -O3 media_movel.cpp -o otimizacao_O3\ng++ -Ofast media_movel.cpp -o otimizacao_Ofast\n</code></pre> <p>media_cpp.slurm <pre><code>#!/bin/bash\n#SBATCH --job=OI_GALERA\n# Define o nome do job. Esse nome aparece nas listas de jobs e \u00e9 \u00fatil para identificar o job.\n\n#SBATCH --output=media_cpp%j.out\n# Especifica o arquivo onde a sa\u00edda padr\u00e3o (stdout) do job ser\u00e1 salva.\n\n#SBATCH --ntasks=1\n# Define o n\u00famero de tarefas que o job executar\u00e1. Neste caso, o job executa uma \u00fanica tarefa.\n\n#SBATCH --time=00:10:00\n# Define o tempo m\u00e1ximo de execu\u00e7\u00e3o para o job. Neste caso, o job tem um tempo limite de 10 minutos. Se o job exceder esse tempo, ele ser\u00e1 automaticamente encerrado.\n\n#SBATCH --partition=normal\n# Especifica a parti\u00e7\u00e3o (ou fila) onde o job ser\u00e1 submetido. Aqui, o job ser\u00e1 submetido a fila \"normal\".\n\n\necho \"========== SEM OTIMIZACAAAOOOO ========\"\ntime ./sem_otimizacao\n\necho \"========= OTIMIZACAO 02 ===============\"\ntime ./otimizacao_O2\n\necho \"======== OTIMIZACAO O3 ===============\"\ntime ./otimizacao_O3\n\necho \"=========== OFAST ESSA ===============\"\ntime ./otimizacao_Ofast\n\n# Executa os bin\u00e1rios dentro do n\u00f3 de computa\u00e7\u00e3o.\n</code></pre></p>"},{"location":"aulas/aula02/#parte-2-execucao-das-implementacoes-no-cluster","title":"Parte 2: Execu\u00e7\u00e3o das Implementa\u00e7\u00f5es no Cluster","text":"<p>Submiss\u00e3o dos Jobs:</p> <p>Utilize o comando <code>sbatch</code> para submeter cada script SLURM ao cluster.</p> <p>Exemplo:</p> <pre><code>sbatch media_py.slurm\nsbatch media_cpp.slurm\n</code></pre> <p>Monitoramento dos Jobs:</p> <p>Use o comando <code>squeue</code> para monitorar o status dos jobs.</p> <p>Exemplo:</p> <pre><code>squeue \n</code></pre> <p>An\u00e1lise dos Resultados:</p> <p>Ap\u00f3s a execu\u00e7\u00e3o dos jobs, os resultados estar\u00e3o dispon\u00edveis nos arquivos <code>.out</code>  especificados em cada script SLURM.</p> <ul> <li> <p>Compare os tempos de execu\u00e7\u00e3o dos programas no cluster.</p> </li> <li> <p>Troque a fila de submiss\u00e3o no arquivo .slurm e compare o desempenho dos programas novamente</p> </li> <li> <p>Analise como as diferentes arquiteturas de hardware dentro do cluster impactam o desempenho do c\u00f3digo, compare tamb\u00e9m com os seus resultados obtidos na atividade 1, executando na sua m\u00e1quina local.</p> </li> </ul> <p>Tip</p> <p>Se quiser explorar mais os comandos do SLURM, temos uma material aqui que pode te ajudar</p> <p>Links \u00fateis</p> <p>Guia do Slurm - CENAPAD Documenta\u00e7\u00e3o Oficial SLURM Guia de Comandos SLURM</p>"},{"location":"aulas/aula02/#esta-atividade-nao-tem-entrega-bom-final-de-semana","title":"Esta atividade n\u00e3o tem entrega, Bom final de semana!","text":""},{"location":"aulas/aula03/","title":"Aula 03 - Otimiza\u00e7\u00e3o e Tiling","text":""},{"location":"aulas/aula03/#objetivo","title":"Objetivo","text":"<p>Explorar t\u00e9cnicas de otimiza\u00e7\u00e3o de c\u00f3digo sequencial em C++ a partir da an\u00e1lise de desempenho. O foco ser\u00e1:</p> <ul> <li>Compreender a rela\u00e7\u00e3o entre hierarquia de mem\u00f3ria (L1, L2, L3) e desempenho.</li> <li>Aplicar tiling (fateamento em blocos) para melhorar o aproveitamento da mem\u00f3ria cache.</li> <li>Reorganizar estruturas de dados para um melhor aproveitamento do principio da localidade espacial.</li> </ul>"},{"location":"aulas/aula03/#contexto","title":"Contexto","text":"<p>Vamos tomar como base o hardware do monstr\u00e3o, ele tem um processador Intel Xeon Gold 5215, que possui:</p> <ul> <li>L1d cache: 32 KiB por n\u00facleo</li> <li>L2 cache: 1 MiB por n\u00facleo</li> <li>L3 cache: 13.75 MiB por socket</li> </ul> <p>Na multiplica\u00e7\u00e3o de matrizes, o maior gargalo costuma se o acesso a mem\u00f3ria. Para otimizar o desempenho de um algoritmo como esse,  dividimos a matriz em blocos que cabem na mem\u00f3ria cache, porque ela \u00e9 a que est\u00e1 mais proxima da CPU. No nosso caso, cada submatriz de tamanho <code>B\u00d7B</code> precisa caber na cache junto com mais dois blocos (A, B e C). A f\u00f3rmula para calcular o tamanho m\u00e1ximo do bloco \u00e9:</p>  B \\leq \\sqrt{\\frac{\\text{Capacidade da Cache}}{24}}  <p>(onde 24 = 3 matrizes \u00d7 8 bytes por double).</p> <p>Analise o c\u00f3digo <code>matmul_seq.cpp</code>:</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;cstdlib&gt;\n#include &lt;algorithm&gt;\n\n\n#define TAM_MATRIZ 1000\n/*\n ============================================================\n   OBJETIVO\n   -----------------------------------------------------------\n   Este programa faz a multiplica\u00e7\u00e3o de matrizes aninhadas\n   de forma SEQUENCIAL e mede o tempo de execu\u00e7\u00e3o.\n\n   Ele pode rodar em dois modos:\n   - Vers\u00e3o INGENUA (sem otimiza\u00e7\u00f5es)\n   - Vers\u00e3o com TILING (fateamento em blocos), onde o tamanho\n     do bloco B \u00e9 passado como par\u00e2metro na linha de comando.\n\n   O objetivo \u00e9 observar como o tamanho do bloco B influencia:\n   - O tempo de execu\u00e7\u00e3o\n   - O uso de cache\n\n ============================================================\n*/\n\n/* Definicoes para melhorar a legibilidade*/\n\nusing Matriz = std::vector&lt;std::vector&lt;double&gt;&gt;;\n\ninline Matriz criaMatriz(int size, double value){\n    return Matriz(size, std::vector&lt;double&gt;(size, value));\n}\n\n/**\n * @brief Vers\u00e3o ing\u00eanua da multiplica\u00e7\u00e3o de matrizes.\n * \n * Implementa a multiplica\u00e7\u00e3o com tr\u00eas loops aninhados (i, j, k) sem uso de tiling.\n * O acesso \u00e0s matrizes \u00e9 feito de forma direta, sem otimiza\u00e7\u00f5es de cache.\n */\ninline void versaoIngenua(){\n\n    // Cria tr\u00eas matrizes NxN em mem\u00f3ria, preenchidas com valores fixos\n    // - A inicializada com 1.0\n    // - Bmat inicializada com 2.0\n    // - C inicializada com 0.0 (resultado)\n\n    Matriz A    = criaMatriz(TAM_MATRIZ, 1.0);\n    Matriz Bmat = criaMatriz(TAM_MATRIZ, 2.0);\n    Matriz C    = criaMatriz(TAM_MATRIZ, 0.0);\n\n    for (int i = 0; i &lt; TAM_MATRIZ; i++) {\n        for (int j = 0; j &lt; TAM_MATRIZ; j++) {\n            for (int k = 0; k &lt; TAM_MATRIZ; k++) {\n                C[i][j] += A[i][k] * Bmat[k][j];\n            }\n        }\n    }\n}\n\n/**\n * @brief Multiplica\u00e7\u00e3o de matrizes utilizando a t\u00e9cnica de tiling (blocking).\n * \n * Realiza a multiplica\u00e7\u00e3o de matrizes dividindo as matrizes em blocos (tiles) de tamanho `tamBloco`.\n * Otimiza o uso da cache ao trabalhar com submatrizes menores que cabem na hierarquia de mem\u00f3ria.\n * \n * @param tamBloco Tamanho do bloco (tile) usado para dividir as matrizes na multiplica\u00e7\u00e3o.\n */\ninline void versaoTiling(int tamBloco){\n\n    // Cria tr\u00eas matrizes NxN em mem\u00f3ria, preenchidas com valores fixos\n    // - A inicializada com 1.0\n    // - Bmat inicializada com 2.0\n    // - C inicializada com 0.0 (resultado)\n\n    Matriz A    = criaMatriz(TAM_MATRIZ, 1.0);\n    Matriz Bmat = criaMatriz(TAM_MATRIZ, 2.0);\n    Matriz C    = criaMatriz(TAM_MATRIZ, 0.0);\n\n    for (int ii = 0; ii &lt; TAM_MATRIZ; ii += tamBloco) {        // blocos de linhas\n        for (int jj = 0; jj &lt; TAM_MATRIZ; jj += tamBloco) {    // blocos de colunas\n            for (int kk = 0; kk &lt; TAM_MATRIZ; kk += tamBloco) {// blocos intermedi\u00e1rios\n                // Multiplica\u00e7\u00e3o de submatrizes tamBloco x tamBloco\n                // Ordem j -&gt; i -&gt; k\n                for (int j = jj; j &lt; std::min(jj + tamBloco, TAM_MATRIZ); j++) {\n                    for (int i = ii; i &lt; std::min(ii + tamBloco, TAM_MATRIZ); i++) {\n                        double sum = C[i][j];\n                        for (int k = kk; k &lt; std::min(kk + tamBloco, TAM_MATRIZ); k++) {\n                            sum += A[i][k] * Bmat[k][j];\n                        }\n                        C[i][j] = sum;\n                    }\n                }\n            }\n        }\n    }\n}\n\n\n\nint main(int argc, char* argv[]) {\n    int tamBloco = 0; // Tamanho do bloco. Se for 0 \u2192 vers\u00e3o ing\u00eanua.\n\n    // L\u00ea o tamanho do bloco da linha de comando\n    // Exemplo: ./matmul_seq 200  \u2192 roda com blocos 200\u00d7200\n    if (argc &gt; 1) {\n        // Atualiza o valor de tamBloco de acordo com o par\u00e2metro de entrada\n        tamBloco = std::atoi(argv[1]);\n    }\n\n    // Marca o in\u00edcio da medi\u00e7\u00e3o de tempo\n    auto start = std::chrono::high_resolution_clock::now();\n\n    if (tamBloco &lt;= 0) {\n        versaoIngenua();\n    } \n    else {\n        versaoTiling(tamBloco);\n    }\n\n    // Marca o fim da medi\u00e7\u00e3o\n    auto end = std::chrono::high_resolution_clock::now();\n\n    // Calcula e imprime o tempo total em milissegundos\n    std::cout &lt;&lt; \"Execu\u00e7\u00e3o (\"\n              &lt;&lt; (tamBloco &lt;= 0 ? \"ing\u00eanua\" : \"tiling tamBloco=\" + std::to_string(tamBloco))\n              &lt;&lt; \"): \"\n              &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(end - start).count()\n              &lt;&lt; \" ms\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"aulas/aula03/#missoes","title":"Miss\u00f5es:","text":""},{"location":"aulas/aula03/#1-compilacao","title":"1. Compila\u00e7\u00e3o","text":"<p>Compile o c\u00f3digo no terminal do head-node <code>matmul_seq.cpp</code>:</p> <pre><code>g++ -O2  matmul_seq.cpp -o matmul_seq\n</code></pre>"},{"location":"aulas/aula03/#2-execucao","title":"2. Execu\u00e7\u00e3o","text":"<p>Crie o lan\u00e7ador do SLURM como em <code>tiling.slurm</code>:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=monstrao_tiling\n#SBATCH --output=monstrao_tiling%j.out\n#SBATCH --error=monstrao_tiling%j.err\n#SBATCH --partition=monstrao\n#SBATCH --ntasks=1\n#SBATCH --time=00:05:00\n#SBATCH --mem=2G\n\necho \"=============== FILA MONSTRAO==============\"\n\necho \"=== Execu\u00e7\u00e3o vers\u00e3o ing\u00eanua ===\"\ntime ./matmul_seq 0\n\necho \"=== Execu\u00e7\u00e3o com blocos L1 (~36x36) ===\"\ntime ./matmul_seq 36\n\necho \"=== Execu\u00e7\u00e3o com blocos L2 (~200x200) ===\"\ntime ./matmul_seq 200\n\necho \"=== Execu\u00e7\u00e3o com blocos L3 (~768x768) ===\"\ntime ./matmul_seq 768\n</code></pre> <p>Execute com:</p> <pre><code>sbatch tiling.slurm\n</code></pre>"},{"location":"aulas/aula03/#explorando-ordenacao-de-loops-e-flags-de-otimizacao-em-diferentes-filas","title":"Explorando Ordena\u00e7\u00e3o de Loops e Flags de Otimiza\u00e7\u00e3o em Diferentes Filas","text":"<p>Voc\u00ea j\u00e1 visualizou o efeito do tiling. Agora, o objetivo \u00e9 entender como a organiza\u00e7\u00e3o dos loops e as otimiza\u00e7\u00f5es do compilador influenciam o desempenho do mesmo c\u00f3digo.</p>"},{"location":"aulas/aula03/#1-alterando-a-ordem-dos-loops","title":"1. Alterando a Ordem dos Loops","text":"<p>Modifique o c\u00f3digo <code>matmul_seq.cpp</code> para usar a ordem i \u2192 k \u2192 j no lugar da ordem original j \u2192 i \u2192 k. Essa mudan\u00e7a melhora a localidade espacial dos acessos \u00e0 matriz B, e tamb\u00e9m beneficia os acessos \u00e0s matrizes A e C.</p>"},{"location":"aulas/aula03/#2-testar-diferentes-flags-de-otimizacao","title":"2. Testar Diferentes Flags de Otimiza\u00e7\u00e3o","text":"<p>Encontre a flag de Otimiza\u00e7\u00e3o com o melhor resultado para esse algoritmo (O2, O3, Ofast)</p>"},{"location":"aulas/aula03/#3-rodar-em-diferentes-filas-do-cluster","title":"3. Rodar em Diferentes Filas do Cluster","text":"<p>Ap\u00f3s identificar as melhores combina\u00e7\u00f5es de loop e flags de otimiza\u00e7\u00e3o no monstrao, identifique quais s\u00e3o os tamanhos das mem\u00f3rias L1, L2 e L3 na fila GPU e repita os testes.</p>"},{"location":"aulas/aula03/#perguntas-para-responder-no-relatorio","title":"Perguntas para responder no relat\u00f3rio:","text":"<ol> <li>A troca de ordem dos loops melhorou ou piorou o tempo de execu\u00e7\u00e3o? Por qu\u00ea?</li> <li>Houveram diferen\u00e7as entre os n\u00f3s monstrao e gpu? Quais?</li> <li>Qual o tamanho de bloco que apresentou o melhor equil\u00edbrio entre tempo de execu\u00e7\u00e3o e aproveitamento de cache em cada fila?</li> </ol>"},{"location":"aulas/aula03/#entregaveis","title":"Entreg\u00e1veis:","text":"<p>Submeta via Classroom um relat\u00f3rio contendo obrigatoriamente:</p> <ul> <li> <p>Identifica\u00e7\u00e3o: seu nome completo</p> </li> <li> <p>Tabelas comparativas: contendo os resultados obtidos</p> </li> <li> <p>Gr\u00e1ficos comparativos: que ilustrem as diferen\u00e7as de desempenho entre as vers\u00f5es testadas</p> </li> <li> <p>Respostas \u00e0s perguntas: an\u00e1lise com base nos resultados observados </p> </li> </ul> <p>Fa\u00e7a a submiss\u00e3o do relat\u00f3rio at\u00e9 22/08, 08h30 pelo link do Github Classromm</p>"},{"location":"aulas/aula04/","title":"Aula 04 - Heur\u00edsticas e Aleatoriedade","text":""},{"location":"aulas/aula04/#objetivo","title":"Objetivo","text":"<p>Ao final desta atividade, voc\u00ea ser\u00e1 capaz de:</p> <ul> <li>Analisar heur\u00edsticas com aleatoriedade para reduzir o espa\u00e7o de busca e fugir de m\u00ednimos locais.</li> <li>Usar aleatoriedade para guiar a busca de solu\u00e7\u00f5es.</li> </ul> <p>Warning</p> <p>Clique aqui para ter acesso ao relat\u00f3rio completo do Emil</p>"},{"location":"aulas/aula04/#um-pouco-de-teoria-o-que-e-nonce","title":"Um pouco de teoria: O que \u00e9 Nonce?","text":"<p>Um nonce \u00e9 um n\u00famero que s\u00f3 pode ser usado uma \u00fanica vez dentro de um determinado contexto. A palavra vem da express\u00e3o inglesa \u201cnumber used once\u201d. O nonce tem um papel fundamental dentro do mecanismo conhecido como Proof of Work.</p> <p>No sistema de Proof of Work, que \u00e9 usado por diversas criptomoedas como o Bitcoin, o objetivo principal \u00e9 garantir que novos blocos de transa\u00e7\u00f5es s\u00f3 sejam adicionados \u00e0 blockchain mediante a realiza\u00e7\u00e3o de um trabalho computacional significativo. Esse trabalho \u00e9 feito pelos mineradores, que tentam encontrar um valor de nonce que, quando combinado com os dados de um bloco e passado por uma fun\u00e7\u00e3o hash (o SHA-256), gere um resultado que satisfa\u00e7a uma condi\u00e7\u00e3o espec\u00edfica de dificuldade. Essa condi\u00e7\u00e3o normalmente exige que o hash gerado comece com um certo n\u00famero de zeros, quanto mais zeros, mais dif\u00edcil o problema.</p> <p>Para encontrar esse nonce, o minerador precisa testar diferentes valores, um a um, recalculando o hash a cada tentativa. Como a fun\u00e7\u00e3o hash \u00e9 determin\u00edstica, mas seu resultado parece aleat\u00f3rio mesmo com pequenas mudan\u00e7as nos dados de entrada, n\u00e3o h\u00e1 como prever qual nonce gerar\u00e1 um hash v\u00e1lido. Isso significa que a \u00fanica forma de resolver o problema \u00e9 por tentativa e erro, o que exige muito poder computacional e tempo.</p> <p>Tip</p> <p>Quer saber mais? Assista esse v\u00eddeo sobre nonce</p>"},{"location":"aulas/aula04/#por-que-usar-heuristicas-com-aleatoriedade","title":"Por que usar heur\u00edsticas com aleatoriedade?","text":"<p>Em contextos como Proof of Work, usar heur\u00edsticas com aleatoriedade \u00e9 interessante porque o espa\u00e7o de busca \u00e9 enorme e imprevis\u00edvel. A fun\u00e7\u00e3o hash se comporta como uma caixa-preta: pequenas mudan\u00e7as no nonce geram resultados totalmente diferentes, sem padr\u00e3o aparente. Isso torna estrat\u00e9gias determin\u00edsticas (como testar de 0 em diante) ineficientes e vulner\u00e1veis a colis\u00f5es entre mineradores.</p> <p>A aleatoriedade permite explorar regi\u00f5es diferentes do espa\u00e7o de busca, reduzindo repeti\u00e7\u00e3o de esfor\u00e7os e aumentando a chance de sucesso. Al\u00e9m disso, torna o processo menos previs\u00edvel, dificultando ataques ou manipula\u00e7\u00f5es. Em um problema onde n\u00e3o h\u00e1 como saber onde est\u00e1 a solu\u00e7\u00e3o, tentar caminhos variados aleatoriamente \u00e9 uma boa forma de encontrar uma resposta mais r\u00e1pido.</p> <p>Analise o c\u00f3digo exemplo <code>mineracao.cpp</code></p> <pre><code>#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n#include &lt;iomanip&gt;\n#include &lt;sstream&gt;\n#include &lt;functional&gt;\n#include &lt;climits&gt;\n\n// -------------------------------------------------------------\n// - Retorna string hex com 16 bytes (64 bits) -&gt; 16 d\u00edgitos hex em ambientes 64 bits.\n// -------------------------------------------------------------\nstd::string sha256(const std::string&amp; input) {\n    std::hash&lt;std::string&gt; hasher;     // Functor de hash da STL\n    size_t h = hasher(input);          // Aplica o hash de 64 bits \u00e0 string\n    unsigned long long v = static_cast&lt;unsigned long long&gt;(h); // Normaliza para 64 bits\n\n    // Converte o valor inteiro para string hexadecimal com padding \u00e0 esquerda\n    // Para 64 bits -&gt; 16 d\u00edgitos hex (2 por byte * 8 bytes)\n    std::ostringstream os;\n    os &lt;&lt; std::hex &lt;&lt; std::nouppercase &lt;&lt; std::setfill('0') &lt;&lt; std::setw(16) &lt;&lt; v;\n    return os.str(); // Ex.: \"00af3c...\"; comprimento t\u00edpico: 16 chars em 64 bits\n}\n\n// -------------------------------------------------------------\n// Verifica se o \"hash\" (string hex) come\u00e7a com 'dificuldade' zeros.\n// -------------------------------------------------------------\nbool validaHash(const std::string&amp; hash, int dificuldade) {\n    if (dificuldade &lt;= 0) return true;               // dificuldade 0 sempre passa\n    if (dificuldade &gt; static_cast&lt;int&gt;(hash.size())) // n\u00e3o pode exigir mais zeros do que o tamanho do hash\n        return false;\n    return hash.rfind(std::string(dificuldade, '0'), 0) == 0; // true se come\u00e7a com zeros\n}\n\n// -------------------------------------------------------------\n// Estrat\u00e9gia 1: Busca linear \u2014 testa nonces em ordem: 0, 1, 2, ...\n// -------------------------------------------------------------\nvoid minerar_linear(const std::string&amp; bloco, int dificuldade) {\n    auto start = std::chrono::high_resolution_clock::now(); // Marca in\u00edcio do cron\u00f4metro\n\n    unsigned long long nonce = 0;        // Come\u00e7a do 0\n    unsigned long long tentativas = 0;   // Contador de tentativas\n\n    while (true) {\n        // Monta a entrada \"bloco || nonce\"\n        std::string tentativa = bloco + std::to_string(nonce);\n        // Calcula o \"hash\" da tentativa\n        std::string hash = sha256(tentativa);\n        ++tentativas;\n\n        // Se atendeu \u00e0 dificuldade (come\u00e7a com N zeros), reporta e encerra\n        if (validaHash(hash, dificuldade)) {\n            auto end = std::chrono::high_resolution_clock::now();\n            double tempo = std::chrono::duration&lt;double&gt;(end - start).count();\n            std::cout &lt;&lt; \"[LINEAR] Nonce: \" &lt;&lt; nonce &lt;&lt; \"\\nHash: \" &lt;&lt; hash\n                      &lt;&lt; \"\\nTentativas: \" &lt;&lt; tentativas &lt;&lt; \"\\nTempo: \" &lt;&lt; tempo &lt;&lt; \"s\\n\\n\";\n            break;\n        }\n        ++nonce; // Tenta o pr\u00f3ximo nonce\n    }\n}\n\n// -------------------------------------------------------------\n// Estrat\u00e9gia 2: Busca aleat\u00f3ria com heur\u00edstica simples\n// - Gera nonces aleat\u00f3rios em 64 bits\n// - Heur\u00edstica: s\u00f3 segue para valida\u00e7\u00e3o completa se o hash come\u00e7ar com '0'\n// - maxTentativas: evita loop \"infinito\" \n// -------------------------------------------------------------\nvoid minerar_random_heuristica(const std::string&amp; bloco, int dificuldade, unsigned long long maxTentativas) {\n    auto start = std::chrono::high_resolution_clock::now(); // Cron\u00f4metro\n\n    // Prepara\u00e7\u00e3o do gerador aleat\u00f3rio:\n    std::random_device rd;                          // Fonte de entropia (seed)\n    std::mt19937_64 gen(rd());                      // Gerador de aleat\u00f3rios\n    std::uniform_int_distribution&lt;unsigned long long&gt; distrib(0, ULLONG_MAX); // Uniforme em [0, 2^64-1]\n\n    unsigned long long tentativas = 0; // Contador de tentativas\n\n    while (tentativas &lt; maxTentativas) {\n        // Sorteia um nonce (explora\u00e7\u00e3o aleat\u00f3ria do espa\u00e7o de busca)\n        unsigned long long nonce = distrib(gen);\n\n        // Monta a tentativa e calcula o hash simulado\n        std::string tentativa = bloco + std::to_string(nonce);\n        std::string hash = sha256(tentativa);\n        ++tentativas;\n\n        // Heur\u00edstica: se o primeiro d\u00edgito n\u00e3o \u00e9 '0', provavelmente n\u00e3o atende a dificuldades maiores\n        if (hash[0] != '0') continue;\n\n        // Verifica\u00e7\u00e3o completa do crit\u00e9rio de dificuldade\n        if (validaHash(hash, dificuldade)) {\n            auto end = std::chrono::high_resolution_clock::now();\n            double tempo = std::chrono::duration&lt;double&gt;(end - start).count();\n            std::cout &lt;&lt; \"[HEURISTICA-RANDOM] Nonce: \" &lt;&lt; nonce &lt;&lt; \"\\nHash: \" &lt;&lt; hash\n                      &lt;&lt; \"\\nTentativas: \" &lt;&lt; tentativas &lt;&lt; \"\\nTempo: \" &lt;&lt; tempo &lt;&lt; \"s\\n\\n\";\n            return; // Sucesso: encerra a fun\u00e7\u00e3o\n        }\n    }\n\n    // Se n\u00e3o encontrou dentro do limite de tentativas, informa\n    std::cout &lt;&lt; \"[HEURISTICA-RANDOM] N\u00e3o encontrou nonce v\u00e1lido em \" &lt;&lt; maxTentativas &lt;&lt; \" tentativas.\\n\\n\";\n}\n\n// -------------------------------------------------------------\n// main: executa as duas estrat\u00e9gias para compara\u00e7\u00e3o \n// -------------------------------------------------------------\nint main() {\n    std::string bloco = \"transacao_simples\"; // Simula\u00e7\u00e3o de transa\u00e7\u00e3o\n    int dificuldade = 5;                     // N\u00ba de zeros \u00e0 esquerda no hash simulado\n    unsigned long long limite_random = 500000; // Limite de tentativas para a estrat\u00e9gia aleat\u00f3ria\n\n    std::cout &lt;&lt; \"=== Minera\u00e7\u00e3o  | dificuldade = \" &lt;&lt; dificuldade &lt;&lt; \" ===\\n\\n\";\n\n    // Estrat\u00e9gia linear \n    minerar_linear(bloco, dificuldade);\n\n    // Estrat\u00e9gia aleat\u00f3ria + heur\u00edstica\n    minerar_random_heuristica(bloco, dificuldade, limite_random);\n\n    return 0; \n}\n</code></pre>"},{"location":"aulas/aula04/#desafio","title":"Desafio!","text":"<p>Objetivo: Analisar e aprimorar a heur\u00edstica exemplo.</p> <p>Execute o c\u00f3digo acima 5 vezes. Compare:</p> <ul> <li> <p>O n\u00famero de tentativas e o tempo da busca linear.</p> </li> <li> <p>O n\u00famero de tentativas e o tempo da busca aleat\u00f3ria com heur\u00edstica.</p> </li> <li> <p>Qual das duas abordagem acerta mais?</p> </li> </ul> <p>Interprete os resultados:</p> <ul> <li> <p>A heur\u00edstica sempre \u00e9 mais r\u00e1pida?</p> </li> <li> <p>Em qual cen\u00e1rio a heuristica aleat\u00f3ria pode ser pior?</p> </li> <li> <p>O que fazer para que a busca aleat\u00f3ria com heur\u00edstica encontre o nonce com mais frequ\u00eancia?</p> </li> <li> <p>Por que usar aleatoriedade e filtros simples (como descartar hashes que n\u00e3o come\u00e7am com '0') pode acelerar a busca por um hash v\u00e1lido?</p> </li> </ul> <p>Pergunta para reflex\u00e3o:</p> <p>Quais melhorias poderiam ser implementadas neste algoritmo para ter uma heuristica mais eficiente?</p>"},{"location":"aulas/aula04/#esta-atividade-nao-tem-entrega-bom-final-de-semana","title":"Esta atividade n\u00e3o tem entrega, bom final de semana!","text":""},{"location":"aulas/aula05/","title":"Paralelismo em CPU com OpenMP","text":""},{"location":"aulas/aula05/#objetivo","title":"Objetivo","text":"<ul> <li>Paralelismo em CPU: como dividir o trabalho entre m\u00faltiplos cores.</li> <li>Threads: cada thread executa uma parte do trabalho.</li> <li>OpenMP: diretivas em OpenMP para paralelizar loops.</li> <li>Scheduling: forma como as itera\u00e7\u00f5es do loop s\u00e3o distribu\u00eddas entre threads (<code>static</code>, <code>dynamic</code>, <code>guided</code>).</li> </ul> <p>Os processadores atuais possuem m\u00faltiplos n\u00facleos de execu\u00e7\u00e3o (cores). Para aproveitar essa capacidade, podemos dividir o trabalho em partes menores que possam ser executadas simultaneamente. Essa divis\u00e3o \u00e9 feita por meio de threads, onde cada thread executa uma fra\u00e7\u00e3o das instru\u00e7\u00f5es.</p> <p>No caso de la\u00e7os de repeti\u00e7\u00e3o, o paralelismo \u00e9 obtido ao repartir as itera\u00e7\u00f5es entre v\u00e1rias threads. Em vez de uma \u00fanica thread percorrer todo o la\u00e7o, cada thread recebe um subconjunto de itera\u00e7\u00f5es, reduzindo o tempo total de execu\u00e7\u00e3o. O OpenMP facilita esse processo por meio de diretivas como <code>#pragma omp parallel for</code>.</p> <p>Tip</p> <p>Para saber mais, veja o material dispon\u00edvel em Guia de Pragmas OpnMP </p>"},{"location":"aulas/aula05/#scheduling-no-openmp","title":"Scheduling no OpenMP","text":"<p>Quando um la\u00e7o \u00e9 paralelizado, \u00e9 preciso definir como as itera\u00e7\u00f5es ser\u00e3o distribu\u00eddas entre as threads. Essa estrat\u00e9gia \u00e9 chamada de schedule (escalonamento).</p> <ul> <li>static \u2192 divide as itera\u00e7\u00f5es em blocos fixos, atribu\u00eddos antecipadamente a cada thread.</li> <li>dynamic \u2192 as itera\u00e7\u00f5es s\u00e3o distribu\u00eddas em blocos sob demanda, conforme as threads terminam suas tarefas.</li> <li>guided \u2192 inicia com blocos maiores e reduz gradualmente o tamanho, equilibrando a carga de trabalho.</li> <li>auto \u2192 delega ao compilador a escolha da estrat\u00e9gia.</li> <li>runtime \u2192 a estrat\u00e9gia \u00e9 definida em tempo de execu\u00e7\u00e3o pela vari\u00e1vel de ambiente <code>OMP_SCHEDULE</code>.</li> </ul> <p>A escolha do escalonamento n\u00e3o altera o resultado final da computa\u00e7\u00e3o, mas impacta diretamente o desempenho e o balanceamento da carga de trabalho.</p> <p>O programa <code>omp_schedulers.cpp</code> \u00e9 um c\u00f3digo exemplo para visualizar a distribui\u00e7\u00e3o das itera\u00e7\u00f5es de um la\u00e7o entre threads em diferentes estrat\u00e9gias de <code>schedule</code>.</p> <p>Para cada pol\u00edtica de escalonamento, o programa registra quais itera\u00e7\u00f5es foram executadas por cada thread e exibe uma sa\u00edda gr\u00e1fica com <code>*</code>, indicando a distribui\u00e7\u00e3o.</p> <p>Dessa forma, \u00e9 poss\u00edvel observar o comportamento de cada pol\u00edtica:</p> <p><code>omp_schedulers.cpp</code> <pre><code>#include &lt;iostream&gt;   \n#include &lt;string&gt;     \n#include &lt;vector&gt;     \n#include &lt;algorithm&gt;  \n#include &lt;omp.h&gt;      // OpenMP (omp_get_thread_num, diretivas)\n\n// -----------------------------------------------------------------------------\n// print_iterations:\n//   - Recebe uma descri\u00e7\u00e3o, um vetor de vetores 'vectors' (4 vetores, um por thread),\n//     e 'n' (n\u00famero total de itera\u00e7\u00f5es do la\u00e7o).\n//   - Constr\u00f3i 4 strings com '*' indicando quais itera\u00e7\u00f5es cada thread executou.\n//   - Imprime a distribui\u00e7\u00e3o para visualizar o efeito do 'schedule'.\n// -----------------------------------------------------------------------------\nvoid print_iterations(const std::string&amp; description,\n                      const std::vector&lt; std::vector&lt;int&gt; &gt;&amp; vectors,\n                      const int n)\n{\n    std::vector&lt;std::string&gt; strings(4, std::string()); // 4 linhas de sa\u00edda, uma por thread\n    for (int i = 0; i != n; i++)                        // varre todas as itera\u00e7\u00f5es 0..n-1\n    {\n        for (int j = 0; j != 4; j++)                   // para cada \"thread\" (0..3)\n        {\n            const auto&amp; vector = vectors[j];           // vetor com as itera\u00e7\u00f5es que a thread j executou\n            auto it = std::find(vector.begin(), vector.end(), i); // procura o i dentro do vetor da thread j\n            if (it != vector.end())\n            {\n                strings[j] += \"*\";                     // se a thread j executou a itera\u00e7\u00e3o i, marca '*'\n            }\n            else\n            { \n                strings[j] += \" \";                     // caso contr\u00e1rio, espa\u00e7o em branco\n            }\n        }\n    }\n    std::cout &lt;&lt; description &lt;&lt; std::endl;             // t\u00edtulo/descri\u00e7\u00e3o da experi\u00eancia\n    for (auto&amp; s : strings)                            // imprime as 4 linhas (uma por thread)\n    {\n        std::cout &lt;&lt; s &lt;&lt; \"\\n\";\n    }\n    std::cout &lt;&lt; std::endl;\n}\n\n// -----------------------------------------------------------------------------\n// schedule (template):\n//   - Fun\u00e7\u00e3o \"driver\" que recebe outra fun\u00e7\u00e3o 'function' (uma pol\u00edtica de agendamento),\n//     a descri\u00e7\u00e3o e 'n'.\n//   - Aloca 'vectors' (4 vetores: um por thread) e chama 'function' para preench\u00ea-los.\n//   - Depois imprime o resultado com print_iterations.\n// -----------------------------------------------------------------------------\ntemplate &lt;typename T&gt;\nvoid schedule(T function, \n              const std::string&amp; description, \n              const int n)\n{\n    std::vector&lt;std::vector&lt;int&gt;&gt; vectors(4, std::vector&lt;int&gt;()); // 4 threads simuladas\n    function(vectors, n);                                         // executa a pol\u00edtica (preenche vectors)\n    print_iterations(description, vectors, n);                    // visualiza distribui\u00e7\u00e3o\n}\n\n// -----------------------------------------------------------------------------\n// Cada fun\u00e7\u00e3o 'scheduleXYZ' abaixo:\n//   - Abre uma regi\u00e3o paralela com 4 threads (num_threads(4))\n//   - Faz um for paralelo '#pragma omp for' sobre i = 0..n-1\n//   - Cada thread registra a itera\u00e7\u00e3o 'i' que executou em vectors[tid]\n//   Observa\u00e7\u00e3o did\u00e1tica: push_back em 'vectors[tid]' \u00e9 aceit\u00e1vel aqui para fins\n//   de visualiza\u00e7\u00e3o (em geral, acessos concorrentes a containers exigem cuidado).\n// -----------------------------------------------------------------------------\n\n// Default: sem especificar 'schedule' explicitamente (deixa o runtime decidir)\nvoid scheduleDefault(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i); // registra a itera\u00e7\u00e3o i sob a thread atual\n        }\n    }\n}\n\n// schedule(static): divide as itera\u00e7\u00f5es em blocos fixos, um por thread (tamanho auto)\nvoid scheduleStatic(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(static)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(static, 4): blocos fixos de 4 itera\u00e7\u00f5es por vez\nvoid scheduleStatic4(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(static, 4)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(static, 8): blocos fixos de 8 itera\u00e7\u00f5es por vez\nvoid scheduleStatic8(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(static, 8)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(dynamic): threads pegam blocos sob demanda (tamanho padr\u00e3o do runtime)\nvoid scheduleDynamic(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(dynamic, 1): blocos din\u00e2micos de 1 itera\u00e7\u00e3o (alto overhead, \u00f3timo balanceamento)\nvoid scheduleDynamic1(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(dynamic, 1)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(dynamic, 4): blocos din\u00e2micos de 4 itera\u00e7\u00f5es\nvoid scheduleDynamic4(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(dynamic, 4)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(dynamic, 8): blocos din\u00e2micos de 8 itera\u00e7\u00f5es\nvoid scheduleDynamic8(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(dynamic, 8)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(guided): blocos come\u00e7am grandes e v\u00e3o diminuindo (bom p/ carga irregular)\nvoid scheduleGuided(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(guided)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(guided, 2): guided com bloco m\u00ednimo de 2\nvoid scheduleGuided2(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(guided, 2)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(guided, 4): guided com bloco m\u00ednimo de 4\nvoid scheduleGuided4(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(guided, 4)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(guided, 8): guided com bloco m\u00ednimo de 8\nvoid scheduleGuided8(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(guided, 8)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(auto): deixa o runtime escolher o melhor esquema\nvoid scheduleAuto(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(auto)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(auto): deixa o compilador escolher a melhor estrat\u00e9gia\nvoid scheduleRuntime(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(auto) \n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\nint main()\n{\n    const int n = 64; // n\u00famero de itera\u00e7\u00f5es do la\u00e7o a serem distribu\u00eddas entre 4 threads\n\n    // Executa cada pol\u00edtica de agendamento e imprime a \u201cfaixa\u201d de itera\u00e7\u00f5es por thread.\n    schedule(scheduleDefault,  \"default:               \", n);\n    schedule(scheduleStatic,   \"schedule(static):      \", n);\n    schedule(scheduleStatic4,  \"schedule(static, 4):   \", n);\n    schedule(scheduleStatic8,  \"schedule(static, 8):   \", n);\n    schedule(scheduleDynamic,  \"schedule(dynamic):     \", n);\n    schedule(scheduleDynamic1, \"schedule(dynamic, 1):  \", n);\n    schedule(scheduleDynamic4, \"schedule(dynamic, 4):  \", n);\n    schedule(scheduleDynamic8, \"schedule(dynamic, 8):  \", n);\n    schedule(scheduleGuided,   \"schedule(guided):      \", n);\n    schedule(scheduleGuided2,  \"schedule(guided, 2):   \", n);\n    schedule(scheduleGuided4,  \"schedule(guided, 4):   \", n);\n    schedule(scheduleGuided8,  \"schedule(guided, 8):   \", n);\n    schedule(scheduleAuto,     \"schedule(auto):        \", n);\n    schedule(scheduleRuntime,  \"schedule(runtime):     \", n);\n\n    return 0;\n}\n</code></pre></p> <p>Compilar o c\u00f3digo com OpenMP</p> <pre><code>g++ -fopenmp omp_schedulers.cpp -o omp_schedulers\n</code></pre> <p>Rodar no cluster com SLURM definindo o n\u00famero de threads:</p> <pre><code>srun --partition=normal --ntasks=1 --cpus-per-task=4 ./omp_schedulers\n</code></pre> <p>ou</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=omp_scheduler_test   # nome do job\n#SBATCH --output=output_omp_schedulers.out  # arquivo de sa\u00edda\n#SBATCH --ntasks=1                      # 1 processo (1 task MPI)\n#SBATCH --cpus-per-task=4               # 4 CPUs para essa task \u2192 4 threads OMP\n#SBATCH --time=00:05:00                 # tempo m\u00e1ximo de execu\u00e7\u00e3o\n#SBATCH --mem=2G                        # Mem\u00f3ria total do job (ex.: 2 GB)\n\n# garante que o OpenMP use exatamente os recursos alocados pelo SLURM\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}\n\n# executa o bin\u00e1rio\n./omp_schedulers\n</code></pre>"},{"location":"aulas/aula05/#analisando-os-schedulers-no-openmp","title":"Analisando os Schedulers no OpenMP","text":"<p>Cada scheduler do OpenMP se comporta de maneira diferente, e voc\u00ea deve observar o impacto de cada um:</p> <p>static: As itera\u00e7\u00f5es s\u00e3o divididas igualmente entre as threads.</p> <p>dynamic: As threads pegam blocos de itera\u00e7\u00f5es conforme terminam o trabalho.</p> <p>guided: Distribui blocos maiores no in\u00edcio e menores no final, equilibrando a carga.</p> <p>auto: Deixa o compilador escolher a melhor estrat\u00e9gia.</p> <p>runtime: Usa a estrat\u00e9gia definida em tempo de execu\u00e7\u00e3o.</p>"},{"location":"aulas/aula05/#atividade-03-paralelismo-com-openmp","title":"Atividade 03 - Paralelismo com OpenMP","text":"<p>C\u00f3digo base para a atividade 03:</p> <p><code>paralelo.cpp</code> <pre><code>// Compile: g++ -FlagDeOtimiza\u00e7\u00e3o -fopenmp paralelo.cpp -o paralelo\n// Execute: ./paralelo [N]  (N padr\u00e3o = 10'000'000)\n\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;algorithm&gt; \n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n    // ------------------------------\n    // Par\u00e2metros e dados de entrada\n    // ------------------------------\n    const int N = (argc &gt;= 2 ? std::stoi(argv[1]) : 10'000'000);\n    std::cout &lt;&lt; \"N = \" &lt;&lt; N &lt;&lt; \"\\n\";\n\n    // Vetor base (valores aleat\u00f3rios em [0,1))\n    std::vector&lt;float&gt; a(N);\n    {\n        std::mt19937 rng(123);                // seed fixa s\u00f3 p/ reprodutibilidade\n        std::uniform_real_distribution&lt;&gt; U(0.0, 1.0);\n        for (int i = 0; i &lt; N; ++i) a[i] = static_cast&lt;float&gt;(U(rng));\n    }\n\n    // =========================================================\n    // TAREFA A: Transforma\u00e7\u00e3o elemento-a-elemento (map)\n    // =========================================================\n    const float alpha = 2.0f, beta = 35.5f;\n    std::vector&lt;float&gt; c(N);\n\n    double t0 = omp_get_wtime();\n\n    for (int i = 0; i &lt; N; ++i) {\n        c[i] = alpha * a[i] + beta;\n    }\n\n    double t1 = omp_get_wtime();\n    std::cout &lt;&lt; \"[A] tempo = \" &lt;&lt; (t1 - t0) &lt;&lt; \" s\\n\";\n    int idx = N/2; // pega o elemento do meio do vetor\n    std::cout &lt;&lt; \"[A] c[\" &lt;&lt; idx &lt;&lt; \"] = \" &lt;&lt; c[idx] &lt;&lt; \"\\n\";\n\n    // =========================================================\n    // TAREFA B: Soma (redu\u00e7\u00e3o) da norma L2 parcial\n    // =========================================================\n    t0 = omp_get_wtime();\n\n    double soma = 0.0;\n    for (int i = 0; i &lt; N; ++i) {\n        soma += static_cast&lt;double&gt;(c[i]) * static_cast&lt;double&gt;(c[i]);\n    }\n\n    t1 = omp_get_wtime();\n    std::cout &lt;&lt; \"[B] tempo = \" &lt;&lt; (t1 - t0) &lt;&lt; \" s | soma  = \" &lt;&lt; soma &lt;&lt; \"\\n\";\n    return 0;\n}\n</code></pre> Para Compilar:</p> <pre><code>g++ -FlagDeOtimiza\u00e7\u00e3o -fopenmp paralelo.cpp -o paralelo\n</code></pre> <p>Para Executar: <pre><code>#!/bin/bash\n#SBATCH --job-name=paralelo_todo      # Nome do job\n#SBATCH --output=paralelo.txt         # nome do arquivo de saida\n#SBATCH --ntasks=1                    # Sempre 1 processo (o programa roda s\u00f3 uma vez)\n#SBATCH --cpus-per-task=4             # Esse processo tem 4 CPUs dispon\u00edveis para usar\n#SBATCH --mem=2G                      # Mem\u00f3ria solicitada\n#SBATCH --time=00:05:00               # Tempo solicitado (hh:mm:ss)\n#SBATCH --partition=normal            # fila\n\n# ------------------------------\n# Configura\u00e7\u00f5es OpenMP\n# ------------------------------\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}   # OpenMP abre 4 threads e distribui o trabalho entre elas\nexport OMP_PLACES=cores                         # Fixa threads em cores\nexport OMP_PROC_BIND=close                      # Coloca threads pr\u00f3ximas (melhor cache)\n\n# Troque aqui o Schedule do seu teste\nexport OMP_SCHEDULE=static\n\necho \"==== Configura\u00e7\u00e3o de Execu\u00e7\u00e3o ====\"\necho \"Job ID          : $SLURM_JOB_ID\"\necho \"CPUs-per-task   : $SLURM_CPUS_PER_TASK\"\necho \"Mem\u00f3ria total   : $SLURM_MEM_PER_NODE MB\"\necho \"OMP_NUM_THREADS : $OMP_NUM_THREADS\"\necho \"OMP_SCHEDULE    : $OMP_SCHEDULE\"\necho \"==================================\"\n\n# ------------------------------\n# Executa o programa\n# ------------------------------\n# paralelo (4 threads, por ex.)\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}   # OpenMP abre 4 threads e distribui o trabalho entre elas\n./paralelo \n</code></pre></p>"},{"location":"aulas/aula05/#objetivo_1","title":"Objetivo","text":"<p>Paralelizar la\u00e7os com OpenMP, comparar o efeito de <code>schedule</code> no desempenho.</p>"},{"location":"aulas/aula05/#tarefa-a-map-transformacao-elemento-a-elemento","title":"Tarefa A - Map: transforma\u00e7\u00e3o elemento-a-elemento","text":"<p>Solicita\u00e7\u00f5es de Implementa\u00e7\u00e3o</p> <ol> <li>Paralelize o c\u00f3digo correspondente a Tarefa A.</li> <li>Registre tempo e valor da conta em 3 execu\u00e7\u00f5es para cada <code>OMP_SCHEDULE = static</code>, <code>dynamic</code>, <code>guided</code>.</li> <li>O que est\u00e1 sendo paralelizado nesse for? O que est\u00e1 sendo distribuido entre as threads?</li> </ol>"},{"location":"aulas/aula05/#tarefa-b-reducao-ingenua-soma-de-quadrados","title":"Tarefa B - Redu\u00e7\u00e3o ing\u00eanua: soma de quadrados","text":"<p>Solicita\u00e7\u00f5es de Implementa\u00e7\u00e3o</p> <ol> <li>Paralelize o c\u00f3digo correspondente a Tarefa B.</li> <li>Registre tempo e valor da soma em 3 execu\u00e7\u00f5es para cada <code>OMP_SCHEDULE = static</code>, <code>dynamic</code>, <code>guided</code>.</li> <li>Compare com a execu\u00e7\u00e3o sequencial (threads=1).</li> <li>O que est\u00e1 sendo paralelizado nesse for? O que est\u00e1 sendo distribuido entre as threads?</li> </ol>"},{"location":"aulas/aula05/#coleta-de-resultados-minimo","title":"Coleta de Resultados (m\u00ednimo)","text":"<ul> <li>Tabela tempos (Parte 1): <code>scheduler</code>, <code>execu\u00e7\u00e3o</code>, <code>tempo (s)</code>.</li> <li>Tabela tempos (Parte 2): <code>schedule</code>, <code>threads</code>, <code>m\u00e9dia (s)</code>, <code>desvio</code>.</li> <li>Tabela soma (Parte 3): <code>schedule</code>, <code>tempo (s)</code>, <code>soma obtida</code>.</li> </ul>"},{"location":"aulas/aula05/#parametros-de-execucao","title":"Par\u00e2metros de Execu\u00e7\u00e3o","text":"<ul> <li>Varie <code>OMP_NUM_THREADS</code> em {1, 2, 4, 8} (quando solicitado).</li> <li>Mantenha os mesmos N (tamanho do problema) em todas as compara\u00e7\u00f5es do mesmo grupo.</li> </ul> <p>Perguntas de An\u00e1lise</p> <ul> <li>Houve speedup com mais threads? At\u00e9 onde?</li> <li><code>static</code> vs <code>dynamic</code> vs <code>guided</code>: quem foi melhor? Alguma diferen\u00e7a relevante?</li> <li>Alguma mudan\u00e7a no resultado das contas? </li> </ul> <p>Fa\u00e7a um relat\u00f3rio com as suas an\u00e1lises e entregue at\u00e9 as 23h59 de 28/08 pelo GitHub Classroom </p>"},{"location":"aulas/aula06/","title":"Efeitos Colaterais do Paralelismo","text":"<p>Nesta atividade vamos explorar os problemas que aparecem quando paralelizamos de forma ing\u00eanua e ver como corrigir logo em seguida. </p>"},{"location":"aulas/aula06/#tarefa-a-transformacao-elemento-a-elemento-map","title":"TAREFA A: Transforma\u00e7\u00e3o elemento-a-elemento (map)","text":"<p>Na aula passada foi pedido que voc\u00ea paralelizasse e analisasse este la\u00e7o:</p> <pre><code>#pragma omp parallel for schedule(runtime)\nfor (int i = 0; i &lt; N; i++) {\n    c[i] = alpha * a[i] + beta;\n}\n</code></pre> <ul> <li>Voc\u00ea executou com 1, 2, 4 e 8 threads.</li> <li>Testou diferentes <code>OMP_SCHEDULE</code> (<code>static</code>, <code>dynamic</code>, <code>guided</code>).</li> <li>Observou que o resultado n\u00e3o muda nunca, apenas o tempo de execu\u00e7\u00e3o varia.</li> </ul> <p>Este \u00e9 um exemplo de paralelismo seguro, pois cada itera\u00e7\u00e3o escreve em posi\u00e7\u00f5es diferentes do vetor <code>c</code>.</p> <p>Pergunta para pensar: por que este la\u00e7o \u00e9 naturalmente paraleliz\u00e1vel sem dar problemas?</p>"},{"location":"aulas/aula06/#tarefa-b-soma-reducao-da-norma-l2-parcial","title":"TAREFA B: Soma (redu\u00e7\u00e3o) da norma L2 parcial","text":"<p>Outro la\u00e7o analisado na aula passada foi:</p> <pre><code>double soma = 0.0;\n#pragma omp parallel for schedule(runtime)\nfor (int i = 0; i &lt; N; i++) {\n    soma += static_cast&lt;double&gt;(c[i]) * static_cast&lt;double&gt;(c[i]); // &lt;- condi\u00e7\u00e3o de corrida\n}\n</code></pre> <p>Neste caso os valores da soma ficaram inconsistentes. Isso acontece porque v\u00e1rias threads tentam atualizar a mesma vari\u00e1vel ao mesmo tempo \u2192 condi\u00e7\u00e3o de corrida (race condition).</p> <p>Pergunta para pensar: se for pedido ao SLURM cpus-per-task=1 n\u00e3o vemos inconsist\u00eancias no resultado da conta?</p>"},{"location":"aulas/aula06/#corrigindo-com-reduction","title":"Corrigindo com reduction","text":"<p>A corre\u00e7\u00e3o \u00e9 simples: usar uma redu\u00e7\u00e3o.</p> <pre><code>double soma = 0.0;\n#pragma omp parallel for schedule(runtime) reduction(+:soma)\nfor (int i = 0; i &lt; N; i++) {\n    soma += (double)c[i] * c[i]; // &lt;- corrigido\n}\n</code></pre> <p>Agora cada thread acumula uma soma local e no final todas s\u00e3o combinadas. O resultado fica est\u00e1vel e correto em qualquer n\u00famero de threads.</p>"},{"location":"aulas/aula06/#dependencia-de-dados","title":"Depend\u00eancia de dados","text":"<p>Nem todos os la\u00e7os podem ser paralelizados:</p> <pre><code>for (int i = 1; i &lt; N; i++) {\n    a[i] = a[i-1] + 1; // depende da itera\u00e7\u00e3o anterior\n}\n</code></pre> <p>Aqui h\u00e1 uma depend\u00eancia entre itera\u00e7\u00f5es: para calcular <code>a[i]</code> \u00e9 necess\u00e1rio j\u00e1 ter calculado <code>a[i-1]</code>. Paralelizar assim gera resultado incorreto.</p> <p>S\u00f3 \u00e9 poss\u00edvel resolver reformulando o algoritmo. O objetivo \u00e9 apenas perceber que nem todo loop \u00e9 paraleliz\u00e1vel.</p> <p>Maaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaas se observarmos bem, esse c\u00e1lculo \u00e9 apenas uma progress\u00e3o aritm\u00e9tica:</p> <ul> <li><code>a[1] = a[0] + 1</code></li> <li><code>a[2] = a[0] + 2</code></li> <li><code>a[3] = a[0] + 3</code></li> <li>\u2026</li> <li><code>a[i] = a[0] + i</code></li> </ul> <p>Ou seja, o valor de <code>a[i]</code> n\u00e3o precisa necessariamente <code>a[i-1]</code>, pode ser calculado diretamente.</p>"},{"location":"aulas/aula06/#versao-paralelizavel","title":"Vers\u00e3o paraleliz\u00e1vel:","text":"<pre><code>#pragma omp parallel for schedule(dynamic)\nfor (int i = 1; i &lt; N; i++) {\n    a[i] = a[0] + i;\n}\n</code></pre> <p>O loop original tem depend\u00eancia sequencial, mas ao analisar o padr\u00e3o, vemos que \u00e9 uma progress\u00e3o. Reformulando o c\u00e1lculo, eliminamos a depend\u00eancia, agora cada itera\u00e7\u00e3o \u00e9 independente e pode ser distribu\u00edda entre threads sem problemas. Esse exemplo \u00e9 \u00f3timo para mostrar que paralelizar n\u00e3o \u00e9 s\u00f3 usar <code>#pragma</code>, \u00e0s vezes \u00e9 preciso pensar no algoritmo.</p>"},{"location":"aulas/aula06/#recursao-com-tasks","title":"Recurs\u00e3o com tasks","text":"<p>O OpenMP tamb\u00e9m permite paralelizar recurs\u00e3o, mas com cuidado.</p> <p>Exemplo: Fibonacci recursivo.</p> <pre><code>int fib(int n) {\n    if (n &lt;= 1) return n;\n    int x, y;\n\n    #pragma omp task shared(x)\n    x = fib(n-1);\n\n    #pragma omp task shared(y)\n    y = fib(n-2);\n\n    #pragma omp taskwait\n    return x + y;\n}\n</code></pre> <p>Se voc\u00ea testar <code>fib(30)</code> ou <code>fib(35)</code>. Ver\u00e1 que muitas tasks pequenas podem at\u00e9 piorar o tempo, devido ao overhead.</p> <p>Pois \u00e9, nem sempre mais paralelismo significa mais velocidade.</p>"},{"location":"aulas/aula06/#conclusao","title":"Conclus\u00e3o","text":"<p>Na aula de hoje vimos que nem todo problema \u00e9 igual. No caso da transforma\u00e7\u00e3o elemento a elemento (map), o paralelismo funciona sem complica\u00e7\u00f5es porque cada itera\u00e7\u00e3o \u00e9 totalmente independente. J\u00e1 na soma parcial, o acesso simult\u00e2neo a uma vari\u00e1vel compartilhada gera condi\u00e7\u00f5es de corrida, que precisam ser resolvidas com mecanismos como <code>reduction</code>.</p> <p>Tamb\u00e9m vimos que alguns la\u00e7os possuem depend\u00eancia entre itera\u00e7\u00f5es, nestes casos, n\u00e3o basta inserir diretivas OpenMP: \u00e9 necess\u00e1rio repensar o algoritmo para eliminar a depend\u00eancia.</p> <p>Por fim, a experi\u00eancia com recurs\u00e3o e tasks mostrou que o paralelismo pode gerar overhead se n\u00e3o for bem controlado. Criar muitas tarefas pequenas pode ser pior do que executar de forma sequencial.</p> <p>Esta atividade n\u00e3o tem entrega, bom fim de semana!!!</p>"},{"location":"aulas/aula07/","title":"Aula 07 - Programa\u00e7\u00e3o Distribu\u00edda","text":"<p>Message Passing Interface (MPI) \u00e9 um padr\u00e3o para comunica\u00e7\u00e3o de dados em computa\u00e7\u00e3o paralela. Existem v\u00e1rias modalidades de computa\u00e7\u00e3o paralela, e dependendo do problema que se est\u00e1 tentando resolver, pode ser necess\u00e1rio passar informa\u00e7\u00f5es entre os v\u00e1rios processadores ou n\u00f3s de um cluster, e o MPI oferece uma infraestrutura para essa tarefa.</p> <p>Para iniciarmos o nosso estudo de MPI, implemente os desafios abaixo, entendendo como encadear sends e receives, e o impacto nos resultados.</p>"},{"location":"aulas/aula07/#ping-pong","title":"Ping-pong","text":"<p>A ideia \u00e9 medir a lat\u00eancia de comunica\u00e7\u00e3o ponto a ponto.</p> <p>Implemente o ping-pong: rank 0 envia uma mensagem ao rank 1, que responde. Fa\u00e7a duas vers\u00f5es:</p> <ul> <li>Bloqueante (<code>MPI_Send/MPI_Recv</code>)</li> <li>N\u00e3o-bloqueante (<code>MPI_Isend/Irecv + MPI_Wait</code>)</li> </ul> <p>Rode os testes:</p> <ul> <li>Mensagens de 16 B, 1 KB, 64 KB, 1 MB</li> <li>Em 2, 3 e 4 n\u00f3s </li> </ul> <p>Dica!</p> <p>Lembre-se, cada double ocupa 8 bytes, cada float ocupa 4 bytes, cada int ocupa 4 bytes, cada char, 1 byte.</p> <p>Analise: </p> <ul> <li>Para mensagens pequenas, o que domina: lat\u00eancia fixa ou tamanho da mensagem?</li> <li>A partir de que tamanho de mensagem o gargalo passa a ser a largura de banda da rede?</li> </ul> <p>C\u00f3digo base: <pre><code>#include &lt;mpi.h&gt;        // Biblioteca principal do MPI para comunica\u00e7\u00e3o entre processos\n#include &lt;iostream&gt;    \n#include &lt;cstring&gt;      \n\nint main(int argc, char** argv) {\n    int rank;               // Vari\u00e1vel que armazenar\u00e1 o \"rank\" (identificador) do processo\n    MPI_Status status;      // Estrutura que armazenar\u00e1 o status da comunica\u00e7\u00e3o MPI\n    char mensagem[100];     // Vetor de caracteres para armazenar a mensagem a ser enviada/recebida\n\n    // Inicializa o ambiente MPI (todos os processos s\u00e3o iniciados)\n    MPI_Init(&amp;argc, &amp;argv);\n\n    // Descobre o \"rank\" do processo atual dentro do comunicador global (MPI_COMM_WORLD)\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n\n    // Se este for o processo de rank 0 (emissor inicial)\n    if (rank == 0) {\n        // Copia a string \"Ol\u00e1\" para a vari\u00e1vel mensagem\n        std::strcpy(mensagem, \"Ol\u00e1\");\n\n        // Envia a mensagem para o processo de rank 1\n        // Par\u00e2metros: buffer, tamanho, tipo, destino, tag, comunicador\n        MPI_Send(mensagem, std::strlen(mensagem) + 1, MPI_CHAR, 1, 0, MPI_COMM_WORLD);\n\n        // Imprime no terminal que a mensagem foi enviada\n        std::cout &lt;&lt; \"Processo 0 enviou: \" &lt;&lt; mensagem &lt;&lt; std::endl;\n\n        // Aguarda a resposta do processo 1\n        // Par\u00e2metros: buffer, tamanho m\u00e1ximo, tipo, origem, tag, comunicador, status\n        MPI_Recv(mensagem, 100, MPI_CHAR, 1, 0, MPI_COMM_WORLD, &amp;status);\n\n        // Imprime a mensagem recebida\n        std::cout &lt;&lt; \"Processo 0 recebeu: \" &lt;&lt; mensagem &lt;&lt; std::endl;\n    }\n\n    // Se este for o processo de rank 1 (receptor inicial)\n    else if (rank == 1) {\n        // Recebe a mensagem enviada pelo processo 0\n        MPI_Recv(mensagem, 100, MPI_CHAR, 0, 0, MPI_COMM_WORLD, &amp;status);\n\n        // Imprime a mensagem recebida\n        std::cout &lt;&lt; \"Processo 1 recebeu: \" &lt;&lt; mensagem &lt;&lt; std::endl;\n\n        // Prepara a resposta \"Oi\"\n        std::strcpy(mensagem, \"Oi\");\n\n        // Envia a resposta de volta ao processo 0\n        MPI_Send(mensagem, std::strlen(mensagem) + 1, MPI_CHAR, 0, 0, MPI_COMM_WORLD);\n\n        // Imprime que a mensagem foi enviada\n        std::cout &lt;&lt; \"Processo 1 enviou: \" &lt;&lt; mensagem &lt;&lt; std::endl;\n    }\n\n    else {\n        // Todos os outros processos apenas informam que est\u00e3o ociosos\n        std::cout &lt;&lt; \"Processo \" &lt;&lt; rank &lt;&lt; \" est\u00e1 ocioso neste exerc\u00edcio.\" &lt;&lt; std::endl;\n    }\n\n    // Finaliza o ambiente MPI (todos os processos encerram)\n    MPI_Finalize();\n\n    return 0;\n}\n</code></pre></p>"},{"location":"aulas/aula07/#compile-o-programa","title":"Compile o programa:","text":"<pre><code>mpic++ -FlagdeOtimiza\u00e7\u00e3o seu_codigo.cpp -o seu_binario\n</code></pre>"},{"location":"aulas/aula07/#script-slurm","title":"Script SLURM","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=mpi_hello\n#SBATCH --output=saida%j.txt\n#SBATCH --partition=express\n#SBATCH --mem=1GB\n#SBATCH --nodes=2\n#SBATCH --ntasks=5\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:02:00\n#SBATCH --export=ALL\n\n# Execute o seu bin\u00e1rio com o MPI\nmpirun -np $SLURM_NTASKS ./seu_binario\n</code></pre>"},{"location":"aulas/aula07/#submeta-o-job-com-slurm","title":"Submeta o job com SLURM:","text":"<pre><code>sbatch SeuSlurm.slurm\n</code></pre>"},{"location":"aulas/aula07/#voce-deve-ver-algo-como-isso","title":"Voc\u00ea deve ver algo como isso:","text":"<pre><code>[liciascl@head-node mpi]$ cat saida.txt\nProcesso 2 est\u00e1 ocioso neste exerc\u00edcio.\nProcesso 3 est\u00e1 ocioso neste exerc\u00edcio.\nProcesso 0 enviou: Ol\u00e1\nProcesso 0 recebeu: Oi\nProcesso 1 recebeu: Ol\u00e1\nProcesso 1 enviou: Oi\nProcesso 4 est\u00e1 ocioso neste exerc\u00edcio.\n</code></pre> <p>Agora \u00e9 a sua vez!  Fa\u00e7a as altera\u00e7\u00f5es no c\u00f3digo exemplo e implemente as outras formas de comunica\u00e7\u00e3o entre n\u00f3s usando MPI</p>"},{"location":"aulas/aula07/#token-em-anel","title":"Token em anel","text":"<p>A ideia \u00e9 perceber o custo de coletar informa\u00e7\u00f5es sequencialmente.</p> <p>Implemente o token em anel: cada rank adiciona uma informa\u00e7\u00e3o nova ao vetor e passa adiante. Execute em 2, 3 e 4 n\u00f3s . Compare com o mesmo problema usando <code>MPI_Gather</code>.</p> <p>Analise:</p> <ul> <li>Como cresce o tempo do anel com o n\u00famero de processos?</li> <li>Qual o gargalo de percorrer todos em sequ\u00eancia?</li> <li>Qual a vantagem de usar <code>MPI_Gather</code>?</li> </ul>"},{"location":"aulas/aula07/#alternancia","title":"Altern\u00e2ncia","text":"<p>A ideia \u00e9 entender como funciona uma distribui\u00e7\u00e3o de tarefas.</p> <p>Rank 0 possui 13 tarefas cada uma com diferentes niveis de complexidade. Implemente uma distribui\u00e7\u00e3o din\u00e2mica de tarefas, o worker que terminar primeiro recebe a pr\u00f3xima tarefa.</p> <p>O que acontece quando as tarefas variam muito de custo?</p>"},{"location":"aulas/aula07/#o-que-voce-deve-entregar","title":"O que voc\u00ea deve entregar:","text":"<p>Para cada exerc\u00edcio:</p> <ol> <li>C\u00f3digo (dispon\u00edvel no reposit\u00f3rio do github).</li> <li>Tabela de resultados (par\u00e2metros usados, tempos medidos).</li> <li>Discuss\u00e3o: An\u00e1lise dos resultados</li> </ol> <p>Envie o seu relat\u00f3rio com as suas an\u00e1lises at\u00e9 as 23h59 de 08/09 pelo GitHub Classroom </p>"},{"location":"aulas/aula08/","title":"MPI e OpenMP","text":"<p>Agora que voc\u00eas aprenderam sobre MPI e j\u00e1 trabalharam bastante com OpenMP, vamos juntar o melhor dos dois mundos!</p> <p>Combinar essas duas abordagens \u00e9 uma estrat\u00e9gia poderosa em computa\u00e7\u00e3o de alto desempenho. Enquanto o OpenMP permite paralelizar tarefas de forma simples e eficiente dentro de uma mesma m\u00e1quina (mem\u00f3ria compartilhada), o MPI possibilita distribuir o trabalho entre v\u00e1rias m\u00e1quinas (mem\u00f3ria distribu\u00edda).</p> <p>Ao usar MPI + OpenMP juntos, conseguimos:</p> <ul> <li>Aproveitar ao m\u00e1ximo os recursos de clusters de alto desempenho, que possuem m\u00faltiplos n\u00f3s (com MPI) e m\u00faltiplos n\u00facleos por n\u00f3 (com OpenMP).</li> <li>Reduzir o overhead de comunica\u00e7\u00e3o, evitando o uso excessivo de mensagens MPI quando podemos usar threads locais com OpenMP.</li> <li>Escalar aplica\u00e7\u00f5es de forma mais eficiente, especialmente em tarefas intensivas como simula\u00e7\u00f5es cient\u00edficas, an\u00e1lise de dados em larga escala e modelagem computacional.</li> </ul> <p>A convolu\u00e7\u00e3o \u00e9 uma t\u00e9cnica amplamente utilizada em vis\u00e3o computacional, redes neurais, filtragem de sinais e imagens, e \u00e9 um excelente exemplo de aplica\u00e7\u00e3o que exige acesso a vizinhos para realizar o c\u00e1lculo de cada ponto da sa\u00edda. </p>"},{"location":"aulas/aula08/#o-que-o-codigo-faz","title":"O que o c\u00f3digo faz:","text":"<ol> <li>Inicializa uma imagem <code>1024x1024</code> em <code>rank 0</code>.</li> <li>Distribui a imagem completa para todos os processos via <code>MPI_Bcast</code>.</li> <li>Cada processo aplica a convolu\u00e7\u00e3o apenas na sua faixa de linhas.</li> <li>O c\u00e1lculo \u00e9 feito de forma paralela com OpenMP, em m\u00faltiplos cores locais.</li> <li>O resultado local de cada processo \u00e9 reunido no <code>rank 0</code> usando <code>MPI_Gather</code>.</li> <li>O processo <code>rank 0</code> imprime que a convolu\u00e7\u00e3o foi conclu\u00edda.</li> </ol> <p><code>conv.cpp</code> <pre><code>// Convolu\u00e7\u00e3o 2D com OpenMP + MPI\n// Objetivo: ilustrar os efeitos da combina\u00e7\u00e3o de paralelismo inter-n\u00f3 (MPI) e intra-n\u00f3 (OpenMP)\n\n#include &lt;mpi.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;algorithm&gt;\n#include &lt;cstdlib&gt;\n#include &lt;ctime&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;climits&gt;\n#include &lt;unistd.h&gt;\n\n#ifndef WIDTH\n#define WIDTH  1024\n#endif\n#ifndef HEIGHT\n#define HEIGHT 1024\n#endif\n\n#define KERNEL_SIZE 3\nstatic const float KERNEL[KERNEL_SIZE][KERNEL_SIZE] = {\n    {1.f/9, 1.f/9, 1.f/9},\n    {1.f/9, 1.f/9, 1.f/9},\n    {1.f/9, 1.f/9, 1.f/9},\n};\n\n// Indexa\u00e7\u00e3o linear (i,j) -&gt; i*WIDTH + j\nstatic inline int idx(int i, int j) { return i * WIDTH + j; }\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n\n    int rank = 0, size = 1;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    // Para manter o exemplo simples com MPI_Gather:\n    // exigimos divis\u00e3o exata de HEIGHT por size.\n    const int rows_per_process = HEIGHT / size;\n    const int remainder        = HEIGHT % size;\n    if (remainder != 0) {\n        if (rank == 0) {\n            std::cerr &lt;&lt; \"[ERRO] HEIGHT (\" &lt;&lt; HEIGHT &lt;&lt; \") n\u00e3o \u00e9 m\u00faltiplo de size (\"\n                      &lt;&lt; size &lt;&lt; \"). Escolha um n\u00famero de ranks que divida HEIGHT \"\n                      &lt;&lt; \"ou troque para MPI_Gatherv.\\n\";\n        }\n        MPI_Abort(MPI_COMM_WORLD, 1);\n    }\n\n    // Buffers cont\u00edguos\n    std::vector&lt;float&gt; image (HEIGHT * WIDTH);\n    std::vector&lt;float&gt; output(HEIGHT * WIDTH, 0.f);\n\n    // Rank 0 inicializa e depois faz broadcast\n    if (rank == 0) {\n        std::srand(static_cast&lt;unsigned&gt;(std::time(nullptr)));\n        for (int i = 0; i &lt; HEIGHT; ++i)\n            for (int j = 0; j &lt; WIDTH;  ++j)\n                image[idx(i,j)] = static_cast&lt;float&gt;(std::rand() % 256);\n    }\n    MPI_Bcast(image.data(), HEIGHT * WIDTH, MPI_FLOAT, 0, MPI_COMM_WORLD);\n\n    // Faixa deste rank\n    const int start_row = rank * rows_per_process;      // inclusivo\n    const int end_row   = start_row + rows_per_process; // exclusivo\n\n    // Faixa efetiva (evita bordas globais e do bloco)\n    const int i_begin = std::max(start_row, 1);\n    const int i_end   = std::min(end_row - 1, HEIGHT - 1); // exclusivo\n\n    // Cabe\u00e7alho por rank (ordenado para n\u00e3o embaralhar)\n    for (int r = 0; r &lt; size; ++r) {\n        MPI_Barrier(MPI_COMM_WORLD);\n        if (rank == r) {\n            char host[128]; gethostname(host, sizeof(host));\n            int tmax = omp_get_max_threads();\n            std::cout &lt;&lt; \"------------------------------------------------------------\\n\";\n            std::cout &lt;&lt; \"[Rank \" &lt;&lt; rank &lt;&lt; \" @ \" &lt;&lt; host &lt;&lt; \"] \"\n                      &lt;&lt; \"size=\" &lt;&lt; size\n                      &lt;&lt; \" | OMP_MAX_THREADS=\" &lt;&lt; tmax &lt;&lt; \"\\n\";\n            std::cout &lt;&lt; \"  Faixa de dados:    [\" &lt;&lt; start_row &lt;&lt; \",\" &lt;&lt; (end_row-1) &lt;&lt; \"]\\n\";\n            std::cout.flush();\n        }\n    }\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    // Vamos medir a faixa REAL tocada por cada thread\n    const int tmax = omp_get_max_threads();\n    std::vector&lt;int&gt; t_min(tmax, INT_MAX); // por thread\n    std::vector&lt;int&gt; t_max(tmax, INT_MIN);\n\n    MPI_Barrier(MPI_COMM_WORLD);\n    const double t0 = MPI_Wtime();\n\n    // Paraleliza SOMENTE no la\u00e7o de i (para facilitar leitura de faixas por thread)\n    #pragma omp parallel\n    {\n        const int tid = omp_get_thread_num();\n        int local_min = INT_MAX, local_max = INT_MIN;\n\n        #pragma omp for schedule(static)\n        for (int i = i_begin; i &lt; i_end; ++i) {\n            for (int j = 1; j &lt; WIDTH - 1; ++j) {\n                float sum = 0.f;\n                for (int ki = -1; ki &lt;= 1; ++ki)\n                    for (int kj = -1; kj &lt;= 1; ++kj)\n                        sum += image[idx(i+ki, j+kj)] * KERNEL[ki+1][kj+1];\n                output[idx(i,j)] = sum;\n            }\n            local_min = std::min(local_min, i);\n            local_max = std::max(local_max, i);\n        }\n\n        if (local_min &lt;= local_max) {\n            t_min[tid] = local_min;\n            t_max[tid] = local_max;\n        }\n    }\n\n    MPI_Barrier(MPI_COMM_WORLD);\n    const double t1 = MPI_Wtime();\n\n    // Impress\u00e3o das faixas por thread (ordenado por rank)\n    for (int r = 0; r &lt; size; ++r) {\n        MPI_Barrier(MPI_COMM_WORLD);\n        if (rank == r) {\n            std::cout &lt;&lt; \"[Rank \" &lt;&lt; rank &lt;&lt; \"] OpenMP (faixas por thread):\\n\";\n            bool alguma = false;\n            for (int t = 0; t &lt; tmax; ++t) {\n                if (t_min[t] &lt;= t_max[t]) {\n                    alguma = true;\n                    std::cout &lt;&lt; \"  - Thread \" &lt;&lt; t\n                              &lt;&lt; \" \u2192 linhas [\" &lt;&lt; t_min[t] &lt;&lt; \",\" &lt;&lt; t_max[t] &lt;&lt; \"]\\n\";\n                }\n            }\n            if (!alguma) std::cout &lt;&lt; \"  (nenhuma thread recebeu itera\u00e7\u00f5es)\\n\";\n            std::cout.flush();\n        }\n    }\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    // Re\u00fane as faixas (cont\u00edguas) no rank 0\n    MPI_Gather(output.data() + start_row * WIDTH,\n               rows_per_process * WIDTH, MPI_FLOAT,\n               output.data(),\n               rows_per_process * WIDTH, MPI_FLOAT,\n               0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        std::cout &lt;&lt; \"------------------------------------------------------------\\n\";\n        std::cout &lt;&lt; \"Convolu\u00e7\u00e3o conclu\u00edda!\\n\";\n        std::cout &lt;&lt; \"c\u00e1lculo local + sync: \" &lt;&lt; (t1 - t0) &lt;&lt; \" s\\n\";\n        std::cout &lt;&lt; \"Configura\u00e7\u00e3o: size=\" &lt;&lt; size\n                  &lt;&lt; \" | rows_per_process=\" &lt;&lt; rows_per_process\n                  &lt;&lt; \" | WIDTH=\" &lt;&lt; WIDTH &lt;&lt; \" | HEIGHT=\" &lt;&lt; HEIGHT &lt;&lt; \"\\n\";\n    }\n\n    MPI_Finalize();\n    return 0;\n}\n</code></pre></p>"},{"location":"aulas/aula08/#compile-o-binario-com-suporte-para-openmp-e-mpi","title":"Compile o bin\u00e1rio com suporte para OpenMP e MPI:","text":"<pre><code>mpic++ -O3 -fopenmp conv.cpp -o conv\n</code></pre>"},{"location":"aulas/aula08/#script-slurm","title":"Script SLURM","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=mpi_openmp\n#SBATCH --output=saida_%j.txt\n#SBATCH --nodes=4                 # 4 n\u00f3s (computadores)\n#SBATCH --ntasks-per-node=1       # 1 rank por n\u00f3\n#SBATCH --cpus-per-task=4         # 4 threads OMP por rank\n#SBATCH --time=00:10:00\n#SBATCH --partition=gpu\n#SBATCH --mem=1G                  # 1 GiB por n\u00f3\n\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}\nexport OMP_PROC_BIND=close\nexport OMP_PLACES=cores\n\n# Execute o seu bin\u00e1rio com o MPI\nmpirun -np $SLURM_NTASKS ./conv\n</code></pre>"},{"location":"aulas/aula08/#submeta-o-job-com-slurm","title":"Submeta o job com SLURM:","text":"<p><pre><code>sbatch SeuSlurm.slurm\n</code></pre> Com a configura\u00e7\u00e3o de hardware pedida ao Slurm, o programa vai rodar com 4 processos MPI (ranks). Como a imagem tem 1024 linhas, cada rank recebe exatamente 256 linhas para processar (1024 \u00f7 4 = 256).</p> <p>Dentro de cada rank, em vez de um \u00fanico n\u00facleo calcular todas as linhas, o trabalho \u00e9 dividido entre 4 threads usando o OpenMP. Ou seja: cada rank distribui suas 256 linhas entre 4 threads locais.</p> <p></p> <p>MPI divide a imagem entre os n\u00f3s (cada computador pega um peda\u00e7o), e OpenMP divide esse peda\u00e7o entre 4 CPU's dentro do n\u00f3 de computa\u00e7\u00e3o.</p>"},{"location":"aulas/aula08/#sua-vez","title":"Sua vez!","text":"<ol> <li>Quanto tempo esse c\u00f3digo leva pra rodar no modo sequencial?</li> <li>Remova <code>OpenMP</code> e compare os tempos s\u00f3 com MPI.</li> <li>Remova <code>MPI</code> e compare os tempos s\u00f3 com OpenMP.</li> <li>Me\u00e7a speedup em diferentes quantidades de processos e threads.</li> </ol>"},{"location":"aulas/aula09/","title":"Projeto 1 - Minera\u00e7\u00e3o de Hashes em ambiente de HPC","text":""},{"location":"aulas/aula09/#grupos-de-no-maximo-3-alunos-data-de-entrega-29setembro","title":"Grupos de no m\u00e1ximo 3 alunos, data de entrega 29/Setembro","text":"<p>Acesse o reposit\u00f3rio do projeto aqui</p> <p>Neste projeto, seu grupo dever\u00e1 diagnosticar e otimizar um algoritmo de minera\u00e7\u00e3o de criptomoedas implementado em C++. O c\u00f3digo inicial foi propositalmente escrito de forma ineficiente, apresentando gargalos p\u00e9ssimas pr\u00e1ticas de uso de mem\u00f3ria.</p> <p>Espera-se que seu grupo seja capaz de identificar esses problemas, propor hip\u00f3teses de melhoria, aplicar t\u00e9cnicas de otimiza\u00e7\u00e3o e mensurar o impacto das mudan\u00e7as no desempenho da aplica\u00e7\u00e3o. Ao final, seu grupo dever\u00e1 elaborar um relat\u00f3rio t\u00e9cnico, documentando todo o processo de an\u00e1lise e otimiza\u00e7\u00e3o.</p> <p>A dificuldade da minera\u00e7\u00e3o \u00e9 ajustada pela quantidade de zeros exigida no in\u00edcio do hash. \u00c0 medida que voc\u00eas aumentam essa dificuldade, o desafio computacional cresce, o que demanda boas decis\u00f5es de otimiza\u00e7\u00e3o e uso eficiente de CPU e mem\u00f3ria. Analise adequadamente os recursos dispon\u00edveis das filas do Cluster Franky para realizar os seus testes e suas otimiza\u00e7\u00f5es.</p>"},{"location":"aulas/aula09/#objetivo","title":"Objetivo","text":"<p>Aplicar conhecimentos de:</p> <ul> <li>An\u00e1lise de desempenho</li> <li>Diagn\u00f3stico de gargalos</li> <li>Boas pr\u00e1ticas de gerenciamento de mem\u00f3ria</li> <li>Paralelismo com OpenMP</li> <li>Distribui\u00e7\u00e3o com MPI</li> </ul>"},{"location":"aulas/aula09/#rubrica-de-avaliacao","title":"R\u00fabrica de Avalia\u00e7\u00e3o","text":"Conceito Crit\u00e9rios T\u00e9cnicos C Executa o minerador sequencial no cluster Franky com dificuldade 6 zeros, Realiza Passagem de objetos grandes por refer\u00eancia ou ponteiro; Minimiza\u00e7\u00e3o de c\u00f3pias desnecess\u00e1rias; Uso eficiente de buffers;  Implementa uma heur\u00edsitca eficiente. B Executa o minerador com dificuldade 7 zeros, Realiza as otimiza\u00e7\u00f5es da r\u00fabrica C e aplica paraleliza\u00e7\u00e3o com OpenMP ou distribui\u00e7\u00e3o com MPI A Executa o minerador com dificuldade 8 zeros, Realiza as otimiza\u00e7\u00f5es da r\u00fabrica C e aplica paraleliza\u00e7\u00e3o com OpenMP E distribui\u00e7\u00e3o com MPI"},{"location":"aulas/aula09/#entrega","title":"Entrega","text":"<p>A entrega deve conter:</p> <ol> <li> <p>O nome de cada integrante do grupo</p> </li> <li> <p>C\u00f3digo-fonte funcional</p> </li> <li> <p>Diagn\u00f3stico dos gargalos do c\u00f3digo base</p> </li> <li> <p>Proposta de otimiza\u00e7\u00e3o e hip\u00f3tese de melhoria</p> </li> <li> <p>Implementa\u00e7\u00e3o da hip\u00f3tese</p> </li> <li> <p>Compara\u00e7\u00e3o de desempenho (tempo, speedup, efici\u00eancia, etc.)</p> </li> <li> <p>Discuss\u00e3o dos resultados e limita\u00e7\u00f5es encontradas</p> </li> </ol>"},{"location":"aulas/aula09/#bonus-por-qualidade-do-relatorio-tecnico","title":"B\u00f4nus por Qualidade do relat\u00f3rio t\u00e9cnico","text":"Conceito Base Com B\u00f4nus C C+ B B+ A A+"},{"location":"aulas/aula09/#observacoes","title":"Observa\u00e7\u00f5es","text":"<ul> <li>Espera-se que o aluno entenda os problemas do c\u00f3digo base antes de corrigir.</li> <li>O bin\u00e1rio <code>transacoes</code> simula um ambiente de rede ass\u00edncrono com envio de blocos n\u00e3o simult\u00e2neos, para que o c\u00f3digo minerador seja tolerante a ordem e tempo de chegada.</li> <li>A execu\u00e7\u00e3o dos testes pode demorar minutos. Se planeje bem, escolha adequadamente a fila que ser\u00e1 utilizada nos seus testes.</li> </ul>"},{"location":"aulas/aula10/","title":"Acesso ao Supercomputador Santos Dumont (SDumont)","text":""},{"location":"aulas/aula10/#o-lncc","title":"O LNCC","text":"<p>O Laborat\u00f3rio Nacional de Computa\u00e7\u00e3o Cient\u00edfica (LNCC) \u00e9 uma unidade de pesquisa do Minist\u00e9rio da Ci\u00eancia, Tecnologia e Inova\u00e7\u00f5es (MCTI), especializada em computa\u00e7\u00e3o cient\u00edfica de alto desempenho, modelagem matem\u00e1tica, simula\u00e7\u00e3o e ci\u00eancia de dados. </p>"},{"location":"aulas/aula10/#o-supercomputador-santos-dumont","title":"O Supercomputador Santos Dumont","text":"<p>O SDumont \u00e9 o maior supercomputador da Am\u00e9rica Latina, operado pelo LNCC. Ele \u00e9 utilizado por pesquisadores e institui\u00e7\u00f5es de todo o Brasil em projetos de alto impacto, como simula\u00e7\u00f5es clim\u00e1ticas, modelagem molecular, bioinform\u00e1tica, intelig\u00eancia artificial, f\u00edsica computacional, entre outros.</p> <p>A infraestrutura do SDumont permite:</p> <ul> <li>Processamento massivo de dados cient\u00edficos;</li> <li>Execu\u00e7\u00e3o de simula\u00e7\u00f5es paralelas e distribu\u00eddas;</li> <li>Acesso remoto via SSH para submiss\u00e3o de jobs com uso de SLURM.</li> </ul>"},{"location":"aulas/aula10/#como-obter-acesso-ao-sdumont","title":"Como obter acesso ao SDumont","text":"<p>Para utilizar o SDumont voc\u00ea deve preencher e assinar o formul\u00e1rio oficial fornecido pelo LNCC.</p> <ol> <li>Preencha o formul\u00e1rio de acesso (dispon\u00edvel aqui) e assine o formul\u00e1rio;</li> </ol> <p>Preencha o documento conforme os exemplos abaixo:</p>"},{"location":"aulas/aula10/#dados-institucionais","title":"Dados Institucionais","text":"<ul> <li>Institui\u00e7\u00e3o: Insper  </li> <li>Telefone / Ramal: 4504-2400  </li> <li>Departamento / Instituto: Laborat\u00f3rio de Redes e Supercomputa\u00e7\u00e3o \u2013 Engenharia da Computa\u00e7\u00e3o  </li> <li>Cargo: Aluno</li> </ul>"},{"location":"aulas/aula10/#dados-do-projeto","title":"Dados do Projeto","text":"<ul> <li>Nome do Coordenador: L\u00edcia Sales Costa Lima  </li> <li>T\u00edtulo/Sigla do Projeto: Computa\u00e7\u00e3o de Alto Desempenho: Um Modelo de Ensino Pr\u00e1tico</li> </ul>"},{"location":"aulas/aula10/#assine-o-documento","title":"Assine o documento","text":"<p>Voc\u00ea pode optar por:</p> <ul> <li> <p>Assinar digitalmente com sua conta Gov.br pelo site https://assinador.iti.br/.</p> </li> <li> <p>ou assinar \u00e0 m\u00e3o, imprimir e escanear o formul\u00e1rio;</p> </li> </ul>"},{"location":"aulas/aula10/#proximos-passos","title":"Pr\u00f3ximos passos","text":"<p>Anexe ao e-mail um documento de identifica\u00e7\u00e3o oficial como RG ou CNH;</p> <p>Envie os documentos por e-mail para liciascl@insper.edu.br.</p> <p>Ap\u00f3s o envio, os formul\u00e1rios devidamente preenchidos e assinados ser\u00e3o encaminhados para o LNCC para cria\u00e7\u00e3o do acesso ao SDumont.</p> <p>Importante: O supercomputador SDumont \u00e9 uma ferramenta poderosa para aprendizado e pesquisa. Use-o com responsabilidade.</p> <p>Site oficial do Santos Dumont https://sdumont.lncc.br/index.php</p>"},{"location":"aulas/aula11/","title":"MPI e as Opera\u00e7\u00f5es Coletivas","text":"<p>No MPI existem duas formas de comunica\u00e7\u00e3o: a ponto-a-ponto e a coletiva. Na comunica\u00e7\u00e3o ponto-a-ponto, apenas dois processos participam: um envia (<code>MPI_Send</code>) e outro recebe (<code>MPI_Recv</code>).  </p> <p>J\u00e1 nas opera\u00e7\u00f5es coletivas, todos os processos de um comunicador (<code>MPI_COMM_WORLD</code>) precisam participar da mesma chamada ao mesmo tempo.  </p> <p>Quando dizemos que \u201cum processo chama a coletiva\u201d, significa que ele executa uma fun\u00e7\u00e3o como <code>MPI_Gather</code>, <code>MPI_Scatter</code> ou <code>MPI_Reduce</code>, junto com todos os outros processos do comunicador. Se algum processo n\u00e3o participar, os demais ficar\u00e3o bloqueados, pois o MPI espera que todos estejam presentes para completar a opera\u00e7\u00e3o.</p> <p>Mesmo quando existe um root, um processo principal que organiza a comunica\u00e7\u00e3o, todos os outros processos ainda assim chamam a fun\u00e7\u00e3o. O root apenas desempenha um papel diferente, como receber todos os dados (<code>Gather</code>), distribu\u00ed-los (<code>Scatter</code>) ou armazenar o resultado final (<code>Reduce</code>).</p>"},{"location":"aulas/aula11/#mpi_gather","title":"MPI_Gather","text":"<p>O <code>MPI_Gather</code> coleta dados de todos os processos e junta em um \u00fanico buffer no root. Cada processo envia a mesma quantidade de dados. O root recebe os blocos organizados na ordem dos ranks.</p> <p>As coletivas no MPI s\u00e3o opera\u00e7\u00f5es globais que substituem sequ\u00eancias de envios e recebimentos individuais. Elas funcionam porque todos os processos participam da chamada, garantindo sincroniza\u00e7\u00e3o e consist\u00eancia. O root organiza a opera\u00e7\u00e3o, mas nunca atua sozinho: ele \u00e9 apenas mais um processo dentro do grupo. </p>"},{"location":"aulas/aula11/#token-em-anel","title":"Token em anel","text":"<p>No anel, um \u00fanico \u201cpacote\u201d (token) d\u00e1 uma volta completa: cada processo recebe o vetor, acrescenta sua informa\u00e7\u00e3o e passa adiante. Assim, h\u00e1 N mensagens para N processos.</p> <p><code>anel_gather.cpp</code> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\nusing namespace std;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n\n    // ------------------------------------------------------------------\n    // [Etapa 0] Identifica\u00e7\u00e3o de ranks e processos\n    // ------------------------------------------------------------------\n    int rank = -1, size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);   // meu rank\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);   // total de processos\n\n    // ------------------------------------------------------------------\n    // [Etapa 1] setup dos vetores e buffers\n    // ------------------------------------------------------------------\n    const int chunk = 2048;                 \n    vector&lt;int&gt; local(chunk, -1);\n\n    if (rank != 0) {\n        // Preenche vetor local do worker de forma identific\u00e1vel\n        for (int i = 0; i &lt; chunk; ++i) local[i] = rank * 1000 + i;\n    }\n\n    // ------------------------------------------------------------------\n    // [Etapa 2] Tabelas de envio por rank \n    //           counts[r] = quantos elementos o rank r envia\n    //           displs[r] = deslocamento (em elementos) no recvbuf do ROOT\n    // ------------------------------------------------------------------\n    vector&lt;int&gt; counts(size, 0);\n    vector&lt;int&gt; displs(size, 0);\n\n    // ranks 1..size-1 enviam 'chunk'\n    for (int r = 1; r &lt; size; ++r) counts[r] = chunk;\n\n    // displs compactado: r=1 ocupa [0..chunk-1], r=2 ocupa [chunk..2*chunk-1], etc.\n    for (int r = 2; r &lt; size; ++r) displs[r] = displs[r - 1] + counts[r - 1];\n\n    // Tamanho total a receber no ROOT: soma(counts[r]) = (size-1)*chunk\n    int total_recv = 0;\n    for (int r = 0; r &lt; size; ++r) total_recv += counts[r];\n\n    // Buffer de recep\u00e7\u00e3o do ROOT\n    vector&lt;int&gt; result;\n    if (rank == 0) result.resize(total_recv);\n\n    // ------------------------------------------------------------------\n    // [Etapa 3] Par\u00e2metros de envio por processo \n    // ------------------------------------------------------------------\n    int   sendcount = 0;\n    int*  sendbuf   = nullptr;\n    int* recvbuf = nullptr;               \n\n\n    if (rank =! 0) {\n        // Workers enviam 'chunk' inteiros do seu vetor local\n        sendcount = chunk;\n        sendbuf   = local.data();\n    }\n\n    if (rank == 0) recvbuf = result.data();\n\n    // ------------------------------------------------------------------\n    // [Etapa 4] Coletiva \n    // ------------------------------------------------------------------\n    double t0 = MPI_Wtime();\n\n    MPI_Gatherv(\n        /*sendbuf   */ sendbuf,\n        /*sendcount */ sendcount,\n        /*sendtype  */ MPI_INT,\n        /*recvbuf   */ recvbuf,\n        /*recvcounts*/ counts.data(),\n        /*displs    */ displs.data(),\n        /*recvtype  */ MPI_INT,\n        /*root      */ 0,\n        /*comm      */ MPI_COMM_WORLD\n    );\n\n    double t1 = MPI_Wtime();\n\n    // ------------------------------------------------------------------\n    // [Etapa 5] Sa\u00edda: ROOT gerencia e imprime\n    // ------------------------------------------------------------------\n    if (rank == 0) {\n        cout &lt;&lt; \"[GATHER] N=\" &lt;&lt; size\n             &lt;&lt; \" (workers=\" &lt;&lt; (size - 1)\n             &lt;&lt; \") tempo=\" &lt;&lt; (t1 - t0) &lt;&lt; \" s\\n\";\n\n        // Amostra: 5 primeiros elementos de cada worker\n        for (int r = 1; r &lt; size; ++r) {\n            cout &lt;&lt; \"Rank \" &lt;&lt; r &lt;&lt; \": \";\n            int base = displs[r];\n            for (int i = 0; i &lt; 5; ++i) cout &lt;&lt; result[base + i] &lt;&lt; ' ';\n            cout &lt;&lt; \"...\\n\";\n        }\n    }\n\n    MPI_Finalize();\n    return 0;\n}\n</code></pre></p>"},{"location":"aulas/aula11/#como-compilar-e-rodar","title":"Como compilar e rodar","text":"<pre><code>mpic++ -O2 anel_gather.cpp -o anel_gather\n</code></pre> <p>Submetendo ao Slurm</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=gather               # nome do job\n#SBATCH --output=gather.%j.txt           # sa\u00edda em arquivo\n#SBATCH --time=00:05:00               # tempo limite\n#SBATCH --nodes=5                     # n\u00famero de n\u00f3s (Computadores)\n#SBATCH --ntasks=5                    # n\u00famero total de Ranks MPI\n#SBATCH --cpus-per-task=1             # CPUs por processo\n#SBATCH --partition=normal            # Fila do SLURM\n#SBATCH --mem=2GB                    # mem\u00f3ria solicitada\n\necho \"=== Executando com 2 processos ===\"\ntime mpirun -np 2 ./anel_gather\necho \"\"\n\necho \"=== Executando com 3 processos ===\"\ntime mpirun -np 3 ./anel_gather\necho \"\"\n\necho \"=== Executando com 4 processos ===\"\ntime mpirun -np 4 ./anel_gather\necho \"\"\n\necho \"=== Executando com 5 processos ===\"\ntime mpirun -np 5 ./anel_gather\necho \"\"\n</code></pre> <p>Este c\u00f3digo \u00e9 equivalente ao anterior, s\u00f3 que agora implementando usando Send/Recv</p> <p><code>anel_p2p.cpp</code> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\nusing namespace std;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);  // identifica o rank de cada processo\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);  // descobre quantos n\u00f3s est\u00e3o rodando\n\n    const int chunk = 2048;                // cada processo envia seu vetor\n\n    // Cada processo prepara seu vetor local \n    vector&lt;int&gt; local(chunk);\n    for (int i = 0; i &lt; chunk; i++) {\n        // preenche de forma did\u00e1tica\n        local[i] = rank * 1000 + i;\n    }\n\n    // O root precisa de um buffer para juntar TODOS os blocos: size * chunk\n    vector&lt;int&gt; result;\n    if (rank == 0) result.resize(size * chunk);\n\n    // Para comparar com o MPI_Gather, medimos somente a fase de troca de dados\n    double t0 = MPI_Wtime();\n\n    if (rank == 0) {\n        // 1) O root primeiro coloca o pr\u00f3prio bloco no lugar correto\n        //    (posi\u00e7\u00e3o 0 .. chunk-1, j\u00e1 que rank==0)\n        std::copy(local.begin(), local.end(), result.begin());\n\n        // 2) Em seguida, recebe de cada rank (1..size-1) o respectivo bloco\n        //    e grava diretamente na \u201cfaixa\u201d correta do vetor final.\n        for (int src = 1; src &lt; size; ++src) {\n            MPI_Recv(result.data() + src * chunk,   // destino no buffer final\n                     chunk, MPI_INT,                 // quantos / tipo\n                     src,                            // origem (rank esperado)\n                     0, MPI_COMM_WORLD,              // tag/comunicador\n                     MPI_STATUS_IGNORE);\n        }\n    } else {\n        // Ranks != root enviam seu bloco para o root\n        MPI_Send(local.data(), chunk, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n\n    double t1 = MPI_Wtime();\n\n    // Root imprime um resumo e alguns elementos para verifica\u00e7\u00e3o\n    if (rank == 0) {\n        cout &lt;&lt; \"[P2P] N=\" &lt;&lt; size\n             &lt;&lt; \" tempo=\" &lt;&lt; (t1 - t0) &lt;&lt; \" s\" &lt;&lt; endl;\n\n        // Mostra s\u00f3 os 5 primeiros valores de cada bloco para n\u00e3o poluir\n        for (int p = 0; p &lt; size; p++) {\n            cout &lt;&lt; \"Rank \" &lt;&lt; p &lt;&lt; \": \";\n            for (int i = 0; i &lt; 5; i++)\n                cout &lt;&lt; result[p * chunk + i] &lt;&lt; \" \";\n            cout &lt;&lt; \"...\\n\";\n        }\n    }\n\n    MPI_Finalize();\n    return 0;\n}\n</code></pre></p>"},{"location":"aulas/aula11/#como-compilar-e-rodar_1","title":"Como compilar e rodar","text":"<pre><code>mpic++ -O2 anel_p2p.cpp -o p2p\n</code></pre> <p>Submetendo ao Slurm</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=p2p               # nome do job\n#SBATCH --output=p2p.%j.txt           # sa\u00edda em arquivo\n#SBATCH --time=00:05:00               # tempo limite\n#SBATCH --nodes=5                    # n\u00famero de n\u00f3s (Computadores)\n#SBATCH --ntasks=5                    # n\u00famero total de Ranks MPI\n#SBATCH --cpus-per-task=1             # CPUs por processo\n#SBATCH --partition=normal            # Fila do SLURM\n#SBATCH --mem=1GB                    # mem\u00f3ria solicitada\n\necho \"=== Executando com 2 processos ===\"\nmpirun -np 2 ./p2p\necho \"==================================\"\n\necho \"=== Executando com 3 processos ===\"\nmpirun -np 3 ./p2p\necho \"==================================\"\n\necho \"=== Executando com 4 processos ===\"\nmpirun -np 4 ./p2p\necho \"==================================\"\n\necho \"=== Executando com 5 processos ===\"\nmpirun -np 5 ./p2p\necho \"==================================\"\n</code></pre>"},{"location":"aulas/aula12/","title":"Aula 12 - Exerc\u00edcios preparat\u00f3rios para AI","text":""},{"location":"aulas/aula12/#exercicios-para-estudar-para-ai","title":"Exerc\u00edcios para estudar para AI","text":"<p>A Ninja La\u00edz Freitas trabalhou na elabora\u00e7\u00e3o de  exerc\u00edcios para que voc\u00eas se ambientem com o estilo de prova e exercitem os seus conhecimentos, os Exerc\u00edcios est\u00e3o separados por aula, voc\u00ea pode acessa-los clicando aqui ou em \"Exerc\u00edcios\" ao lado de \"Suporte\";</p>"},{"location":"aulas/aula12/#simulado-ai","title":"Simulado AI","text":"<p>Al\u00e9m dos exerc\u00edcios preparados pela Ninja La\u00edz, tamb\u00e9m disponibilizo um simulado. A prova contar\u00e1 com quest\u00f5es te\u00f3ricas no Blackboard e quest\u00f5es pr\u00e1ticas no Classroom, elaboradas no mesmo n\u00edvel de dificuldade do simulado disponibilizado. </p> \"\u00c9 fundamental que voc\u00ea realize os testes necess\u00e1rios para garantir que o SMOWL esteja funcionando corretamente em seu computador antes da prova. A responsabilidade pela infraestrutura adequada \u00e9 inteiramente do aluno. Caso a ferramenta n\u00e3o esteja dispon\u00edvel, a sua prova ser\u00e1 anulada. Em situa\u00e7\u00f5es de dificuldade t\u00e9cnica, procure o Helpdesk."},{"location":"aulas/aula12/#questoes-teoricas","title":"Quest\u00f5es Te\u00f3ricas","text":"ATEN\u00c7\u00c3O: As respostas est\u00e3o gigantes para que voc\u00ea tenha material para estudar, ao responder na hora da prova, voc\u00ea pode ser mais direto. <p>1. Tiling</p> <p>Explique por que a t\u00e9cnica de tiling melhora o desempenho de programas paralelos.</p> <ul> <li>Relacione com hierarquia de mem\u00f3ria (L1, L2, L3, RAM).</li> <li>Diga por que, na pr\u00e1tica, costuma-se usar o tamanho da cache L2 como refer\u00eancia para o tamanho dos blocos.</li> </ul> Ver Resposta <pre><code>A t\u00e9cnica de tiling consiste em dividir um problema grande (matriz, vetor, dados) \nem sub-blocos menores, chamados de tiles, que s\u00e3o processados um de cada vez.\n\nO processador tem m\u00faltiplos n\u00edveis de mem\u00f3ria cache:\n\n- L1: muito r\u00e1pida, mas muito pequena. \n- L2: maior que L1, ainda r\u00e1pida.  \n- L3: bem maior, mas mais lenta que L1/L2 e \u00e9 compartilhada entre os cores.\n- RAM: muito maior, mas muito lenta comparada \u00e0s caches.\n\nSe os dados acessados couberem na cache, evitamos o custo de buscar na RAM.\n\nTrabalhar em blocos significa utilizar dados que j\u00e1 est\u00e3o na cache antes que sejam descartados.\n\nPor que usar L2 como refer\u00eancia para o tamanho dos blocos?\nO tiling melhora o desempenho porque organiza o acesso \u00e0 mem\u00f3ria de forma que os dados \n\u201cfiquem mais tempo nas caches r\u00e1pidas\u201d e menos tempo sendo buscados na RAM.\nUsar o tamanho da L2 \u00e9 a pr\u00e1tica comum porque ela oferece\no melhor equil\u00edbrio entre capacidade e lat\u00eancia.\n</code></pre> <p>2. Balanceamento de carga \u2014 OpenMP</p> <p>Considere um la\u00e7o paralelizado com OpenMP em que cada itera\u00e7\u00e3o tem custo vari\u00e1vel.</p> <ul> <li>Compare <code>schedule(static)</code> e <code>schedule(dynamic)</code>.</li> <li>Explique em qual cen\u00e1rio cada estrat\u00e9gia \u00e9 mais vantajosa.</li> <li>Cite uma situa\u00e7\u00e3o em que <code>schedule(guided)</code> pode ser melhor.</li> </ul> Ver Resposta <p>Quando usamos OpenMP, a forma como as itera\u00e7\u00f5es de um la\u00e7o s\u00e3o distribu\u00eddas entre as threads pode impactar o desempenho. O static divide o espa\u00e7o de itera\u00e7\u00f5es em blocos fixos e atribui cada bloco a uma thread antes da execu\u00e7\u00e3o come\u00e7ar. Essa estrat\u00e9gia tem a vantagem de ter overhead muito baixo, porque a divis\u00e3o \u00e9 feita apenas uma vez, e mant\u00e9m uma boa localidade de mem\u00f3ria, j\u00e1 que cada thread tende a percorrer regi\u00f5es cont\u00edguas do vetor ou da matriz. Por isso, o <code>schedule(static)</code> \u00e9 bastante eficiente quando o custo por itera\u00e7\u00e3o \u00e9 previs\u00edvel e relativamente uniforme.</p> <p>O dynamic funciona de forma adaptativa: as threads recebem blocos de itera\u00e7\u00f5es sob demanda e, assim que terminam, pegam novos blocos dispon\u00edveis. Esse modelo introduz mais overhead, porque \u00e9 necess\u00e1rio sincronizar a fila de tarefas v\u00e1rias vezes, e pode prejudicar um pouco a localidade de cache, j\u00e1 que as itera\u00e7\u00f5es n\u00e3o necessariamente ficam cont\u00edguas para cada thread. A contrapartida \u00e9 que essa abordagem consegue lidar melhor com la\u00e7os em que o custo das itera\u00e7\u00f5es \u00e9 irregular. Se algumas itera\u00e7\u00f5es demandam muito mais trabalho do que outras, o <code>dynamic</code> evita que uma thread fique sobrecarregada enquanto outras ficam ociosas, promovendo melhor balanceamento da carga de trabalho.</p> <p>O guided, \u00e9 uma varia\u00e7\u00e3o do dynamic. Os blocos come\u00e7am grandes e v\u00e3o diminuindo de tamanho conforme o la\u00e7o avan\u00e7a. Assim, o in\u00edcio da execu\u00e7\u00e3o tem menos overhead de gerenciamento, enquanto o final se beneficia de blocos menores que ajudam a equilibrar a carga restante. Essa estrat\u00e9gia \u00e9 \u00fatil quando temos um n\u00famero muito grande de itera\u00e7\u00f5es com custos vari\u00e1veis, pois combina a efici\u00eancia inicial de blocos maiores com a adaptabilidade final de blocos pequenos.</p> <p>Na pr\u00e1tica, escolhemos <code>static</code> para problemas regulares e previs\u00edveis, <code>dynamic</code> para casos irregulares ou imprevis\u00edveis, e <code>guided</code> quando queremos um meio-termo entre overhead baixo e balanceamento eficiente, quando temos la\u00e7os longos e diferentes complexidades computacionais.</p> <p>3. MPI \u2014 Comunica\u00e7\u00e3o</p> <p>Explique a diferen\u00e7a entre comunica\u00e7\u00e3o ponto-a-ponto e coletiva no MPI. D\u00ea um exemplo de uso para cada categoria.</p> Ver Resposta <p>A comunica\u00e7\u00e3o ponto-a-ponto ocorre quando dois processos trocam mensagens diretamente entre si, de forma expl\u00edcita. Normalmente, isso \u00e9 feito com fun\u00e7\u00f5es como <code>MPI_Send</code> e <code>MPI_Recv</code>. Nesse modelo, um processo envia uma mensagem contendo dados e outro processo, identificado pelo seu rank, recebe essa mensagem. Esse tipo de comunica\u00e7\u00e3o \u00e9 \u00fatil quando queremos ter controle fino sobre quem fala com quem e em que momento, como em um pipeline onde cada processo realiza uma etapa do c\u00e1lculo e passa o resultado para o pr\u00f3ximo.</p> <p>J\u00e1 a comunica\u00e7\u00e3o coletiva envolve um grupo inteiro de processos dentro de um comunicador, coordenando a troca de informa\u00e7\u00f5es de forma padronizada. Exemplos t\u00edpicos s\u00e3o <code>MPI_Bcast</code>, que envia uma mensagem de um processo para todos os outros, <code>MPI_Reduce</code>, que combina dados de todos os processos em um \u00fanico resultado, e <code>MPI_Gather</code>, que junta dados espalhados em um \u00fanico processo. Esse tipo de comunica\u00e7\u00e3o \u00e9 mais conveniente quando todos os processos precisam participar da mesma opera\u00e7\u00e3o, como calcular a soma global de resultados parciais de um vetor distribu\u00eddo entre diferentes processos.</p> <p>Assim, enquanto a comunica\u00e7\u00e3o ponto-a-ponto \u00e9 flex\u00edvel e granular, permitindo desenhar padr\u00f5es espec\u00edficos de intera\u00e7\u00e3o, a comunica\u00e7\u00e3o coletiva simplifica opera\u00e7\u00f5es envolvendo todos os processos.</p> <p>4. C\u00f3digos h\u00edbridos MPI+OpenMP</p> <p>Quais s\u00e3o as vantagens de combinar MPI e OpenMP em um cluster de HPC?</p> Ver Resposta <p>A principal vantagem de combinar MPI e OpenMP em um cluster de HPC \u00e9 aproveitar dois n\u00edveis de paralelismo ao mesmo tempo, MPI divide o trabalho entre os diferentes n\u00f3s do cluster (mem\u00f3ria distribu\u00edda). O OpenMP divide o trabalho entre os n\u00facleos de CPU dentro de cada n\u00f3 usando thread(mem\u00f3ria compartilhada).</p> <p>Isso reduz o n\u00famero de processos MPI, diminui o tr\u00e1fego de mensagens, e melhora o uso da cache dos n\u00f3s do cluster.</p> <p>5. Passagem por valor, refer\u00eancia e ponteiro</p> <p>a) Explique as diferen\u00e7as entre passagem por valor, refer\u00eancia e ponteiro em C++.  b) Em termos de c\u00f3pia de dados e efici\u00eancia, qual \u00e9 a diferen\u00e7a pr\u00e1tica?</p> Ver Resposta <p>Em C++, quando passamos um par\u00e2metro por valor, o compilador cria uma c\u00f3pia independente da vari\u00e1vel original. Isso garante seguran\u00e7a (o original nunca \u00e9 alterado), mas pode ser custoso se o objeto for grande, j\u00e1 que toda a c\u00f3pia precisa ser feita.</p> <p>Na passagem por refer\u00eancia, n\u00e3o h\u00e1 c\u00f3pia: a fun\u00e7\u00e3o recebe um \u201capelido\u201d para a vari\u00e1vel original. Assim, qualquer modifica\u00e7\u00e3o feita dentro da fun\u00e7\u00e3o afeta o valor fora dela. Essa forma \u00e9 eficiente porque evita c\u00f3pias desnecess\u00e1rias, mas exige cuidado para n\u00e3o alterar dados de forma indesejada.</p> <p>J\u00e1 na passagem por ponteiro, a fun\u00e7\u00e3o recebe o endere\u00e7o da vari\u00e1vel. A efici\u00eancia \u00e9 semelhante \u00e0 da refer\u00eancia (n\u00e3o h\u00e1 c\u00f3pia), mas o c\u00f3digo fica mais verboso e exige aten\u00e7\u00e3o extra, pois ponteiros podem ser nulos ou apontar para locais inv\u00e1lidos na mem\u00f3ria.</p> <p>Na pr\u00e1tica, a diferen\u00e7a est\u00e1 no custo de c\u00f3pia: valores grandes (como vetores ou objetos complexos) s\u00e3o muito mais eficientes quando passados por refer\u00eancia ou ponteiro. A passagem por valor s\u00f3 \u00e9 recomendada para tipos pequenos e triviais (como <code>int</code> ou <code>bool</code>).</p> <p>6. Escalonamento e desempenho</p> <p>a) Por que a escolha do escalonamento <code>schedule</code> pode afetar o desempenho de um programa paralelo com OpenMP?</p> <p>b) O que isso tem a ver com tiling (divis\u00e3o de blocos de dados) para encaixar na cache?</p> Ver Resposta <p>a) A escolha do <code>schedule</code> em OpenMP afeta diretamente como as itera\u00e7\u00f5es de um loop s\u00e3o distribu\u00eddas entre as threads, e isso tem impacto no equil\u00edbrio de carga e no uso eficiente da mem\u00f3ria. Se usamos <code>schedule(static)</code>, cada thread recebe blocos fixos de itera\u00e7\u00f5es, o que funciona bem quando todas as itera\u00e7\u00f5es t\u00eam custo parecido. Mas, se o custo variar, algumas threads podem terminar mais cedo e ficar ociosas, desperdi\u00e7ando desempenho. J\u00e1 <code>schedule(dynamic)</code> e <code>guided</code> permitem redistribuir itera\u00e7\u00f5es conforme as threads v\u00e3o terminando, equilibrando melhor a carga, mas com um pouco mais de overhead de gerenciamento.</p> <p>b) Esse conceito se conecta ao tiling porque dividir as os dados em blocos tamb\u00e9m \u00e9 uma forma de escalonamento, mas voltada para a hierarquia de mem\u00f3ria. Ao quebrar os dados em blocos do tamanho adequado para caber na cache, garantimos que cada thread trabalhe em um conjunto de dados cont\u00edguos e reutiliz\u00e1veis. Tanto o <code>schedule</code> quanto o <code>tiling</code> lidam com a divis\u00e3o do trabalho, o primeiro com balanceamento de carga entre n\u00f3s, o segundo com otimiza\u00e7\u00e3o da mem\u00f3ria cache.</p>"},{"location":"aulas/aula12/#questoes-praticas","title":"Quest\u00f5es Pr\u00e1ticas","text":"<p>7. Tiling em produto vetorial</p> <p>Implemente a multiplica\u00e7\u00e3o de dois vetores grandes em blocos <code>tiling</code>, comparando o desempenho com a vers\u00e3o ing\u00eanua.</p> <ul> <li>Use <code>Bsize</code> definido para caber na cache L2.</li> <li>Me\u00e7a o tempo de execu\u00e7\u00e3o com e sem tiling.</li> </ul> <pre><code>// q07.cpp\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nint main(int argc, char** argv) {\n    int N = (argc &gt; 1 ? std::atoi(argv[1]) : 1000000);\n    int Bsize = (argc &gt; 2 ? std::atoi(argv[2]) : 32768); // ajuste pensando na L2\n\n    std::vector&lt;float&gt; A(N, 1.1f), B(N, 2.2f), C_naive(N, 0.0f), C_tile(N, 0.0f);\n\n    // ===== Vers\u00e3o ing\u00eanua =====\n    std::chrono::high_resolution_clock::time_point t0 = std::chrono::high_resolution_clock::now();\n    // TODO: percorrer i=0..N-1 e preencher C_naive[i] = A[i] * B[i]\n    std::chrono::high_resolution_clock::time_point t1 = std::chrono::high_resolution_clock::now();\n\n    // ===== Vers\u00e3o com tiling =====\n    std::chrono::high_resolution_clock::time_point t2 = std::chrono::high_resolution_clock::now();\n    // TODO: la\u00e7o de blocos\n    std::chrono::high_resolution_clock::time_point t3 = std::chrono::high_resolution_clock::now();\n\n    double naive_ms = std::chrono::duration&lt;double, std::milli&gt;(t1 - t0).count();\n    double tile_ms  = std::chrono::duration&lt;double, std::milli&gt;(t3 - t2).count();\n\n    std::cout &lt;&lt; \"N=\" &lt;&lt; N &lt;&lt; \" Bsize=\" &lt;&lt; Bsize\n              &lt;&lt; \" naive_ms=\" &lt;&lt; naive_ms\n              &lt;&lt; \" tile_ms=\"  &lt;&lt; tile_ms &lt;&lt; \"\\n\";\n\n    // TODO: validar (comparar C_naive vs C_tile)\n    return 0;\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\n// Objetivo: comparar a vers\u00e3o ing\u00eanua (varre o vetor todo) com a vers\u00e3o em BLOCOS (tiling).\n// Melhor aproveitamento da cache: processamos blocos cont\u00edguos que \"cabem\" na L2.\n\nint main(int argc, char** argv) {\n    int N = (argc &gt; 1 ? std::atoi(argv[1]) : 1000000);\n    int Bsize = (argc &gt; 2 ? std::atoi(argv[2]) : 32768); // ajuste pensando na L2 (50\u201375% da L2/sizeof(float))\n\n    std::vector&lt;float&gt; A(N, 1.1f), B(N, 2.2f), C_naive(N, 0.0f), C_tile(N, 0.0f);\n\n    // ===== Vers\u00e3o ing\u00eanua (baseline) =====\n    std::chrono::high_resolution_clock::time_point t0 = std::chrono::high_resolution_clock::now();\n    for (int i = 0; i &lt; N; i++) {\n        C_naive[i] = A[i] * B[i];\n    }\n    std::chrono::high_resolution_clock::time_point t1 = std::chrono::high_resolution_clock::now();\n\n    // ===== Vers\u00e3o com tiling =====\n    // Percorre o vetor em janelas [start, end) cont\u00edguas \u2192 melhor localidade espacial.\n    std::chrono::high_resolution_clock::time_point t2 = std::chrono::high_resolution_clock::now();\n    for (int start = 0; start &lt; N; start += Bsize) {\n        int end = (start + Bsize &lt; N) ? (start + Bsize) : N;\n        for (int i = start; i &lt; end; i++) {\n            C_tile[i] = A[i] * B[i];\n        }\n    }\n    std::chrono::high_resolution_clock::time_point t3 = std::chrono::high_resolution_clock::now();\n\n    double naive_ms = std::chrono::duration&lt;double, std::milli&gt;(t1 - t0).count();\n    double tile_ms  = std::chrono::duration&lt;double, std::milli&gt;(t3 - t2).count();\n\n    // Valida\u00e7\u00e3o simples\n    int erros = 0;\n    for (int i = 0; i &lt; N; i++) {\n        if (C_naive[i] != C_tile[i]) { erros++; break; }\n    }\n\n    std::cout &lt;&lt; \"N=\" &lt;&lt; N &lt;&lt; \" Bsize=\" &lt;&lt; Bsize\n            &lt;&lt; \" naive_ms=\" &lt;&lt; naive_ms\n            &lt;&lt; \" tile_ms=\"  &lt;&lt; tile_ms\n            &lt;&lt; \" ok=\" &lt;&lt; (erros == 0) &lt;&lt; \"\\n\";\n    return 0;\n}\n</code></pre> <p>8. Balanceamento de carga em OpenMP</p> <p>Implemente um programa em C++ que conta quantos n\u00fameros primos existem em um vetor de inteiros grandes.</p> <ul> <li>Paralelize com <code>#pragma omp parallel for</code>.</li> <li>Encontre qual \u00e9 o menor custo de hardware para o melhor benef\u00edcio de otimiza\u00e7\u00e3o</li> </ul> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;omp.h&gt;\n\nstatic bool is_prime(unsigned x) {\n    // TODO: implementar teste de primalidade simples (ou copiar do material de exerc\u00edcios)\n    return false; \n}\n\nint main(int argc, char** argv) {\n    int N = (argc &gt; 1 ? std::atoi(argv[1]) : 500000);\n    unsigned seed = (argc &gt; 2 ? (unsigned)std::atoi(argv[2]) : 123u);\n\n    std::vector&lt;unsigned&gt; v(N);\n    std::mt19937 rng(seed);\n    std::uniform_int_distribution&lt;unsigned&gt; U(1u, 5000000u);\n    for (int i = 0; i &lt; N; i++) v[i] = U(rng);\n\n    long long total_primos = 0;\n    double t0 = omp_get_wtime();\n\n\n    //TODO paralelize adequadamente esse loop\n    for (int i = 0; i &lt; N; i++) {\n        // TODO: se for primo, incrementa a lista de primos\n    }\n\n    double t1 = omp_get_wtime();\n    std::cout &lt;&lt; \"N=\" &lt;&lt; N &lt;&lt; \" primos=\" &lt;&lt; total_primos\n              &lt;&lt; \" tempo_s=\" &lt;&lt; (t1 - t0) &lt;&lt; \"\\n\";\n    return 0;\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;omp.h&gt;\n\n// Fun\u00e7\u00e3o para verificar se um n\u00famero \u00e9 primo\nstatic bool eh_primo(unsigned int numero) {\n    if (numero &lt; 2) return false;                // menores que 2 n\u00e3o s\u00e3o primos\n    if (numero % 2 == 0) return numero == 2;     // m\u00faltiplos de 2 s\u00f3 s\u00e3o primos se forem o pr\u00f3prio 2\n\n    // Testa apenas divisores \u00edmpares at\u00e9 a raiz quadrada do n\u00famero\n    unsigned int divisor = 3;\n    while (divisor * divisor &lt;= numero) {\n        if (numero % divisor == 0) return false; // achou divisor \u2192 n\u00e3o \u00e9 primo\n        divisor += 2;                            // incrementa de 2 em 2 \u2192 s\u00f3 \u00edmpares\n    }\n    return true;\n}\n\nint main(int argc, char** argv) {\n    // Quantos n\u00fameros vamos testar (padr\u00e3o = 500.000)\n    int quantidade_numeros = (argc &gt; 1 ? std::atoi(argv[1]) : 500000);\n\n    // Semente para o gerador de n\u00fameros aleat\u00f3rios (padr\u00e3o = 123)\n    unsigned int semente = (argc &gt; 2 ? (unsigned int)std::atoi(argv[2]) : 123);\n\n    // Vetor que guarda os n\u00fameros aleat\u00f3rios\n    std::vector&lt;unsigned int&gt; numeros(quantidade_numeros);\n\n    // Gerador pseudoaleat\u00f3rio\n    std::mt19937 gerador(semente);\n    std::uniform_int_distribution&lt;unsigned int&gt; distribuicao(1, 5000000);\n\n    // Preenche o vetor com n\u00fameros aleat\u00f3rios entre 1 e 5.000.000\n    for (int i = 0; i &lt; quantidade_numeros; i++) {\n        numeros[i] = distribuicao(gerador);\n    }\n\n    long long contador_primos = 0;  // contador de primos encontrados\n\n    // Marca tempo inicial\n    double tempo_inicio = omp_get_wtime();\n\n    // Loop paralelo com OpenMP\n    // - Cada thread pega um peda\u00e7o do vetor\n    // - reduction(+:contador_primos) \u2192 soma local de cada thread \u00e9 acumulada corretamente\n    // - schedule(static,4) \u2192 podemos testar com OMP_SCHEDULE=dynamic,4 ou guided,4\n    #pragma omp parallel for reduction(+:contador_primos) schedule(static,4)\n    for (int i = 0; i &lt; quantidade_numeros; i++) {\n        if (eh_primo(numeros[i])) {\n            contador_primos += 1;\n        }\n    }\n\n    // Marca tempo final\n    double tempo_fim = omp_get_wtime();\n\n    // Exibe resultados\n    std::cout &lt;&lt; \"Total de numeros testados = \" &lt;&lt; quantidade_numeros &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Quantidade de primos encontrados = \" &lt;&lt; contador_primos &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Tempo de execucao = \" &lt;&lt; (tempo_fim - tempo_inicio) &lt;&lt; \" segundos\\n\";\n\n    return 0;\n}\n</code></pre> <p>9. MPI \u2014 Somas distribu\u00eddas</p> <p>Escreva um programa MPI que:</p> <ul> <li>Inicializa um vetor de tamanho <code>N</code> no <code>rank 0</code>.</li> <li>Divide o vetor com <code>MPI_Scatter</code>.</li> <li>Cada processo calcula a soma parcial.</li> <li>Usa <code>MPI_Reduce</code> para calcular a soma total no <code>rank 0</code>.</li> </ul> <pre><code>// q09_mpi_soma.cpp\n#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;cstdlib&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n\n    int rank = 0, size = 1;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = (argc &gt; 1 ? std::atoi(argv[1]) : (1 &lt;&lt; 20));\n    std::vector&lt;int&gt; v;\n    if (rank == 0) {\n        v.resize(N);\n        for (int i = 0; i &lt; N; i++) v[i] = i % 10;\n    }\n\n    // Assumimos N % size == 0 neste esqueleto\n    int chunk = N / size;\n    std::vector&lt;int&gt; local(chunk);\n\n    // TODO dividir o vetor com  MPI scatter\n\n    long long soma_local = 0;\n    // TODO: somar todos os elementos do vetor local[0..chunk-1] em soma_local\n\n    long long soma_total = 0;\n\n    // TODO: implementar MPI Reduce\n    if (rank == 0) {\n        std::cout &lt;&lt; \"Soma total = \" &lt;&lt; soma_total &lt;&lt; \"\\n\";\n    }\n\n    MPI_Finalize();\n    return 0;\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;mpi.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;cstdlib&gt;\n\n// Padr\u00e3o: assume N % size == 0 para simplicidade.\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n\n    int rank = 0, size = 1;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = (argc &gt; 1 ? std::atoi(argv[1]) : (1 &lt;&lt; 20)); // ~1M\n    std::vector&lt;int&gt; v;\n    if (rank == 0) {\n        v.resize(N);\n        for (int i = 0; i &lt; N; i++) v[i] = i % 10; // dados simples\n    }\n\n    int chunk = N / size;\n    std::vector&lt;int&gt; local(chunk);\n\n    // Divide o vetor v em peda\u00e7os cont\u00edguos para todos os ranks\n    MPI_Scatter(v.data(), chunk, MPI_INT,\n                local.data(), chunk, MPI_INT,\n                0, MPI_COMM_WORLD);\n\n    // Soma local do peda\u00e7o recebido\n    long long soma_local = 0;\n    for (int i = 0; i &lt; chunk; i++) soma_local += local[i];\n\n    // Reduz todas as somas locais para o rank 0\n    long long soma_total = 0;\n    MPI_Reduce(&amp;soma_local, &amp;soma_total, 1, MPI_LONG_LONG, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        std::cout &lt;&lt; \"Soma total = \" &lt;&lt; soma_total &lt;&lt; \"\\n\";\n    }\n\n    MPI_Finalize();\n    return 0;\n}\n</code></pre> <p>10. C\u00f3digo h\u00edbrido MPI+OpenMP</p> <p>Implemente um programa que calcula o produto escalar entre dois vetores grandes:</p> <ul> <li>Distribua os vetores entre os processos com <code>MPI_Scatter</code>.</li> <li>Cada processo calcula a soma parcial com OpenMP reduction.</li> <li>Combine os resultados no <code>rank 0</code> com <code>MPI_Reduce</code>.</li> </ul> <pre><code>// q10_hibrido_dot.cpp\n#include &lt;mpi.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;cstdlib&gt;\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n\n    int rank = 0, size = 1;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = (argc &gt; 1 ? std::atoi(argv[1]) : (1 &lt;&lt; 20));\n    std::vector&lt;float&gt; v, w;\n    if (rank == 0) {\n        v.assign(N, 1.0f);\n        w.assign(N, 2.0f);\n    }\n\n    int chunk = N / size; // esqueleto simples (N m\u00faltiplo de size)\n    std::vector&lt;float&gt; vl(chunk), wl(chunk);\n    //TODO: implementar o MPI_scatter para o vetor v\n\n    //TODO: implementar o MPI_scatter para o vetor w\n\n    double soma_local = 0.0;\n\n    // TODO: paralelizar com OpenMP  e calcular soma_local \n\n    double soma_total = 0.0;\n    // TODO implementar MPI_Reduce \n\n    if (rank == 0) {\n        std::cout &lt;&lt; \"dot = \" &lt;&lt; soma_total &lt;&lt; \"\\n\";\n    }\n\n    MPI_Finalize();\n    return 0;\n}\n</code></pre> Ver respostas <pre><code>#include &lt;mpi.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;cstdlib&gt;\n\n// Estrat\u00e9gia: Scatter v e w, cada processo calcula produto parcial com OpenMP (reduction),\n// depois Reduce (soma) no rank 0.\n\nint main(int argc, char** argv) {\n    MPI_Init(&amp;argc, &amp;argv);\n\n    int rank = 0, size = 1;\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    int N = (argc &gt; 1 ? std::atoi(argv[1]) : (1 &lt;&lt; 20));\n    std::vector&lt;float&gt; v, w;\n    if (rank == 0) {\n        v.assign(N, 1.0f);\n        w.assign(N, 2.0f);\n    }\n\n    int chunk = N / size; // simples: N m\u00faltiplo de size\n    std::vector&lt;float&gt; vl(chunk), wl(chunk);\n\n    MPI_Scatter(v.data(), chunk, MPI_FLOAT, vl.data(), chunk, MPI_FLOAT, 0, MPI_COMM_WORLD);\n    MPI_Scatter(w.data(), chunk, MPI_FLOAT, wl.data(), chunk, MPI_FLOAT, 0, MPI_COMM_WORLD);\n\n    // Redu\u00e7\u00e3o em double reduz erro de arredondamento\n    double soma_local = 0.0;\n\n    // Paralelismo intra-n\u00f3 com OpenMP\n    #pragma omp parallel for reduction(+:soma_local) schedule(static)\n    for (int i = 0; i &lt; chunk; i++) {\n        soma_local += (double)vl[i] * (double)wl[i];\n    }\n\n    double soma_total = 0.0;\n    MPI_Reduce(&amp;soma_local, &amp;soma_total, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        std::cout &lt;&lt; \"dot = \" &lt;&lt; soma_total &lt;&lt; \"\\n\";\n    }\n\n    MPI_Finalize();\n    return 0;\n}\n</code></pre> <p>11. Otimiza\u00e7\u00e3o com passagem por refer\u00eancia</p> <p>Implemente duas vers\u00f5es de uma fun\u00e7\u00e3o que calcula a m\u00e9dia m\u00f3vel de um vetor de <code>double</code>:</p> <ul> <li>Vers\u00e3o (a) recebe os dados por valor.</li> <li>Vers\u00e3o (b) recebe os dados por refer\u00eancia constante.</li> <li>Compare os tempos de execu\u00e7\u00e3o para vetores de 10\u2076 elementos e indique qual foi a vers\u00e3o mais eficiente e justifique porque.</li> </ul> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n\n// (a) M\u00e9dia m\u00f3vel passando POR VALOR (copia 'dados')\nstd::vector&lt;double&gt; media_movel_por_valor(std::vector&lt;double&gt; dados, std::size_t janela_K) {\n    // TODO: validar janela_K (0 &lt; janela_K &lt;= dados.size())\n    // TODO: somar os 'janela_K' primeiros elementos\n    // TODO: empurrar a primeira m\u00e9dia para o vetor de sa\u00edda\n    // TODO: janela deslizante: para i = janela_K..N-1\n    //       soma += dados[i] - dados[i - janela_K];\n    //       empurrar nova m\u00e9dia\n    return std::vector&lt;double&gt;();\n}\n\n// (b) TODO passe os dados POR REFER\u00caNCIA \nstd::vector&lt;double&gt; media_movel_por_referencia(std::vector&lt;double&gt; dados, std::size_t janela_K){\n    // TODO: mesma l\u00f3gica da vers\u00e3o por valor, mas SEM copiar 'dados'\n    return std::vector&lt;double&gt;();\n}\n\nint main(int argc, char** argv) {\n    // Par\u00e2metros de entrada\n    std::size_t tamanho_N = (argc &gt; 1 ? (std::size_t)std::atoll(argv[1]) : 1000000);\n    std::size_t janela_K  = (argc &gt; 2 ? (std::size_t)std::atoll(argv[2]) : 128);\n\n    // Gera dados aleat\u00f3rios em [0,1)\n    std::vector&lt;double&gt; vetor_dados(tamanho_N);\n    std::mt19937_64 gerador(42u);\n    std::uniform_real_distribution&lt;double&gt; distribuicao(0.0, 1.0);\n    for (std::size_t i = 0; i &lt; tamanho_N; i++) {\n        vetor_dados[i] = distribuicao(gerador);\n    }\n\n    // Mede tempo da vers\u00e3o por VALOR\n    std::chrono::high_resolution_clock::time_point inicio_valor = std::chrono::high_resolution_clock::now();\n    std::vector&lt;double&gt; medias_valor = media_movel_por_valor(vetor_dados, janela_K);\n    std::chrono::high_resolution_clock::time_point fim_valor = std::chrono::high_resolution_clock::now();\n\n    // Mede tempo da vers\u00e3o por REFER\u00caNCIA\n    std::chrono::high_resolution_clock::time_point inicio_referencia = std::chrono::high_resolution_clock::now();\n    std::vector&lt;double&gt; medias_referencia = media_movel_por_referencia(vetor_dados, janela_K);\n    std::chrono::high_resolution_clock::time_point fim_referencia = std::chrono::high_resolution_clock::now();\n\n    // C\u00e1lculo de tempos (ms)\n    double tempo_valor_ms      = std::chrono::duration&lt;double, std::milli&gt;(fim_valor - inicio_valor).count();\n    double tempo_referencia_ms = std::chrono::duration&lt;double, std::milli&gt;(fim_referencia - inicio_referencia).count();\n\n    // Valida\u00e7\u00e3o simples (toler\u00e2ncia num\u00e9rica)\n    bool resultados_iguais = (medias_valor.size() == medias_referencia.size());\n    for (std::size_t i = 0; resultados_iguais &amp;&amp; i &lt; medias_valor.size(); i++) {\n        if (std::abs(medias_valor[i] - medias_referencia[i]) &gt; 1e-12) {\n            resultados_iguais = false;\n        }\n    }\n\n    // Sa\u00edda\n    std::cout &lt;&lt; \"tempo_valor_ms=\" &lt;&lt; tempo_valor_ms\n              &lt;&lt; \" tempo_referencia_ms=\" &lt;&lt; tempo_referencia_ms\n              &lt;&lt; \" iguais=\" &lt;&lt; (resultados_iguais ? 1 : 0) &lt;&lt; \"\\n\";\n\n    return 0;\n}\n</code></pre> Ver resposta <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n#include &lt;cmath&gt;\n\n// (a) M\u00e9dia m\u00f3vel passando POR VALOR (copia 'dados')\nstd::vector&lt;double&gt; media_movel_por_valor(std::vector&lt;double&gt; dados, std::size_t janela_K) {\n    std::vector&lt;double&gt; medias;\n    if (janela_K == 0 || janela_K &gt; dados.size()) return medias;\n\n    // soma inicial dos K primeiros\n    double soma = 0.0;\n    for (std::size_t i = 0; i &lt; janela_K; i++) {\n        soma += dados[i];\n    }\n    medias.push_back(soma / (double)janela_K);\n\n    // janela deslizante\n    for (std::size_t i = janela_K; i &lt; dados.size(); i++) {\n        soma += dados[i];                 // entra o novo\n        soma -= dados[i - janela_K];     // sai o antigo\n        medias.push_back(soma / (double)janela_K);\n    }\n    return medias;\n}\n\n// (b) M\u00e9dia m\u00f3vel passando POR REFER\u00caNCIA \nstd::vector&lt;double&gt; media_movel_por_referencia(const std::vector&lt;double&gt;&amp; dados, std::size_t janela_K) {\n    std::vector&lt;double&gt; medias;\n    if (janela_K == 0 || janela_K &gt; dados.size()) return medias;\n\n    double soma = 0.0;\n    for (std::size_t i = 0; i &lt; janela_K; i++) {\n        soma += dados[i];\n    }\n    medias.push_back(soma / (double)janela_K);\n\n    for (std::size_t i = janela_K; i &lt; dados.size(); i++) {\n        soma += dados[i];\n        soma -= dados[i - janela_K];\n        medias.push_back(soma / (double)janela_K);\n    }\n    return medias;\n}\n\nint main(int argc, char** argv) {\n    // Par\u00e2metros de entrada\n    std::size_t tamanho_N = (argc &gt; 1 ? (std::size_t)std::atoll(argv[1]) : 1000000);\n    std::size_t janela_K  = (argc &gt; 2 ? (std::size_t)std::atoll(argv[2]) : 128);\n\n    // Gera dados aleat\u00f3rios em [0,1)\n    std::vector&lt;double&gt; vetor_dados(tamanho_N);\n    std::mt19937_64 gerador(42u);\n    std::uniform_real_distribution&lt;double&gt; distribuicao(0.0, 1.0);\n    for (std::size_t i = 0; i &lt; tamanho_N; i++) {\n        vetor_dados[i] = distribuicao(gerador);\n    }\n\n    // Mede tempo da vers\u00e3o por VALOR\n    std::chrono::high_resolution_clock::time_point inicio_valor = std::chrono::high_resolution_clock::now();\n    std::vector&lt;double&gt; medias_valor = media_movel_por_valor(vetor_dados, janela_K);\n    std::chrono::high_resolution_clock::time_point fim_valor = std::chrono::high_resolution_clock::now();\n\n    // Mede tempo da vers\u00e3o por REFER\u00caNCIA\n    std::chrono::high_resolution_clock::time_point inicio_referencia = std::chrono::high_resolution_clock::now();\n    std::vector&lt;double&gt; medias_referencia = media_movel_por_referencia(vetor_dados, janela_K);\n    std::chrono::high_resolution_clock::time_point fim_referencia = std::chrono::high_resolution_clock::now();\n\n    // C\u00e1lculo de tempos (ms)\n    double tempo_valor_ms      = std::chrono::duration&lt;double, std::milli&gt;(fim_valor - inicio_valor).count();\n    double tempo_referencia_ms = std::chrono::duration&lt;double, std::milli&gt;(fim_referencia - inicio_referencia).count();\n\n    // Valida\u00e7\u00e3o simples (toler\u00e2ncia num\u00e9rica)\n    bool resultados_iguais = (medias_valor.size() == medias_referencia.size());\n    for (std::size_t i = 0; resultados_iguais &amp;&amp; i &lt; medias_valor.size(); i++) {\n        if (std::abs(medias_valor[i] - medias_referencia[i]) &gt; 1e-12) {\n            resultados_iguais = false;\n        }\n    }\n\n    // Sa\u00edda\n    std::cout &lt;&lt; \"tempo_valor_ms=\" &lt;&lt; tempo_valor_ms\n            &lt;&lt; \" tempo_referencia_ms=\" &lt;&lt; tempo_referencia_ms\n            &lt;&lt; \" iguais=\" &lt;&lt; (resultados_iguais ? 1 : 0) &lt;&lt; \"\\n\";\n\n    return 0;\n}\n</code></pre> <p>12. Otimiza\u00e7\u00e3o com ponteiros</p> <p>Implemente uma fun\u00e7\u00e3o em C++ que calcula a m\u00e9dia m\u00f3vel de um vetor usando aritm\u00e9tica de ponteiros em vez de \u00edndices.</p> <ul> <li>Compare o desempenho com a vers\u00e3o que usa \u00edndices tradicionais.</li> <li>Mostre que <code>*(ptr + i)</code> \u00e9 equivalente a <code>ptr[i]</code>.</li> </ul> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n\nstd::vector&lt;double&gt; media_movel_ptr(const double* ptr, std::size_t N, std::size_t K) {\n    // TODO: validar ponteiro e K\n    // TODO: somar os K primeiros usando *(ptr + i) e empurrar a m\u00e9dia\n    // TODO: janela deslizante: soma += *(ptr + i) - *(ptr + i - K); push m\u00e9dia\n    return std::vector&lt;double&gt;();\n}\n\nint main(int argc, char** argv) {\n    std::size_t N = (argc &gt; 1 ? (std::size_t)std::atoll(argv[1]) : 1000000);\n    std::size_t K = (argc &gt; 2 ? (std::size_t)std::atoll(argv[2]) : 256);\n\n    std::vector&lt;double&gt; v(N);\n    std::mt19937_64 rng(123u);\n    std::uniform_real_distribution&lt;double&gt; U(0.0, 1.0);\n    for (std::size_t i = 0; i &lt; N; i++) v[i] = U(rng);\n\n    std::chrono::high_resolution_clock::time_point t0 = std::chrono::high_resolution_clock::now();\n    std::vector&lt;double&gt; mv = media_movel_ptr(v.data(), v.size(), K);\n    std::chrono::high_resolution_clock::time_point t1 = std::chrono::high_resolution_clock::now();\n\n    std::cout &lt;&lt; \"ptr_ms=\" &lt;&lt; std::chrono::duration&lt;double, std::milli&gt;(t1 - t0).count()\n              &lt;&lt; \" out_size=\" &lt;&lt; mv.size() &lt;&lt; \"\\n\";\n\n    // TODO: comparar com vers\u00e3o por refer\u00eancia/\u00edndices\n    return 0;\n}\n</code></pre> Ver Resposta <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n#include &lt;cmath&gt;\n\n// Fun\u00e7\u00e3o: calcula a m\u00e9dia m\u00f3vel de tamanho janela_K usando ponteiros\nstd::vector&lt;double&gt; media_movel_ptr(const double* dados_ptr, size_t tamanho_N, size_t janela_K) {\n    // Valida\u00e7\u00e3o de entrada\n    if (dados_ptr == nullptr) return std::vector&lt;double&gt;();\n    if (janela_K == 0 || janela_K &gt; tamanho_N) return std::vector&lt;double&gt;();\n\n    std::vector&lt;double&gt; medias;  // vetor de sa\u00edda\n    double soma = 0.0;           // acumulador da janela\n\n    // Soma inicial dos primeiros K elementos\n    for (size_t i = 0; i &lt; janela_K; i++) {\n        soma += *(dados_ptr + i);   // equivalente a dados_ptr[i]\n    }\n    medias.push_back(soma / (double)janela_K);\n\n    // Janela deslizante: entra um elemento novo, sai o mais antigo\n    for (size_t i = janela_K; i &lt; tamanho_N; i++) {\n        soma += *(dados_ptr + i);           // adiciona o novo\n        soma -= *(dados_ptr + i - janela_K); // remove o antigo\n        medias.push_back(soma / (double)janela_K);\n    }\n\n    return medias;\n}\n\nint main(int argc, char** argv) {\n    // Tamanho do vetor e janela definidos pela linha de comando ou valores padr\u00e3o\n    size_t tamanho_N = (argc &gt; 1 ? (size_t)std::atoll(argv[1]) : 1000000);\n    size_t janela_K  = (argc &gt; 2 ? (size_t)std::atoll(argv[2]) : 256);\n\n    // Cria vetor de dados aleat\u00f3rios no intervalo [0, 1)\n    std::vector&lt;double&gt; vetor_dados(tamanho_N);\n    std::mt19937 gerador(123);  // gerador pseudoaleat\u00f3rio com semente fixa\n    std::uniform_real_distribution&lt;double&gt; distribuicao(0.0, 1.0);\n\n    for (size_t i = 0; i &lt; tamanho_N; i++) {\n        vetor_dados[i] = distribuicao(gerador);\n    }\n\n    // Mede tempo da vers\u00e3o com ponteiros\n    auto inicio = std::chrono::high_resolution_clock::now();\n    std::vector&lt;double&gt; medias = media_movel_ptr(vetor_dados.data(), vetor_dados.size(), janela_K);\n    auto fim = std::chrono::high_resolution_clock::now();\n\n    double tempo_ms = std::chrono::duration&lt;double, std::milli&gt;(fim - inicio).count();\n    std::cout &lt;&lt; \"tempo_ptr_ms=\" &lt;&lt; tempo_ms\n            &lt;&lt; \" tamanho_saida=\" &lt;&lt; medias.size() &lt;&lt; \"\\n\";\n\n    return 0;\n}\n</code></pre>"},{"location":"aulas/aula13/","title":"Uma Introdu\u00e7\u00e3o a CUDA","text":"<p>O CUDA (Compute Unified Device Architecture) \u00e9 o modelo de programa\u00e7\u00e3o paralela desenvolvido pela NVIDIA. Ele permite que desenvolvedores usem o poder das GPUs para acelerar aplica\u00e7\u00f5es de alto desempenho, executando milhares de threads simultaneamente.</p> <p>Em um sistema HPC com SLURM, como o Franky ou o SDumont, a execu\u00e7\u00e3o de programas CUDA segue tr\u00eas etapas principais:</p> <ol> <li>Carregar o m\u00f3dulo CUDA dispon\u00edvel no cluster.</li> <li>Compilar o c\u00f3digo com o compilador <code>nvcc</code>.</li> <li>Executar o bin\u00e1rio com o <code>srun</code> ou <code>sbatch</code>(solicitando uma GPU).</li> </ol>"},{"location":"aulas/aula13/#etapa-1-preparando-o-ambiente","title":"Etapa 1 \u2014 Preparando o ambiente","text":"<p>Para saber informa\u00e7\u00f5es sobre as filas que voc\u00ea tem acesso</p> <pre><code>sacctmgr list user $USER -s format=partition%20,MaxJobs,MaxSubmit,MaxNodes,MaxCPUs,MaxWall\n</code></pre> <p>Dentro do seu diret\u00f3rio de trabalho <code>/scratch/insperhpc/seu_login/GPU/</code>:</p> <pre><code>mkdir /scratch/insperhpc/seu_login/GPU\ncd /scratch/insperhpc/seu_login/GPU\n</code></pre> <p>Liste os m\u00f3dulos dispon\u00edveis e carregue o CUDA:</p> <pre><code>module avail cuda\nmodule load cuda/12.6_sequana\n</code></pre> <p>Verifique se o compilador CUDA est\u00e1 ativo:</p> <pre><code>nvcc --version\n</code></pre>"},{"location":"aulas/aula13/#etapa-2-codigo-base-cpu","title":"Etapa 2 \u2014 C\u00f3digo Base (CPU)","text":"<p>Vamos come\u00e7ar com um programa simples em C++ que soma os elementos de dois vetores na CPU.</p> <p>Crie o arquivo:</p> <pre><code>nano exemplo_cpu.cpp\n</code></pre> <p>Cole o c\u00f3digo abaixo:</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;math.h&gt;\n\n// Fun\u00e7\u00e3o que soma os elementos de dois vetores\nvoid add(int n, float *x, float *y)\n{\n  for (int i = 0; i &lt; n; i++)\n      y[i] = x[i] + y[i];\n}\n\nint main(void)\n{\n  int N = 1&lt;&lt;20; // 1 milh\u00e3o de elementos\n  float *x = new float[N];\n  float *y = new float[N];\n\n  // Inicializa os vetores\n  for (int i = 0; i &lt; N; i++) {\n    x[i] = 1.0f;\n    y[i] = 2.0f;\n  }\n\n  // Executa a soma na CPU\n  add(N, x, y);\n\n  // Verifica erro\n  float maxError = 0.0f;\n  for (int i = 0; i &lt; N; i++)\n    maxError = fmax(maxError, fabs(y[i]-3.0f));\n\n  std::cout &lt;&lt; \"Erro m\u00e1ximo: \" &lt;&lt; maxError &lt;&lt; std::endl;\n\n  delete [] x;\n  delete [] y;\n\n  return 0;\n}\n</code></pre> <p>Compile e execute localmente (sem GPU):</p> <pre><code>g++ exemplo_cpu.cpp -o ex_cpu\n</code></pre> <pre><code>srun --partition=sequana_cpu_dev ./ex_cpu\n</code></pre> <p>Sa\u00edda esperada:</p> <pre><code>srun: job 123456 queued and waiting for resources\nsrun: job 123456 has been allocated resources\nErro m\u00e1ximo: 0\n</code></pre>"},{"location":"aulas/aula13/#etapa-3-migrando-para-gpu-cuda","title":"Etapa 3 \u2014 Migrando para GPU (CUDA)","text":"<p>Agora, vamos reescrever o mesmo c\u00f3digo para rodar na GPU.</p> <p>Crie o arquivo:</p> <pre><code>nano exemplo1.cu\n</code></pre> <p>Cole o c\u00f3digo abaixo:</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;math.h&gt;\n\n// Kernel CUDA: soma os elementos de dois vetores\n__global__\nvoid add(int n, float *x, float *y)\n{\n  int index = blockIdx.x * blockDim.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n  for (int i = index; i &lt; n; i += stride)\n    y[i] = x[i] + y[i];\n}\n\nint main(void)\n{\n  int N = 1&lt;&lt;20;\n  float *x, *y;\n\n  // Aloca Mem\u00f3ria Unificada \u2013 acess\u00edvel pela CPU e pela GPU\n  cudaMallocManaged(&amp;x, N*sizeof(float));\n  cudaMallocManaged(&amp;y, N*sizeof(float));\n\n  // Inicializa vetores na CPU\n  for (int i = 0; i &lt; N; i++) {\n    x[i] = 1.0f;\n    y[i] = 2.0f;\n  }\n\n  // Configura\u00e7\u00e3o da grade e dos blocos\n  int blockSize = 256;\n  int numBlocks = (N + blockSize - 1) / blockSize;\n\n  // Lan\u00e7a o kernel na GPU\n  add&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(N, x, y);\n\n  // Aguarda a GPU terminar\n  cudaDeviceSynchronize();\n\n  // Verifica o erro m\u00e1ximo\n  float maxError = 0.0f;\n  for (int i = 0; i &lt; N; i++)\n    maxError = fmax(maxError, fabs(y[i]-3.0f));\n\n  std::cout &lt;&lt; \"Erro m\u00e1ximo: \" &lt;&lt; maxError &lt;&lt; std::endl;\n\n  // Libera mem\u00f3ria\n  cudaFree(x);\n  cudaFree(y);\n\n  return 0;\n}\n</code></pre> <p>Compile com o <code>nvcc</code>:</p> <pre><code>nvcc exemplo1.cu -o ex1\n</code></pre>"},{"location":"aulas/aula13/#etapa-4-executando-no-no-gpu-com-slurm","title":"Etapa 4 \u2014 Executando no n\u00f3 GPU com SLURM","text":"<p>Agora, vamos executar o bin\u00e1rio pedindo uma GPU via <code>srun</code>:</p> <pre><code>srun --partition=sequana_gpu_dev --gres=gpu:1 ./ex1\n</code></pre> <p>\ud83d\udca1 Explica\u00e7\u00e3o dos par\u00e2metros:</p> Op\u00e7\u00e3o Significado <code>--partition=sequana_gpu_dev</code> Escolhe a fila de GPU <code>--gres=gpu:1</code> Solicita 1 GPU <code>./ex1</code> Executa o programa compilado <p>Sa\u00edda esperada:</p> <pre><code>srun: job 11402255 queued and waiting for resources\nsrun: job 11402255 has been allocated resources\nErro m\u00e1ximo: 0\n</code></pre>"},{"location":"aulas/aula13/#explicacao-do-kernel-cuda","title":"Explica\u00e7\u00e3o do Kernel CUDA","text":"<p>At\u00e9 agora, vimos como executar um kernel CUDA com m\u00faltiplas threads dentro de um \u00fanico bloco. Mas as GPUs modernas s\u00e3o compostas por m\u00faltiplos processadores paralelos, chamados Streaming Multiprocessors (SMs). Cada SM pode executar v\u00e1rios blocos de threads simultaneamente.</p> <p>Por exemplo:</p> <ul> <li>Uma GPU Tesla P100 (arquitetura Pascal) possui 56 SMs.</li> <li>Cada SM pode manter at\u00e9 2048 threads ativas.</li> <li>Isso totaliza mais de 100 mil threads em execu\u00e7\u00e3o paralela real!</li> </ul> <p>Para aproveitar todo esse paralelismo, precisamos lan\u00e7ar o kernel com m\u00faltiplos blocos, e n\u00e3o apenas um.</p>"},{"location":"aulas/aula13/#o-que-e-uma-grid-e-o-que-e-um-block","title":"O que \u00e9 uma Grid e o que \u00e9 um Block?","text":"<p>Em CUDA:</p> <ul> <li>Cada bloco (block) \u00e9 um grupo de threads que trabalham juntas e compartilham mem\u00f3ria local.</li> <li>O conjunto de todos os blocos forma uma grade (grid).</li> </ul> <p>Portanto:</p> <p>Uma grade \u00e9 composta por v\u00e1rios blocos, e cada bloco cont\u00e9m v\u00e1rias threads.</p> <p>A GPU distribui esses blocos entre seus SMs, executando eles conforme h\u00e1 recursos dispon\u00edveis.</p>"},{"location":"aulas/aula13/#configurando-a-execucao-com-multiplos-blocos","title":"Configurando a Execu\u00e7\u00e3o com M\u00faltiplos Blocos","text":"<p>Se temos <code>N</code> elementos (ex: 1 milh\u00e3o) e queremos 256 threads por bloco, precisamos calcular quantos blocos s\u00e3o necess\u00e1rios para cobrir todos os elementos.</p> <p>O c\u00e1lculo \u00e9 simples:</p> <pre><code>int blockSize = 256;\nint numBlocks = (N + blockSize - 1) / blockSize;\nadd&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(N, x, y);\n</code></pre> <ul> <li><code>blockSize</code> \u2192 n\u00famero de threads por bloco (normalmente m\u00faltiplo de 32).</li> <li><code>numBlocks</code> \u2192 n\u00famero de blocos necess\u00e1rios (arredondando para cima).</li> <li><code>&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;</code> \u2192 diz ao CUDA quantos blocos e threads criar.</li> </ul> <p>Dessa forma, garantimos pelo menos N threads para processar todos os elementos.</p>"},{"location":"aulas/aula13/#calculando-o-indice-global-de-cada-thread","title":"Calculando o \u00cdndice Global de Cada Thread","text":"<p>Agora, dentro do kernel, precisamos adaptar o c\u00f3digo para que cada thread saiba qual parte do vetor processar.</p> <p>CUDA fornece vari\u00e1veis internas que ajudam nisso:</p> <ul> <li><code>threadIdx.x</code> \u2192 \u00edndice da thread dentro do bloco</li> <li><code>blockIdx.x</code> \u2192 \u00edndice do bloco dentro da grade</li> <li><code>blockDim.x</code> \u2192 n\u00famero de threads por bloco</li> <li><code>gridDim.x</code> \u2192 n\u00famero total de blocos</li> </ul> <p>O \u00edndice global \u00e9 calculado assim:</p> <pre><code>int index = blockIdx.x * blockDim.x + threadIdx.x;\n</code></pre> <p>Esse c\u00e1lculo \u00e9 padr\u00e3o em CUDA, porque \u00e9 o permite mapear cada thread a uma posi\u00e7\u00e3o \u00fanica no vetor.</p>"},{"location":"aulas/aula13/#percorrendo-grandes-vetores-com-grid-stride-loop","title":"Percorrendo Grandes Vetores com Grid-Stride Loop","text":"<p>Mesmo com muitos blocos, \u00e0s vezes o n\u00famero de threads ainda \u00e9 menor que N. Para lidar com isso, usamos um padr\u00e3o chamado grid-stride loop:</p> <pre><code>int stride = blockDim.x * gridDim.x;\nfor (int i = index; i &lt; n; i += stride)\n    y[i] = x[i] + y[i];\n</code></pre> <p>O que isso faz:</p> <ul> <li><code>stride</code> representa o n\u00famero total de threads ativas na GPU.</li> <li>Cada thread processa m\u00faltiplos elementos separados por esse intervalo.</li> <li>Assim, mesmo que <code>N</code> seja muito grande, todas as posi\u00e7\u00f5es do vetor s\u00e3o tratadas.</li> </ul>"},{"location":"aulas/aula13/#kernel-completo-com-multiplos-blocos","title":"Kernel completo com m\u00faltiplos blocos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;math.h&gt;\n\n// Kernel CUDA para somar dois vetores usando m\u00faltiplos blocos\n__global__\nvoid add(int n, float *x, float *y)\n{\n  int index  = blockIdx.x * blockDim.x + threadIdx.x; // \u00edndice global da thread\n  int stride = blockDim.x * gridDim.x;                // salto entre itera\u00e7\u00f5es\n\n  for (int i = index; i &lt; n; i += stride)\n    y[i] = x[i] + y[i];\n}\n\nint main(void)\n{\n  int N = 1&lt;&lt;20; // 1 milh\u00e3o de elementos\n  float *x, *y;\n\n  // Mem\u00f3ria unificada (CPU + GPU)\n  cudaMallocManaged(&amp;x, N*sizeof(float));\n  cudaMallocManaged(&amp;y, N*sizeof(float));\n\n  // Inicializa\u00e7\u00e3o dos vetores\n  for (int i = 0; i &lt; N; i++) {\n    x[i] = 1.0f;\n    y[i] = 2.0f;\n  }\n\n  // Configura\u00e7\u00e3o da execu\u00e7\u00e3o\n  int blockSize = 256;\n  int numBlocks = (N + blockSize - 1) / blockSize;\n\n  // Lan\u00e7amento do kernel\n  add&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(N, x, y);\n\n  // Sincroniza\u00e7\u00e3o\n  cudaDeviceSynchronize();\n\n  // Verifica\u00e7\u00e3o do resultado\n  float maxError = 0.0f;\n  for (int i = 0; i &lt; N; i++)\n    maxError = fmax(maxError, fabs(y[i]-3.0f));\n\n  std::cout &lt;&lt; \"Erro m\u00e1ximo: \" &lt;&lt; maxError &lt;&lt; std::endl;\n\n  cudaFree(x);\n  cudaFree(y);\n  return 0;\n}\n</code></pre> <p>Vers\u00e3o com prints did\u00e1ticos  <pre><code>#include &lt;iostream&gt;\n#include &lt;math.h&gt;\n#include &lt;cuda_runtime.h&gt;\n\n// Kernel CUDA para somar dois vetores usando m\u00faltiplos blocos\n__global__\nvoid add(int n, float *x, float *y)\n{\n  // Calcula o \u00edndice global e o salto entre itera\u00e7\u00f5es\n  int index  = blockIdx.x * blockDim.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n\n  // Imprime informa\u00e7\u00f5es das primeiras threads de cada bloco\n  if (threadIdx.x == 0) {\n    printf(\"Bloco %d ativo com %d threads (index inicial global = %d)\\n\",\n           blockIdx.x, blockDim.x, index);\n  }\n\n  // Cada thread processa m\u00faltiplos elementos separados por 'stride'\n  for (int i = index; i &lt; n; i += stride) {\n    if (i &lt; 10 &amp;&amp; blockIdx.x == 0 &amp;&amp; threadIdx.x &lt; 5) {\n      printf(\"[Thread %d | Bloco %d] somando x[%d]=%.1f + y[%d]=%.1f\\n\",\n             threadIdx.x, blockIdx.x, i, x[i], i, y[i]);\n    }\n    y[i] = x[i] + y[i];\n  }\n}\n\nint main(void)\n{\n  int N = 1&lt;&lt;20; // 1 milh\u00e3o de elementos\n  float *x, *y;\n\n  std::cout &lt;&lt; \"=== Inicializando mem\u00f3ria unificada ===\" &lt;&lt; std::endl;\n  cudaMallocManaged(&amp;x, N*sizeof(float));\n  cudaMallocManaged(&amp;y, N*sizeof(float));\n\n  // Inicializa\u00e7\u00e3o dos vetores\n  std::cout &lt;&lt; \"=== Inicializando vetores x e y ===\" &lt;&lt; std::endl;\n  for (int i = 0; i &lt; N; i++) {\n    x[i] = 1.0f;\n    y[i] = 2.0f;\n  }\n\n  // Configura\u00e7\u00e3o da execu\u00e7\u00e3o\n  int blockSize = 256;\n  int numBlocks = (N + blockSize - 1) / blockSize;\n\n  std::cout &lt;&lt; \"=== Configura\u00e7\u00e3o do kernel ===\" &lt;&lt; std::endl;\n  std::cout &lt;&lt; \"N\u00famero total de elementos: \" &lt;&lt; N &lt;&lt; std::endl;\n  std::cout &lt;&lt; \"Threads por bloco (blockSize): \" &lt;&lt; blockSize &lt;&lt; std::endl;\n  std::cout &lt;&lt; \"N\u00famero de blocos (numBlocks): \" &lt;&lt; numBlocks &lt;&lt; std::endl;\n  std::cout &lt;&lt; \"Threads totais (gridDim*blockDim): \"\n            &lt;&lt; numBlocks * blockSize &lt;&lt; std::endl;\n  std::cout &lt;&lt; \"=======================================\" &lt;&lt; std::endl;\n\n  // Lan\u00e7amento do kernel\n  add&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(N, x, y);\n\n  // Sincroniza\u00e7\u00e3o\n  cudaDeviceSynchronize();\n\n  std::cout &lt;&lt; \"\\n=== Kernel finalizado, verificando resultados ===\" &lt;&lt; std::endl;\n\n  // Verifica\u00e7\u00e3o do resultado\n  float maxError = 0.0f;\n  for (int i = 0; i &lt; N; i++)\n    maxError = fmax(maxError, fabs(y[i]-3.0f));\n\n  std::cout &lt;&lt; \"Erro m\u00e1ximo: \" &lt;&lt; maxError &lt;&lt; std::endl;\n\n  // Mostra os primeiros 10 resultados\n  std::cout &lt;&lt; \"\\n=== Amostra dos primeiros 10 valores de y ===\" &lt;&lt; std::endl;\n  for (int i = 0; i &lt; 10; i++)\n    std::cout &lt;&lt; \"y[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; y[i] &lt;&lt; std::endl;\n\n  cudaFree(x);\n  cudaFree(y);\n  std::cout &lt;&lt; \"\\n=== Execu\u00e7\u00e3o completa ===\" &lt;&lt; std::endl;\n\n  return 0;\n}\n</code></pre></p>"},{"location":"aulas/aula13/#visualizacao-do-modelo","title":"Visualiza\u00e7\u00e3o do Modelo","text":"N\u00edvel Identificador Exemplo Fun\u00e7\u00e3o Thread <code>threadIdx.x</code> 0\u2013255 Uma linha de execu\u00e7\u00e3o Bloco <code>blockIdx.x</code> 0\u20134095 Agrupa 256 threads Grade <code>gridDim.x</code> 4096 Agrupa todos os blocos <p>Cada thread calcula:</p> <pre><code>index = blockIdx.x * blockDim.x + threadIdx.x\n</code></pre> <p>e acessa <code>y[index]</code>.</p>"},{"location":"aulas/aula13/#compilando-e-executando-no-hpc","title":"Compilando e executando no HPC","text":"<p>No seu ambiente:</p> <pre><code>module load cuda/12.6_sequana\nnvcc add_grid.cu -o add_grid\nsrun --partition=sequana_gpu_dev --gres=gpu:1 ./add_grid\n</code></pre> <p>Sa\u00edda esperada:</p> <pre><code>srun: job 11402255 queued and waiting for resources\nsrun: job 11402255 has been allocated resources\nErro m\u00e1ximo: 0\n</code></pre>"},{"location":"aulas/aula13/#conceitos-chave-dessa-etapa","title":"Conceitos-chave dessa etapa","text":"Conceito Explica\u00e7\u00e3o Streaming Multiprocessor (SM) Unidade de processamento paralela da GPU Grid Conjunto de blocos lan\u00e7ados na GPU Block Grupo de threads que compartilham mem\u00f3ria local Grid-Stride Loop T\u00e9cnica para percorrer grandes vetores com menos threads blockIdx.x * blockDim.x + threadIdx.x F\u00f3rmula padr\u00e3o de indexa\u00e7\u00e3o CUDA"},{"location":"aulas/aula13/#exercicios","title":"Exerc\u00edcios:","text":"<ol> <li>Teste outros tamanhos de vetor.</li> <li>Modifique o n\u00famero de blocos e threads para observar o impacto.</li> <li>Adicione medi\u00e7\u00f5es de tempo com as fun\u00e7\u00f5es CUDA (<code>cudaEventRecord</code>).</li> <li>Teste kernels com mais dimens\u00f5es.</li> </ol>"},{"location":"aulas/aula13/#se-quiser-aprender-mais","title":"Se quiser aprender mais","text":"<ol> <li>Explore a documenta\u00e7\u00e3o do CUDA Toolkit.    Veja o Guia R\u00e1pido de Instala\u00e7\u00e3o e o Programming Guide.</li> <li>Teste o uso de <code>printf()</code> dentro do kernel para imprimir <code>threadIdx.x</code> e <code>blockIdx.x</code>.</li> <li>Experimente <code>threadIdx.y</code>, <code>threadIdx.z</code> e <code>blockIdx.y</code>.    Descubra como definir grids e blocos em m\u00faltiplas dimens\u00f5es.</li> <li>Leia sobre a Unified Memory no CUDA 8 e o mecanismo de migra\u00e7\u00e3o de p\u00e1ginas da arquitetura Pascal.</li> </ol> <p>obs: Material adaptado do Deep Learning Institute NVIDIA e do NVIDIA Teaching kit - Accelerated Computing</p> <p>```</p>"},{"location":"aulas/aula14/","title":"Data Race, Atomics e Throughput em GPU","text":"<p>Quando come\u00e7amos a ver sobre paralelismo em CPU com OpenMP, aprendemos que certas opera\u00e7\u00f5es compartilhadas entre threads \u2014 como somas globais ou atualiza\u00e7\u00f5es em vetores \u2014 exigem cuidados. Usar um <code>#pragma omp critical</code> ou um <code>#pragma omp atomic</code> garante corre\u00e7\u00e3o, mas tamb\u00e9m gera um gargalo, pois apenas uma thread pode acessar aquele trecho de c\u00f3digo por vez. Em muitos casos, podemos substituir o uso de <code>critical</code> por estrat\u00e9gias mais inteligentes, como redu\u00e7\u00f5es (<code>reduction</code>) ou vetores locais por thread, justamente para evitar o custo da sincroniza\u00e7\u00e3o.</p> <p>Em CUDA o racioc\u00ednio \u00e9 o mesmo, mas em uma escala muito maior. Uma GPU n\u00e3o executa 8 ou 16 threads, e sim milhares \u00e0s vezes dezenas de milhares de forma simult\u00e2nea. Isso significa que qualquer ponto de conten\u00e7\u00e3o, como uma opera\u00e7\u00e3o <code>atomicAdd()</code> sobre um mesmo endere\u00e7o de mem\u00f3ria, pode eliminar completamente o paralelismo e fazer com que o desempenho da GPU drasticamente.</p> <p>Por isso, \u00e9 importante evitar ao m\u00e1ximo o uso de opera\u00e7\u00f5es at\u00f4micas</p>"},{"location":"aulas/aula14/#por-que-o-atomic-e-tao-custoso-na-gpu","title":"Por que o atomic \u00e9 t\u00e3o custoso na GPU","text":"<p>Uma opera\u00e7\u00e3o at\u00f4mica \u00e9 uma forma de bloquear temporariamente um endere\u00e7o de mem\u00f3ria enquanto uma thread o atualiza, impedindo que outra thread interfira. Em CPU, o impacto \u00e9 pequeno, porque h\u00e1 poucas threads competindo. Mas na GPU, a atomic vira um verdadeiro funil: centenas ou milhares de threads tentam acessar o mesmo dado ao mesmo tempo, e o hardware \u00e9 obrigado a serializar os acessos, uma thread por vez.</p> <p>Em OpenMP, se voc\u00ea usar <code>#pragma omp atomic</code>, oito threads se alternam para atualizar uma vari\u00e1vel o atraso \u00e9 percept\u00edvel, mas suport\u00e1vel. Em CUDA, <code>atomicAdd()</code> pode ser disputado por 10.000 threads ao mesmo tempo, e o tempo de espera se torna centenas de vezes maior. Na pr\u00e1tica, o throughput (quantidade de opera\u00e7\u00f5es conclu\u00eddas por segundo) despenca. O programa perde completamente o sentido de ser paralelo.</p>"},{"location":"aulas/aula14/#uma-solucao-reduzir-a-competicao-por-memoria","title":"Uma solu\u00e7\u00e3o: reduzir a competi\u00e7\u00e3o por mem\u00f3ria","text":"<p>A melhor forma de evitar atomics n\u00e3o \u00e9 torcer para que elas fiquem baratas, mas reorganizar o algoritmo para que cada thread ou bloco trabalhe em regi\u00f5es de mem\u00f3ria diferentes. No exemplo do histograma, em vez de todas as threads atualizarem o mesmo vetor global, cada bloco de threads constr\u00f3i seu pr\u00f3prio histograma local, em shared memory (mem\u00f3ria compartilhada do bloco). Essa mem\u00f3ria \u00e9 muito mais r\u00e1pida, e como \u00e9 exclusiva daquele bloco, n\u00e3o h\u00e1 conflito entre blocos portanto, nenhum atomic \u00e9 necess\u00e1rio.</p> <p>Cada thread do bloco incrementa contadores no seu histograma local de forma direta (sem precisar de <code>atomicAdd()</code> global), e no final o bloco escreve o resultado em uma regi\u00e3o separada da mem\u00f3ria global. Depois, uma etapa de fus\u00e3o combina os histogramas locais para gerar o resultado final. Essa fus\u00e3o pode ser feita no host (CPU) ou em um segundo kernel da GPU. Mesmo que use algumas atomics na fus\u00e3o, o custo \u00e9 muito menor, porque agora temos poucos blocos competindo, e n\u00e3o milhares de threads.</p>"},{"location":"aulas/aula14/#exemplo-tres-abordagens-de-histograma","title":"Exemplo: tr\u00eas abordagens de histograma","text":"<p>Neste exemplo temos tr\u00eas implementa\u00e7\u00f5es do mesmo histograma em CUDA:</p> <ol> <li> <p>Vers\u00e3o ing\u00eanua:    As threads incrementam diretamente o vetor <code>hist[bin]++</code>.    \u00c9 a mais r\u00e1pida, mas incorreta pois acontece data race.</p> </li> <li> <p>Vers\u00e3o com <code>atomicAdd</code>:    Corrige o problema, mas for\u00e7a o hardware a serializar as opera\u00e7\u00f5es.    Funciona, mas \u00e9 como colocar <code>#pragma omp critical</code> dentro do loop cada incremento \u00e9 seguro, por\u00e9m caro.</p> </li> <li> <p>Vers\u00e3o com mem\u00f3ria compartilhada:    Cada bloco calcula seu histograma local em shared memory e depois os resultados s\u00e3o somados.    Essa abordagem evita o conflito global e preserva o paralelismo.    \u00c9 o equivalente GPU da t\u00e9cnica de reduction do OpenMP \u2014 divide o trabalho, reduz localmente, combina no final.</p> </li> </ol> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;cuda_runtime.h&gt;\n\n//\n// =====================================================\n// Kernel ing\u00eanuo \u2014 demonstra condi\u00e7\u00e3o de corrida (data race)\n// =====================================================\n//\n// Cada thread l\u00ea um valor do vetor `dados` e incrementa o contador\n// do \"chunk\" correspondente no vetor global `histograma`.\n//\n// Problema: v\u00e1rias threads podem tentar incrementar o mesmo \u00edndice\n// ao mesmo tempo. Como a opera\u00e7\u00e3o (ler \u2192 somar \u2192 escrever) n\u00e3o \u00e9 at\u00f4mica,\n// o resultado final se corrompe.\n//\n__global__ void histograma_ingenuo(const int *dados, int *histograma, int N, int numChunks) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i &lt; N) {\n        int chunk = dados[i];\n        histograma[chunk]++;  // condi\u00e7\u00e3o de corrida (data race)\n    }\n}\n\n//\n// =====================================================\n// Kernel com atomicAdd \u2014 correto, mas reduz throughput\n// =====================================================\n//\n// A fun\u00e7\u00e3o `atomicAdd()` garante exclusividade de acesso a um endere\u00e7o.\n// Assim, o incremento \u00e9 seguro, mas o paralelismo efetivo diminui,\n// pois v\u00e1rias threads competem para acessar o mesmo chunk.\n//\n__global__ void histograma_atomico(const int *dados, int *histograma, int N, int numChunks) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i &lt; N) {\n        int chunk = dados[i];\n        atomicAdd(&amp;histograma[chunk], 1);  // funciona, por\u00e9m destroi o paralelismo\n    }\n}\n\n//\n// =====================================================\n// Kernel otimizado \u2014 histograma local em mem\u00f3ria compartilhada\n// =====================================================\n//\n// Cada bloco cria um histograma local na mem\u00f3ria compartilhada (`shared memory`),\n// que \u00e9 muito mais r\u00e1pida e exclusiva de cada bloco.\n// Assim, evitamos o uso de opera\u00e7\u00f5es at\u00f4micas globais.\n// \n// Ap\u00f3s o c\u00e1lculo local, cada bloco copia seu histograma parcial\n// para a mem\u00f3ria global, e a fus\u00e3o final \u00e9 feita na CPU.\n//\n__global__ void histograma_compartilhado(const int *dados, int *histogramas_blocos, int N, int numChunks) {\n    extern __shared__ int hist_local[];  // mem\u00f3ria compartilhada din\u00e2mica\n    int tid_global = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // --- Etapa 1: Inicializa o histograma local com zeros ---\n    for (int i = threadIdx.x; i &lt; numChunks; i += blockDim.x)\n        hist_local[i] = 0;\n    __syncthreads();\n\n    // --- Etapa 2: Atualiza o histograma local ---\n    if (tid_global &lt; N) {\n        int chunk = dados[tid_global];\n        hist_local[chunk]++;\n    }\n    __syncthreads();\n\n    // --- Etapa 3: Copia o histograma local para a mem\u00f3ria global ---\n    for (int i = threadIdx.x; i &lt; numChunks; i += blockDim.x)\n        histogramas_blocos[blockIdx.x * numChunks + i] = hist_local[i];\n}\n\n//\n// =====================================================\n// Fus\u00e3o dos histogramas locais na CPU\n// =====================================================\n//\n// Ap\u00f3s cada bloco gerar seu histograma local na GPU,\n// esta fun\u00e7\u00e3o soma todos os histogramas parciais\n// em um histograma final consolidado.\n//\nvoid fundir_histogramas_CPU(const std::vector&lt;int&gt; &amp;histogramas_blocos,\n                            std::vector&lt;int&gt; &amp;histograma_final,\n                            int numBlocos, int numChunks) {\n    for (int b = 0; b &lt; numBlocos; b++)\n        for (int c = 0; c &lt; numChunks; c++)\n            histograma_final[c] += histogramas_blocos[b * numChunks + c];\n}\n\n//\n// =====================================================\n// Fun\u00e7\u00e3o principal\n// =====================================================\n//\n// Mede o tempo de execu\u00e7\u00e3o de cada abordagem (ing\u00eanua, at\u00f4mica, compartilhada)\n// e compara os resultados.\n//\nint main() {\n    const int N = 1 &lt;&lt; 20;        // 1 milh\u00e3o de elementos\n    const int numChunks = 256;    // quantidade de \"caixas\" do histograma\n    const int tamBloco = 256;     // threads por bloco\n    const int numBlocos = (N + tamBloco - 1) / tamBloco;\n\n    std::cout &lt;&lt; \"=== HISTOGRAMA EM GPU ===\\n\";\n    std::cout &lt;&lt; \"Elementos: \" &lt;&lt; N\n              &lt;&lt; \" | Chunks: \" &lt;&lt; numChunks\n              &lt;&lt; \" | \" &lt;&lt; numBlocos &lt;&lt; \" blocos x \"\n              &lt;&lt; tamBloco &lt;&lt; \" threads\\n\\n\";\n\n    // -----------------------------\n    // Aloca\u00e7\u00e3o e inicializa\u00e7\u00e3o no host\n    // -----------------------------\n    std::vector&lt;int&gt; h_dados(N);\n    for (auto &amp;v : h_dados) v = rand() % numChunks;\n\n    std::vector&lt;int&gt; h_hist_ingenuo(numChunks, 0);\n    std::vector&lt;int&gt; h_hist_atomico(numChunks, 0);\n    std::vector&lt;int&gt; h_hist_compart(numChunks, 0);\n\n    // -----------------------------\n    // Aloca\u00e7\u00e3o na GPU\n    // -----------------------------\n    int *d_dados = nullptr;\n    int *d_hist = nullptr;\n    int *d_hist_blocos = nullptr;\n    cudaMalloc(&amp;d_dados, N * sizeof(int));\n    cudaMalloc(&amp;d_hist, numChunks * sizeof(int));\n    cudaMalloc(&amp;d_hist_blocos, numBlocos * numChunks * sizeof(int));\n\n    cudaMemcpy(d_dados, h_dados.data(), N * sizeof(int), cudaMemcpyHostToDevice);\n\n    size_t tamMemCompart = numChunks * sizeof(int);\n\n    // Vari\u00e1veis para medir tempo\n    cudaEvent_t inicio, fim;\n    cudaEventCreate(&amp;inicio);\n    cudaEventCreate(&amp;fim);\n    float tempo_ingenuo = 0.0f, tempo_atomico = 0.0f, tempo_compart = 0.0f;\n\n    // =====================================================\n    // Vers\u00e3o ing\u00eanua\n    // =====================================================\n    cudaMemset(d_hist, 0, numChunks * sizeof(int));\n    cudaEventRecord(inicio);\n    histograma_ingenuo&lt;&lt;&lt;numBlocos, tamBloco&gt;&gt;&gt;(d_dados, d_hist, N, numChunks);\n    cudaEventRecord(fim);\n    cudaEventSynchronize(fim);\n    cudaEventElapsedTime(&amp;tempo_ingenuo, inicio, fim);\n    cudaMemcpy(h_hist_ingenuo.data(), d_hist, numChunks * sizeof(int), cudaMemcpyDeviceToHost);\n\n    // =====================================================\n    // Vers\u00e3o at\u00f4mica\n    // =====================================================\n    cudaMemset(d_hist, 0, numChunks * sizeof(int));\n    cudaEventRecord(inicio);\n    histograma_atomico&lt;&lt;&lt;numBlocos, tamBloco&gt;&gt;&gt;(d_dados, d_hist, N, numChunks);\n    cudaEventRecord(fim);\n    cudaEventSynchronize(fim);\n    cudaEventElapsedTime(&amp;tempo_atomico, inicio, fim);\n    cudaMemcpy(h_hist_atomico.data(), d_hist, numChunks * sizeof(int), cudaMemcpyDeviceToHost);\n\n    // =====================================================\n    // Vers\u00e3o otimizada (mem\u00f3ria compartilhada)\n    // =====================================================\n    cudaEventRecord(inicio);\n    histograma_compartilhado&lt;&lt;&lt;numBlocos, tamBloco, tamMemCompart&gt;&gt;&gt;(d_dados, d_hist_blocos, N, numChunks);\n    cudaEventRecord(fim);\n    cudaEventSynchronize(fim);\n    cudaEventElapsedTime(&amp;tempo_compart, inicio, fim);\n\n    std::vector&lt;int&gt; h_hist_blocos(numBlocos * numChunks);\n    cudaMemcpy(h_hist_blocos.data(), d_hist_blocos, numBlocos * numChunks * sizeof(int), cudaMemcpyDeviceToHost);\n    fundir_histogramas_CPU(h_hist_blocos, h_hist_compart, numBlocos, numChunks);\n\n    // =====================================================\n    // C\u00e1lculo do throughput (M ops/s)\n    // =====================================================\n    auto throughput = [&amp;](float ms) {\n        return static_cast&lt;double&gt;(N) / (ms / 1000.0) / 1e6;\n    };\n\n    double thr_ingenuo  = throughput(tempo_ingenuo);\n    double thr_atomico  = throughput(tempo_atomico);\n    double thr_compart  = throughput(tempo_compart);\n\n    std::cout &lt;&lt; \"\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\n\";\n    std::cout &lt;&lt; \"Vers\u00e3o         | Tempo (ms)      | Throughput (M ops/s)\\n\";\n    std::cout &lt;&lt; \"\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\n\";\n    std::cout &lt;&lt; \"Ing\u00eanua        | \" &lt;&lt; tempo_ingenuo  &lt;&lt; \"         | \" &lt;&lt; thr_ingenuo  &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"At\u00f4mica        | \" &lt;&lt; tempo_atomico &lt;&lt; \"        | \" &lt;&lt; thr_atomico &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"Otimizada      | \" &lt;&lt; tempo_compart &lt;&lt; \"        | \" &lt;&lt; thr_compart &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\n\\n\";\n\n    // =====================================================\n    // Libera\u00e7\u00e3o de recursos\n    // =====================================================\n    cudaFree(d_dados);\n    cudaFree(d_hist);\n    cudaFree(d_hist_blocos);\n    cudaEventDestroy(inicio);\n    cudaEventDestroy(fim);\n\n    return 0;\n}\n</code></pre> <p>Lembre-se de carregar o modulo cuda dispon\u00edvel, depois compile com: </p> <pre><code>nvcc -Ofast hist.cu -o hist\n</code></pre> <p>Execute usando o srun:</p> <pre><code>srun --partition=gpu --gres=gpu:1 ./hist\n</code></pre> <p>Em programa\u00e7\u00e3o paralela sincronizar sempre tem custo. Mas, na GPU, esse custo \u00e9 multiplicado por milhares de threads, e o impacto pode ser catastr\u00f3fico. Por isso, usar fun\u00e7\u00f5es at\u00f4micas deve ser o \u00faltimo recurso, reservado apenas para casos em que n\u00e3o h\u00e1 outra forma de evitar uma condi\u00e7\u00e3o de corrida.</p> <p>A verdadeira otimiza\u00e7\u00e3o em CUDA n\u00e3o est\u00e1 em \u201cusar mais threads\u201d, e sim em organizar o trabalho de modo que cada thread e cada bloco acessem dados diferentes. Sempre que o acesso for independente, a GPU mostra toda sua for\u00e7a; quando h\u00e1 disputa, ela se comporta de forma lenta.</p>"},{"location":"aulas/aula14/#o-que-e-throughput","title":"O que \u00e9 Throughput","text":"<p>O termo throughput mede a quantidade de trabalho que um sistema realiza por unidade de tempo. No nosso caso, ele indica quantos incrementos (opera\u00e7\u00f5es) a GPU consegue fazer por segundo.</p> <p>Em outras palavras:</p> <p>Throughput = quantas opera\u00e7\u00f5es o programa consegue realizar por segundo.</p> <p>Cada thread da GPU processa um elemento do vetor de entrada <code>dados[]</code> e incrementa o contador do \u201cchunk\u201d correspondente no vetor <code>histograma[]</code>. Logo, temos N opera\u00e7\u00f5es (uma para cada elemento).</p> <p>O tempo total de execu\u00e7\u00e3o (<code>tempo_ms</code>) \u00e9 medido com os eventos do CUDA (<code>cudaEventRecord</code>).</p>"},{"location":"aulas/aula14/#formula-utilizada-no-codigo","title":"F\u00f3rmula utilizada no c\u00f3digo","text":"<p>O throughput \u00e9 calculado como:</p>  \\text{Throughput (M ops/s)} = \\frac{N}{t_s} \\div 10^6  <p>onde:</p> S\u00edmbolo Significado ( N ) N\u00famero total de opera\u00e7\u00f5es executadas (elementos processados) ( t_s ) Tempo total do kernel em segundos ( 10^6 ) Convers\u00e3o para \u201cmilh\u00f5es de opera\u00e7\u00f5es por segundo\u201d <p>Como <code>cudaEventElapsedTime()</code> retorna o tempo em milissegundos, fazemos:</p>  t_s = \\frac{t_{ms}}{1000}"},{"location":"aulas/aula15/","title":"Programa\u00e7\u00e3o Paralela em GPU com CUDA \u2013 Stencil, Tiling e Agendamento de Threads","text":""},{"location":"aulas/aula15/#o-que-e-um-stencil-operation","title":"O que \u00e9 um Stencil Operation?","text":"<p>Um stencil \u00e9 um padr\u00e3o computacional onde o valor de uma c\u00e9lula de sa\u00edda depende de uma vizinhan\u00e7a local de c\u00e9lulas de entrada.</p> <ul> <li>F\u00f3rmula geral:</li> </ul>  out[i, j] = f(in[i-1, j], in[i, j-1], in[i, j], in[i+1, j], in[i, j+1])  <p>Quando estamos trabalhando em GPU \u00e9 preciso pensar em blocos e vizinhos compartilhados.</p>"},{"location":"aulas/aula15/#aplicando-a-logica-de-stencil-a-uma-operacao-de-convolucao","title":"Aplicando a l\u00f3gica de Stencil a uma opera\u00e7\u00e3o de convolu\u00e7\u00e3o","text":"<p> Convolu\u00e7\u00e3o - Fonte: https://www.ibm.com/think/topics/convolutional-neural-networks</p>"},{"location":"aulas/aula15/#exemplo-filtro-33","title":"Exemplo: Filtro 3\u00d73","text":"<p>Problema: cada thread acessa os mesmos elementos da mem\u00f3ria global.</p> <p>Solu\u00e7\u00e3o: usar shared memory com tiling.</p> <pre><code>__global__ void conv2D(float *input,   // ponteiro para a imagem de entrada \n                       float *output,  // ponteiro para a imagem de sa\u00edda\n                       float *mask,    // m\u00e1scara 3x3 usada na convolu\u00e7\u00e3o\n                       int width,      // largura da imagem\n                       int height) {   // altura da imagem\n\n    int i = blockIdx.y * blockDim.y + threadIdx.y; // linha da imagem\n    int j = blockIdx.x * blockDim.x + threadIdx.x; // coluna da imagem\n\n    float acc = 0.0f; // acumulador\n\n   // Varre a vizinhan\u00e7a 3x3 ao redor do pixel central (i, j)\n    for (int y = -1; y &lt;= 1; y++) {\n        for (int x = -1; x &lt;= 1; x++) {\n\n            // Calcula a posi\u00e7\u00e3o do vizinho dentro da imagem de entrada\n            int r = i + y;\n            int c = j + x;\n\n            // Verifica se a posi\u00e7\u00e3o (r, c) est\u00e1 dentro dos limites da imagem\n            bool dentroDaImagem = (r &gt;= 0 &amp;&amp; r &lt; height &amp;&amp; c &gt;= 0 &amp;&amp; c &lt; width);\n\n            if (dentroDaImagem) {\n                int pixelIndex = r * width + c;\n                int maskRow = y + 1;\n                int maskCol = x + 1;\n                int maskIndex = maskRow * 3 + maskCol;\n                float pixelValue = input[pixelIndex];\n                float maskValue  = mask[maskIndex];\n\n                acc += pixelValue * maskValue;\n            }\n        }\n    }\n\n    // Escreve o resultado final no pixel correspondente da sa\u00edda.\n    output[i * width + j] = acc;\n}\n</code></pre>"},{"location":"aulas/aula15/#tiling","title":"Tiling","text":""},{"location":"aulas/aula15/#relembrando","title":"Relembrando:","text":"<ul> <li>Dividimos a matriz em tiles (blocos) que cabem na mem\u00f3ria compartilhada .</li> <li>Cada bloco carrega seu peda\u00e7o + uma margem extra para carregar dados vizinhos.</li> <li>Cada thread block cuida de um tile.</li> <li>Halo \u00e9 o peda\u00e7o adicional carregado com os dados vizinhos, para evitar depend\u00eancia entre blocos.</li> <li><code>__syncthreads()</code> barreira para garantir que todas as threads carregaram antes de processar.</li> </ul>"},{"location":"aulas/aula15/#mesmo-codigo-agora-com-shared-memory-e-bordas","title":"Mesmo c\u00f3digo, agora com shared memory e bordas","text":"<pre><code>#define TILE_SIZE 16      // tamanho da \u00e1rea de processamento do bloco\n#define MASK_RADIUS 1     // raio da m\u00e1scara 3x3\n#define MASK_SIZE 3\n\n__global__ void conv2D_tiled(float *input,   // imagem de entrada\n                             float *output,  // imagem de sa\u00edda\n                             float *mask,    // m\u00e1scara 3x3\n                             int width,      // largura da imagem\n                             int height) {   // altura da imagem\n\n\n    int tx = threadIdx.x;  // coluna da thread dentro do bloco\n    int ty = threadIdx.y;  // linha da thread dentro do bloco\n\n    // posi\u00e7\u00e3o global (i,j) da thread na imagem\n    int j = blockIdx.x * TILE_SIZE + tx;\n    int i = blockIdx.y * TILE_SIZE + ty;\n\n    // Mem\u00f3ria compartilhada do bloco\n    __shared__ float tile[TILE_SIZE + 2 * MASK_RADIUS][TILE_SIZE + 2 * MASK_RADIUS];\n\n    // Calcula a posi\u00e7\u00e3o global do pixel que esta thread deve carregar\n    int inputRow = i - MASK_RADIUS;\n    int inputCol = j - MASK_RADIUS;\n\n    // Carregamento da imagem para a mem\u00f3ria compartilhada, cada thread carrega um elemento\n    if (inputRow &gt;= 0 &amp;&amp; inputRow &lt; height &amp;&amp; inputCol &gt;= 0 &amp;&amp; inputCol &lt; width) {\n        tile[ty][tx] = input[inputRow * width + inputCol];\n    } else {\n        tile[ty][tx] = 0.0f;  // preenche com 0 fora da imagem \n    }\n\n    // Garante que todas as threads terminaram de carregar o tile\n    __syncthreads();\n\n    // Somente threads dentro da regi\u00e3o \u00fatil calculam o pixel de sa\u00edda\n    if (tx &gt;= MASK_RADIUS &amp;&amp; tx &lt; TILE_SIZE + MASK_RADIUS &amp;&amp;\n        ty &gt;= MASK_RADIUS &amp;&amp; ty &lt; TILE_SIZE + MASK_RADIUS &amp;&amp;\n        i &lt; height &amp;&amp; j &lt; width) {\n\n        float acc = 0.0f; // acumulador da convolu\u00e7\u00e3o\n\n        // Varre a vizinhan\u00e7a 3x3 dentro da mem\u00f3ria compartilhada\n        for (int y = -MASK_RADIUS; y &lt;= MASK_RADIUS; y++) {\n            for (int x = -MASK_RADIUS; x &lt;= MASK_RADIUS; x++) {\n                int maskRow = y + MASK_RADIUS;\n                int maskCol = x + MASK_RADIUS;\n                float pixelValue = tile[ty + y][tx + x];\n                float maskValue  = mask[maskRow * MASK_SIZE + maskCol];\n                acc += pixelValue * maskValue;\n            }\n        }\n\n        // Escreve o valor final na imagem de sa\u00edda (mem\u00f3ria global)\n        output[i * width + j] = acc;\n    }\n}\n</code></pre>"},{"location":"aulas/aula15/#agendamento-de-threads","title":"Agendamento de Threads","text":"<p>A GPU organiza o trabalho em:</p> <p> Fonte: https://developer.codeplay.com/products/computecpp/ce/1.3.0/guides/sycl-for-cuda-developers/execution-model</p> <ul> <li>Warps: grupos de 32 threads que executam em SIMT (Single Instruction, Multiple Thread).</li> <li>SM (Streaming Multiprocessor): executa v\u00e1rios warps alternadamente para amenizar a lat\u00eancia.</li> <li>O agendador de warps alterna entre os warps prontos para computa\u00e7\u00e3o.</li> </ul> <p> Fonte: https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/</p>"},{"location":"aulas/aula15/#implicacoes-praticas","title":"Implica\u00e7\u00f5es pr\u00e1ticas:","text":"<ul> <li>Melhor usar blocos com m\u00faltiplos de 32 threads.</li> <li>Evitar diverg\u00eancia de fluxo (ifs dentro do warp).</li> <li>Maximizar ocupa\u00e7\u00e3o: usar <code>cudaOccupancyMaxPotentialBlockSize()</code> ajuda a determinar o tamanho adequado dos blocos.</li> </ul> <p>Aplicando todas as otimiza\u00e7\u00f5es: <pre><code>//demo.cu\n#include &lt;iostream&gt;\n#include &lt;iomanip&gt;\n#include &lt;cmath&gt;\n#include &lt;cuda_runtime.h&gt;\nusing namespace std;\n\n#define MASK_RADIUS 1\n#define ITER_LOCAL 100  \n\n// Stencil 2D com tiling em shared\n__global__ void heatStencil2D(float *input, float *output,\n                              int width, int height,\n                              float alpha, float dt,\n                              int tileSize) {\n    extern __shared__ float tile[];  // shared din\u00e2mica (TILE_EXT*TILE_EXT floats)\n    const int TILE_EXT = tileSize + 2 * MASK_RADIUS;\n\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n\n    // mapeia thread do bloco para coordenadas globais com halo\n    int j = blockIdx.x * tileSize + tx - MASK_RADIUS;\n    int i = blockIdx.y * tileSize + ty - MASK_RADIUS;\n\n    // carrega input -&gt; shared (com padding 0 fora da imagem)\n    if (i &gt;= 0 &amp;&amp; i &lt; height &amp;&amp; j &gt;= 0 &amp;&amp; j &lt; width)\n        tile[ty * TILE_EXT + tx] = input[i * width + j];\n    else\n        tile[ty * TILE_EXT + tx] = 0.0f;\n\n    __syncthreads();\n\n    // regi\u00e3o \u00fatil (ignora threads que s\u00f3 carregaram halo)\n    if (tx &gt;= MASK_RADIUS &amp;&amp; tx &lt; TILE_EXT - MASK_RADIUS &amp;&amp;\n        ty &gt;= MASK_RADIUS &amp;&amp; ty &lt; TILE_EXT - MASK_RADIUS &amp;&amp;\n        i &lt; height &amp;&amp; j &lt; width) {\n\n        float Tij  = tile[ty * TILE_EXT + tx];\n        float Tnew = Tij;\n\n        for (int k = 0; k &lt; ITER_LOCAL; k++) {\n            float lap =\n                tile[(ty-1) * TILE_EXT + tx] +\n                tile[(ty+1) * TILE_EXT + tx] +\n                tile[ty * TILE_EXT + (tx-1)] +\n                tile[ty * TILE_EXT + (tx+1)] -\n                4.0f * Tij;\n\n            Tnew = Tij + alpha * dt * tanhf(lap);\n            Tij  = 0.99f * Tnew + 0.01f * sinf(Tnew);\n        }\n\n        output[i * width + j] = Tnew;\n    }\n}\n\n\nint main() {\n    // Conjunto de dados\n    const int width  = 8192;\n    const int height = 8192;\n    const long long N = 1LL * width * height;\n\n    cout &lt;&lt; \"Stencil 2D em GPU (\" &lt;&lt; width &lt;&lt; \"x\" &lt;&lt; height\n         &lt;&lt; \"), \" &lt;&lt; fixed &lt;&lt; setprecision(1) &lt;&lt; (N/1e6) &lt;&lt; \" Mpx\\n\";\n\n    // par\u00e2metros \u201cf\u00edsicos\u201d para a conta\n    const float alpha = 0.25f;\n    const float dt    = 0.1f;\n\n    // aloca\u00e7\u00e3o com cuda Malloc Managed\n    float *input = nullptr, *output = nullptr;\n    CHECK_CUDA(cudaMallocManaged(&amp;input,  N * sizeof(float)));\n    CHECK_CUDA(cudaMallocManaged(&amp;output, N * sizeof(float)));\n\n    // inicializa\u00e7\u00e3o simples\n    for (long long i = 0; i &lt; N; i++) input[i] = 1.0f;\n\n    // threads por bloco\n    int minGrid=0, optBlock=0;\n    CHECK_CUDA(cudaOccupancyMaxPotentialBlockSize(&amp;minGrid, &amp;optBlock,\n                     heatStencil2D, 0, 0));\n\n    // tile aproximado\n    int suggestedTileExt  = (int)floor(sqrt((double)optBlock));\n    int suggestedTileSize = suggestedTileExt - 2*MASK_RADIUS;\n    if (suggestedTileSize &lt; 4) suggestedTileSize = 4; // sanidade\n\n    // ================================================================\n    // An\u00e1lise de ocupa\u00e7\u00e3o te\u00f3rica (CUDA)\n    // ================================================================\n    cout &lt;&lt; \"\\n============================================================\\n\";\n    cout &lt;&lt; \"AN\u00c1LISE DOS TILES\\n\";\n    cout &lt;&lt; \"------------------------------------------------------------\\n\";\n    cout &lt;&lt; \"\u2022 Threads ideais por bloco : \" &lt;&lt; optBlock &lt;&lt; \"\\n\";\n    cout &lt;&lt; \"\u2022 TILE_EXT sugerido        : \" &lt;&lt; suggestedTileExt\n        &lt;&lt; \"  \u2192  TILE_SIZE sugerido \u2248 \" &lt;&lt; suggestedTileSize &lt;&lt; \"\\n\";\n    cout &lt;&lt; \"\u2022 Grade m\u00ednima recomendada : \" &lt;&lt; minGrid &lt;&lt; \" blocos totais\\n\";\n    cout &lt;&lt; \"============================================================\\n\\n\";\n\n    // ================================================================\n    // Testando diferentes tamanhos de TILE\n    // ================================================================\n    int tileSizes[] = {suggestedTileSize, 8, 12, 14, 16, 32};\n    const int numTests = sizeof(tileSizes)/sizeof(tileSizes[0]);\n\n    cout &lt;&lt; \"INICIANDO EXPERIMENTO DE DESEMPENHO GPU\\n\";\n    cout &lt;&lt; \"   (m\u00e9dia de \" &lt;&lt; repeats &lt;&lt; \" execu\u00e7\u00f5es por configura\u00e7\u00e3o)\\n\\n\";\n\n    cout &lt;&lt; left\n        &lt;&lt; setw(10) &lt;&lt; \"Tile\"\n        &lt;&lt; setw(16) &lt;&lt; \"Threads/Bloco\"\n        &lt;&lt; setw(8)  &lt;&lt; \"Warps\"\n        &lt;&lt; setw(14) &lt;&lt; \"Tempo (ms)\"\n        &lt;&lt; setw(14) &lt;&lt; \"Mpx/s\"\n        &lt;&lt; \"Coment\u00e1rio\\n\";\n    cout &lt;&lt; string(75, '-') &lt;&lt; \"\\n\";\n\n    // Mede m\u00e9dia de v\u00e1rias execu\u00e7\u00f5es para precis\u00e3o\n    const int repeats = 20;\n\n    for (int t = 0; t &lt; numTests; t++) {\n        int TILE_SIZE = tileSizes[t];\n        if (TILE_SIZE &lt;= 0) continue;\n\n        const int TILE_EXT = TILE_SIZE + 2 * MASK_RADIUS;\n        const int threadsPerBlock = TILE_EXT * TILE_EXT;\n        const int warps = (threadsPerBlock + 31) / 32;\n\n        dim3 threads(TILE_EXT, TILE_EXT);\n        dim3 blocks(\n            (width  + TILE_SIZE - 1) / TILE_SIZE,\n            (height + TILE_SIZE - 1) / TILE_SIZE\n        );\n\n        size_t shmem = (size_t)TILE_EXT * TILE_EXT * sizeof(float);\n\n        // --- Medi\u00e7\u00e3o do tempo m\u00e9dio ---\n        cudaEvent_t start, stop;\n        CHECK_CUDA(cudaEventCreate(&amp;start));\n        CHECK_CUDA(cudaEventCreate(&amp;stop));\n\n        CHECK_CUDA(cudaEventRecord(start));\n        for (int r = 0; r &lt; repeats; r++) {\n            heatStencil2D&lt;&lt;&lt;blocks, threads, shmem&gt;&gt;&gt;(input, output, width, height, alpha, dt, TILE_SIZE);\n        }\n        CHECK_CUDA(cudaEventRecord(stop));\n        CHECK_CUDA(cudaEventSynchronize(stop));\n\n        float msTotal = 0.0f;\n        CHECK_CUDA(cudaEventElapsedTime(&amp;msTotal, start, stop));\n        CHECK_CUDA(cudaEventDestroy(start));\n        CHECK_CUDA(cudaEventDestroy(stop));\n\n        const double ms = msTotal / repeats;\n        const double mpxPerSec = (N / 1e6) / (ms / 1000.0); // milh\u00f5es de pixels por segundo\n\n        // --- An\u00e1lise do resultado ---\n        string comment;\n        if (threadsPerBlock == optBlock)\n            comment = \"\u2248 Ideal te\u00f3rico \";\n        else if (abs(threadsPerBlock - optBlock) &lt; 64)\n            comment = \"Pr\u00f3ximo ao ideal\";\n        else if (threadsPerBlock &lt; optBlock)\n            comment = \"Subocupa\u00e7\u00e3o (bloco pequeno)\";\n        else\n            comment = \"Shared alta\";\n\n        cout &lt;&lt; left\n            &lt;&lt; setw(10) &lt;&lt; (to_string(TILE_SIZE) + \"x\" + to_string(TILE_SIZE))\n            &lt;&lt; setw(16) &lt;&lt; threadsPerBlock\n            &lt;&lt; setw(8)  &lt;&lt; warps\n            &lt;&lt; setw(14) &lt;&lt; fixed &lt;&lt; setprecision(3) &lt;&lt; ms\n            &lt;&lt; setw(14) &lt;&lt; fixed &lt;&lt; setprecision(2) &lt;&lt; mpxPerSec\n            &lt;&lt; comment &lt;&lt; \"\\n\";\n    }\n\n    CHECK_CUDA(cudaFree(input));\n    CHECK_CUDA(cudaFree(output));\n    return 0;\n}\n</code></pre></p> <p>Slurm para executar em um Cluster HPC:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=demo\n#SBATCH --output=saida.out\n#SBATCH --partition=gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gres=gpu:1\n#SBATCH --time=00:10:00\n#SBATCH --mem=4G\n\n./demo\n</code></pre> <p>!!!! warning \"N\u00e3o esque\u00e7a de carregar o modulo cuda e compilar com nvcc\"</p>"},{"location":"aulas/aula15/#conclusao","title":"Conclus\u00e3o","text":"<p>Percebemos como o tamanho do bloco (tile) influencia a efici\u00eancia de execu\u00e7\u00e3o de um kernel em GPU.</p> <p>Para interpretar a tabela corretamente, \u00e9 importante observar tr\u00eas par\u00e2metros principais:</p> <ul> <li>Tempo m\u00e9dio (Tempo ms)</li> <li>Taxa de processamento (Mpx/s)</li> </ul> <p>O tempo (ms) indica quanto cada configura\u00e7\u00e3o levou para processar toda a matriz. Valores menores significam execu\u00e7\u00f5es mais r\u00e1pidas, mas devem ser analisados com cuidado: blocos grandes podem reduzir artificialmente o tempo total por utilizarem poucos blocos na GPU, o que mascara o real desempenho paralelo.</p> <p>O par\u00e2metro mais confi\u00e1vel \u00e9 o Mpx/s (milh\u00f5es de pixels por segundo), que mede quantos milh\u00f5es de elementos foram processados por segundo. Esse valor reflete o throughput da GPU, ou seja, qu\u00e3o bem o hardware foi aproveitado. Quanto maior o Mpx/s, mais eficiente foi o uso dos recursos. </p> <p>Ao comparar esses valores, percebemos que os blocos menores (8\u00d78, 12\u00d712) apresentam maiores tempos e menores taxas de Mpx/s.</p> <p>Isso acontece porque h\u00e1 poucas threads por bloco, resultando em subocupa\u00e7\u00e3o da GPU.</p> <p>Nos blocos intermedi\u00e1rios (14\u00d714 a 25\u00d725), o desempenho melhora gradualmente: o tempo diminui, e o Mpx/s aumenta at\u00e9 atingir um ponto em torno do tile de 25\u00d725, o valor sugerido pelo CUDA. Esse \u00e9 o ponto de equil\u00edbrio entre paralelismo e uso de mem\u00f3ria compartilhada, o bloco \u00e9 grande o suficiente para gerar alto throughput, mas n\u00e3o t\u00e3o grande a ponto de limitar a quantidade de blocos ativos por SM.</p> <p>J\u00e1 o bloco de 32\u00d732 aparenta ter tempo \u201czero\u201d, mas isso \u00e9 um bug de medi\u00e7\u00e3o: o kernel termina t\u00e3o rapidamente que o cron\u00f4metro perde precis\u00e3o. Na pr\u00e1tica, blocos muito grandes consomem mais mem\u00f3ria compartilhada e reduzem a ocupa\u00e7\u00e3o real da GPU, resultando em menor efici\u00eancia, mesmo que o tempo aparente seja baixo.</p> <p>O tempo isolado n\u00e3o \u00e9 o melhor indicador, o desempenho real est\u00e1 no ponto em que o Mpx/s \u00e9 m\u00e1ximo, pois esse indicador apresenta de fato o trabalho da GPU.</p>"},{"location":"complementar/aula02/","title":"Explorando o Poder de um Cluster HPC","text":"<p>Antes de qualquer coisa, precisamos configurar a conex\u00e3o SSH com o sistema de HPC.</p> <p>Para ter acesso ao Cluster Franky voc\u00ea precisa configurar suas credenciais de acesso e realizar acesso remoto via SSH.</p> <p>As chaves foram enviadas para o seu email Insper, Fa\u00e7a o download da pasta completa, que cont\u00e9m os arquivos <code>id_rsa</code> (chave privada) e <code>id_rsa.pub</code> (chave p\u00fablica). Dependendo do sistema operacional que voc\u00ea utiliza, siga as instru\u00e7\u00f5es abaixo para configurar corretamente seu acesso ao cluster Franky.</p>"},{"location":"complementar/aula02/#para-macbook-ou-linux","title":"Para Macbook ou Linux:","text":"<p>Abra o terminal, navegue at\u00e9 a pasta onde a chave privada (<code>id_rsa</code>) foi baixada, mova a chave para o diret\u00f3rio <code>.ssh</code> em sua home:</p> <pre><code>mv id_rsa ~/.ssh/\n</code></pre> <p>Garanta que apenas voc\u00ea possa ler o arquivo:</p> <pre><code>chmod 400 ~/.ssh/id_rsa\n</code></pre> <p>Conecte-se ao cluster utilizando o comando SSH:</p> <p>O login \u00e9 o seu \"usuario Insper\", o endere\u00e7o de IP foi fornecido durante a aula.</p> <p><pre><code>ssh -i ~/.ssh/id_rsa login@ip_do_cluster\n</code></pre> ou</p> <pre><code>ssh login@ip_do_cluster\n</code></pre>"},{"location":"complementar/aula02/#para-windows","title":"Para Windows:","text":"<p>Usando MobaXTerm</p> <p>Baixe o MobaXterm Home Edition em: https://mobaxterm.mobatek.net/download-home-edition.html</p> <p>Execute a aplica\u00e7\u00e3o, com o MobaXterm aberto, clique em Session, depois em SSH. </p> <p>Preencha todos os campos marcados em vermelho </p> <p>Estabele\u00e7a a conex\u00e3o, se tudo der certo, voc\u00ea ver\u00e1 algo como: </p>"},{"location":"complementar/aula02/#conhecendo-o-sistema","title":"Conhecendo o Sistema","text":"<p>Antes de come\u00e7ar a fazer pedidos de recursos pro SLURM, vamos conhecer os diferentes hardwares que temos dispon\u00edvel no Franky. Vamos utilizar alguns comandos de sistema operacional para ler os recursos de CPU, mem\u00f3ria e GPU dispon\u00edveis</p>"},{"location":"complementar/aula02/#comandos-utilizados","title":"Comandos utilizados","text":"<ul> <li><code>lscpu</code>: mostra detalhes da CPU (n\u00facleos, threads, mem\u00f3ria cache...)</li> <li><code>cat /proc/meminfo</code>: mostra detalhes sobre a mem\u00f3ria RAM </li> <li><code>nvidia-smi</code>: mostra detalhes de GPU, se dispon\u00edvel</li> </ul>"},{"location":"complementar/aula02/#comando-srun","title":"Comando SRUN","text":"<pre><code>srun --partition=normal --ntasks=1 --cpus-per-task=1 --mem=1G --time=00:05:00 \\\n--pty bash -c \"hostname &amp;&amp; \\\ncat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' &amp;&amp; \\\nlscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache' &amp;&amp; \\\n{ command -v nvidia-smi &amp;&gt; /dev/null &amp;&amp; nvidia-smi || echo 'nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada'; }\" \n</code></pre> <p>Voc\u00ea deve ver algo como:</p> <p></p> <p><code>srun</code></p> <p>\u00c9 o comando do SLURM usado para executar uma tarefa interativamente em um n\u00f3 do cluster.</p> <p><code>--partition=normal</code></p> <p>Indica em qual fila (parti\u00e7\u00e3o) o job ser\u00e1 executado. No seu caso, <code>normal</code> pode ser substitu\u00eddo por qualquer outra fila do sistema</p> <p><code>--ntasks=1</code></p> <p>Solicita 1 tarefa (processo). Se voc\u00ea estivesse rodando um c\u00f3digo paralelo, faz sentido trocar esse valor.</p> <p><code>--cpus-per-task=1</code></p> <p>Cada tarefa receber\u00e1 1 CPU (core). Quando estiver usando paralelismo com v\u00e1rias threads , faz sentido aumentar esse valor.</p> <p><code>--mem=1G</code></p> <p>Aloca 1 gigabyte de mem\u00f3ria RAM para essa tarefa. Se ultrapassar esse limite, o job ser\u00e1 encerrado.</p> <p><code>--time=00:05:00</code></p> <p>Define um tempo m\u00e1ximo de execu\u00e7\u00e3o de 5 minutos. Depois disso, o SLURM mata o processo automaticamente.</p> <p><code>--pty bash</code></p> <p>Solicita um terminal para o SLURM dentro do n\u00f3 de computa\u00e7\u00e3o. Interessante para fazer testes no c\u00f3digo ou realizar debugs</p> <p><code>{ command -v nvidia-smi &amp;&gt; /dev/null &amp;&amp; nvidia-smi || echo 'nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada'; }</code></p> <p>Esse trecho verifica se o comando <code>nvidia-smi</code> est\u00e1 dispon\u00edvel no sistema (ou seja, se h\u00e1 driver NVIDIA instalado e uma GPU NVIDIA acess\u00edvel).</p> <ul> <li>Se <code>nvidia-smi</code> estiver dispon\u00edvel, ele ser\u00e1 executado e mostrar\u00e1 as informa\u00e7\u00f5es da(s) GPU(s) no n\u00f3 (como nome, mem\u00f3ria, uso, driver etc).</li> <li>Se n\u00e3o estiver dispon\u00edvel (por exemplo, em n\u00f3s sem GPU ou sem driver instalado), exibir\u00e1 a mensagem:   <code>\"nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada\"</code>.</li> </ul> <p>Tip</p> <ul> <li>Em n\u00f3s CPU-only (como os da parti\u00e7\u00e3o <code>normal</code>), \u00e9 esperado que <code>nvidia-smi</code> n\u00e3o esteja presente.</li> <li>Para testar o comando em um n\u00f3 com GPU, use <code>--partition=gpu</code> ou <code>--partition=monstrao</code>  para alocar n\u00f3s com placas NVIDIA.</li> </ul> <p>O comando abaixo faz exatamente a mesma coisa, mas eu coloquei ele dentro de um shell script para ter uma formata\u00e7\u00e3o melhor no display:</p> <pre><code>srun --partition=normal --ntasks=1 --pty bash -c \\\n\"echo '=== HOSTNAME ==='; hostname; echo; \\\n echo '=== MEMORIA (GB) ==='; \\\n cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' | \\\n awk '{printf \\\"%s %.2f GB\\\\n\\\", \\$1, \\$2 / 1048576}'; \\\n echo; \\\n echo '=== CPU INFO ==='; \\\n lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\n echo '=== GPU INFO ==='; \\\n if command -v nvidia-smi &amp;&gt; /dev/null; then nvidia-smi; else echo 'nvidia-smi n\u00e3o dispon\u00edvel'; fi\"\n</code></pre> <p></p> <p>O comando <code>sinfo</code> mostra quais s\u00e3o as filas e quais s\u00e3o os status dos n\u00f3s </p> <p><pre><code>sinfo\n</code></pre> O comando abaixo mostra detalhes sobre os recursos de cada fila</p> <pre><code>scontrol show partition\n</code></pre> <p>Recomendo que voc\u00ea mude o nome da fila (partition) no comando abaixo para se ambientar no Cluster Franky e desconrir quais s\u00e3o as diferen\u00e7as entre as filas</p> <pre><code>srun --partition=normal --ntasks=1 --cpus-per-task=1 --mem=1G --time=00:05:00 \\\n     --pty bash -c \"hostname &amp;&amp; cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' &amp;&amp; lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\"\n</code></pre>"},{"location":"complementar/aula02/#introducao-teorica","title":"Introdu\u00e7\u00e3o Te\u00f3rica","text":"<p>Antes de partir para o c\u00f3digo, \u00e9 importante compreender o modelo de execu\u00e7\u00e3o em HPC.</p> Tipo de paralelismo Exemplo de biblioteca Escopo Comunica\u00e7\u00e3o Paralelismo local (CPU) <code>multiprocessing</code>, <code>threading</code>, <code>numba</code> Dentro do mesmo n\u00f3 Mem\u00f3ria compartilhada Paralelismo em GPU <code>numba.cuda</code>, <code>cupy</code>, <code>pycuda</code> Dentro do mesmo n\u00f3 Mem\u00f3ria da GPU Paralelismo distribu\u00eddo <code>mpi4py</code> Entre n\u00f3s do cluster Mensagens (MPI) <p>Um cluster \u00e9 formado por v\u00e1rios n\u00f3s interligados, e o SLURM coordena a execu\u00e7\u00e3o dos programas nesses n\u00f3s. Cada camada de paralelismo atua em um n\u00edvel diferente do hardware:</p>"},{"location":"complementar/aula02/#parte-1-baseline-sequencial","title":"Parte 1 \u2014 Baseline Sequencial","text":"<p>Come\u00e7amos com um problema simples, mas computacionalmente intenso: Aproximar o valor de pi usando o m\u00e9todo de Monte Carlo.</p> <pre><code>#!/usr/bin/env python3\n# seq_montecarlo.py\nimport random\nimport time\n\ndef estimate_pi(N):\n    inside = 0\n    for _ in range(N):\n        x, y = random.random(), random.random()\n        if x*x + y*y &lt;= 1.0:\n            inside += 1\n    return 4 * inside / N\n\nif __name__ == \"__main__\":\n    N = 10_000_000\n    t0 = time.time()\n    pi = estimate_pi(N)\n    print(f\"\u03c0 \u2248 {pi:.4f} (tempo: {time.time()-t0:.3f}s)\")\n</code></pre> <p>Vamos criar um arquivo slurm para executar esse c\u00f3digo:</p> <pre><code>srun --partition=normal --ntasks=1 --nodes=1 --cpus-per-task=1 python seq_montecarlo.py\n</code></pre>"},{"location":"complementar/aula02/#parte-2-paralelismo-em-cpu","title":"Parte 2 - Paralelismo em CPU","text":"<pre><code>#!/usr/bin/env python3\n# paralelo_montecarlo.py\nimport os\nimport random\nimport time\nfrom multiprocessing import Pool\n\ndef worker(n):\n    inside = 0\n    for _ in range(n):\n        x, y = random.random(), random.random()\n        if x*x + y*y &lt;= 1.0:\n            inside += 1\n    return inside\n\ndef main():\n    N = 10_000\n    nproc = int(os.getenv(\"SLURM_CPUS_PER_TASK\", os.cpu_count()))\n    chunk = N // nproc\n\n    t0 = time.time()\n    with Pool(nproc) as p:\n        results = p.map(worker, [chunk]*nproc)\n\n    pi = 4 * sum(results) / N\n    print(f\"\u03c0 \u2248 {pi:.4f} (nproc={nproc}, tempo={time.time()-t0:.3f}s)\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Criando um arquivo .slurm</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=pi-mp\n#SBATCH --output=pi_paralelo_%j.out\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=2\n#SBATCH --time=00:05:00\n#SBATCH --partition=normal\n#SBATCH --mem=2G                       \n\npython paralelo_montecarlo.py\n</code></pre>"},{"location":"complementar/aula03/","title":"O Laborat\u00f3rio que Ficou Preso em um Loop","text":"<p>Era uma manh\u00e3 chuvosa no Laborat\u00f3rio Egghead, o centro de pesquisa mais avan\u00e7ado do mundo. O cientista Edson Vegapunk, trabalhava em um projeto ousado: criar Akuma no Mi artificiais, as lend\u00e1rias frutas que concedem poderes sobre-humanos.</p> <p>Para isso, ele precisava calcular o score de compatibilidade gen\u00e9tica de milhares de amostras de DNA coletadas de marinheiros, piratas e at\u00e9 de alguns animais mutantes.</p> <p>Seu algoritmo era simples (pelo menos para ele): para cada amostra, aplicar uma fun\u00e7\u00e3o matem\u00e1tica complexa envolvendo trigonometria, exponenciais e ra\u00edzes quadradas, um algoritmo que simulava o quanto o DNA era compat\u00edvel com uma fruta m\u00edstica.</p> <p>Mas havia um problema. O processamento demorava mais de 4 horas para rodar uma \u00fanica leva de dados.</p> <p>Enquanto o c\u00f3digo rodava, Vegapunk olhava para o monitor e murmurava:</p> <p>\u201cSe eu continuar nesse ritmo... o Luffy j\u00e1 vai ter comido todas antes de eu terminar o prot\u00f3tipo!\u201d</p> <pre><code># score.py\nimport math, random, time\n\ndef score(x):\n    return math.sin(x)**2 + math.sqrt(abs(x)) + math.exp(-x**2 / 50)\n\ndata = [random.uniform(0, 1000) for _ in range(10_000_000)]\nstart = time.time()\n\nresults = [score(x) for x in data]\nend = time.time()\nprint(f\"Score m\u00e9dio: {sum(results)/len(results):.4f}\")\nprint(f\"Tempo total: {end - start:.2f}s\")\n</code></pre> <p>Edson percebeu algo curioso. Seu computador tinha 20 n\u00facleos, mas apenas um estava em uso.</p> <p>Usando seu conhecimento, ele modificou o c\u00f3digo para que cada n\u00facleo da CPU processasse uma parte das amostras.</p> <p>\u201cCom isso, teremos v\u00e1rios n\u00facleos trabalhando em paralelo!\u201d</p> <pre><code>#score_paralelo.py\nimport math\nimport random\nimport time\nimport multiprocessing as mp\n\n# --- Fun\u00e7\u00e3o de c\u00e1lculo pesado ---\ndef score(x):\n    \"\"\"Simula o c\u00e1lculo de um score computacionalmente intensivo.\"\"\"\n    return math.sin(x)**2 + math.sqrt(abs(x)) + math.exp(-x**2 / 50)\n\n# --- Fun\u00e7\u00e3o que executa um teste com N processos ---\ndef run_test(nproc, N=10_000_00):\n    \"\"\"Executa o c\u00e1lculo com nproc processos e retorna o tempo e o score m\u00e9dio.\"\"\"\n    data = [random.uniform(0, 1000) for _ in range(N)]\n    start = time.time()\n    with mp.Pool(processes=nproc) as pool:\n        results = pool.map(score, data)\n    end = time.time()\n    total_time = end - start\n    avg_score = sum(results) / len(results)\n    return total_time, avg_score\n\n# --- Execu\u00e7\u00e3o principal ---\nif __name__ == \"__main__\":\n    test_procs = [1, 2, 4, 8, 16]\n    results = []\n\n    print(\"\\n=== Teste de Speedup ===\")\n    print(f\"[INFO] CPUs detectadas: {mp.cpu_count()}\")\n    print(f\"[INFO] Dataset: 10 milh\u00f5es de amostras\\n\")\n\n    # --- Rodar o caso base (1 CPU) ---\n    print(\"[INFO] Medindo tempo base (1 CPU)...\")\n    base_time, base_score = run_test(1)\n    print(f\"[BASE] Tempo com 1 CPU: {base_time:.2f}s | Score m\u00e9dio: {base_score:.4f}\")\n    print(\"-\" * 50)\n\n    # --- Testes com m\u00faltiplos processos ---\n    for n in test_procs[1:]:  # come\u00e7a a partir de 2\n        t, s = run_test(n)\n        speedup = base_time / t\n        results.append((n, t, speedup))\n        print(f\"{n:2d} CPUs \u2192 {t:7.2f}s | Speedup={speedup:6.2f}\u00d7\")\n\n    # --- Resumo final ---\n    print(\"\\n=== Resumo ===\")\n    print(f\"{'Nproc':&gt;5} | {'Tempo (s)':&gt;10} | {'Speedup':&gt;8}\")\n    print(\"-\" * 30)\n    print(f\"{1:5d} | {base_time:10.2f} | {1.00:8.2f}\")\n    for n, t, sp in results:\n        print(f\"{n:5d} | {t:10.2f} | {sp:8.2f}\")\n</code></pre> <p>Vamos testar no Cluster Franky para ver o resultado:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=score-speedup\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=16\n#SBATCH --mem=2G\n#SBATCH --time=00:15:00\n#SBATCH --partition=gpu\n#SBATCH --output=logs/score_%j.out\n\npython score_paralelo.py\n</code></pre> <p>Quando o experimento terminou, o laborat\u00f3rio inteiro vibrou. Na tela principal, o log do Cluster Franky mostrava:</p> <pre><code>16 CPUs \u2192   14.87s | Speedup= 13.27\u00d7 | Efici\u00eancia= 82.9%\n</code></pre> <p>Edson abriu um sorriso.</p> <p>\u201cMaravilha! O c\u00e1lculo que levava quatro horas agora termina em minutos. O poder das Akuma no Mi artificiais est\u00e1 cada vez mais pr\u00f3ximo!\u201d</p> <p>O experimento de Vegapunk revelou o que \u00e9 essencial em Computa\u00e7\u00e3o de Alto Desempenho:</p> Conceito Explica\u00e7\u00e3o Paralelismo Dividir uma grande tarefa em partes menores e execut\u00e1-las simultaneamente em m\u00faltiplos n\u00facleos. Speedup (S = T\u2081 / T\u2099) Mede o quanto o programa ficou mais r\u00e1pido com N processadores. Efici\u00eancia (E = S / N) Mede o quanto cada CPU contribuiu de fato para o ganho total. Overhead A comunica\u00e7\u00e3o e coordena\u00e7\u00e3o entre processos que impede o ganho linear perfeito. <p>Mesmo com 16 n\u00facleos, a efici\u00eancia n\u00e3o chegou a 100%. Parte do tempo foi gasta na sincroniza\u00e7\u00e3o e gerenciamento de processos, dificilmente um c\u00f3digo pode ser paralelizado completamente.</p> <p></p>"},{"location":"projetos/","title":"Projeto da disciplina","text":"<p>O projeto da nossa disciplina est\u00e1 dispon\u00edvel nesse link</p>"},{"location":"projetos/exaustiva/","title":"Busca Exaustiva para Alinhamento de Sequencias","text":"<p>A busca exaustiva, conforme vista aula, gera todas as solu\u00e7\u00f5es vi\u00e1veis para um problema e, de acordo com um crit\u00e9rio de otimalidade, elege uma solu\u00e7\u00e3o \u00f3tima para o problema. Especificamente para o problema de alinhamento de sequencias, ele pode ser especificado da seguinte forma:</p> <pre><code>ALGORITMO BUSCA EXAUSTIVA\nEntrada: Duas sequencias de DNA a e b\n        Pesos wmat, wmis e wgap para match, mismatch e gap respectivamente\nSa\u00edda: Score de um alinhamento das sequencias\n      Subsequencias alinhadas\n\n1. Gerar todas as subsequencias a\u00b4 e b\u00b4 n\u00e3o-nulas de a e b, respectivamente.\n2. Calcular os alinhamentos de cada par de subsequencias (a\u00b4, b\u00b4) com os pesos wmat, wmis e wgap\n3. Devolver o score m\u00e1ximo m entre os scores do passo (2) e as subsequencias associadas a ele\n</code></pre> <p>Observe que, no passo (2), as subsequencias podem n\u00e3o ter o mesmo tamanho. Assim, n\u00e3o ser\u00e1 poss\u00edvel calcular diretamente um score simples. Podemos usar, por exemplo:</p> <ul> <li> a estrat\u00e9gia vista no primeiro projeto (Alinhamento Local de Smith-Waterman) para comparar duas subsequencias          <li> um truncamento da subsequencia maior pelo tamanho da subsequencia menor e calcular o score simples entre as duas subsequencias resultantes          <li> o Alinhamento Local de Smith-Waterman quando as subsequencias forem de tamanhos diferentes e, quando forem de tamanho igual, a estrat\u00e9gia aleat\u00f3ria do Projeto II.                    <p>A partir desta descri\u00e7\u00e3o, nosso terceiro projeto ter\u00e1 duas tarefas:</p> <ul> <li> Implementar um programa C++ para ler um arquivo contendo os tamanhos de duas sequencias de DNA, seguidos das duas sequencias, uma por linha. Calcular o score m\u00e1ximo utilizando o algoritmo acima, assim como as subsequencias associadas a ele.    <li> Implementar duas estrat\u00e9gias diferentes para calcular os alinhamentos entre os pares de subsequencias do passo (2).  No diret\u00f3rio do projeto, h\u00e1 um gerador de entradas disponibilizado como um notebook Python. Como se trata de uma busca exaustiva, recomenda-se come\u00e7ar a testar com tamanhos pequenos e      ir aumentando gradativamente at\u00e9 atingir o tamanho m\u00e1ximo que a sua plataforma ainda consiga executar."},{"location":"projetos/gpu/","title":"Paralelismo com GPU","text":"<p>Esta etapa do projeto consiste em resolver nosso problema por meio da biblioteca Thrust. Vamos come\u00e7ar revendo a formaliza\u00e7\u00e3o de nosso problema:</p> <p>Entrada:</p> <p>Um inteiro N representando o n\u00famero de filmes dispon\u00edveis para assistir. Tr\u00eas vetores H, F e C de tamanho N, onde H[i] \u00e9 a hora de in\u00edcio, F[i] \u00e9 a hora de t\u00e9rmino e C[i] \u00e9 a categoria do i-\u00e9simo filme. Um inteiro M representando o n\u00famero de categorias. Um vetor L de tamanho M, onde L[j] \u00e9 o n\u00famero m\u00e1ximo de filmes que podem ser assistidos na categoria j.</p> <p>Sa\u00edda:</p> <p>Um inteiro representando o n\u00famero m\u00e1ximo de filmes que podem ser assistidos de acordo com as restri\u00e7\u00f5es de hor\u00e1rios e n\u00famero m\u00e1ximo por categoria.</p> <p>Para resolver esse problema utilizando a biblioteca thrust, podemos utilizar um algoritmo de programa\u00e7\u00e3o din\u00e2mica para construir a solu\u00e7\u00e3o de forma eficiente. O algoritmo consiste em criar uma matriz dp de tamanho (N+1) x (M+1) para armazenar o n\u00famero m\u00e1ximo de filmes que podem ser assistidos at\u00e9 o filme i e a categoria j.</p> <p>Segue abaixo um pseudo-c\u00f3digo (incompleto) para resolver o problema</p> <pre><code>// Carregar os dados do arquivo de entrada na mem\u00f3ria da GPU\nthrust::device_vector&lt;int&gt; start_times(N);\nthrust::device_vector&lt;int&gt; end_times(N);\nthrust::device_vector&lt;int&gt; categories(N);\n\n// Ler os dados do arquivo de entrada\n// ...\n\n// Criar a matriz de programa\u00e7\u00e3o din\u00e2mica\nthrust::device_vector&lt;int&gt; dp((N+1) * (M+1), 0);\n\n// Inicializar a primeira linha da matriz com zeros\nthrust::fill(dp.begin(), dp.begin() + M + 1, 0);\n\n// Preencher a matriz com as solu\u00e7\u00f5es para subproblemas menores\nfor (int i = 1; i &lt;= N; i++) {\n  for (int j = 1; j &lt;= M; j++) {\n    // Encontrar o n\u00famero m\u00e1ximo de filmes que podem ser assistidos at\u00e9 o filme i e categoria j\n    int max_count = 0;\n    for (int k = 0; k &lt; i; k++) {\n      if (categories[k] == j &amp;&amp; end_times[k] &lt;= start_times[i] &amp;&amp; dp[(k*(M+1)) + j-1] + 1 &lt;= L[j-1]) {\n        max_count = max(max_count, dp[(k*(M+1)) + j-1] + 1);\n      } else {\n        max_count = max(max_count, dp[(k*(M+1)) + j]);\n      }\n    }\n    dp[(i*(M+1)) + j] = max_count;\n  }\n}\n\n// Encontrar o n\u00famero m\u00e1ximo de filmes que podem ser assistidos\nint max_count = 0;\nfor (int j = 1; j &lt;= M; j++) {\n  max_count = max(max_count, dp[(N*(M+1)) + j]);\n}\n\n// Escrever o resultado no arquivo de sa\u00edda\n// ...\n</code></pre> <p>A ideia do algoritmo \u00e9 criar uma matriz dp de tamanho (N+1) x (M+1) para armazenar o n\u00famero m\u00e1ximo de filmes que podem ser assistidos at\u00e9 o filme i e a categoria j. O algoritmo preenche a matriz com as solu\u00e7\u00f5es para subproblemas menores, at\u00e9 chegar na solu\u00e7\u00e3o do problema original.</p> <p>Para cada c\u00e9lula (i,j) da matriz dp, o algoritmo verifica se \u00e9 poss\u00edvel adicionar o filme i \u00e0 categoria j, respeitando as restri\u00e7\u00f5es de hor\u00e1rio e limite m\u00e1ximo de filmes por categoria. Em seguida, o algoritmo verifica se \u00e9 melhor adicionar o filme i \u00e0 categoria j ou manter a solu\u00e7\u00e3o anterior sem o filme i. O n\u00famero m\u00e1ximo de filmes que podem ser assistidos \u00e9 o valor da c\u00e9lula (N, j) da matriz dp, onde j \u00e9 a categoria que maximiza o n\u00famero de filmes assistidos.</p> <p>Sua tarefa \u00e9 realizar essa implementa\u00e7\u00e3o em C++ com a Thrust e comparar o desempenho frente as demais implementa\u00e7\u00f5es. </p>"},{"location":"projetos/heuristico/","title":"Heur\u00edstica Gulosa","text":"<p>A primeira implementa\u00e7\u00e3o da heur\u00edstica para nosso projeto consiste em uma implementa\u00e7\u00e3o gulosa (Greedy).</p> <p>Implemente uma vers\u00e3o gulosa que ordena os filmes por hora de fim crescente e escolhe aqueles que come\u00e7am primeiro e n\u00e3o conflitam com os filmes j\u00e1 escolhidos, al\u00e9m de verificar se h\u00e1 vagas dispon\u00edveis na categoria do filme.</p>"},{"location":"projetos/local/","title":"Aleatoriedade","text":"<p>Como vimos em aula, aleatoriedade \u00e9 uma estrat\u00e9gia bastante comum para constru\u00e7\u00e3o de algoritmos de busca local, podendo ser usada de forma isolada ou de forma complementar a outra estrat\u00e9gia de varredura de um espa\u00e7o de solu\u00e7\u00f5es. </p> <p>Essa implementa\u00e7\u00e3o consiste na adapta\u00e7\u00e3o da heur\u00edstica gulosa de nosso projeto. A proposta \u00e9 que voc\u00ea modifique a sua heur\u00edstica gulosa de modo que ao longo da sele\u00e7\u00e3o de um filme voc\u00ea tenha 25% de chance de pegar outro filme qualquer que respeite o hor\u00e1rio. Isso far\u00e1 com que sua heur\u00edstica tenha um pouco mais de exploration e possamos ter alguns resultados melhores. </p> <p>Importante: \u00e9 essencial que voc\u00ea guarde todos os inputs usados ao longo do projeto, para que possa comparar o desempenho de seus algoritmos conforme mudamos a heur\u00edstica. Ou seja, todas as heur\u00edsticas devem ser submetidas aos mesmos arquivos de input. O seu resultado deve ser comparado sob duas perspectivas, no m\u00ednimo: (i) tempo de execu\u00e7\u00e3o em fun\u00e7\u00e3o do aumento de filmes e de categorias e (ii) tempo de tela (isto \u00e9, ser\u00e1 que estamos conseguindo ocupar bem as 24h do dia assitindo filmes?).</p>"},{"location":"projetos/openmp/","title":"Paralelismo com OpenMP","text":"<p>At\u00e9 agora experimentamos heur\u00edsticas que buscaram resolver o nosso problema em um tempo razo\u00e1vel, sem garantias de otimalidade. \u00c9 chegado o momento de incorporar o paralelismo de tarefas em nossas alternativas de resolu\u00e7\u00e3o.</p> <p>Para isso, voc\u00ea deve modificar a vers\u00e3o exaustiva de sua implementa\u00e7\u00e3o. Voc\u00ea pode fazer uso da diretiva <code>#pragma omp parallel for</code> para distribuir as itera\u00e7\u00f5es de um loop entre as threads dispon\u00edveis. Dentro do loop, voc\u00ea pode fazer a verifica\u00e7\u00e3o de cada filme e, caso ele esteja dentro das restri\u00e7\u00f5es de hor\u00e1rio e categoria, incrementar uma vari\u00e1vel compartilhada <code>count</code>. Observe que por ser uma vari\u00e1vel compartilhada, voc\u00ea precisa preservar essa regi\u00e3o cr\u00edtica entre as threads. </p> <p>Vale ressaltar que o uso do OpenMP n\u00e3o necessariamente ir\u00e1 garantir um desempenho melhor, pois a paraleliza\u00e7\u00e3o tem um overhead que pode acabar diminuindo a performance do programa em alguns casos. \u00c9 importante fazer testes para verificar se a utiliza\u00e7\u00e3o do OpenMP \u00e9 realmente ben\u00e9fica para o problema em quest\u00e3o.</p>"},{"location":"projetos/relatorio_parcial/","title":"Relat\u00f3rio Parcial","text":"<p>O relat\u00f3rio parcial \u00e9 a entrega intermedi\u00e1ria do projeto, a qual deve ser feita pelo blackboard at\u00e9 a data da prova intermedi\u00e1ria.</p> <p>Seu relat\u00f3rio dever\u00e1 conter as implementa\u00e7\u00f5es gulosa e aleat\u00f3ria. </p> <p>O que voc\u00ea dever\u00e1 fazer:</p> <ul> <li> <p>No blackboard, voc\u00ea deve fazer upload de todos os c\u00f3digos-fonte, arquivos de input, arquivos de output para cada heur\u00edtica. Caso opte por enviar um link do github com o reposit\u00f3rio completo, tamb\u00e9m poder\u00e1 faze-lo, desde que garanta que teremos acesso aos arquivos no seu reposit\u00f3rio;</p> </li> <li> <p>Voc\u00ea deve elaborar um relat\u00f3rio parcial contendo as seguintes se\u00e7\u00f5es:</p> <ul> <li> <p>Para cada heur\u00edstica voc\u00ea deve explicar como implementou a heur\u00edstica (detalhe como voc\u00ea tratou o input, qual a l\u00f3gica do seu output, quais invariantes existem em suas heur\u00edsticas), apresentar (i) o c\u00f3digo-fonte comentado, (ii) fazer considera\u00e7\u00f5es sobre o profiling (valgrind) do c\u00f3digo-fonte (use apenas 1 arquivo de input para isso, n\u00e3o h\u00e1 necessidade de fazer esse profiling para v\u00e1rios inputs), (iii) o resultado compartivo entre as heur\u00edsticas quando voc\u00ea varia o input (o input deve variar na quantidade de filmes e de categorias).</p> </li> <li> <p>Seu relat\u00f3rio deve ser gr\u00e1ficos e tabelas que subsidem as suas considera\u00e7\u00f5es</p> </li> <li> <p>\u00c9 permitido criar um programa em python ou outra linguagem que automatize a gera\u00e7\u00e3o de seus resultados, isto \u00e9, que execute seus c\u00f3digos C++ em fun\u00e7\u00e3o dos diferentes inputs.</p> </li> </ul> </li> </ul> <p>Preferencialmente o relat\u00f3rio deve ser apresentado em formato html. </p>"},{"location":"projetos/2021-2/","title":"Alinhamento de Sequencias de DNA","text":"<p>Em Bioinform\u00e1tica, o problema de alinhamento de sequ\u00eancias de DNA consiste no processo de comparar duas ou mais sequ\u00eancias de bases de forma a se observar seu n\u00edvel de similaridade. Trata-se de um problema extremamente importante no contexto atual, pois permite comparar sequencias virais de SARS-COV2 em bancos de dados gen\u00f4micos para detec\u00e7\u00e3o de novas muta\u00e7\u00f5es.</p> <p>O n\u00edvel de similaridade pode ser calculado com base em acertos (match) e erros (gap e mismatch). Os acertos contribuem com sinal positivo (+) para o n\u00edvel de similaridade e, os erros, com sinal negativo (-). Abaixo temos um exemplo de c\u00e1lculo do n\u00edvel similaridade:</p> <p></p> <p>Vamos associar a pontua\u00e7\u00e3o +1 (match) e as penalidades -1 (gap) e -4 (mismatch). Assim, teremos o seguinte n\u00edvel de similaridade:</p> <p>23 matches x (+1) + 4 gaps x (-1) + 3 mismatches x (-4) = 23-4-12 = 7</p> <p>Neste contexto, o problema de alinhamento de sequencias de DNA pode ser colocado da seguinte forma:</p> <pre><code>Dadas duas sequencias de DNA, com as bases A,T,G,C e - para indicar gap, \nencontrar o alinhamento que maximize o n\u00edvel de similaridade. \n</code></pre> <p>Neste projeto, seu objetivo ser\u00e1 construir programas para encontrar este alinhamento de n\u00edvel m\u00e1ximo de similaridade, utilizando v\u00e1rias estrat\u00e9gias. </p> <p>Cada um dos seus programas tomar\u00e1 como entrada a seguinte estrutura: a primeira linha cont\u00e9m dois n\u00fameros <code>n</code> e <code>m</code>, onde <code>n</code> \u00e9 o tamanho da primeira sequencia e, <code>m</code>, o tamanho da segunda. Assuma <code>n \u2264 200</code> e <code>m \u2264 200</code>. A segunda linha cont\u00e9m as bases da primeira sequencia e, a terceira linha, as bases da segunda.</p> <pre><code>5 7\nAT-CC\nTTTCCAA\n</code></pre> <p>A sa\u00edda deve ser uma linha com um n\u00famero inteiro indicando o n\u00edvel m\u00e1ximo de similaridade.</p> <p><pre><code>2\n</code></pre> Neste caso, este n\u00edvel m\u00e1ximo de similaridade pode ser associado ao alinhamento T-CC/TTCC (1-1+1+1=2) ou a CC/CC(1+1=2). Voc\u00ea pode usar o c\u00f3digo python abaixo para gerar inst\u00e2ncias aleat\u00f3rias para seus testes.</p> <pre><code>import random\nn = 10 # tamanho da primeira sequ\u00eancia\nm = 40 # tamanho da segunda sequ\u00eancia\nfile = 'dna.seq' # nome do arquivo a ser gerado\nf = open(file, 'w')\nseq=[str(n)+'\\n',\n     str(m)+'\\n',\n     ''.join(random.choices(['A','T','C','G','-'],k=n))+'\\n',\n     ''.join(random.choices(['A','T','C','G','-'],k=m))]\nf.writelines(seq)\nf.close()\nprint(''.join(seq))\n</code></pre> <p>Um poss\u00edvel output para este c\u00f3digo acima \u00e9:</p> <pre><code>10\n40\nTGGCGAT--C\nAGC-TCTCTTC--ATT--CAC-TACACCGACA-CGC-G-A\n</code></pre>"},{"location":"projetos/2021-2/#estrategias-a-serem-estudadas-e-correcao-automatica","title":"Estrat\u00e9gias a serem estudadas e corre\u00e7\u00e3o autom\u00e1tica","text":"<p>Para cada estrat\u00e9gia que vamos estudar, implementaremos um programa correspondente no projeto. Veja abaixo as datas de entrega e descri\u00e7\u00f5es de cada estrat\u00e9gia a ser implementada. Em geral, o enunciado de uma parte \u00e9 liberado ap\u00f3s a data de entrega da parte anterior.</p> <ol> <li>Solu\u00e7\u00e3o Heur\u00edstica (18/03)</li> <li>Busca Local (01/04)</li> <li>Busca Exaustiva (15/04)</li> <li>Relat\u00f3rio Preliminar (29/04)</li> <li>Paralelismo Multicore (13/05)</li> <li>Paralelismo GPU (27/05)</li> <li>Relat\u00f3rio Final (03/06)</li> </ol>"},{"location":"projetos/2021-2/#avaliacao","title":"Avalia\u00e7\u00e3o","text":"<p>O projeto ser\u00e1 avaliado usando rubricas para as entregas b\u00e1sicas. As rubricas de avalia\u00e7\u00e3o dos relat\u00f3rios estar\u00e3o descritas em suas p\u00e1ginas de entrega.</p>"},{"location":"projetos/2021-2/#conceito-d","title":"Conceito D","text":"<p>Algum dos seguintes itens n\u00e3o foi entregue corretamente ou possui problemas s\u00e9rios (no caso do relat\u00f3rio final).</p> <ol> <li>Solu\u00e7\u00e3o heur\u00edstica</li> <li>Busca local</li> <li>Busca exaustiva</li> <li>Busca local paralela (CPU)</li> <li>Busca local paralela (GPU)</li> <li>Relat\u00f3rio preliminar</li> <li>Relat\u00f3rio final</li> </ol>"},{"location":"projetos/2021-2/#conceito-c","title":"Conceito C","text":"<p>Todas as atividades abaixo foram validadas pelo corretor e (no caso do relat\u00f3rio final) alcan\u00e7aram qualidade m\u00ednima exigida.</p> <ol> <li>Solu\u00e7\u00e3o heur\u00edstica</li> <li>Busca local</li> <li>Busca exaustiva</li> <li>Busca local paralela (CPU)</li> <li>Busca local paralela (GPU)</li> <li>Relat\u00f3rio preliminar</li> <li>Relat\u00f3rio final</li> </ol>"},{"location":"projetos/2021-2/#conceito-c_1","title":"Conceito C+","text":"<p>Al\u00e9m do j\u00e1 validado no conceito C, os relat\u00f3rios entregues n\u00e3o tinham nenhum ponto em desenvolvimento ou insatisfat\u00f3rio na rubrica do relat\u00f3rio.</p>"},{"location":"projetos/2021-2/#conceitos-avancados","title":"Conceitos avan\u00e7ados","text":"<p>A partir do  conceito C+ cada atividade avan\u00e7ada vale meio conceito. Elas ser\u00e3o listadas aqui conforme o semestre avan\u00e7a e ser\u00e3o testadas pela checagem de resultados dispon\u00edvel no reposit\u00f3rio de entregas.</p>"},{"location":"projetos/2021-2/busca-exaustiva/","title":"Solu\u00e7\u00e3o Busca exaustiva - Branch and Bound","text":"<p>Fa\u00e7a agora uma implementa\u00e7\u00e3o de busca exaustiva para o problema do min-set-cover. Assuma inicialmente que todos os subconjuntos s\u00e3o necess\u00e1rios. Para cada subconjunto da solu\u00e7\u00e3o, remova ele a solu\u00e7\u00e3o em quest\u00e3o e verifique se a propriedade de cobertura \u00e9 mantida. Fa\u00e7a isso para todos os elementos na ordem do vetor de solu\u00e7\u00f5es, enquanto a propriedade for v\u00e1lida. Se a propriedade ficar inv\u00e1lida, voc\u00ea deve interromper essa linha de processamento, executando ent\u00e3o uma nova estrutura de possibilidades em que considera esse conjunto vital para a continuidade do problema. </p> <p>Para auxiliar na sua implementa\u00e7\u00e3o, voc\u00ea pode se basear no pseudoc\u00f3digo abaixo. Assuma que custos \u00e9 um vetor unit\u00e1rio de cardinalidade igual ao vetor que armazena os subconjuntos. H\u00e1 um programa Python disponibilizado neste link para que voc\u00ea possa simular a implementa\u00e7\u00e3o desse pseudoc\u00f3digo. </p> <p>Avalie: H\u00e1 garantia de que o resultado \u00f3timo \u00e9 obtido? Justifique. </p> <p></p>"},{"location":"projetos/2021-2/busca-local/","title":"Solu\u00e7\u00e3o Busca local","text":"<p>A busca local consiste em uma metaheur\u00edstica usada para resolver problemas de otimiza\u00e7\u00e3o computacionalmente dif\u00edceis. Esse tipo de algoritmo percorre o espa\u00e7o de busca movendo-se iterativamente de uma solu\u00e7\u00e3o candidata para outra, seguindo um caminho atrav\u00e9s da rela\u00e7\u00e3o de vizinhan\u00e7a, at\u00e9 que uma solu\u00e7\u00e3o considerada boa o suficiente seja encontrada ou um limite de tempo decorrido. Normalmente todo candidato possui mais de uma solu\u00e7\u00e3o de vizinho e a escolha entre elas \u00e9 feita com o aux\u00edlio de informa\u00e7\u00f5es locais e experi\u00eancia anterior.</p> <p>A solu\u00e7\u00e3o por busca local  tenta maximizar o n\u00famero de elementos com o m\u00ednimo de subconjuntos poss\u00edvel. Precisamos capturar esse crit\u00e9rio por meio de uma fun\u00e7\u00e3o de fitness. Uma maneira poss\u00edvel de fazer isso \u00e9 construir uma fun\u00e7\u00e3o de fitness calculando o n\u00famero de elementos capturados pelos subconjuntos de uma solu\u00e7\u00e3o candidata e, em seguida, dividindo-o pelo n\u00famero de subconjuntos que cont\u00e9m. Essa fun\u00e7\u00e3o de pontua\u00e7\u00e3o favorecer\u00e1 as solu\u00e7\u00f5es que acumulam a maioria dos elementos do universo U com o m\u00ednimo de subconjuntos.</p> <p>Para isso, implemente as seguintes altera\u00e7\u00f5es em seu projeto:</p> <ol> <li>Gerar uma solu\u00e7\u00e3o aleat\u00f3ria para o problema do min-set-cover;</li> <li>Percorra novamente os conjuntos os elementos da sua solu\u00e7\u00e3o e, de maneira rand\u00f4mica, troque at\u00e9 r (r entre 1 e 3) elementos da sua solu\u00e7\u00e3o por subconjuntos que ficaram de fora da solu\u00e7\u00e3o. </li> <li>Se a solu\u00e7\u00e3o tiver melhor escore, mantenha ela. </li> </ol> <p>Para verificar o desempenho, construa um cen\u00e1rio com ao menos 200 elementos e 80 subconjuntos, de at\u00e9 40 elementos cada.  Fa\u00e7a tr\u00eas varia\u00e7\u00f5es desse cen\u00e1rio (elementos, subconjuntos, n\u00famero de elementos em subconjuntos) e avalie o desempenho e a efetividade em encontrar uma solu\u00e7\u00e3o \u00f3tima.</p> <p>Para a entrega, usaremos o site codePost, voc\u00ea recebeu na sala de aula o link para criar sua conta. A submiss\u00e3o ser\u00e1 feita unicamente por ele. Caso tenha alguma d\u00favida, entre em contato.</p>"},{"location":"projetos/2021-2/heuristico/","title":"Solu\u00e7\u00e3o heur\u00edstica","text":"<p>Um dos melhores estrat\u00e9gias para resolu\u00e7\u00e3o do problema min-set-cover \u00e9 a estrat\u00e9gia gulosa. O algoritmo guloso encontra uma solu\u00e7\u00e3o para o problema de cobertura de conjunto escolhendo iterativamente um conjunto que cobre o maior n\u00famero poss\u00edvel de vari\u00e1veis descobertas restantes.</p> <p>Sua tarefa: implemente a estrat\u00e9gia gulosa para o problema do min-set-cover. A cada itera\u00e7\u00e3o, o algoritmo deve selecionar o subconjunto de F que ir\u00e1 cobrir o maior n\u00famero de elementos de U que estavam descobertos.</p> <p>Veja abaixo um pseudo-c\u00f3digo da estrat\u00e9gia gulosa que voc\u00ea deve implementar.</p> <p></p> <p>Fa\u00e7a testes para diversos tipos de entradas, e foque principalmente em uma grande quantidade de elementos e subconjuntos (n &gt; 250).</p> <p>Voc\u00ea deve entregar, al\u00e9m de c\u00f3digo-fonte e todas as entradas e sa\u00eddas geradas para o seu programa, um arquivo contendo o resultado do programa <code>verify</code> ( que voc\u00ea implementou ) e comentar sobre o n\u00famero de vezes em que voc\u00ea conseguiu encontrar uma solu\u00e7\u00e3o para o problema. Comente tamb\u00e9m sobre o tempo de execu\u00e7\u00e3o de sua implementa\u00e7\u00e3o. </p> <p>Para a entrega, usaremos o site codePost, voc\u00ea recebeu na sala de aula o link para criar sua conta. A submiss\u00e3o ser\u00e1 feita unicamente por ele. Caso tenha alguma d\u00favida, entre em contato.</p>"},{"location":"projetos/2021-2/paralelismo-gpu/","title":"Paralelismo em GPU","text":"<p>Seu trabalho nesta atividade ser\u00e1 criar uma implementa\u00e7\u00e3o paralela em GPU do algoritmo de busca local.</p>"},{"location":"projetos/2021-2/paralelismo-gpu/#compilacao-do-programa","title":"Compila\u00e7\u00e3o do programa","text":"<p>Voc\u00ea dever\u00e1 colocar o c\u00f3digo de seu programa em um arquivo com extens\u00e3o .cu na pasta da busca local. Este programa ser\u00e1 compilado com <code>nvcc -O3</code>. </p> <p>Para a entrega, usaremos o site codePost.</p> <p>\u2192</p>"},{"location":"projetos/2021-2/paralelismo-multicore/","title":"Paralelismo multi-core","text":"<p>Seu trabalho nesta atividade ser\u00e1 criar uma implementa\u00e7\u00e3o paralela do algoritmo de busca local.</p>"},{"location":"projetos/2021-2/paralelismo-multicore/#compilacao-do-programa","title":"Compila\u00e7\u00e3o do programa","text":"<p>Seu programa multi-core dever\u00e1 ser gerado a partir do mesmo c\u00f3digo fonte do sequencial. Ou seja, compilar com <code>-fopenmp</code> habilita o programa paralelo. Compilar sem essa flag obtem os resultados sequenciais. Caso seu programa use as chamadas do OpenMP para c\u00f3digos auxiliares (aloca\u00e7\u00e3o de mem\u00f3ria, etc), voc\u00ea pode checar se seu programa foi compilado com esta flag seguindo o exemplo abaixo.</p> <pre><code>#ifdef _OPENMP\n    // c\u00f3digo espec\u00edfico para multi-core aqui\n#else\n    // c\u00f3digo espec\u00edfico para sequencia aqui\n#endif\n</code></pre> <p>Para a entrega, usaremos o site codePost.</p>"},{"location":"projetos/2021-2/relatorio-1/","title":"Relat\u00f3rio - v1","text":"<p>Nesta primeira parte do relat\u00f3rio iremos analisar as implementa\u00e7\u00f5es j\u00e1 criadas com rela\u00e7\u00e3o a sua velocidade e qualidade da solu\u00e7\u00e3o. Os objetivos deste relat\u00f3rio s\u00e3o </p> <ul> <li>criar entradas de tamanho adequado para os prop\u00f3sitos dos testes</li> <li>estudar o efeito do n\u00famero de pessoas e do n\u00famero de objetos nas medidas de interesse (tempo e qualidade da solu\u00e7\u00e3o)</li> <li>comparar o desempenho dos algoritmos implementados at\u00e9 o momento em rela\u00e7\u00e3o a essas duas medidas.</li> </ul> <p>Seu trabalhou dever\u00e1 ser entregue como um arquivo PDF chamado relatorio-intermediario.pdf na pasta relatorios do reposit\u00f3rio. Ele poder\u00e1 ser gerado a partir de um Jupyter notebook (como feito na aula 01) ou usando a ferramenta pweave (recomendado). A rubrica de avalia\u00e7\u00e3o est\u00e1 dispon\u00edvel abaixo e tamb\u00e9m neste link.</p> <p>Data de entrega: 31/10/2021, pelo blackboard.</p> <p></p>"},{"location":"projetos/2022-1/","title":"Alinhamento de Sequencias de DNA","text":"<p>Em Bioinform\u00e1tica, o problema de alinhamento de sequ\u00eancias de DNA consiste no processo de comparar duas ou mais sequ\u00eancias de bases de forma a se observar seu n\u00edvel de similaridade. Trata-se de um problema extremamente importante no contexto atual, pois permite comparar sequencias virais de SARS-COV2 em bancos de dados gen\u00f4micos para detec\u00e7\u00e3o de novas muta\u00e7\u00f5es.</p> <p>O n\u00edvel de similaridade pode ser calculado com base em acertos (match) e erros (gap e mismatch). Os acertos contribuem com sinal positivo (+) para o n\u00edvel de similaridade e, os erros, com sinal negativo (-). Abaixo temos um exemplo de c\u00e1lculo do n\u00edvel similaridade:</p> <p></p> <p>Vamos associar a pontua\u00e7\u00e3o +1 (match) e as penalidades -1 (gap) e -4 (mismatch). Assim, teremos o seguinte n\u00edvel de similaridade:</p> <p>23 matches x (+1) + 4 gaps x (-1) + 3 mismatches x (-4) = 23-4-12 = 7</p> <p>Neste contexto, o problema de alinhamento de sequencias de DNA pode ser colocado da seguinte forma:</p> <pre><code>Dadas duas sequencias de DNA, com as bases A,T,G,C e - para indicar gap, \nencontrar o alinhamento que maximize o n\u00edvel de similaridade. \n</code></pre> <p>Neste projeto, seu objetivo ser\u00e1 construir programas para encontrar este alinhamento de n\u00edvel m\u00e1ximo de similaridade, utilizando v\u00e1rias estrat\u00e9gias. </p> <p>Cada um dos seus programas tomar\u00e1 como entrada a seguinte estrutura: a primeira linha cont\u00e9m dois n\u00fameros <code>n</code> e <code>m</code>, onde <code>n</code> \u00e9 o tamanho da primeira sequencia e, <code>m</code>, o tamanho da segunda. Assuma <code>n \u2264 200</code> e <code>m \u2264 200</code>. A segunda linha cont\u00e9m as bases da primeira sequencia e, a terceira linha, as bases da segunda.</p> <pre><code>5 7\nAT-CC\nTTTCCAA\n</code></pre> <p>A sa\u00edda deve ser uma linha com um n\u00famero inteiro indicando o n\u00edvel m\u00e1ximo de similaridade.</p> <p><pre><code>2\n</code></pre> Neste caso, este n\u00edvel m\u00e1ximo de similaridade pode ser associado ao alinhamento T-CC/TTCC (1-1+1+1=2) ou a CC/CC(1+1=2). Voc\u00ea pode usar o notebook SequenceGenerator.ipynb para gerar inst\u00e2ncias aleat\u00f3rias para seus testes.</p>"},{"location":"projetos/2022-1/#estrategias-a-serem-estudadas-e-correcao-automatica","title":"Estrat\u00e9gias a serem estudadas e corre\u00e7\u00e3o autom\u00e1tica","text":"<p>Para cada estrat\u00e9gia que vamos estudar, implementaremos um programa correspondente no projeto. Veja abaixo as datas de entrega e descri\u00e7\u00f5es de cada estrat\u00e9gia a ser implementada. Em geral, o enunciado de uma parte \u00e9 liberado ap\u00f3s a data de entrega da parte anterior.</p> <ol> <li>Solu\u00e7\u00e3o Heur\u00edstica (18/03)</li> <li>Busca Local(01/04)</li> <li>Busca Exaustiva(15/04)</li> <li>Relat\u00f3rio Preliminar (29/04)</li> <li>Paralelismo Multicore (13/05)</li> <li>Paralelismo GPU (27/05)</li> <li>Relat\u00f3rio Final (03/06)</li> </ol>"},{"location":"projetos/2022-1/#avaliacao","title":"Avalia\u00e7\u00e3o","text":"<p>O projeto ser\u00e1 avaliado usando rubricas para as entregas b\u00e1sicas. As rubricas de avalia\u00e7\u00e3o dos relat\u00f3rios estar\u00e3o descritas em suas p\u00e1ginas de entrega.</p>"},{"location":"projetos/2022-1/#conceito-d","title":"Conceito D","text":"<p>Algum dos seguintes itens n\u00e3o foi entregue corretamente ou possui problemas s\u00e9rios (no caso do relat\u00f3rio final).</p> <ol> <li>Solu\u00e7\u00e3o heur\u00edstica</li> <li>Busca local</li> <li>Busca exaustiva</li> <li>Busca local paralela (CPU)</li> <li>Busca local paralela (GPU)</li> <li>Relat\u00f3rio preliminar</li> <li>Relat\u00f3rio final</li> </ol>"},{"location":"projetos/2022-1/#conceito-c","title":"Conceito C","text":"<p>Todas as atividades abaixo foram validadas pelo corretor e (no caso do relat\u00f3rio final) alcan\u00e7aram qualidade m\u00ednima exigida.</p> <ol> <li>Solu\u00e7\u00e3o heur\u00edstica</li> <li>Busca local</li> <li>Busca exaustiva</li> <li>Busca local paralela (CPU)</li> <li>Busca local paralela (GPU)</li> <li>Relat\u00f3rio preliminar</li> <li>Relat\u00f3rio final</li> </ol>"},{"location":"projetos/2022-1/#conceito-c_1","title":"Conceito C+","text":"<p>Al\u00e9m do j\u00e1 validado no conceito C, os relat\u00f3rios entregues n\u00e3o tinham nenhum ponto em desenvolvimento ou insatisfat\u00f3rio na rubrica do relat\u00f3rio.</p>"},{"location":"projetos/2022-1/#conceitos-avancados","title":"Conceitos avan\u00e7ados","text":"<p>A partir do  conceito C+ cada atividade avan\u00e7ada vale meio conceito. Elas ser\u00e3o listadas aqui conforme o semestre avan\u00e7a e ser\u00e3o testadas pela checagem de resultados dispon\u00edvel no reposit\u00f3rio de entregas.</p>"},{"location":"projetos/2022-1/SequenceGenerator/","title":"SequenceGenerator","text":"<p>GERADOR DE INST\u00c3\u201aNCIAS PARA COMPARA\u00c3\u2021\u00c3\u0192O DE SEQUENCIAS DE DNA</p> <p>Para usar este gerador, voc\u00c3\u00aa deve fornecer tr\u00c3\u00aas par\u00c3\u00a2metros:</p> <p>n = tamanho da primeira sequencia </p> <p>m = tamanho da segunda inst\u00c3\u00a2ncia </p> <p>file = nome do arquivo da inst\u00c3\u00a2ncia a ser gerada</p> <pre><code>import random\nn = 10\nm = 40\nfile = 'dna.seq'\nf = open(file, 'w')\nseq=[str(n)+'\\n',\n     str(m)+'\\n',\n     ''.join(random.choices(['A','T','C','G','-'],k=n))+'\\n',\n     ''.join(random.choices(['A','T','C','G','-'],k=m))]\nf.writelines(seq)\nf.close()\nprint(''.join(seq))\n</code></pre> <pre>\n<code>10\n40\nTGGCGAT--C\nAGC-TCTCTTC--ATT--CAC-TACACCGACA-CGC-G-A\n</code>\n</pre>"},{"location":"projetos/2022-1/heuristico/","title":"Heur\u00edstica de Alinhamento Local de Smith-Waterman","text":"<p>Um algoritmo ing\u00eanuo para fazer o alinhamento local de duas sequencias de DNA poderia ser:</p> <ol> <li>Gere todas as subsequ\u00eancias, de tamanho 1 at\u00e9 o tamanho total de cada sequ\u00eancia</li> <li>Compare todos os pares de subsequencias, sempre escolhendo uma subsequencia de um DNA e do outro DNA, calculado seus scores</li> <li>Escolha uma que produza o score m\u00e1ximo</li> </ol> <p>Nao \u00e9 dif\u00edcil ver que este algoritmo ing\u00eanuo pode demorar muito tempo para executar quando aumentamos o tamanho das sequencias de DNA.</p> <p>Uma heur\u00edstica sequencial bastante interessante para reduzir o tempo de obten\u00e7\u00e3o dos alinhamentos foi proposta por Smith e Waterman (1981), utilizando programa\u00e7\u00e3o din\u00e2mica. Abaixo, temos a descri\u00e7\u00e3o do algoritmo desta estrat\u00e9gia:</p> <pre>\nALGORITMO SMITH-WATERMAN\nEntrada: Duas sequencias de DNA a[i] e b[j], de tamanhos n e m respectivamente\nSa\u00edda: score m\u00e1ximo de alinhamento \n\n1. Inicializar H[i,0]=0, 0\u2264i\u2264n\n2. Inicializar H[0,j]=0, 0\u2264j\u2264m\n3. Para cada 1\u2264i\u2264n e 1\u2264j\u2264m:\n4.     Calcular diagonal = H[i-1,j-1] + w(a[i],b[j]), onde w(a[i],b[j])=2 se houve match, \n                           w(a[i],b[j])= -1 se houve mismatch e  \n                           w(a[i],b[j])= -1 se houve gap\n5.     Calcular dele\u00e7\u00e3o  = H[i-1,j] - 1\n6.     Calcular inser\u00e7\u00e3o = H[i,j-1] - 1\n7.     Calcular H[i,j]=m\u00e1ximo (0, diagonal, dele\u00e7\u00e3o, inser\u00e7\u00e3o)\n9. Retornar o m\u00e1ximo de H[_,_]\n</pre> <p>Os passos diagonal, dele\u00e7\u00e3o e inser\u00e7\u00e3o s\u00e3o chamados, respectivamente, de salto em diagonal, salto de cima para baixo e salto da esquerda para a direita, e representam movimenta\u00e7\u00f5es para obten\u00e7\u00e3o do alinhamento local \u00f3timo. </p> <p>No link abaixo, \u00e9 poss\u00edvel simular este algoritmo para diversos valores de pesos:</p> <p>http://rna.informatik.uni-freiburg.de/Teaching/index.jsp?toolName=Smith-Waterman</p> <p>Abaixo temos um exemplo da matriz H calculada para as sequ\u00eancias AGCACACA e ACACACTA:</p> <p></p> <p>Para obter o alinhamento local \u00f3timo, come\u00e7amos com o maior valor na matriz (i,j). Ent\u00e3o, n\u00f3s vamos para tr\u00e1s para uma das posi\u00e7\u00f5es (i-1,j), (i,j-1) ou (i-1,j-1), dependendo da dire\u00e7\u00e3o de movimento usado para construir a matriz. Mantemos o processo at\u00e9 chegar a um c\u00e9lula da matriz com valor zero, ou o valor na posi\u00e7\u00e3o (0,0).</p> <p>No exemplo, o valor mais alto corresponde \u00e0 c\u00e9lula na posi\u00e7\u00e3o (8,8). A caminhada de volta corresponde a (8,8), (7,7), (7,6), (6,5), (5,4), (4,3), (3,2), (2,1), (1,1), e (0,0),</p> <p>Uma vez que tenhamos terminado, reconstruimos o alinhamento da seguinte forma: Come\u00e7ando com o \u00faltimo valor, chegamos a (i,j) usando o caminho previamente calculado. Um salto na diagonal implica que h\u00e1 um alinhamento (ou uma correspond\u00eancia ou uma n\u00e3o correspond\u00eancia). Um salto de cima para baixo implica que h\u00e1 uma dele\u00e7\u00e3o. Um salto da esquerda para a direita implica que h\u00e1 uma inser\u00e7\u00e3o. Assim, para a reconstru\u00e7\u00e3o, \u00e9 importante guardar durante a montagem da tabela H qual o tipo de salto foi utilizado.</p> <p>Para o exemplo das sequencias acima, obtemos o seguinte alinhamento local \u00f3timo (em rela\u00e7\u00e3o aos pesos dados para match, mismatch e gap):</p> <pre>\nSequ\u00eancia 1 = A-CACACTA\nSequ\u00eancia 2 = AGCACAC-A\n</pre> <p>A partir desta descri\u00e7\u00e3o, nosso primeiro projeto ter\u00e1 duas tarefas:</p> <ul> <li> Implementar um programa C++ para ler um arquivo contendo os tamanhos de duas sequencias de DNA, seguidos das duas sequencias, uma por linha. Calcular o score m\u00e1ximo de alinhamento local usando a heur\u00edstica de Smith-Waterman. As informa\u00e7\u00f5es para reconstru\u00e7\u00e3o dever\u00e3o ser armazenadas no formato de struct.   <li> a partir do score m\u00e1ximo, reconstruir e exibir o alinhamento local \u00f3timo das duas sequencias.  <p>No diret\u00f3rio do projeto, h\u00e1 um gerador de entradas disponibilizado como um notebook Python.</p> <p>Para quem estiver interessado no artigo original da heur\u00edstica de Smith-Waterman, basta consultar o link http://arep.med.harvard.edu/pdf/Smith81.pdf.</p>"},{"location":"projetos/2025-2/projeto-cpu/","title":"Projeto 1 - Minera\u00e7\u00e3o de Hashes CPU em ambiente de HPC","text":"<p>A minera\u00e7\u00e3o surgiu com o Bitcoin, criado por Satoshi Nakamoto em 2008. A proposta era descentralizar o controle do dinheiro, permitindo que qualquer pessoa pudesse participar da valida\u00e7\u00e3o das transa\u00e7\u00f5es em uma rede p\u00fablica.</p> <p>A valida\u00e7\u00e3o \u00e9 feita por meio de um algoritmo de consenso chamado Proof of Work (PoW). A PoW exige que os n\u00f3s da rede (os mineradores) resolvam um problema matem\u00e1tico dif\u00edcil \u2014 e quem resolve primeiro, tem o direito de adicionar um novo bloco \u00e0 blockchain e receber uma recompensa.</p> <p>Essa \u201cprova\u201d \u00e9 feita atrav\u00e9s de um processo chamado de hashing, e no caso do Bitcoin, utiliza o algoritmo SHA-256.</p>"},{"location":"projetos/2025-2/projeto-cpu/#o-que-e-sha-256","title":"O que \u00e9 SHA-256","text":"<p>SHA-256 \u00e9 parte da fam\u00edlia de fun\u00e7\u00f5es de hash SHA-2, desenvolvida pela Ag\u00eancia de Seguran\u00e7a Nacional dos Estados Unidos (NSA) em 2001. SHA significa Secure Hash Algorithm.</p>"},{"location":"projetos/2025-2/projeto-cpu/#caracteristicas-principais","title":"Caracter\u00edsticas principais:","text":"<ul> <li>Gera uma sa\u00edda de 256 bits (64 caracteres hexadecimais)</li> <li>\u00c9 uma fun\u00e7\u00e3o determin\u00edstica: mesma entrada, mesma sa\u00edda</li> <li>\u00c9 unidirecional: n\u00e3o d\u00e1 para \"voltar\" da sa\u00edda para a entrada</li> <li>Pequenas mudan\u00e7as na entrada resultam em mudan\u00e7as dr\u00e1sticas na sa\u00edda (efeito avalanche)</li> <li>Altamente sens\u00edvel \u00e0 colis\u00f5es (duas entradas diferentes que d\u00e3o a mesma sa\u00edda s\u00e3o indesej\u00e1veis)</li> </ul>"},{"location":"projetos/2025-2/projeto-cpu/#como-o-sha-256-funciona","title":"Como o SHA-256 funciona?","text":"<p>SHA-256 funciona em blocos de 512 bits de entrada, que passam por v\u00e1rias etapas:</p> <ol> <li>Pr\u00e9-processamento:</li> <li>Padding: a mensagem \u00e9 estendida at\u00e9 m\u00faltiplos de 512 bits.</li> <li>Parsing: a mensagem \u00e9 dividida em blocos de 512 bits.</li> <li> <p>Inicializa\u00e7\u00e3o: 8 vari\u00e1veis de 32 bits com constantes iniciais (derivadas da raiz quadrada dos primeiros 8 primos).</p> </li> <li> <p>Fun\u00e7\u00e3o de compress\u00e3o:</p> </li> <li>Cada bloco de 512 bits passa por 64 rodadas de opera\u00e7\u00f5es bit a bit (AND, OR, XOR, ROTR, etc).</li> <li>Usa uma tabela de 64 constantes (derivadas da raiz c\u00fabica dos primeiros 64 primos).</li> <li> <p>A cada rodada, as vari\u00e1veis s\u00e3o atualizadas com fun\u00e7\u00f5es n\u00e3o lineares.</p> </li> <li> <p>Concatena\u00e7\u00e3o final:</p> </li> <li>Ap\u00f3s todos os blocos processados, os 8 valores de 32 bits s\u00e3o concatenados e formam o hash final de 256 bits.</li> </ol>"},{"location":"projetos/2025-2/projeto-cpu/#mineracao-com-sha-256-o-que-acontece","title":"Minera\u00e7\u00e3o com SHA-256: o que acontece?","text":"<p>O minerador tenta encontrar um valor chamado nonce que, quando combinado com o cabe\u00e7alho do bloco e passado pelo SHA-256 duas vezes (double SHA-256), resulta em um hash menor que o alvo definido pela dificuldade da rede.</p> <p>Ou seja, o minerador est\u00e1 basicamente tentando encontrar um n\u00famero (nonce) que leve o hash a come\u00e7ar com N zeros.</p>"},{"location":"projetos/2025-2/projeto-cpu/#por-que-e-um-problema-de-hpc","title":"Por que \u00e9 um problema de HPC?","text":"<p>A minera\u00e7\u00e3o \u00e9 um problema de busca exaustiva. Os mineradores testam bilh\u00f5es de nonces por segundo. A performance da minera\u00e7\u00e3o depende da capacidade de realizar SHA-256 o mais r\u00e1pido poss\u00edvel.</p> <p>Por tr\u00e1s da id\u00e9ia de \"minerar bitcoins\", existe um problema computacional intensivo, cuja solu\u00e7\u00e3o depende de capacidade de processamento, efici\u00eancia do c\u00f3digo e uso inteligente dos recursos de hardware.</p> <p>Ent\u00e3o, o que a minera\u00e7\u00e3o tem a ver com HPC?</p> <p>Simples: a minera\u00e7\u00e3o de criptomoedas \u00e9 um problema cl\u00e1ssico de HPC moderno, por envolver:</p> <pre><code>Busca exaustiva de solu\u00e7\u00f5es (nonces)\n\nProcessamento paralelo de dados\n\nUso de algoritmos de hash otimizados (SHA-256)\n\nAproveitamento de CPU, GPU e clusters\n</code></pre> <p>para entender com mais detalhes como SHA-256 se relaciona com um sistema de criptomoedas, assista o v\u00eddeo. Vamos ao projeto...</p>"},{"location":"projetos/2025-2/projeto-cpu/#projeto-1-mineracao-de-hashes-em-ambiente-de-hpc","title":"Projeto 1 - Minera\u00e7\u00e3o de Hashes em ambiente de HPC","text":""},{"location":"projetos/2025-2/projeto-cpu/#grupos-de-no-maximo-3-alunos-data-de-entrega-29setembro","title":"Grupos de no m\u00e1ximo 3 alunos, data de entrega 29/Setembro","text":"<p>Acesse o reposit\u00f3rio do projeto aqui</p> <p>Neste projeto, seu grupo dever\u00e1 diagnosticar e otimizar um algoritmo de minera\u00e7\u00e3o de criptomoedas implementado em C++. O c\u00f3digo inicial foi propositalmente escrito de forma ineficiente, apresentando gargalos p\u00e9ssimas pr\u00e1ticas de uso de mem\u00f3ria.</p> <p>Espera-se que seu grupo seja capaz de identificar esses problemas, propor hip\u00f3teses de melhoria, aplicar t\u00e9cnicas de otimiza\u00e7\u00e3o e mensurar o impacto das mudan\u00e7as no desempenho da aplica\u00e7\u00e3o. Ao final, seu grupo dever\u00e1 elaborar um relat\u00f3rio t\u00e9cnico, documentando todo o processo de an\u00e1lise e otimiza\u00e7\u00e3o.</p> <p>A dificuldade da minera\u00e7\u00e3o \u00e9 ajustada pela quantidade de zeros exigida no in\u00edcio do hash. \u00c0 medida que voc\u00eas aumentam essa dificuldade, o desafio computacional cresce, o que demanda boas decis\u00f5es de otimiza\u00e7\u00e3o e uso eficiente de CPU e mem\u00f3ria. Analise adequadamente os recursos dispon\u00edveis das filas do Cluster Franky para realizar os seus testes e suas otimiza\u00e7\u00f5es.</p>"},{"location":"projetos/2025-2/projeto-cpu/#objetivo","title":"Objetivo","text":"<p>Aplicar conhecimentos de:</p> <ul> <li>An\u00e1lise de desempenho</li> <li>Diagn\u00f3stico de gargalos</li> <li>Boas pr\u00e1ticas de gerenciamento de mem\u00f3ria</li> <li>Paralelismo com OpenMP</li> <li>Distribui\u00e7\u00e3o com MPI</li> </ul>"},{"location":"projetos/2025-2/projeto-cpu/#rubrica-de-avaliacao","title":"R\u00fabrica de Avalia\u00e7\u00e3o","text":"Conceito Crit\u00e9rios T\u00e9cnicos C Executa o minerador sequencial no cluster Franky com dificuldade 6 zeros, Realiza Passagem de objetos grandes por refer\u00eancia ou ponteiro; Minimiza\u00e7\u00e3o de c\u00f3pias desnecess\u00e1rias; Uso eficiente de buffers;  Implementa uma heur\u00edsitca eficiente. B Executa o minerador com dificuldade 7 zeros, Realiza as otimiza\u00e7\u00f5es da r\u00fabrica C e aplica paraleliza\u00e7\u00e3o com OpenMP ou distribui\u00e7\u00e3o com MPI A Executa o minerador com dificuldade 8 zeros, Realiza as otimiza\u00e7\u00f5es da r\u00fabrica C e aplica paraleliza\u00e7\u00e3o com OpenMP E distribui\u00e7\u00e3o com MPI"},{"location":"projetos/2025-2/projeto-cpu/#entrega","title":"Entrega","text":"<p>A entrega deve conter:</p> <ol> <li> <p>O nome de cada integrante do grupo</p> </li> <li> <p>C\u00f3digo-fonte funcional</p> </li> <li> <p>Diagn\u00f3stico dos gargalos do c\u00f3digo base</p> </li> <li> <p>Proposta de otimiza\u00e7\u00e3o e hip\u00f3tese de melhoria</p> </li> <li> <p>Implementa\u00e7\u00e3o da hip\u00f3tese</p> </li> <li> <p>Compara\u00e7\u00e3o de desempenho (tempo, speedup, efici\u00eancia, etc.)</p> </li> <li> <p>Discuss\u00e3o dos resultados e limita\u00e7\u00f5es encontradas</p> </li> </ol>"},{"location":"projetos/2025-2/projeto-cpu/#bonus-por-qualidade-do-relatorio-tecnico","title":"B\u00f4nus por Qualidade do relat\u00f3rio t\u00e9cnico","text":"Conceito Base Com B\u00f4nus C C+ B B+ A A+"},{"location":"projetos/2025-2/projeto-cpu/#observacoes","title":"Observa\u00e7\u00f5es","text":"<ul> <li>Espera-se que o aluno entenda os problemas do c\u00f3digo base antes de corrigir.</li> <li>O bin\u00e1rio <code>transacoes</code> simula um ambiente de rede ass\u00edncrono com envio de blocos n\u00e3o simult\u00e2neos, para que o c\u00f3digo minerador seja tolerante a ordem e tempo de chegada.</li> <li>A execu\u00e7\u00e3o dos testes pode demorar minutos. Se planeje bem, escolha adequadamente a fila que ser\u00e1 utilizada nos seus testes.</li> </ul>"},{"location":"projetos/2025-2/projeto-gpu/","title":"Projeto 2 - Minera\u00e7\u00e3o de Hashes GPU em ambiente de HPC","text":""},{"location":"projetos/2025-2/projeto-gpu/#individual-data-de-entrega-14novembro","title":"Individual, data de entrega 14/Novembro","text":"<p>Acesse o reposit\u00f3rio do projeto aqui</p> <p>Neste projeto, voc\u00ea dever\u00e1 diagnosticar e otimizar um algoritmo de minera\u00e7\u00e3o de criptomoedas implementado em C++. </p> <p>Espera-se que voc\u00ea seja capaz de identificar os gargalos do c\u00f3digo, aplicar t\u00e9cnicas de otimiza\u00e7\u00e3o e mensurar o impacto das mudan\u00e7as no desempenho da aplica\u00e7\u00e3o. Ao final, voc\u00ea dever\u00e1 elaborar um relat\u00f3rio, documentando todo o processo de an\u00e1lise e otimiza\u00e7\u00e3o.</p> <p>A dificuldade da minera\u00e7\u00e3o \u00e9 ajustada pela quantidade de zeros exigida no in\u00edcio do hash. \u00c0 medida que voc\u00eas aumentam essa dificuldade, o desafio computacional cresce, o que demanda boas decis\u00f5es de otimiza\u00e7\u00e3o e uso eficiente de CPU, GPU e mem\u00f3ria. Analise adequadamente os recursos dispon\u00edveis no sistema de HPC utilizado para realizar os seus testes e suas otimiza\u00e7\u00f5es.</p>"},{"location":"projetos/2025-2/projeto-gpu/#entrega","title":"Entrega","text":"<p>A entrega deve incluir um relat\u00f3rio t\u00e9cnico descrevendo de forma clara:</p> <ul> <li>as estrat\u00e9gias de otimiza\u00e7\u00e3o aplicadas no c\u00f3digo, justificando as escolhas de cada abordagem;</li> <li>as m\u00e9tricas de desempenho utilizadas (tempo de execu\u00e7\u00e3o, throughput, etc.);</li> <li>os ganhos de desempenho obtidos, com evid\u00eancias experimentais (gr\u00e1ficos, tabelas).</li> </ul> <p>O relat\u00f3rio deve refletir o racioc\u00ednio cr\u00edtico sobre o impacto das otimiza\u00e7\u00f5es no uso da GPU e a efici\u00eancia paralela alcan\u00e7ada.</p> Conceito Crit\u00e9rios C Executa o minerador com paralelismo em GPU, demonstrando dom\u00ednio de boas pr\u00e1ticas como minimiza\u00e7\u00e3o de c\u00f3pias entre CPU e GPU, uso eficiente de buffers, redu\u00e7\u00e3o de acessos \u00e0 mem\u00f3ria global e implementa\u00e7\u00e3o de uma heur\u00edstica eficiente. O c\u00f3digo deve atingir dificuldade 6 zeros e realizar a minera\u00e7\u00e3o em at\u00e9 20 minutos no Cluster Franky. B Executa o minerador com dificuldade 7 zeros aplicando todas as otimiza\u00e7\u00f5es da r\u00fabrica C. O experimento deve ser executado no supercomputador Santos Dumont, completando a minera\u00e7\u00e3o de todos os blocos em no m\u00e1ximo 20 minutos. A Executa o minerador com dificuldade 7 zeros, aplicando todas as otimiza\u00e7\u00f5es da r\u00fabrica C. O experimento deve ser executado no supercomputador Santos Dumont, completando a minera\u00e7\u00e3o de todos os blocos em no m\u00e1ximo 10 minutos. A+ Executa o minerador com dificuldade 8 zeros, aplicando todas as otimiza\u00e7\u00f5es da r\u00fabrica C. O experimento deve ser executado no supercomputador Santos Dumont, completando a minera\u00e7\u00e3o de todos os blocos em no m\u00e1ximo 1 hora e 35 minutos."},{"location":"teoria/","title":"Materiais e Guias para estudo","text":"<p>Material Te\u00f3rico para estudo</p> <p>Contextualizando HPC</p> <p>Cluster Franky</p> <p>SLURM</p> <p>Conceitos B\u00e1sicos de HW</p> <p>Conceitos B\u00e1sicos de C++</p> <p>Como compilar e executar c\u00f3digos em C++</p> <p>Loops e La\u00e7os</p> <p>Passagens de par\u00e2metros (por refer\u00eancia, por ponteiro)</p> <p>Const Correctness em HPC</p> <p>Aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica</p> <p>Sobrecarga de fun\u00e7\u00f5es C++</p> <p>Classes e Objetos</p> <p>Manipula\u00e7\u00e3o de Vetores</p> <p>Flags de compila\u00e7\u00e3o</p> <p>Profiling</p>"},{"location":"teoria/MPI/","title":"MPI","text":""},{"location":"teoria/MPI/#conceitos-basicos-de-mpi","title":"Conceitos b\u00e1sicos de MPI","text":"<p>MPI (Message Passing Interface) \u00e9 um padr\u00e3o para programa\u00e7\u00e3o paralela em mem\u00f3ria compartilhada, o seja, em v\u00e1rios n\u00f3s de computa\u00e7\u00e3o. Cada processo \u00e9 identificado por um rank (um n\u00famero de 0 at\u00e9 <code>size-1</code>), todos os processos de um programa MPI formam um comunicador (por padr\u00e3o <code>MPI_COMM_WORLD</code>).</p>"},{"location":"teoria/MPI/#comunicacao-ponto-a-ponto","title":"Comunica\u00e7\u00e3o ponto a ponto","text":""},{"location":"teoria/MPI/#envio-e-recebimento-bloqueantes","title":"Envio e recebimento bloqueantes","text":"<pre><code>MPI_Send(buffer, count, MPI_CHAR, destino, tag, MPI_COMM_WORLD);\nMPI_Recv(buffer, count, MPI_CHAR, origem, tag, MPI_COMM_WORLD, &amp;status);\n</code></pre> <ul> <li><code>buffer</code>: ponteiro para os dados.</li> <li><code>count</code>: n\u00famero de elementos.</li> <li><code>MPI_CHAR</code>, <code>MPI_INT</code>, <code>MPI_DOUBLE</code> etc.</li> <li><code>destino</code> / <code>origem</code>: rank do processo de envio/recebimento.</li> <li><code>tag</code>: identificador da mensagem (permite diferenciar mensagens).</li> <li><code>status</code>: metadados sobre a recep\u00e7\u00e3o.</li> </ul>"},{"location":"teoria/MPI/#envio-e-recebimento-nao-bloqueantes","title":"Envio e recebimento n\u00e3o-bloqueantes","text":"<pre><code>MPI_Request req;\nMPI_Isend(buffer, count, MPI_INT, destino, tag, MPI_COMM_WORLD, &amp;req);\nMPI_Wait(&amp;req, MPI_STATUS_IGNORE);\n</code></pre> <pre><code>MPI_Request req;\nMPI_Irecv(buffer, count, MPI_INT, origem, tag, MPI_COMM_WORLD, &amp;req);\nMPI_Wait(&amp;req, MPI_STATUS_IGNORE);\n</code></pre> <ul> <li>Permitem sobrepor comunica\u00e7\u00e3o e computa\u00e7\u00e3o.</li> <li>Precisa sempre de <code>MPI_Wait</code> (ou <code>MPI_Test</code>).</li> </ul>"},{"location":"teoria/MPI/#comunicacao-coletiva","title":"Comunica\u00e7\u00e3o coletiva","text":"<ul> <li>Broadcast</li> </ul> <pre><code>MPI_Bcast(buffer, count, MPI_INT, root, MPI_COMM_WORLD);\n</code></pre> <p>Envia <code>buffer</code> do processo <code>root</code> para todos.</p> <ul> <li>Scatter</li> </ul> <pre><code>MPI_Scatter(sendbuf, count, MPI_INT, recvbuf, count, MPI_INT, root, MPI_COMM_WORLD);\n</code></pre> <p>Distribui partes de um vetor do root para todos.</p> <ul> <li>Gather</li> </ul> <pre><code>MPI_Gather(sendbuf, count, MPI_INT, recvbuf, count, MPI_INT, root, MPI_COMM_WORLD);\n</code></pre> <p>Cada processo envia dados para o root.</p> <ul> <li>Reduce</li> </ul> <pre><code>MPI_Reduce(&amp;valor_local, &amp;valor_total, 1, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n</code></pre> <p>Combina valores de todos os processos (soma, m\u00e1ximo, m\u00ednimo, etc.).</p> <ul> <li>Barrier</li> </ul> <pre><code>MPI_Barrier(MPI_COMM_WORLD);\n</code></pre> <p>Todos os processos param at\u00e9 que todos cheguem aqui.</p>"},{"location":"teoria/MPI/#medicao-de-tempo","title":"Medi\u00e7\u00e3o de tempo","text":"<pre><code>double t0 = MPI_Wtime();\n// ... c\u00f3digo ...\ndouble t1 = MPI_Wtime();\nif(rank==0) std::cout &lt;&lt; \"Tempo = \" &lt;&lt; (t1-t0) &lt;&lt; \" segundos\\n\";\n</code></pre>"},{"location":"teoria/MPI/#estruturas-uteis","title":"Estruturas \u00fateis","text":"<ul> <li>MPI_Status \u2192 cont\u00e9m informa\u00e7\u00f5es de mensagens recebidas (como rank origem).</li> </ul> <pre><code>MPI_Status status;\nMPI_Recv(buf, n, MPI_INT, origem, tag, MPI_COMM_WORLD, &amp;status);\nint origem_real; MPI_Get_count(&amp;status, MPI_INT, &amp;origem_real);\n</code></pre> <ul> <li>Tags \u2192 permitem diferenciar mensagens diferentes em paralelo.</li> </ul>"},{"location":"teoria/MPI/#carregue-o-modulo","title":"Carregue o modulo","text":"<pre><code>spack load openmpi\n</code></pre>"},{"location":"teoria/MPI/#teste-para-ver-se-o-modulo-foi-carregado-corretamente","title":"Teste para ver se o modulo foi carregado corretamente","text":"<pre><code>mpicc --version\n</code></pre>"},{"location":"teoria/MPI/#deve-aparecer-algo-como","title":"Deve aparecer algo como:","text":"<pre><code>gcc (GCC) 14.2.0\nCopyright (C) 2024 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre>"},{"location":"teoria/MPI/#compile-o-programa","title":"Compile o programa:","text":"<pre><code>mpic++ -FlagdeOtimiza\u00e7\u00e3o seu_codigo.cpp -o seu_binario\n</code></pre> <p>Executar com SLURM (arquivo <code>job.slurm</code>):</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=mpi_hello\n#SBATCH --output=saida%j.txt\n#SBATCH --partition=express\n#SBATCH --mem=1GB\n#SBATCH --nodes=2\n#SBATCH --ntasks=5\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:02:00\n#SBATCH --export=ALL\n\n\n# Fa\u00e7a load nos m\u00f3dulos dentro do n\u00f3 de computa\u00e7\u00e3o\nsource /etc/profile\n. /opt/spack/share/spack/setup-env.sh\nmodule use /opt/spack/share/spack/lmod/linux-rocky9-x86_64/Core\nmodule --ignore_cache load openmpi/5.0.8-gcc-14.2.0\n\n# Execute o seu bin\u00e1rio com o MPI\nmpirun -np $SLURM_NTASKS ./seu_binario\n</code></pre> <p>Submit:</p> <pre><code>sbatch job.slurm\n</code></pre> <p>Documenta\u00e7\u00e3o: https://www.physics.rutgers.edu/~haule/509/MPI_Guide_C++.pdf</p>"},{"location":"teoria/comandos-ssh/","title":"Transfer\u00eancia de Arquivos entre sua m\u00e1quina e o Cluster Franky","text":"<p>O comando <code>scp</code> (Secure Copy Protocol) \u00e9 uma ferramenta segura e eficiente para transferir arquivos entre sua m\u00e1quina local e um servidor remoto, como o cluster Franky. Ele utiliza o protocolo SSH para realizar a transfer\u00eancia de arquivos, garantindo a seguran\u00e7a dos dados durante o processo.</p>"},{"location":"teoria/comandos-ssh/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que: - Voc\u00ea tenha acesso ao cluster Franky via SSH. - O comando <code>scp</code> esteja instalado em sua m\u00e1quina (a maioria dos sistemas operacionais baseados em Unix/Linux j\u00e1 possuem o <code>scp</code> por padr\u00e3o).</p>"},{"location":"teoria/comandos-ssh/#transferindo-um-arquivo-da-sua-maquina-para-o-cluster-franky","title":"Transferindo um Arquivo da Sua M\u00e1quina para o Cluster Franky","text":"<p>Para transferir um arquivo do seu computador para o cluster Franky, voc\u00ea pode usar o seguinte comando:</p> <p><pre><code>scp /caminho/local/do/arquivo.txt usuario@ip_do_cluster:/caminho/remoto/destino/\n</code></pre> Este comando copia o arquivo <code>meu_arquivo.txt</code> do diret\u00f3rio local <code>/home/user/</code> para o diret\u00f3rio <code>/home/usuario/destino/</code> no cluster Franky.</p>"},{"location":"teoria/comandos-ssh/#explicacao-dos-parametros","title":"Explica\u00e7\u00e3o dos Par\u00e2metros:","text":"<ul> <li><code>/caminho/local/do/arquivo.txt</code>: Caminho completo do arquivo na sua m\u00e1quina local que voc\u00ea deseja transferir.</li> <li><code>usuario@ip_do_cluster</code>: Seu nome de usu\u00e1rio e o endere\u00e7o de ip do cluster Franky.</li> <li><code>/caminho/remoto/destino/</code>: O diret\u00f3rio de destino no cluster Franky onde voc\u00ea deseja salvar o arquivo.</li> </ul>"},{"location":"teoria/comandos-ssh/#transferindo-um-arquivo-do-cluster-franky-para-sua-maquina","title":"Transferindo um Arquivo do Cluster Franky para sua M\u00e1quina","text":"<p>Para copiar um arquivo do cluster Franky para a sua m\u00e1quina local, use o seguinte comando no seu terminal:</p> <p><pre><code>scp usuario@ip_do_cluster:/caminho/remoto/do/arquivo.txt /caminho/local/destino/\n</code></pre> Este comando copia o arquivo <code>arquivo_remoto.txt</code> do diret\u00f3rio <code>/home/usuario/</code> no cluster Franky para o diret\u00f3rio <code>/home/user/destino_local/</code> na sua m\u00e1quina.</p>"},{"location":"teoria/comandos-ssh/#explicacao-dos-parametros_1","title":"Explica\u00e7\u00e3o dos Par\u00e2metros:","text":"<ul> <li><code>usuario@franky.cluster:/caminho/remoto/do/arquivo.txt</code>: O caminho completo do arquivo no cluster Franky que voc\u00ea deseja transferir para sua m\u00e1quina local.</li> <li> <p><code>/caminho/local/destino/</code>: O diret\u00f3rio de destino na sua m\u00e1quina local onde voc\u00ea deseja salvar o arquivo.</p> </li> <li> <p>Transfer\u00eancia Recursiva: Para transferir diret\u00f3rios inteiros (incluindo subdiret\u00f3rios e arquivos), use a op\u00e7\u00e3o <code>-r</code>:</p> </li> </ul> <pre><code>scp -r /caminho/local/do/diretorio/ usuario@ip_do_cluster:/caminho/remoto/destino/\n</code></pre> <p>O comando <code>scp</code> \u00e9 uma ferramenta poderosa para transferir arquivos entre sua m\u00e1quina e o cluster Franky de forma segura e eficiente. Com as instru\u00e7\u00f5es e exemplos fornecidos neste guia, voc\u00ea deve ser capaz de realizar transfer\u00eancias de arquivos com facilidade.</p>"},{"location":"teoria/comandos/","title":"\u00datil","text":""},{"location":"teoria/comandos/#comandos-slurm","title":"Comandos SLURM","text":""},{"location":"teoria/comandos/#principais-recursos-que-voce-pode-pedir-com-srun","title":"Principais recursos que voc\u00ea pode pedir com <code>srun</code>","text":"O que pedir Op\u00e7\u00e3o do <code>srun</code> Exemplo N\u00famero de tarefas (processos) <code>--ntasks</code> ou <code>-n</code> <code>--ntasks=2</code> CPUs por tarefa <code>--cpus-per-task</code> <code>--cpus-per-task=2</code> Mem\u00f3ria total ou por CPU <code>--mem</code>, <code>--mem-per-cpu</code> <code>--mem=4G</code> ou <code>--mem-per-cpu=2G</code> Tempo de execu\u00e7\u00e3o <code>--time=DD-HH:MM:SS</code> <code>--time=01:12:49</code> N\u00famero de n\u00f3s <code>--nodes</code> <code>--nodes=2</code> N\u00f3 espec\u00edfico <code>--nodelist</code> <code>--nodelist=compute13</code> GPUs <code>--gpus</code> ou <code>--gres=gpu:&lt;num&gt;</code> <code>--gpus=1</code> ou <code>--gres=gpu:2</code> Parti\u00e7\u00e3o (fila) <code>--partition</code> ou <code>-p</code> <code>--partition=gpu</code> Sess\u00e3o interativa <code>--pty bash</code> <code>--pty bash</code> <p>Exemplos</p> <p>Pedido simples de execu\u00e7\u00e3o de tarefa para o SLURM <pre><code>srun --nodelist=compute10 --partition=normal --ntasks=1 --pty bash\n</code></pre> --srun: Comando SLURM para executar tarefas  --nodelist=compute10: for\u00e7a o SLURM a alocar exatamente esse n\u00f3. --partition=normal: indica a parti\u00e7\u00e3o \u00e0 qual o n\u00f3 pertence. --ntasks=1: pede uma tarefa. --pty bash: pede um terminal dentro do n\u00f3.</p> <p>Pedido sem especificar o n\u00f3 exato: <pre><code>srun --partition=normal --ntasks=1 --pty bash\n</code></pre></p> <p>Pedido com varias tasks para executar seu programa direto: <pre><code>srun --partition=normal --ntasks=4 ./meu_programa_paralelo\n</code></pre></p>"},{"location":"teoria/comandos/#principais-recursos-que-voce-pode-pedir-com-sbatch","title":"Principais recursos que voc\u00ea pode pedir com <code>sbatch</code>","text":"O que pedir Op\u00e7\u00e3o do <code>sbatch</code> (no script) Exemplo dentro do script Nome do job <code>--job-name</code> <code>#SBATCH --job-name=teste%j</code> N\u00famero de tarefas (processos) <code>--ntasks</code> ou <code>-n</code> <code>#SBATCH --ntasks=2</code> CPUs por tarefa <code>--cpus-per-task</code> <code>#SBATCH --cpus-per-task=2</code> Mem\u00f3ria total ou por CPU <code>--mem</code>, <code>--mem-per-cpu</code> <code>#SBATCH --mem=4G</code> ou <code>--mem-per-cpu=2G</code> Tempo de execu\u00e7\u00e3o <code>--time=DD-HH:MM:SS</code> <code>#SBATCH --time=01:12:49</code> N\u00famero de n\u00f3s <code>--nodes</code> <code>#SBATCH --nodes=2</code> N\u00f3 espec\u00edfico <code>--nodelist</code> <code>#SBATCH --nodelist=compute13</code> GPUs <code>--gpus</code> ou <code>--gres=gpu:&lt;num&gt;</code> <code>#SBATCH --gpus=1</code> ou <code>#SBATCH --gres=gpu:2</code> Parti\u00e7\u00e3o (fila) <code>--partition</code> ou <code>-p</code> <code>#SBATCH --partition=gpu</code> Sa\u00edda padr\u00e3o (log) <code>--output</code> <code>#SBATCH --output=saida%j.txt</code> Log de Erro do sistema <code>--error</code> <code>#SBATCH --error=erro%j.txt</code> <p>Exemplos</p> <p>Arquivo: <code>job1.slurm</code></p> <pre><code>#!/bin/bash\n#SBATCH --job-name=teste%j\n#SBATCH --partition=normal\n#SBATCH --ntasks=1\n#SBATCH --time=00:10:00\n#SBATCH --output=saida%j.txt\n\n./meu_programa\n</code></pre> <p>Submeter com:</p> <pre><code>sbatch job1.slurm\n</code></pre>"},{"location":"teoria/comandos/#comandos-gerais-do-slurm","title":"Comandos gerais do SLURM","text":"Finalidade Comando Exemplo Ver status das parti\u00e7\u00f5es e n\u00f3s <code>sinfo</code> <code>sinfo -N -l</code> Ver detalhes de um n\u00f3 espec\u00edfico <code>scontrol show node</code> <code>scontrol show node compute24</code> Ver detalhes de uma parti\u00e7\u00e3o <code>scontrol show partition</code> <code>scontrol show partition normal</code> Ver todos os jobs ativos <code>squeue</code> <code>squeue</code> Ver seus pr\u00f3prios jobs <code>squeue -u &lt;usu\u00e1rio&gt;</code> <code>squeue -u liciascl</code> Ver detalhes de um job <code>scontrol show job</code> <code>scontrol show job 12345</code> Cancelar job em execu\u00e7\u00e3o ou na fila <code>scancel</code> <code>scancel 12345</code> Cancelar todos os seus jobs <code>scancel -u &lt;usu\u00e1rio&gt;</code> <code>scancel -u liciascl</code>"},{"location":"teoria/comandos/#ver-todos-os-nos-com-status-detalhado","title":"Ver todos os n\u00f3s com status detalhado","text":"<p><pre><code>sinfo -N -l\n</code></pre> \u00datil para ver quais n\u00f3s est\u00e3o idle, alocados, down ou drain.</p>"},{"location":"teoria/comandos/#ver-informacoes-completas-do-no-compute24","title":"Ver informa\u00e7\u00f5es completas do n\u00f3 <code>compute24</code>","text":"<p><pre><code>scontrol show node compute24\n</code></pre> Mostra: mem\u00f3ria total e usada, CPUs alocadas, jobs em execu\u00e7\u00e3o, estado (<code>IDLE</code>, <code>ALLOCATED</code>, etc.).</p>"},{"location":"teoria/comandos/#ver-configuracoes-de-uma-particao-especifica","title":"Ver configura\u00e7\u00f5es de uma parti\u00e7\u00e3o especifica","text":"<p><pre><code>scontrol show partition normal\n</code></pre> Mostra: tempo m\u00e1ximo de job, n\u00famero de n\u00f3s, limites de mem\u00f3ria/CPU, GPUs, estado da fila.</p>"},{"location":"teoria/comandos/#ver-jobs-no-sistema","title":"Ver jobs no sistema","text":"<p><pre><code>squeue\n</code></pre> Mostra todos os jobs na fila e em execu\u00e7\u00e3o com status <code>R</code> (running), <code>PD</code> (pending), etc.</p>"},{"location":"teoria/comandos/#ver-so-os-jobs-da-usuaria-liciascl","title":"Ver s\u00f3 os jobs da usu\u00e1ria <code>liciascl</code>","text":"<p><pre><code>squeue -u liciascl\n</code></pre> \u00datil para depurar seus pr\u00f3prios jobs (ID, parti\u00e7\u00e3o, status, tempo, n\u00f3, etc.)</p>"},{"location":"teoria/comandos/#ver-informacoes-completas-de-um-job-especifico","title":"Ver informa\u00e7\u00f5es completas de um job espec\u00edfico","text":"<p><pre><code>scontrol show job 12345\n</code></pre> Mostra: usu\u00e1rio, parti\u00e7\u00e3o, CPUs/n\u00f3s alocados, prioridade, estado, tempo usado, comando enviado.</p>"},{"location":"teoria/comandos/#cancelar-job-com-id-12345","title":"Cancelar job com ID <code>12345</code>","text":"<p><pre><code>scancel 12345\n</code></pre> \u00datil se o job travou ou est\u00e1 consumindo recursos indevidamente.</p>"},{"location":"teoria/comandos/#cancelar-todos-os-seus-jobs","title":"Cancelar todos os seus jobs","text":"<p><pre><code>scancel -u $USER\n</code></pre> Cancela em lote \u2014 \u00f3timo em caso de erro em scripts ou submiss\u00f5es mal feitas.</p> <p>Para mais consulte a documenta\u00e7\u00e3o oficial em https://slurm.schedmd.com/documentation.html</p>"},{"location":"teoria/comandos/#pra-verificar-hardware","title":"Pra verificar Hardware","text":""},{"location":"teoria/comandos/#cpu","title":"CPU","text":"<ul> <li>lscpu   Mostra arquitetura, n\u00famero de n\u00facleos, threads, caches.</li> </ul> <pre><code>lscpu\n</code></pre> <p>Exemplo de sa\u00edda:</p> <pre><code>Architecture:           x86_64\nCPU(s):                 40\nThread(s) per core:     2\nCore(s) per socket:     10\nSocket(s):              2\nL1d cache:              32K\nL2 cache:               1M\nL3 cache:               13M\n</code></pre> <p>Lista detalhes por CPU l\u00f3gico (modelo, MHz, cache).</p> <pre><code>cat /proc/cpuinfo \n</code></pre> <p>Mostra o n\u00famero de CPUs dispon\u00edveis.</p> <pre><code>nproc\n</code></pre>"},{"location":"teoria/comandos/#memoria-ram","title":"Mem\u00f3ria RAM","text":"<p>Mostra uso e total de mem\u00f3ria f\u00edsica e swap.</p> <pre><code>free -h\n</code></pre> <p>Detalhes avan\u00e7ados de mem\u00f3ria (MemTotal, MemFree, Buffers, Cached).</p> <pre><code>cat /proc/meminfo | grep -E \"MemTotal|MemFree|MemAvailable|Swap\"\n</code></pre> <p>Estat\u00edsticas de mem\u00f3ria, processos e CPU.</p> <pre><code>vmstat 1 5\n</code></pre>"},{"location":"teoria/comandos/#cache","title":"Cache","text":"<p>Mostra rapidamente o tamanho das caches.</p> <pre><code>lscpu | grep cache\n</code></pre> <p>Lista tamanhos de cada n\u00edvel de cache (por CPU).</p> <pre><code>cat /sys/devices/system/cpu/cpu0/cache/index*/size\n</code></pre> <p>Shell script para trazer de forma resumida informa\u00e7\u00f5es \u00fateis</p> <p><pre><code>echo '=== HOSTNAME ==='; hostname; echo; \\\n echo '=== MEMORIA (GB) ==='; \\\n cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' | \\\n awk '{printf \\\"%s %.2f GB\\\\n\\\", \\$1, \\$2 / 1048576}'; \\\n echo; \\\n echo '=== CPU INFO ==='; \\\n lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\n echo '=== GPU INFO ==='; \\\n if command -v nvidia-smi &amp;&gt; /dev/null; then nvidia-smi; else echo 'nvidia-smi n\u00e3o dispon\u00edvel'; fi\n</code></pre> Para executar dentro de um n\u00f3 de computa\u00e7\u00e3o:</p> <pre><code>srun --partition=normal --ntasks=1 --pty bash -c \\\n\"echo '=== HOSTNAME ==='; hostname; echo; \\\n echo '=== MEMORIA (GB) ==='; \\\n cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' | \\\n awk '{printf \\\"%s %.2f GB\\\\n\\\", \\$1, \\$2 / 1048576}'; \\\n echo; \\\n echo '=== CPU INFO ==='; \\\n lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\n echo '=== GPU INFO ==='; \\\n if command -v nvidia-smi &amp;&gt; /dev/null; then nvidia-smi; else echo 'nvidia-smi n\u00e3o dispon\u00edvel'; fi\"\n</code></pre>"},{"location":"teoria/comandos/#bug-de-arquivos-gerados-no-windows","title":"Bug de arquivos gerados no Windows","text":"<p>Trabalhando em 2 ambientes diferentes \u00e9 comum ocorrer problemas de fim de linha entre DOS e UNIX. </p> <p>Caso voc\u00ea encontre esse problema aqui v\u00e3o algumas op\u00e7\u00f5es. </p> <p>Video ilustrando o passo a passo</p> <p>Utilizando o editor NANO</p> <p>Abra o arquivo utilizando a flag unix: <pre><code>nano --unix arquivo.ext\n</code></pre></p> <p>feito isso basta salvar com C^O e sair C^X</p> <p>Utilizando o editor VI/VIM</p> <pre><code>vi arquivo.ext\n</code></pre> <p>Com ele aberto \u00e9 possivel definir o <code>fileformat</code> com o seguinte comando:</p> <pre><code>:set ff=unix\n</code></pre> <p>e ent\u00e3o sair e salvar com:</p> <pre><code>:wq!\n</code></pre> <p>o <code>!</code> ir\u00e1 for\u00e7ar a sobrescrita. </p> <p>Utilizando o VI/VIM por linha de comando:</p> <pre><code>vi -c \"set ff=unix\" -c \"wq\" arquivo.ext\n</code></pre> <p>Se dos2unix tiver instalado:</p> <pre><code>dos2unix arquico.ext\n</code></pre>"},{"location":"teoria/heuristicas/","title":"M\u00e9todos de Busca Heur\u00edstica","text":"<p>As heur\u00edsticas de busca s\u00e3o estrat\u00e9gias para encontrar solu\u00e7\u00f5es em problemas dif\u00edceis sem precisar explorar todo o espa\u00e7o de possibilidades. Elas n\u00e3o garantem o resultado \u00f3timo, mas entregam respostas \u00fateis com um custo de tempo menor. Temos aqui algumas fam\u00edlias de heur\u00edsticas e uma implementa\u00e7\u00e3o em pseudoc\u00f3digo para servir de inspira\u00e7\u00e3o, mas n\u00e3o se sinta satisfeito apenas com o que temos aqui, existem in\u00fameras heuristicas que n\u00e3o est\u00e3o descritas aqui.</p>"},{"location":"teoria/heuristicas/#heuristicas-construtivas","title":"Heur\u00edsticas construtivas","text":"<p>A ideia \u00e9 construir passo a passo a solu\u00e7\u00e3o seguindo uma regra de decis\u00e3o. Essa regra pode ser gulosa (sempre escolher o melhor incremento local) ou conter aleatoriedade para gerar diversidade. No cacheiro viajante, por exemplo, a cidade mais pr\u00f3xima ainda n\u00e3o visitada \u00e9 escolhida; em mochila, o iten \u00e9 escolhido por melhor rela\u00e7\u00e3o valor/peso at\u00e9 atingir a capacidade m\u00e1xima da mochila.</p> <pre><code>def heuristica_construtiva():\n    S = solucao_vazia()\n    while not solucao_completa(S):\n        candidatos = candidatos_admissiveis(S)\n        # regra gulosa: minimiza custo incremental \n        c_escolhido = min(candidatos, key=lambda c: custo_incremental(S, c))\n        S = inserir(S, c_escolhido)           # atualizar estado parcial\n    return S\n</code></pre>"},{"location":"teoria/heuristicas/#busca-local","title":"Busca local","text":"<p>Partimos de uma solu\u00e7\u00e3o inicial e tentamos melhor\u00e1-la explorando \u201cvizinhos\u201d obtidos por pequenas altera\u00e7\u00f5es. Se um vizinho melhora o custo, aceitamos a mudan\u00e7a e repetimos o processo at\u00e9 n\u00e3o existir mais melhora. </p> <pre><code>def busca_local(S0):\n    S = S0\n    while True:\n        melhorou = False\n        for S_viz in gerar_vizinhos(S):\n            if custo(S_viz) &lt; custo(S):\n                S = S_viz          # estrat\u00e9gia \"first improvement\"\n                melhorou = True\n                break\n        if not melhorou:\n            break\n    return S\n</code></pre>"},{"location":"teoria/heuristicas/#heuristicas-baseadas-em-construcao","title":"Heur\u00edsticas baseadas em constru\u00e7\u00e3o","text":"<p>Combinam constru\u00e7\u00e3o e refino: primeiro geramos uma boa solu\u00e7\u00e3o inicial de forma gulosa ou com aleatoriedade e, em seguida, aplicamos busca local para polir o resultado. </p> <pre><code>def construcao_mais_refino():\n    S = heuristica_construtiva()  # ou uma varia\u00e7\u00e3o com aleatoriedade (RCL)\n    S = busca_local(S)            # refino por movimentos locais\n    return S\n</code></pre>"},{"location":"teoria/heuristicas/#heuristicas-baseadas-em-modificacao","title":"Heur\u00edsticas baseadas em modifica\u00e7\u00e3o","text":"<p>Aqui trabalhamos sobre uma solu\u00e7\u00e3o existente aplicando uma perturba\u00e7\u00e3o para escapar de \u00f3timos locais. Ap\u00f3s perturbar, refinamos novamente com busca local. Esse padr\u00e3o \u00e9 a base do ILS (Iterated Local Search) e do VNS (Variable Neighborhood Search).</p> <pre><code>def modificacao_baseada(S_inicial, max_iter=100):\n    S_best = S_inicial\n    for _ in range(max_iter):\n        S_pert = perturbar(S_best, intensidade=ajustar_intensidade())\n        S_ref = busca_local(S_pert)\n        if custo(S_ref) &lt; custo(S_best):\n            S_best = S_ref\n    return S_best\n</code></pre>"},{"location":"teoria/heuristicas/#heuristicas-baseadas-em-recombinacao","title":"Heur\u00edsticas baseadas em recombina\u00e7\u00e3o","text":"<p>Inspiradas em algoritmos evolutivos, combinam duas (ou mais) solu\u00e7\u00f5es \u201cpais\u201d para gerar uma nova solu\u00e7\u00e3o \u201cfilha\u201d, aproveitando blocos de boa qualidade de cada pai. Depois, refinam a filha com busca local. </p> <pre><code>def recombinacao_baseada(populacao, criterio_parada):\n    P = inicializar_populacao(populacao)\n    while not criterio_parada(P):\n        A, B = selecionar_pais(P)             # torneio, roleta, ranking etc.\n        C = recombinar(A, B)                  # OX/PMX/path-relinking/uni\u00e3o+reparo\n        C = busca_local(C)                    # passo mem\u00e9tico (refino)\n        P = atualizar_populacao(P, C)         # elitismo/substitui\u00e7\u00e3o\n    return melhor_solucao(P)\n</code></pre>"},{"location":"teoria/heuristicas/#hibridizacao-de-heuristicas","title":"Hibridiza\u00e7\u00e3o de heur\u00edsticas","text":"<p>Misturamos estrat\u00e9gias para buffar o algor\u00edtmo: constru\u00e7\u00e3o gulosa aleat\u00f3ria para diversidade, seguida de busca local para intensifica\u00e7\u00e3o, e ILS para escapar de \u00f3timos locais. </p> <pre><code>def hibrida_grasp_ils(max_iter=50):\n    S_best = None\n    for _ in range(max_iter):\n        S = construtiva_aleatoria_com_RCL()   # constru\u00e7\u00e3o com lista restrita de candidatos\n        S = busca_local(S)                    # intensifica\u00e7\u00e3o\n        S = ILS(S)                            # diversifica\u00e7\u00e3o controlada\n        if S_best is None or custo(S) &lt; custo(S_best):\n            S_best = S\n    return S_best\n\ndef ILS(S, limite_sem_melhora=10):\n    sem_melhora = 0\n    while sem_melhora &lt; limite_sem_melhora:\n        S_p = perturbar(S)                    # ex.: ruin&amp;recreate, 3-opt forte, shake(VNS)\n        S_p = busca_local(S_p)\n        if custo(S_p) &lt; custo(S):\n            S = S_p\n            sem_melhora = 0\n        else:\n            sem_melhora += 1\n    return S\n</code></pre>"},{"location":"teoria/heuristicas/#hiper-heuristicas","title":"H\u00edper-heur\u00edsticas","text":"<p>Em vez de desenhar uma \u00fanica heur\u00edstica, criamos um \u201corquestrador\u201d que escolhe dinamicamente qual heur\u00edstica de baixo n\u00edvel aplicar a cada momento, com base em desempenho observado. Assim, o sistema alterna entre operadores como 2-opt, swap e reinser\u00e7\u00e3o, aprendendo quais funcionam melhor ao longo da execu\u00e7\u00e3o.</p> <pre><code>from math import sqrt, log\nimport random\n\ndef hiper_heuristica(S0, heuristicas, T, epsilon=0.1):\n    # heuristicas: lista de fun\u00e7\u00f5es do tipo h(S) -&gt; S'\n    estat = {h: {\"ganho\": 0.0, \"usos\": 0} for h in heuristicas}\n    S = S0\n    for t in range(1, T + 1):\n        if random.random() &lt; epsilon:\n            h = random.choice(heuristicas)    # explora\u00e7\u00e3o\n        else:\n            h = selecionar_por_ucb(estat, t)  # explora\u00e7\u00e3o vs. explora\u00e7\u00e3o\n\n        S_novo = h(S)\n        ganho = max(0.0, custo(S) - custo(S_novo))\n        estat[h][\"ganho\"] += ganho\n        estat[h][\"usos\"]  += 1\n\n        if custo(S_novo) &lt; custo(S):\n            S = S_novo\n    return S\n\ndef selecionar_por_ucb(estat, t):\n    # UCB1 simples: m\u00e9dia + sqrt(2*ln(t)/n)\n    melhor_h, melhor_score = None, float(\"-inf\")\n    for h, info in estat.items():\n        n = max(1, info[\"usos\"])\n        media = info[\"ganho\"] / n\n        bonus = sqrt(2.0 * log(max(2, t)) / n)\n        score = media + bonus\n        if score &gt; melhor_score:\n            melhor_h, melhor_score = h, score\n    return melhor_h\n</code></pre> <p>Entendi! Voc\u00ea quer exemplos de heur\u00edsticas aleat\u00f3rias (estrat\u00e9gias que exploram o espa\u00e7o com escolhas ao acaso) e de heur\u00edsticas com filtro (estrat\u00e9gias que usam algum crit\u00e9rio para selecionar candidatos, descartando op\u00e7\u00f5es ruins). Vou explicar de forma did\u00e1tica e depois te dar exemplos em pseudoc\u00f3digo estilo Python.</p>"},{"location":"teoria/heuristicas/#heuristicas-aleatorias","title":"Heur\u00edsticas aleat\u00f3rias","text":"<p>A ideia aqui \u00e9 simples: em vez de sempre escolher o \u201cmelhor\u201d pr\u00f3ximo passo, escolhemos aleatoriamente uma op\u00e7\u00e3o, ou entre todas, ou entre um subconjunto. Isso permite explorar solu\u00e7\u00f5es diferentes e fugir de caminhos muito determin\u00edsticos.</p> <pre><code>import random\n\ndef heuristica_aleatoria(items, capacidade):\n    mochila = []\n    peso = 0\n    while True:\n        candidatos = [i for i in items if peso + i.peso &lt;= capacidade]\n        if not candidatos:\n            break\n        escolhido = random.choice(candidatos)   # sorteia qualquer candidato vi\u00e1vel\n        mochila.append(escolhido)\n        peso += escolhido.peso\n        items.remove(escolhido)\n    return mochila\n</code></pre>"},{"location":"teoria/heuristicas/#heuristicas-com-filtro","title":"Heur\u00edsticas com filtro","text":"<p>Aqui, em vez de aceitar qualquer candidato, aplicamos um filtro para limitar as op\u00e7\u00f5es a um subconjunto de candidatos considerados \u201cbons\u201d. Depois, escolhemos um deles (\u00e0s vezes aleatoriamente, \u00e0s vezes pelo melhor custo). Essa ideia \u00e9 a base do GRASP.</p> <pre><code>import random\n\ndef heuristica_com_filtro(items, capacidade, alpha=0.3):\n    mochila = []\n    peso = 0\n    while True:\n        candidatos = [i for i in items if peso + i.peso &lt;= capacidade]\n        if not candidatos:\n            break\n        # filtro: mant\u00e9m apenas candidatos dentro do top \u03b1 (percentil de valor/peso)\n        ratio = [i.valor / i.peso for i in candidatos]\n        limite = min(ratio) + alpha * (max(ratio) - min(ratio))\n        RCL = [i for i in candidatos if i.valor / i.peso &gt;= limite]\n\n        escolhido = random.choice(RCL)   # escolhe entre bons candidatos\n        mochila.append(escolhido)\n        peso += escolhido.peso\n        items.remove(escolhido)\n    return mochila\n</code></pre>"},{"location":"teoria/openmp/","title":"Guia de Pragmas OpenMP","text":""},{"location":"teoria/openmp/#funcoes-da-api-openmp","title":"Fun\u00e7\u00f5es da API OpenMP","text":"<ul> <li><code>omp_get_thread_num()</code> \u2192 retorna o ID da thread.</li> <li><code>omp_get_num_threads()</code> \u2192 total de threads na regi\u00e3o paralela.</li> <li><code>omp_get_wtime()</code> \u2192 cron\u00f4metro de alta resolu\u00e7\u00e3o.</li> <li><code>omp_get_max_threads()</code> \u2192 n\u00famero m\u00e1ximo de threads dispon\u00edveis.</li> <li><code>OMP_NUM_THREADS</code> \u2192 n\u00famero de threads usadas no programa</li> <li><code>OMP_SCHEDULE</code> \u2192 define a pol\u00edtica de escalonamento quando se usa <code>schedule(runtime)</code></li> </ul>"},{"location":"teoria/openmp/#criando-regioes-paralelas","title":"Criando regi\u00f5es paralelas","text":"<pre><code>#pragma omp parallel\n{\n    // c\u00f3digo aqui roda em paralelo (todas as threads executam)\n}\n</code></pre>"},{"location":"teoria/openmp/#paralelizando-lacos-for","title":"Paralelizando la\u00e7os (<code>for</code>)","text":"<pre><code>#pragma omp parallel for\nfor (int i = 0; i &lt; N; i++) {\n    a[i] = b[i] + c[i];\n}\n</code></pre> <ul> <li> <p>Cl\u00e1usula <code>schedule</code>: define como dividir as itera\u00e7\u00f5es entre threads</p> </li> <li> <p><code>schedule(static)</code> \u2192 divide blocos iguais e fixos</p> </li> <li><code>schedule(dynamic, chunk)</code> \u2192 distribui em blocos de <code>chunk</code> de forma din\u00e2mica</li> <li><code>schedule(guided, chunk)</code> \u2192 blocos come\u00e7am grandes e v\u00e3o diminuindo</li> <li><code>schedule(runtime)</code> \u2192 definido pela vari\u00e1vel de ambiente <code>OMP_SCHEDULE</code></li> </ul>"},{"location":"teoria/openmp/#variaveis-privadas-e-compartilhadas","title":"Vari\u00e1veis privadas e compartilhadas","text":"<pre><code>#pragma omp parallel for private(x) shared(y)\nfor (int i = 0; i &lt; N; i++) {\n    int x = i;        // cada thread tem sua c\u00f3pia\n    y[i] = f(x);      // y \u00e9 vis\u00edvel por todas\n}\n</code></pre> <ul> <li><code>private(var)</code> \u2192 cada thread cria sua pr\u00f3pria c\u00f3pia</li> <li><code>shared(var)</code> \u2192 todas as threads acessam a mesma vari\u00e1vel</li> </ul>"},{"location":"teoria/openmp/#reducoes-somatorios-produtos-etc","title":"Redu\u00e7\u00f5es (somat\u00f3rios, produtos, etc.)","text":"<pre><code>double soma = 0.0;\n#pragma omp parallel for reduction(+:soma)\nfor (int i = 0; i &lt; N; i++) {\n    soma += a[i];\n}\n</code></pre> <ul> <li><code>+</code> \u2192 soma (ex.: <code>soma += ...</code>)</li> <li><code>*</code> \u2192 produto (ex.: <code>prod *= ...</code>)</li> <li><code>max</code> \u2192 m\u00e1ximo (ex.: encontra o maior valor)</li> <li><code>min</code> \u2192 m\u00ednimo (ex.: encontra o menor valor)</li> <li><code>&amp;&amp;</code> \u2192 AND l\u00f3gico</li> <li><code>||</code> \u2192 OR l\u00f3gico</li> <li><code>^</code>  \u2192 XOR bit a bit</li> </ul>"},{"location":"teoria/openmp/#secoes-paralelas","title":"Se\u00e7\u00f5es paralelas","text":"<pre><code>#pragma omp parallel sections\n{\n    #pragma omp section\n    tarefa1();\n\n    #pragma omp section\n    tarefa2();\n}\n</code></pre> <ul> <li>Divide blocos de c\u00f3digo independentes entre threads.</li> </ul>"},{"location":"teoria/openmp/#areas-criticas-e-exclusao-mutua","title":"\u00c1reas cr\u00edticas e exclus\u00e3o m\u00fatua","text":"<pre><code>#pragma omp critical\n{\n    contador++;\n}\n</code></pre> <ul> <li>Apenas uma thread por vez entra nesse bloco.</li> <li>\u00datil para proteger atualiza\u00e7\u00f5es em vari\u00e1veis compartilhadas.</li> </ul>"},{"location":"teoria/openmp/#diretiva-single","title":"Diretiva <code>single</code>","text":"<pre><code>#pragma omp parallel\n{\n    #pragma omp single\n    {\n        std::cout &lt;&lt; \"Executado por apenas 1 thread\\n\";\n    }\n}\n</code></pre> <ul> <li>Apenas uma thread executa esse trecho, mas as outras esperam.</li> </ul>"},{"location":"teoria/openmp/#barreira-de-sincronizacao","title":"Barreira de sincroniza\u00e7\u00e3o","text":"<pre><code>#pragma omp barrier\n</code></pre> <ul> <li>Faz todas as threads esperarem umas pelas outras antes de seguir adiante.</li> </ul> <p>Sim \ud83d\ude4c al\u00e9m das diretivas b\u00e1sicas que j\u00e1 coloquei no guia, existem outras muito usadas na pr\u00e1tica que valem a pena aparecer num material de refer\u00eancia r\u00e1pida para os alunos. Vou complementar a lista com as mais \u00fateis/did\u00e1ticas:</p>"},{"location":"teoria/openmp/#pragma-omp-parallel-for-collapsen","title":"<code>#pragma omp parallel for collapse(n)</code>","text":"<p>O <code>collapse(n)</code> junta <code>n</code> loops aninhados em um s\u00f3 loop paralelo. Muito \u00fatil em matrizes e tensores.</p> <pre><code>#pragma omp parallel for collapse(2)\nfor (int i = 0; i &lt; N; i++) {\n    for (int j = 0; j &lt; M; j++) {\n        A[i][j] = i + j;\n    }\n}\n</code></pre>"},{"location":"teoria/openmp/#pragma-omp-task","title":"<code>#pragma omp task</code>","text":"<p>Permite criar tarefas ass\u00edncronas dentro de uma regi\u00e3o paralela. Muito usado para grafos, \u00e1rvores e pipelines.</p> <pre><code>#pragma omp parallel\n{\n    #pragma omp single\n    {\n        #pragma omp task\n        f1();\n\n        #pragma omp task\n        f2();\n\n        #pragma omp taskwait   // sincroniza as tasks\n    }\n}\n</code></pre>"},{"location":"teoria/openmp/#pragma-omp-atomic","title":"<code>#pragma omp atomic</code>","text":"<p>Protege uma opera\u00e7\u00e3o simples (ex.: incremento) de condi\u00e7\u00f5es de corrida, com overhead menor que <code>critical</code>.</p> <pre><code>#pragma omp parallel for\nfor (int i = 0; i &lt; N; i++) {\n    #pragma omp atomic\n    soma += a[i];\n}\n</code></pre>"},{"location":"teoria/openmp/#pragma-omp-master-e-pragma-omp-single-nowait","title":"<code>#pragma omp master</code> e <code>#pragma omp single nowait</code>","text":"<ul> <li><code>master</code>: s\u00f3 a thread 0 roda.</li> <li><code>single</code>: apenas uma thread roda (n\u00e3o necessariamente a 0).</li> <li><code>nowait</code>: libera as threads de esperarem.</li> </ul> <pre><code>#pragma omp parallel\n{\n    #pragma omp master\n    { std::cout &lt;&lt; \"Apenas a thread master executa\\n\"; }\n\n    #pragma omp single nowait\n    { std::cout &lt;&lt; \"Uma thread qualquer executa e n\u00e3o h\u00e1 barreira\\n\"; }\n}\n</code></pre>"},{"location":"teoria/openmp/#pragma-omp-simd","title":"<code>#pragma omp simd</code>","text":"<p>For\u00e7a a vetoriza\u00e7\u00e3o SIMD (Single Instruction Multiple Data).  Pode ser combinado com <code>parallel for</code> \u2192 <code>#pragma omp parallel for simd</code>.</p> <pre><code>#pragma omp simd\nfor (int i = 0; i &lt; N; i++) {\n    c[i] = a[i] + b[i];\n}\n</code></pre>"},{"location":"teoria/openmp/#controlando-variaveis","title":"Controlando vari\u00e1veis","text":"<ul> <li><code>firstprivate(var)</code> \u2192 cada thread ganha uma c\u00f3pia inicializada com o valor original.</li> <li><code>lastprivate(var)</code> \u2192 garante que, ao final, o valor da \u00faltima itera\u00e7\u00e3o fique na vari\u00e1vel global.</li> <li><code>default(shared)</code> \u2192 define pol\u00edtica padr\u00e3o de vari\u00e1veis (bom para pegar erros!).</li> </ul> <p>Documenta\u00e7\u00e3o dispon\u00edvel em openmp.org</p>"},{"location":"teoria/profiling/","title":"Profiling","text":"<p>Profiling \u00e9 o processo de medir o comportamento de um programa em termos de consumo de recursos, como tempo de execu\u00e7\u00e3o, uso de CPU, mem\u00f3ria e I/O. As informa\u00e7\u00f5es coletadas durante o profiling ajudam a identificar \"gargalos\" ou partes do c\u00f3digo que s\u00e3o ineficientes.</p> <p>Use o Cluster Franky</p> <pre><code>Acessando o terminal dele via ssh com o comando ssh nome_da_pasta@ip_do_cluster\n</code></pre> <p>ficou com d\u00favida?</p>"},{"location":"teoria/profiling/#ferramentas-para-profiling-em-c","title":"Ferramentas para Profiling em C++","text":"<p>gprof: O gprof (GNU Profiler) \u00e9 uma ferramenta de profiling que faz parte do GNU Compiler Collection (GCC). Ele \u00e9 usado para medir o tempo de execu\u00e7\u00e3o gasto em cada fun\u00e7\u00e3o de um programa e criar um relat\u00f3rio detalhado de como esse tempo \u00e9 distribu\u00eddo entre as v\u00e1rias partes do c\u00f3digo. O gprof \u00e9 \u00fatil para identificar \"gargalos\" de desempenho em um programa, onde otimiza\u00e7\u00f5es podem ser mais eficazes.</p> <p>Valgrind: O Valgrind \u00e9 uma su\u00edte de ferramentas que ajuda a encontrar bugs de mem\u00f3ria e a realizar profiling de programas,tamb\u00e9m \u00e9 usado para medir o desempenho do programa em termos de uso de CPU.</p>"},{"location":"teoria/profiling/#exemplo-1-usando-gprof","title":"Exemplo 1: Usando <code>gprof</code>","text":"<p>Vamos come\u00e7ar com um exemplo b\u00e1sico de como usar o <code>gprof</code>.</p>"},{"location":"teoria/profiling/#codigo-de-exemplo-em-c","title":"C\u00f3digo de Exemplo em C++","text":"<p>O c\u00f3digo exemplo mult_matriz.cpp realiza uma opera\u00e7\u00e3o de multiplica\u00e7\u00e3o de matrizes. Ele multiplica duas matrizes  A  e  B  e armazena o resultado na matriz C.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nvoid multiplyMatrices(const std::vector&lt;std::vector&lt;int&gt;&gt;&amp; A, const std::vector&lt;std::vector&lt;int&gt;&gt;&amp; B, std::vector&lt;std::vector&lt;int&gt;&gt;&amp; C) {\n    int n = A.size();\n    for (int i = 0; i &lt; n; ++i) {\n        for (int j = 0; j &lt; n; ++j) {\n            C[i][j] = 0;\n            for (int k = 0; k &lt; n; ++k) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n}\n\nint main() {\n    int n = 100;\n    std::vector&lt;std::vector&lt;int&gt;&gt; A(n, std::vector&lt;int&gt;(n, 1));\n    std::vector&lt;std::vector&lt;int&gt;&gt; B(n, std::vector&lt;int&gt;(n, 2));\n    std::vector&lt;std::vector&lt;int&gt;&gt; C(n, std::vector&lt;int&gt;(n, 0));\n\n    multiplyMatrices(A, B, C);\n\n    std::cout &lt;&lt; \"Matrix multiplication completed.\" &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/profiling/#compilacao-com-suporte-a-profiling","title":"Compila\u00e7\u00e3o com Suporte a Profiling","text":"<p>Para usar o <code>gprof</code>, precisamos compilar o c\u00f3digo com a flag <code>-pg</code>, que habilita o suporte ao profiling:</p> <pre><code>g++ -pg mult_matriz.cpp -o mult_matriz\n</code></pre>"},{"location":"teoria/profiling/#executando-o-programa","title":"Executando o Programa","text":"<p>Depois de compilar, execute o programa normalmente:</p> <pre><code>./mult_matriz\n</code></pre> <p>Essa execu\u00e7\u00e3o vai gerar um arquivo chamado <code>gmon.out</code>, que cont\u00e9m os dados de profiling.</p>"},{"location":"teoria/profiling/#analisando-os-dados-com-gprof","title":"Analisando os Dados com <code>gprof</code>","text":"<p>Agora, use o <code>gprof</code> para analisar os dados:</p> <pre><code>gprof mult_matriz gmon.out &gt; analise.txt\n</code></pre> <p>Isso cria um relat\u00f3rio detalhado do tempo gasto em cada fun\u00e7\u00e3o e a quantidade de chamadas feitas. O relat\u00f3rio ser\u00e1 salvo no arquivo <code>analise.txt</code>.</p>"},{"location":"teoria/profiling/#entendendo-o-relatorio-de-profiling","title":"Entendendo o Relat\u00f3rio de Profiling","text":"<p>Ap\u00f3s executar o seu programa com <code>gprof</code>, voc\u00ea obter\u00e1 um relat\u00f3rio que cont\u00e9m duas se\u00e7\u00f5es principais: o Flat Profile e o Call Graph. Vamos explorar o significado de cada uma e como interpret\u00e1-las.</p>"},{"location":"teoria/profiling/#flat-profile-identificando-as-funcoes-criticas","title":"Flat Profile: Identificando as Fun\u00e7\u00f5es Cr\u00edticas","text":"<p>O Flat Profile fornece uma vis\u00e3o geral do tempo que cada fun\u00e7\u00e3o consome durante a execu\u00e7\u00e3o do programa. Aqui est\u00e3o os principais elementos do relat\u00f3rio:</p> <ul> <li> <p>% time: Indica a porcentagem do tempo total de execu\u00e7\u00e3o que foi gasto em cada fun\u00e7\u00e3o. Fun\u00e7\u00f5es com valores mais altos s\u00e3o geralmente os principais alvos para otimiza\u00e7\u00e3o.</p> </li> <li> <p>cumulative seconds: \u00c9 o tempo acumulado at\u00e9 essa fun\u00e7\u00e3o ser chamada. Ele ajuda a entender quanto tempo foi gasto no programa at\u00e9 aquele ponto.</p> </li> <li> <p>self seconds: \u00c9 ao tempo gasto exclusivamente dentro da fun\u00e7\u00e3o, sem incluir o tempo das fun\u00e7\u00f5es que ela chama.</p> </li> <li> <p>calls: Mostra quantas vezes a fun\u00e7\u00e3o foi chamada. Fun\u00e7\u00f5es chamadas muitas vezes podem ser boas candidatas para otimiza\u00e7\u00e3o, especialmente se tiverem um tempo significativo por chamada.</p> </li> <li> <p>self ms/call e total ms/call: Esses valores mostram o tempo m\u00e9dio gasto em cada chamada da fun\u00e7\u00e3o. <code>self ms/call</code> \u00e9 o tempo gasto na pr\u00f3pria fun\u00e7\u00e3o, enquanto <code>total ms/call</code> inclui o tempo das fun\u00e7\u00f5es que ela invoca.</p> </li> </ul>"},{"location":"teoria/profiling/#call-graph-compreendendo-as-relacoes-entre-funcoes","title":"Call Graph: Compreendendo as Rela\u00e7\u00f5es Entre Fun\u00e7\u00f5es","text":"<p>O Call Graph mostra a hierarquia de chamadas entre as fun\u00e7\u00f5es do seu programa. Ele detalha como as fun\u00e7\u00f5es est\u00e3o interconectadas e qual o impacto de cada uma no tempo de execu\u00e7\u00e3o total.</p> <ul> <li> <p>Self/Children Time: O tempo \"Self\" \u00e9 o gasto na pr\u00f3pria fun\u00e7\u00e3o, enquanto o tempo \"Children\" \u00e9 o gasto nas fun\u00e7\u00f5es que ela chama.</p> </li> <li> <p>Called: Informa quantas vezes uma fun\u00e7\u00e3o foi chamada, seja diretamente ou indiretamente por outras fun\u00e7\u00f5es.</p> </li> </ul>"},{"location":"teoria/profiling/#analise-do-relatorio-de-profiling","title":"An\u00e1lise do Relat\u00f3rio de Profiling","text":"<p>No relat\u00f3rio gerado, as fun\u00e7\u00f5es relacionadas ao operador <code>operator[]</code> do <code>std::vector</code> aparecem como cr\u00edticas, consumindo cerca de 33% do tempo de execu\u00e7\u00e3o cada. Isso indica que a maneira como os vetores s\u00e3o acessados e manipulados no c\u00f3digo esta consumindo bastante tempo.</p> <p>Al\u00e9m disso, a fun\u00e7\u00e3o <code>multiplyMatrices</code> aparece com um tempo de execu\u00e7\u00e3o acumulado consider\u00e1vel. Como esta fun\u00e7\u00e3o realiza o trabalho pesado da multiplica\u00e7\u00e3o de matrizes, \u00e9 natural que ela seja um foco de aten\u00e7\u00e3o para otimiza\u00e7\u00e3o.</p>"},{"location":"teoria/profiling/#oportunidades-de-otimizacao","title":"Oportunidades de Otimiza\u00e7\u00e3o","text":"<p>Com base no relat\u00f3rio, os poss\u00edveis candidatos a otimiza\u00e7\u00e3o s\u00e3o:</p> <ul> <li> <p>Reduzir Acessos ao Vetor: Como o acesso aos elementos do vetor (<code>operator[]</code>) consome uma parte significativa do tempo de execu\u00e7\u00e3o, podemos tentar reduzir o n\u00famero de acessos diretos ao vetor. </p> </li> <li> <p>Otimizar a Fun\u00e7\u00e3o <code>multiplyMatrices</code>: Esta fun\u00e7\u00e3o \u00e9 o cora\u00e7\u00e3o do processamento e qualquer melhoria aqui ter\u00e1 um grande impacto no desempenho global. Podemos pensar em paralelizar a fun\u00e7\u00e3o para distribuir o trabalho entre m\u00faltiplos n\u00facleos ou m\u00e1quinas, em um ambiente HPC como o Cluster Franky.</p> </li> </ul>"},{"location":"teoria/profiling/#exemplo-2-usando-valgrind-para-profiling-de-memoria","title":"Exemplo 2: Usando Valgrind para Profiling de Mem\u00f3ria","text":"<p>O Valgrind tem um conjunto de ferramentas para an\u00e1lise de programas. Uma de suas funcionalidades mais conhecidas \u00e9 a detec\u00e7\u00e3o de problemas de mem\u00f3ria, mas tamb\u00e9m pode ser usado para profiling de CPU.</p> <p>Vamos usar o mesmo c\u00f3digo de multiplica\u00e7\u00e3o de matrizes do exemplo anterior.</p>"},{"location":"teoria/profiling/#usando-o-valgrind-para-detectar-problemas-de-memoria","title":"Usando o Valgrind para Detectar Problemas de Mem\u00f3ria","text":"<p>Primeiro, compile o c\u00f3digo normalmente, sem flags especiais:</p> <pre><code>g++ mult_matriz.cpp -o mult_matriz\n</code></pre> <p>Agora, execute o programa usando o Valgrind para detectar problemas de mem\u00f3ria:</p> <pre><code>valgrind --leak-check=full ./mult_matriz &amp;&gt;leak-check.txt\n</code></pre> <p>O Valgrind ir\u00e1 executar o programa e relatar quaisquer vazamentos de mem\u00f3ria ou acessos inv\u00e1lidos no arquivo leak-check.txt.</p> <p>No relat\u00f3rio obtido aqui nos meus testes eu tive os seguintes resultados:</p>"},{"location":"teoria/profiling/#interpretacao-do-relatorio-valgrind","title":"Interpreta\u00e7\u00e3o do Relat\u00f3rio Valgrind","text":"<ol> <li>HEAP SUMMARY (Resumo da Pilha)</li> <li> <p>in use at exit: 0 bytes in 0 blocks: Isso significa que, ao final da execu\u00e7\u00e3o do programa, n\u00e3o h\u00e1 blocos de mem\u00f3ria alocados que n\u00e3o foram liberados. Ou seja, toda a mem\u00f3ria que foi alocada foi devidamente liberada.</p> </li> <li> <p>total heap usage: 308 allocs, 308 frees, 202,128 bytes allocated: Este campo indica que, ao longo da execu\u00e7\u00e3o do programa, 308 aloca\u00e7\u00f5es de mem\u00f3ria heap ocorreram, e todas as 308 foram correspondidas por uma libera\u00e7\u00e3o. O total de mem\u00f3ria alocada durante o programa foi de 202,128 bytes.</p> </li> <li> <p>All heap blocks were freed -- no leaks are possible</p> </li> <li> <p>Esta linha confirma que todos os blocos de mem\u00f3ria foram liberados corretamente, portanto, n\u00e3o h\u00e1 vazamentos de mem\u00f3ria poss\u00edveis. Isso significa que o gerenciamento de mem\u00f3ria no programa est\u00e1 sendo feito corretamente.</p> </li> <li> <p>ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)</p> </li> <li>Esta parte do relat\u00f3rio informa que n\u00e3o houve nenhum erro de mem\u00f3ria detectado. Isso inclui erros como acessos inv\u00e1lidos, uso de mem\u00f3ria n\u00e3o inicializada, ou acessos fora dos limites. O Valgrind n\u00e3o encontrou nenhum problema relacionado \u00e0 mem\u00f3ria neste programa.</li> </ol>"},{"location":"teoria/profiling/#usando-o-valgrind-para-profiling-de-cpu-com-callgrind","title":"Usando o Valgrind para Profiling de CPU com <code>callgrind</code>","text":"<p>O Valgrind tamb\u00e9m pode ser usado para profiling de CPU com a ferramenta Callgrind:</p> <pre><code>valgrind --tool=callgrind ./mult_matriz \n</code></pre> <p>Este comando vai resultar em um arquivo de sa\u00edda <code>callgrind.out.&lt;PID&gt;</code>, que cont\u00e9m informa\u00e7\u00f5es detalhadas sobre o uso da CPU por cada fun\u00e7\u00e3o do programa.</p> <p>O relat\u00f3rio que voc\u00ea executou com Callgrind fornece um resumo sobre o desempenho do programa em termos de instru\u00e7\u00f5es executadas. Os elementos principais do relat\u00f3rio s\u00e3o:</p> <ol> <li> <p>Events: Ir: <code>Ir</code> significa \"Instruction References\". Este evento conta o n\u00famero total de instru\u00e7\u00f5es de m\u00e1quina que foram executadas pelo programa. As instru\u00e7\u00f5es de m\u00e1quina s\u00e3o as opera\u00e7\u00f5es mais b\u00e1sicas que a CPU realiza, como somar n\u00fameros, carregar dados da mem\u00f3ria, ou comparar valores. No relat\u00f3rio aqui do meu teste, o valor de <code>Ir</code> \u00e9 128,306,660. Isso significa que o programa executou mais de 128 milh\u00f5es de instru\u00e7\u00f5es durante a multiplica\u00e7\u00e3o de matrizes.</p> </li> <li> <p>Collected: 128,306,660: Este n\u00famero indica que o Callgrind coletou dados sobre todas essas 128 milh\u00f5es de instru\u00e7\u00f5es. \u00c9 uma confirma\u00e7\u00e3o de que todas as instru\u00e7\u00f5es executadas foram monitoradas.</p> </li> <li> <p>I refs: 128,306,660 : <code>I refs</code> \u00e9 uma m\u00e9trica que mostra o n\u00famero total de refer\u00eancias de instru\u00e7\u00e3o que foram feitas durante a execu\u00e7\u00e3o do programa. Como o valor \u00e9 igual ao de <code>Ir</code>, isso indica que cada instru\u00e7\u00e3o foi contabilizada.</p> </li> </ol> <p>O que fazer com essas informa\u00e7\u00f5es?</p> <ul> <li> <p>N\u00famero de Instru\u00e7\u00f5es: Um alto n\u00famero de instru\u00e7\u00f5es (<code>Ir</code>) pode indicar que o programa est\u00e1 realizando muitas opera\u00e7\u00f5es. Em um ambiente HPC, isso pode ser bom ou ruim, dependendo da efici\u00eancia dessas instru\u00e7\u00f5es. Muitas instru\u00e7\u00f5es simples podem ser r\u00e1pidas, enquanto poucas instru\u00e7\u00f5es complexas podem ser mais lentas.</p> </li> <li> <p>Identifica\u00e7\u00e3o de Gargalos: Ao combinar esses dados com outras informa\u00e7\u00f5es, como tempos de execu\u00e7\u00e3o e cache misses (que Callgrind tamb\u00e9m pode monitorar), voc\u00ea pode identificar quais partes do c\u00f3digo consomem mais recursos e otimizar essas \u00e1reas. Por exemplo, se uma fun\u00e7\u00e3o espec\u00edfica estiver gerando um grande n\u00famero de instru\u00e7\u00f5es e utilizando muito cache, ela pode ser um gargalo que precisa ser otimizado.</p> </li> </ul>"},{"location":"teoria/profiling/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<p>Para uma an\u00e1lise mais detalhada, voc\u00ea pode:</p> <p>Usar o KCachegrind (uma interface gr\u00e1fica) para visualizar o resultado detalhadamente:</p> <pre><code>kcachegrind callgrind.out.&lt;PID&gt;\n</code></pre> <p></p> <p>Como podemos ver na imagem, a fun\u00e7\u00e3o <code>multiplyMatrices</code> est\u00e1 destacada em laranja e consome 97.80% do total de instru\u00e7\u00f5es. Isso indica que a multiplica\u00e7\u00e3o de matrizes \u00e9 a opera\u00e7\u00e3o mais intensiva e cr\u00edtica em termos de desempenho no c\u00f3digo. Como essa fun\u00e7\u00e3o domina o uso de CPU, ela \u00e9 o principal alvo para otimiza\u00e7\u00e3o.</p> <p>As fun\u00e7\u00f5es que manipulam <code>std::vector</code> tamb\u00e9m aparecem com destaque:</p> <p><code>std::vector::operator[]</code>: Consome 18.71% das instru\u00e7\u00f5es. Esse operador \u00e9 chamado cada vez que um elemento do vetor \u00e9 acessado. A alta porcentagem indica que muitos acessos ao vetor est\u00e3o ocorrendo, o que pode ser um ponto de otimiza\u00e7\u00e3o.</p> <p><code>std::vector::allocator</code>: Tamb\u00e9m est\u00e1 destacada, indicando que a aloca\u00e7\u00e3o e acesso aos elementos do vetor \u00e9 um fator importante no uso de recursos.</p>"},{"location":"teoria/profiling/#comparacao-entre-gprof-e-valgrind","title":"Compara\u00e7\u00e3o entre Gprof e Valgrind","text":"<p>Gprof e Valgrind s\u00e3o ferramentas de profiling, mas com focos e funcionalidades especificas. Na tabela temos uma compara\u00e7\u00e3o detalhada entre essas duas ferramentas:</p> Aspecto Gprof Valgrind Foco Principal Profiling de desempenho, medindo o tempo gasto em fun\u00e7\u00f5es. Detecta erros de uso de mem\u00f3ria e oferece ferramentas de profiling. Uso T\u00edpico Mapear gargalos de desempenho e identificar o tempo de execu\u00e7\u00e3o das fun\u00e7\u00f5es. Detectar vazamentos de mem\u00f3ria, acessos inv\u00e1lidos, e mapear o uso de CPU e mem\u00f3ria. Complexidade Relativamente simples de usar e interpretar, adequado para profiling inicial. Mais complexo, com v\u00e1rias ferramentas especializadas para diferentes tipos de an\u00e1lise. Overhead de Execu\u00e7\u00e3o Baixo overhead; o programa roda quase na velocidade normal. Alto overhead; o programa pode rodar significativamente mais lento devido \u00e0 an\u00e1lise detalhada. An\u00e1lise de Fun\u00e7\u00f5es Oferece relat\u00f3rios de chamadas (Call Graph) e perfis de fun\u00e7\u00f5es para entender o tempo de execu\u00e7\u00e3o. Oferece gr\u00e1ficos de chamadas detalhados com Callgrind, al\u00e9m de perfis de cache e instru\u00e7\u00f5es. Depura\u00e7\u00e3o de Mem\u00f3ria N\u00e3o fornece suporte para debug de mem\u00f3ria. Ferramenta principal para depura\u00e7\u00e3o de mem\u00f3ria, com suporte para detectar vazamentos e erros. Multithreading Suporta an\u00e1lise b\u00e1sica, mas n\u00e3o \u00e9 especializado em detectar race conditions. Helgrind \u00e9 especializado race conditions em programas multithreaded. Integra\u00e7\u00e3o e Uso Parte do GCC, f\u00e1cil de integrar em fluxos de trabalho de compila\u00e7\u00e3o. Requer execu\u00e7\u00e3o com a ferramenta espec\u00edfica e pode necessitar de ajustes no ambiente para uso eficiente. Ambiente de Uso Ideal para profiling em ambientes de desenvolvimento e produ\u00e7\u00e3o. Melhor utilizado em desenvolvimento e testes devido ao overhead; \u00fatil em produ\u00e7\u00e3o para an\u00e1lise pontual."},{"location":"teoria/profiling/#conclusao","title":"Conclus\u00e3o","text":"<p>Gprof e Valgrind s\u00e3o ferramentas complementares no arsenal de um desenvolvedor:</p> <ul> <li> <p>Gprof \u00e9 uma boa escolha quando o objetivo \u00e9 entender a distribui\u00e7\u00e3o de tempo de execu\u00e7\u00e3o entre as fun\u00e7\u00f5es de um programa. Com seu baixo overhead, \u00e9 ideal para profiling inicial e para identificar rapidamente as \u00e1reas do c\u00f3digo que mais consomem tempo.</p> </li> <li> <p>Valgrind \u00e9 indispens\u00e1vel quando se trata de garantir o bom funcionamento do c\u00f3digo, especialmente em rela\u00e7\u00e3o ao uso de mem\u00f3ria. Embora introduza um overhead significativo, suas ferramentas como Memcheck e Callgrind s\u00e3o essenciais para detectar vazamentos de mem\u00f3ria, acessos inv\u00e1lidos, e para visualizar o desempenho em termos de uso de CPU e cache.</p> </li> </ul> <p>Em ambientes de HPC, usar Gprof para identificar gargalos de desempenho e Valgrind para garantir que o c\u00f3digo esteja livre de erros de mem\u00f3ria e bem otimizado, proporciona uma abordagem robusta para garantir que o software seja tanto r\u00e1pido quanto confi\u00e1vel. </p>"},{"location":"teoria/slurm/","title":"SLURM","text":""},{"location":"teoria/slurm/#o-que-e-slurm","title":"O que \u00e9 SLURM?","text":"<p>SLURM (Simple Linux Utility for Resource Management) \u00e9 um gerenciador de workload open-source amplamente utilizado em clusters de computa\u00e7\u00e3o de alto desempenho (HPC). Ele \u00e9 respons\u00e1vel por alocar recursos de computa\u00e7\u00e3o (como CPUs, mem\u00f3ria e GPUs) aos usu\u00e1rios e suas tarefas, gerenciar filas de jobs, monitorar o uso de recursos e agendar a execu\u00e7\u00e3o de tarefas de forma eficiente.</p>"},{"location":"teoria/slurm/#principais-funcionalidades-do-slurm","title":"Principais Funcionalidades do SLURM","text":"<ol> <li>Aloca\u00e7\u00e3o de Recursos: SLURM distribui recursos de computa\u00e7\u00e3o, como n\u00f3s e processadores, conforme solicitado pelos usu\u00e1rios. Ele assegura que os recursos s\u00e3o utilizados de maneira eficiente e equitativa.</li> <li>Submiss\u00e3o de Jobs: Usu\u00e1rios podem submeter jobs (tarefas de computa\u00e7\u00e3o) ao SLURM, que coloca esses jobs em uma fila e os executa quando os recursos necess\u00e1rios est\u00e3o dispon\u00edveis.</li> <li>Monitoramento e Gerenciamento: SLURM monitoriza o estado dos jobs, n\u00f3s e parti\u00e7\u00f5es do cluster, fornecendo ferramentas para verificar o status e a utiliza\u00e7\u00e3o de recursos.</li> <li>Pol\u00edticas de Prioriza\u00e7\u00e3o: Implementa pol\u00edticas para priorizar jobs com base em v\u00e1rios fatores, como tempo de espera, utiliza\u00e7\u00e3o de recursos e prioridades definidas pelo administrador do cluster.</li> </ol>"},{"location":"teoria/slurm/#comandos-principais-do-slurm","title":"Comandos Principais do SLURM","text":"<p>Alguns dos comandos principais usados no SLURM:</p> <ol> <li>sbatch: \u00c9 um comando do SLURM usado para submeter scripts de jobs para execu\u00e7\u00e3o em um cluster. Esses scripts cont\u00eam instru\u00e7\u00f5es sobre como os recursos devem ser alocados e quais comandos devem ser executados</li> <li>scancel: Cancela um job pendente ou em execu\u00e7\u00e3o.</li> <li>scontrol: Ferramenta administrativa usada para visualizar e/ou modificar o estado do SLURM. Muitos comandos <code>scontrol</code> s\u00f3 podem ser executados pelo adminstrador do sistema.</li> <li>sinfo: Relata o estado das filas e n\u00f3s gerenciados pelo SLURM, com v\u00e1rias op\u00e7\u00f5es de filtragem, ordena\u00e7\u00e3o e formata\u00e7\u00e3o.</li> <li>sprio: Exibe uma vis\u00e3o detalhada dos componentes que afetam a prioridade de um job.</li> <li>squeue: Relata o estado dos jobs em execu\u00e7\u00e3o em ordem de prioridade e depois os jobs pendentes em ordem de prioridade.</li> <li>srun: Submete um job para execu\u00e7\u00e3o e faz o pedido de aloca\u00e7\u00e3o dos recursos da maquina.</li> <li>strigger: Define, obt\u00e9m ou visualiza gatilhos de eventos, como n\u00f3s caindo ou jobs se aproximando do limite de tempo.</li> </ol>"},{"location":"teoria/slurm/#exemplos-de-uso-para-cada-comando-slurm","title":"Exemplos de Uso para Cada Comando SLURM","text":""},{"location":"teoria/slurm/#1-sbatch","title":"1. sbatch","text":"<p>Submete scripts de jobs para execu\u00e7\u00e3o em um cluster. Esses scripts cont\u00eam instru\u00e7\u00f5es sobre como os recursos devem ser alocados e quais comandos devem ser executados.</p> <p>Exemplo de Script:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=meu_job        # Nome do job\n#SBATCH --output=meu_job.out      # Arquivo de sa\u00edda\n#SBATCH --error=meu_job.err       # Arquivo de erro\n#SBATCH --ntasks=1                # N\u00famero de tarefas\n#SBATCH --cpus-per-task=4         # N\u00famero de CPUs por tarefa\n#SBATCH --mem=4G                  # Mem\u00f3ria total alocada para o job\n#SBATCH --time=00:02:00           # Tempo m\u00e1ximo de execu\u00e7\u00e3o (hh:mm:ss)\n#SBATCH --partition=normal        # Fila do cluster\n\necho \"Iniciando o job\"\nsleep 60\necho \"Job finalizado\"\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <p><code>-job-name=meu_job</code>: Define o nome do job como <code>meu_job</code>.</p> <p><code>-output=meu_job.out</code>: Especifica o arquivo onde a sa\u00edda padr\u00e3o do job ser\u00e1 registrada.</p> <p><code>-error=meu_job.err</code>: Especifica o arquivo onde os erros ser\u00e3o registrados.</p> <p><code>-ntasks=1</code>: Define o n\u00famero de tarefas (processos) a serem utilizados pelo job.</p> <p><code>-cpus-per-task=4</code>: Aloca 4 CPUs para cada tarefa.</p> <p><code>-mem=4G</code>: Especifica que 4 GB de mem\u00f3ria ser\u00e3o alocados para o job.</p> <p><code>-time=00:02:00</code>: Define o tempo m\u00e1ximo de execu\u00e7\u00e3o do job como 2 minutos.</p> <p><code>-partition=normal</code>: Especifica a fila do cluster onde o job ser\u00e1 executado.</p>"},{"location":"teoria/slurm/#2-scancel","title":"2. scancel","text":"<p>Cancela um job pendente ou em execu\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>scancel 12345\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <ul> <li><code>12345</code>: Especifica o ID do job que deve ser cancelado.</li> </ul>"},{"location":"teoria/slurm/#3-scontrol","title":"3. scontrol","text":"<p>Ferramenta administrativa usada para visualizar e/ou modificar o estado do SLURM. Muitos comandos <code>scontrol</code> s\u00f3 podem ser executados pelo administrador do sistema.</p> <p>Exemplo:</p> <pre><code>scontrol show job 12345\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <p><code>show job 12345</code>: Exibe informa\u00e7\u00f5es detalhadas sobre o job com ID <code>12345</code>.</p>"},{"location":"teoria/slurm/#4-sinfo","title":"4. sinfo","text":"<p>Relata o estado das filas e n\u00f3s gerenciados pelo SLURM.</p> <p>Exemplo:</p> <pre><code>sinfo\n</code></pre>"},{"location":"teoria/slurm/#5-sprio","title":"5. sprio","text":"<p>Exibe uma vis\u00e3o detalhada dos componentes que afetam a prioridade de um job.</p> <p>Exemplo:</p> <pre><code>sprio\n</code></pre>"},{"location":"teoria/slurm/#6-squeue","title":"6. squeue","text":"<p>Relata o estado dos jobs em execu\u00e7\u00e3o em ordem de prioridade e depois os jobs pendentes em ordem de prioridade.</p> <p>Exemplo:</p> <pre><code>squeue -u username\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <p><code>u username</code>: Filtra a sa\u00edda para mostrar apenas os jobs do usu\u00e1rio <code>username</code>.</p>"},{"location":"teoria/slurm/#7-srun","title":"7. srun","text":"<p>Submete um job para execu\u00e7\u00e3o e faz o pedido de aloca\u00e7\u00e3o dos recursos da m\u00e1quina.</p> <p>Exemplo:</p> <pre><code>srun -N 1 -n 1 --time=00:01:00 ./meu_programa\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <p><code>N 1</code>: Especifica que 1 n\u00f3 deve ser alocado.</p> <p><code>n 1</code>: Define que 1 tarefa deve ser executadas.</p> <p><code>-time=00:01:00</code>: Define o tempo m\u00e1ximo de execu\u00e7\u00e3o do job como 1 minuto.</p> <p><code>./meu_programa</code>: Especifica o programa a ser executado.</p>"},{"location":"teoria/slurm/#9-strigger","title":"9. strigger","text":"<p>Define, obt\u00e9m ou visualiza gatilhos de eventos, como n\u00f3s caindo ou jobs se aproximando do limite de tempo.</p> <p>Exemplo: Vamos supor que voc\u00ea queira configurar um gatilho (<code>strigger</code>) para monitorar o uso de mem\u00f3ria de um job espec\u00edfico e enviar um alerta quando o uso de mem\u00f3ria ultrapassar um certo limite. Aqui est\u00e1 um exemplo completo:</p> <pre><code>strigger --set --jobid=&lt;JOB_ID&gt; --threshold=500 --action=\"echo 'Aten\u00e7\u00e3o: O uso de mem\u00f3ria ultrapassou 500 MB!'\"\n</code></pre>"},{"location":"teoria/slurm/#explicacao-do-comando","title":"Explica\u00e7\u00e3o do Comando:","text":"<p><code>strigger</code>: Comando para configurar um gatilho no SLURM.</p> <p><code>--set</code>: Indica que estamos criando um novo gatilho.</p> <p><code>--jobid=&lt;JOB_ID&gt;</code>: Especifica o ID do job que queremos monitorar. Substitua <code>&lt;JOB_ID&gt;</code> pelo ID real do job.</p> <p><code>--threshold=500</code>: Define o limiar de 500 MB de uso de mem\u00f3ria. Quando o job usar mais de 500 MB, o gatilho ser\u00e1 ativado.</p> <p><code>--action=\"echo 'Aten\u00e7\u00e3o: O uso de mem\u00f3ria ultrapassou 500 MB!'\"</code>: Define a a\u00e7\u00e3o que ser\u00e1 executada quando o gatilho for ativado. Neste caso, a a\u00e7\u00e3o \u00e9 um simples comando <code>echo</code> que imprime uma mensagem de alerta.</p> <p>Este gatilho ser\u00e1 acionado quando o job especificado pelo <code>&lt;JOB_ID&gt;</code> ultrapassar 500 MB de uso de mem\u00f3ria. A a\u00e7\u00e3o definida (<code>echo</code>) ser\u00e1 executada, e voc\u00ea ver\u00e1 a mensagem \"Aten\u00e7\u00e3o: O uso de mem\u00f3ria ultrapassou 500 MB!\" no terminal ou no arquivo de sa\u00edda do job.</p> <p>Voc\u00ea pode personalizar o comando <code>strigger</code> para outras situa\u00e7\u00f5es, como monitorar o tempo restante de um job, detectar falhas de n\u00f3s, ou monitorar o uso de CPU, simplesmente ajustando os par\u00e2metros e as a\u00e7\u00f5es conforme necess\u00e1rio.</p>"},{"location":"teoria/slurm/#tipos-comuns-de-eventos-monitoraveis-pelo-strigger","title":"Tipos Comuns de Eventos Monitor\u00e1veis pelo <code>strigger</code>:","text":"<p>Tempo Restante (<code>TIME_LIMIT</code>):</p> <p>Aciona o gatilho quando um job se aproxima de seu limite de tempo de execu\u00e7\u00e3o.</p> <p>Uso do <code>--threshold</code>: Especifica o tempo restante em segundos.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --threshold=60 --action=\"echo 'Job est\u00e1 a 60 segundos do limite de tempo!'\"</code></p> <p>Uso de Mem\u00f3ria (<code>MEMORY</code>):</p> <p>Aciona o gatilho quando o uso de mem\u00f3ria de um job ultrapassa um certo limite.</p> <p>Uso do <code>--threshold</code>: Especifica a quantidade de mem\u00f3ria usada, geralmente em megabytes (MB).</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --threshold=1024 --action=\"echo 'Job ultrapassou 1GB de mem\u00f3ria!'\"</code></p> <p>Falha de N\u00f3 (<code>NODE_FAIL</code>):</p> <p>Aciona o gatilho quando um n\u00f3 falha ou fica indispon\u00edvel.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de falha ocorre.</p> <p>Exemplo: <code>strigger --set --node=&lt;NODE_NAME&gt; --event=NODE_FAIL --action=\"echo 'N\u00f3 falhou!'\"</code></p> <p>Falha de Job (<code>JOB_FAIL</code>):</p> <p>Aciona o gatilho quando um job falha por qualquer motivo.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de falha ocorre.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --event=JOB_FAIL --action=\"echo 'Job falhou!'\"</code></p> <p>In\u00edcio de Job (<code>JOB_START</code>):</p> <p>Aciona o gatilho quando um job come\u00e7a a ser executado.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de in\u00edcio ocorre.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --event=JOB_START --action=\"echo 'Job iniciou!'\"</code></p> <p>Finaliza\u00e7\u00e3o de Job (<code>JOB_END</code>):</p> <p>Aciona o gatilho quando um job termina sua execu\u00e7\u00e3o, independentemente de ter sido conclu\u00eddo com sucesso ou n\u00e3o.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de finaliza\u00e7\u00e3o ocorre.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --event=JOB_END --action=\"echo 'Job terminou!'\"</code></p> <p>Limite de CPU (<code>CPU_LIMIT</code>):</p> <p>Aciona o gatilho quando o uso de CPU de um job ultrapassa um certo limite.</p> <p>Uso do <code>--threshold</code>: Especifica o uso de CPU em segundos de CPU ou em porcentagem.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --threshold=80 --action=\"echo 'Job ultrapassou 80% do uso de CPU!'\"</code></p> <p>Submiss\u00e3o de Job (<code>JOB_SUBMIT</code>):</p> <p>Aciona o gatilho quando um job \u00e9 submetido para execu\u00e7\u00e3o.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de submiss\u00e3o ocorre.</p> <p>Exemplo: <code>strigger --set --user=&lt;USER_NAME&gt; --event=JOB_SUBMIT --action=\"echo 'Um job foi submetido!'\"</code></p> <p>Queda de Parti\u00e7\u00e3o (<code>PARTITION_DOWN</code>):</p> <p>Aciona o gatilho quando uma parti\u00e7\u00e3o inteira do cluster cai ou fica indispon\u00edvel.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de queda da parti\u00e7\u00e3o ocorre.</p> <p>Exemplo: <code>strigger --set --partition=&lt;PARTITION_NAME&gt; --event=PARTITION_DOWN --action=\"echo 'Parti\u00e7\u00e3o caiu!'\"</code></p> <p>Chegada de Job ao Limiar de Tempo (<code>TIME_LIM_REACHED</code>):</p> <p>Similar ao <code>TIME_LIMIT</code>, mas pode ser mais espec\u00edfico para quando o tempo limite \u00e9 alcan\u00e7ado, n\u00e3o apenas quando est\u00e1 pr\u00f3ximo.</p> <p>Uso do <code>--threshold</code>: Especifica o tempo restante ou o evento do tempo limite.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --event=TIME_LIM_REACHED --action=\"echo 'Tempo limite alcan\u00e7ado!'\"</code></p>"},{"location":"teoria/aula01/","title":"Conte\u00fado te\u00f3rico de apoio - Aula 01","text":"Mapa de mem\u00f3ria, pilha, essas coisas... <p>Conceitos basicos de arquitetura de computadores</p> Algumas vantagens do C++ <p>Conceitos B\u00e1sicos de C++</p> <p>Loops e La\u00e7os</p> <p>Passagens de par\u00e2metros (por refer\u00eancia, por ponteiro)</p> <p>Const Correctness em HPC</p> <p>Aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica</p> <p>Sobrecarga de fun\u00e7\u00f5es C++</p> <p>Classes e Objetos</p> <p>Manipula\u00e7\u00e3o de Vetores</p> <p>Flags de compila\u00e7\u00e3o</p> Como compilar c\u00f3digos em C++ <p>Como compilar e executar c\u00f3digos em C++</p>"},{"location":"teoria/aula01/classes-e-objetos/","title":"Classes e objetos","text":"<p>Uma classe em C++ \u00e9 uma estrutura que define um conjunto de atributos (dados) e m\u00e9todos (fun\u00e7\u00f5es) que operam sobre esses dados. \u00c9 uma forma de agrupar dados e comportamentos relacionados, facilitando a modularidade e a reutiliza\u00e7\u00e3o do c\u00f3digo. Objetos s\u00e3o inst\u00e2ncias de classes. Eles representam entidades espec\u00edficas que possuem os atributos e m\u00e9todos definidos pela classe.</p>"},{"location":"teoria/aula01/classes-e-objetos/#exemplo-pratico-problema-da-mochila","title":"Exemplo Pr\u00e1tico: Problema da Mochila","text":"<p>No exemplo do problema da mochila, criamos uma classe <code>Knapsack</code> para encapsular a l\u00f3gica do problema. Vamos detalhar cada parte do c\u00f3digo para entender como classes e objetos s\u00e3o utilizados.</p>"},{"location":"teoria/aula01/classes-e-objetos/#declaracao-da-classe","title":"Declara\u00e7\u00e3o da Classe","text":"<p>A classe <code>Knapsack</code> \u00e9 definida com atributos e m\u00e9todos necess\u00e1rios para resolver o problema da mochila.</p> <pre><code>#include &lt;iostream&gt;\n\n// Declara\u00e7\u00e3o da classe Knapsack\nclass Knapsack {\npublic:\n    Knapsack(int capacidade, int numItens);       // Construtor que inicializa a mochila\n    ~Knapsack();                                  // Destrutor que libera a mem\u00f3ria alocada\n    void adicionaItem(int peso, int valor);       // M\u00e9todo para adicionar um item\n    int resolve();                                // M\u00e9todo para resolver o problema da mochila\n    void imprimeItens();                          // M\u00e9todo para imprimir os itens adicionados\n\nprivate:\n    int capacidade;                               // Capacidade m\u00e1xima da mochila\n    int numItens;                                 // N\u00famero total de itens\n    int* pesos;                                   // Vetor din\u00e2mico para armazenar os pesos dos itens\n    int* valores;                                 // Vetor din\u00e2mico para armazenar os valores dos itens\n    int contadorItens;                            // Contador de itens adicionados\n};\n</code></pre> <ul> <li>Atributos:<ul> <li><code>capacidade</code>: Capacidade m\u00e1xima da mochila.</li> <li><code>numItens</code>: N\u00famero total de itens.</li> <li><code>pesos</code>: Ponteiro para um vetor que armazena os pesos dos itens.</li> <li><code>valores</code>: Ponteiro para um vetor que armazena os valores dos itens.</li> <li><code>contadorItens</code>: Contador para acompanhar quantos itens foram adicionados.</li> </ul> </li> <li>M\u00e9todos:<ul> <li><code>Knapsack(int capacidade, int numItens)</code>: Construtor que inicializa os atributos e aloca mem\u00f3ria para os vetores.</li> <li><code>~Knapsack()</code>: Destrutor que libera a mem\u00f3ria alocada para os vetores.</li> <li><code>void adicionaItem(int peso, int valor)</code>: M\u00e9todo para adicionar um item \u00e0 mochila.</li> <li><code>int resolve()</code>: M\u00e9todo para resolver o problema da mochila usando programa\u00e7\u00e3o din\u00e2mica.</li> <li><code>void imprimeItens()</code>: M\u00e9todo para imprimir os itens adicionados \u00e0 mochila.</li> </ul> </li> </ul>"},{"location":"teoria/aula01/classes-e-objetos/#implementacao-do-construtor-e-destrutor","title":"Implementa\u00e7\u00e3o do Construtor e Destrutor","text":"<p>O construtor inicializa os atributos e aloca mem\u00f3ria para os vetores de pesos e valores. O destrutor libera essa mem\u00f3ria.</p> <pre><code>// Implementa\u00e7\u00e3o do construtor\nKnapsack::Knapsack(int capacidade, int numItens)\n    : capacidade(capacidade), numItens(numItens), contadorItens(0) {\n    pesos = new int[numItens];                    // Aloca mem\u00f3ria para os pesos dos itens\n    valores = new int[numItens];                  // Aloca mem\u00f3ria para os valores dos itens\n}\n\n// Implementa\u00e7\u00e3o do destrutor\nKnapsack::~Knapsack() {\n    delete[] pesos;                               // Libera a mem\u00f3ria alocada para os pesos\n    delete[] valores;                             // Libera a mem\u00f3ria alocada para os valores\n}\n</code></pre>"},{"location":"teoria/aula01/classes-e-objetos/#metodo-para-adicionar-itens","title":"M\u00e9todo para Adicionar Itens","text":"<p>O m\u00e9todo <code>adicionaItem</code> permite adicionar itens \u00e0 mochila, atualizando os vetores de pesos e valores.</p> <pre><code>// Implementa\u00e7\u00e3o do m\u00e9todo para adicionar um item\nvoid Knapsack::adicionaItem(int peso, int valor) {\n    if (contadorItens &lt; numItens) {\n        pesos[contadorItens] = peso;              // Adiciona o peso do item\n        valores[contadorItens] = valor;           // Adiciona o valor do item\n        contadorItens++;                          // Incrementa o contador de itens\n    } else {\n        std::cerr &lt;&lt; \"N\u00famero m\u00e1ximo de itens excedido!\" &lt;&lt; std::endl;\n    }\n}\n</code></pre>"},{"location":"teoria/aula01/classes-e-objetos/#metodo-para-resolver-o-problema-da-mochila","title":"M\u00e9todo para Resolver o Problema da Mochila","text":"<p>Programa\u00e7\u00e3o Din\u00e2mica (Dynamic Programming, DP) \u00e9 uma t\u00e9cnica de otimiza\u00e7\u00e3o usada para resolver problemas complexos dividindo-os em subproblemas mais simples. Ela \u00e9 especialmente eficaz para problemas que podem ser divididos em subproblemas menores, onde os resultados de subproblemas anteriores podem ser reutilizados para resolver subproblemas maiores.</p> <p>No problema da mochila, a programa\u00e7\u00e3o din\u00e2mica \u00e9 usada para encontrar a combina\u00e7\u00e3o de itens que maximiza o valor total sem exceder a capacidade da mochila. Construindo uma tabela que armazena os valores m\u00e1ximos poss\u00edveis para diferentes capacidades e conjuntos de itens.</p> <p>A tabela de DP (K) \u00e9 constru\u00edda de forma que cada entrada K[i][w] representa o valor m\u00e1ximo que pode ser obtido usando os primeiros i itens com uma capacidade m\u00e1xima de w.</p>"},{"location":"teoria/aula01/classes-e-objetos/#metodo-resolve","title":"M\u00e9todo resolve","text":"<ol> <li> <p>Inicializa\u00e7\u00e3o da Tabela de DP:</p> <pre><code>int** K = new int*[numItens + 1];             // Aloca mem\u00f3ria para a tabela de DP\nfor (int i = 0; i &lt;= numItens; ++i) {\n    K[i] = new int[capacidade + 1];           // Aloca mem\u00f3ria para cada linha da tabela de DP\n}\n</code></pre> <ul> <li>Alocamos uma tabela <code>K</code> com <code>numItens + 1</code> linhas e <code>capacidade + 1</code> colunas. Cada entrada <code>K[i][w]</code> armazenar\u00e1 o valor m\u00e1ximo poss\u00edvel para a submochila com capacidade <code>w</code> usando os primeiros <code>i</code> itens.</li> <li>Preenchimento da Tabela de DP:</li> </ul> <pre><code>for (int i = 0; i &lt;= numItens; ++i) {\n    for (int w = 0; w &lt;= capacidade; ++w) {\n        if (i == 0 || w == 0) {\n            K[i][w] = 0;                      // Caso base: capacidade 0 ou nenhum item\n        } else if (pesos[i - 1] &lt;= w) {\n            // Escolhe o m\u00e1ximo entre incluir ou n\u00e3o o item atual\n            K[i][w] = std::max(valores[i - 1] + K[i - 1][w - pesos[i - 1]], K[i - 1][w]);\n        } else {\n            K[i][w] = K[i - 1][w];            // N\u00e3o inclui o item atual\n        }\n    }\n}\n</code></pre> <ul> <li>Usamos um loop duplo para preencher a tabela.</li> <li>Caso Base: Se n\u00e3o h\u00e1 itens (<code>i == 0</code>) ou a capacidade \u00e9 zero (<code>w == 0</code>), o valor m\u00e1ximo \u00e9 0.</li> <li>Decis\u00e3o: Para cada item, verificamos se ele pode ser inclu\u00eddo na submochila (<code>pesos[i - 1] &lt;= w</code>). Se puder, escolhemos o m\u00e1ximo entre incluir o item (somando seu valor com o valor da submochila restante) e n\u00e3o inclu\u00ed-lo.</li> <li>Exclus\u00e3o do Item: Se o item n\u00e3o puder ser inclu\u00eddo, simplesmente copiamos o valor da submochila sem ele.</li> <li>Resultado Final:</li> </ul> <pre><code>int resultado = K[numItens][capacidade];      // Resultado final da DP\n</code></pre> <ul> <li>O valor m\u00e1ximo poss\u00edvel para a mochila completa \u00e9 encontrado em <code>K[numItens][capacidade]</code>.</li> <li>Libera\u00e7\u00e3o da Mem\u00f3ria:</li> </ul> <pre><code>for (int i = 0; i &lt;= numItens; ++i) {\n    delete[] K[i];                            // Libera mem\u00f3ria para cada linha\n}\ndelete[] K;                                   // Libera mem\u00f3ria para o vetor de ponteiros\n</code></pre> <ul> <li>Ap\u00f3s o c\u00e1lculo, liberamos a mem\u00f3ria alocada dinamicamente para a tabela <code>K</code>.</li> </ul> </li> </ol> <p>Neste contexto, a programa\u00e7\u00e3o din\u00e2mica (DP) \u00e9 usada para resolver o problema da mochila de maneira eficiente, evitando recomputa\u00e7\u00f5es de subproblemas ao armazenar os resultados intermedi\u00e1rios em uma tabela. A classe <code>Knapsack</code> encapsula a l\u00f3gica do problema, tornando o c\u00f3digo modular e f\u00e1cil de manter. A aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria permite a flexibilidade de lidar com diferentes tamanhos de problemas sem desperdi\u00e7ar mem\u00f3ria.</p>"},{"location":"teoria/aula01/classes-e-objetos/#metodo-para-imprimir-itens","title":"M\u00e9todo para Imprimir Itens","text":"<p>O m\u00e9todo <code>imprimeItens</code> imprime os itens adicionados \u00e0 mochila.</p> <pre><code>// Implementa\u00e7\u00e3o do m\u00e9todo para imprimir os itens adicionados\nvoid Knapsack::imprimeItens() {\n    std::cout &lt;&lt; \"Itens adicionados (peso, valor):\" &lt;&lt; std::endl;\n    for (int i = 0; i &lt; contadorItens; ++i) {\n        std::cout &lt;&lt; \"(\" &lt;&lt; pesos[i] &lt;&lt; \", \" &lt;&lt; valores[i] &lt;&lt; \")\" &lt;&lt; std::endl;\n    }\n}\n</code></pre>"},{"location":"teoria/aula01/classes-e-objetos/#funcao-main","title":"Fun\u00e7\u00e3o <code>main</code>","text":"<p>A fun\u00e7\u00e3o <code>main</code> cria um objeto <code>Knapsack</code>, adiciona itens \u00e0 mochila, imprime os itens adicionados e resolve o problema da mochila.</p> <pre><code>int main() {\n    int capacidade = 50;                           // Capacidade da mochila\n    int numItens = 3;                              // N\u00famero de itens dispon\u00edveis\n\n    Knapsack mochila(capacidade, numItens);\n\n    mochila.adicionaItem(10, 60);                  // Adiciona item (peso, valor)\n    mochila.adicionaItem(20, 100);                 // Adiciona item (peso, valor)\n    mochila.adicionaItem(30, 120);                 // Adiciona item (peso, valor)\n\n    mochila.imprimeItens();                        // Imprime os itens adicionados\n\n    int valorMaximo = mochila.resolve();           // Resolve o problema da mochila\n\n    std::cout &lt;&lt; \"Valor m\u00e1ximo que pode ser levado: \" &lt;&lt; valorMaximo &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>Neste exemplo, a classe <code>Knapsack</code> encapsula todos os dados e m\u00e9todos necess\u00e1rios para resolver o problema da mochila. Usamos aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria para gerenciar os vetores de pesos, valores dos itens, e a tabela de programa\u00e7\u00e3o din\u00e2mica utilizada na solu\u00e7\u00e3o do problema.</p>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/","title":"Compilar/Executar C\u00f3digos C++","text":"<p>Pr\u00e9-requisitos:</p> <ul> <li>Visual Studio Code (VSCode) instalado</li> </ul>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#passos-para-windows","title":"Passos para Windows","text":"<ol> <li> <p>Instalar o Compilador Siga este tutorial</p> </li> <li> <p>Instalar Extens\u00f5es Necess\u00e1rias no VSCode:</p> <ul> <li>Abra o VSCode.</li> <li>V\u00e1 para a aba de extens\u00f5es (\u00edcone de quadrado no lado esquerdo).</li> <li>Pesquise e instale a extens\u00e3o:<ul> <li>C/C++ (Microsoft)</li> </ul> </li> </ul> </li> </ol>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#passos-para-linux","title":"Passos para Linux","text":"<ol> <li> <p>Instalar o Compilador G++:</p> <ul> <li>N\u00e3o precisa, j\u00e1 vem instalado &lt;3</li> </ul> </li> <li> <p>Instalar Extens\u00f5es Necess\u00e1rias no VSCode:</p> <ul> <li>Abra o VSCode.</li> <li>V\u00e1 para a aba de extens\u00f5es (\u00edcone de quadrado no lado esquerdo).</li> <li>Pesquise e instale as seguintes extens\u00e3o:<ul> <li>C/C++ (Microsoft)</li> </ul> </li> </ul> </li> </ol>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#passos-para-macos","title":"Passos para macOS","text":"<ol> <li> <p>Instalar o compilador:</p> <ul> <li>N\u00e3o precisa, j\u00e1 vem instalado &lt;3</li> <li>Mas se quiser saber mais detalhes sobre o Clang, sugiro este material</li> </ul> </li> <li> <p>Instalar Extens\u00f5es Necess\u00e1rias no VSCode:</p> <ul> <li>Abra o VSCode.</li> <li>V\u00e1 para a aba de extens\u00f5es (\u00edcone de quadrado no lado esquerdo).</li> <li>Pesquise e instale a extens\u00f5es:<ul> <li>C/C++ (Microsoft)</li> </ul> </li> </ul> </li> </ol>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#compilando-um-exemplo-em-c-para-testar","title":"Compilando um Exemplo em C++ para Testar","text":"<p>Crie um arquivo <code>main.cpp</code> com o seguinte conte\u00fado:</p> <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nint main() {\n    cout &lt;&lt; \"Hello, World!\" &lt;&lt; endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#windows-compilar-e-executar","title":"Windows \u2192 Compilar e Executar","text":"<pre><code>g++ main.cpp -o main.exe\n./main.exe\n</code></pre>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#linux-compilar-e-executar","title":"Linux \u2192 Compilar e Executar:","text":"<pre><code>g++ main.cpp -o main\n./main\n</code></pre>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#macos-compilar-e-executar","title":"MacOS \u2192 Compilar e Executar","text":"<pre><code>clang++ main.cpp -o main\n./main\n</code></pre> <p>Seguindo esses passos, voc\u00ea deve ser capaz de compilar e executar programas C++ em Windows, Linux ou macOS usando o VSCode.</p>"},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/","title":"Conceitos b\u00e1sicos de C++","text":"<p>Esses s\u00e3o os tipos de vari\u00e1veis e seus respectivos tamanhos em C++ </p> Tipo de Dados Tamanho (em bytes) Valor M\u00ednimo Valor M\u00e1ximo bool 1 false true char 1 -128 127 unsigned char 1 0 255 short 2 -32,768 32,767 unsigned short 2 0 65,535 int 4 -2,147,483,648 2,147,483,647 unsigned int 4 0 4,294,967,295 long 8 -9,223,372,036,854,775,808 9,223,372,036,854,775,807 unsigned long 8 0 18,446,744,073,709,551,615 float 4 1.2E-38 3.4E+38 double 8 2.3E-308 1.7E+308 long double 16 3.4E-4932 1.1E+4932 wchar_t 4 0 4,294,967,295  \u26a0\ufe0f Esses tamanhos podem variar dependendo da arquitetura do sistema. Esta tabela assume um sistema de 64 bits."},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/#o-que-e-um-namespace","title":"O que \u00e9 um Namespace?","text":"<p>Um namespace \u00e9 uma forma de agrupar identificadores (nomes de fun\u00e7\u00f5es, classes, objetos, etc.) sob um nome comum, evitando conflitos de nome entre diferentes partes de um programa ou entre diferentes bibliotecas.</p>"},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/#exemplo-simples-de-namespace","title":"Exemplo Simples de Namespace","text":"<p>Imagine duas bibliotecas diferentes que ambas definem uma fun\u00e7\u00e3o chamada <code>print()</code>. Se voc\u00ea incluir ambas as bibliotecas em seu programa, o compilador n\u00e3o saber\u00e1 qual <code>print()</code> usar. Para resolver isso, cada biblioteca pode colocar sua fun\u00e7\u00e3o <code>print()</code> em seu pr\u00f3prio namespace:</p> <pre><code>// Biblioteca A\nnamespace A {\n    void print() {\n        std::cout &lt;&lt; \"Imprimindo da biblioteca A\" &lt;&lt; std::endl;\n    }\n}\n\n// Biblioteca B\nnamespace B {\n    void print() {\n        std::cout &lt;&lt; \"Imprimindo da biblioteca B\" &lt;&lt; std::endl;\n    }\n}\n\nint main() {\n    A::print(); // Chama a fun\u00e7\u00e3o print() da biblioteca A\n    B::print(); // Chama a fun\u00e7\u00e3o print() da biblioteca B\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/#usando-namespaces","title":"Usando Namespaces","text":"<p>Existem v\u00e1rias maneiras de usar namespaces em C++:</p> <ol> <li> <p>Usar o nome completo do namespace (qualifica\u00e7\u00e3o total):</p> <pre><code>#include &lt;iostream&gt;\n\nint main() {\n    std::cout &lt;&lt; \"Hello, World!\" &lt;&lt; std::endl; // Usa std::cout e std::endl\n    return 0;\n}\n</code></pre> </li> <li> <p>Usar a declara\u00e7\u00e3o <code>using</code> para trazer membros espec\u00edficos do namespace para o escopo atual:</p> <pre><code>#include &lt;iostream&gt;\nusing std::cout;\nusing std::endl;\n\nint main() {\n    cout &lt;&lt; \"Hello, World!\" &lt;&lt; endl; // Usa cout e endl sem o prefixo std::\n    return 0;\n}\n</code></pre> </li> <li> <p>Usar a diretiva <code>using</code> para trazer todos os membros do namespace para o escopo atual:</p> <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nint main() {\n    cout &lt;&lt; \"Hello, World!\" &lt;&lt; endl; // Usa cout e endl sem o prefixo std::\n    return 0;\n}\n</code></pre> </li> </ol>"},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/#o-que-e-std","title":"O que \u00e9 <code>std</code>?","text":"<p><code>std</code> \u00e9 o namespace padr\u00e3o da biblioteca padr\u00e3o C++ (Standard Library). Ele cont\u00e9m a maior parte das fun\u00e7\u00f5es, objetos, tipos e classes fornecidos pela biblioteca padr\u00e3o do C++. Quando voc\u00ea usa recursos da biblioteca padr\u00e3o, como <code>std::vector</code>, <code>std::cout</code>, <code>std::string</code>, etc., voc\u00ea est\u00e1 acessando esses elementos do namespace <code>std</code>.</p> <p>Por exemplo:</p> <ul> <li><code>std::cout</code> \u00e9 o objeto de fluxo de sa\u00edda padr\u00e3o usado para imprimir dados na tela.</li> <li><code>std::vector</code> \u00e9 uma classe de cont\u00eainer que representa um array din\u00e2mico.</li> </ul>"},{"location":"teoria/aula01/conceitos-basicos-hw/","title":"Relembrando conceitos importantes","text":"<p>O mapa de mem\u00f3ria de um computador revela como a mem\u00f3ria \u00e9 organizada e gerenciada, isso \u00e9 essencial para entender o armazenamento, o acesso e a manipula\u00e7\u00e3o de dados pela CPU. A mem\u00f3ria principal do sistema inclui o heap, a stack e os segmentos de dados e c\u00f3digo. </p> <ol> <li>Pilha: Localizada no topo do mapa de mem\u00f3ria, \u00e9 usada para armazenar vari\u00e1veis locais e chamadas de fun\u00e7\u00e3o. Cada thread possui sua pr\u00f3pria pilha.</li> <li>Espa\u00e7o Livre: Espa\u00e7o entre a pilha e o heap, permitindo o crescimento de ambos conforme necess\u00e1rio.</li> <li>Heap: \u00c1rea usada para a aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica. Mem\u00f3ria \u00e9 alocada e desalocada conforme necess\u00e1rio durante a execu\u00e7\u00e3o do programa.</li> <li>Segmento de Dados: Cont\u00e9m vari\u00e1veis globais e est\u00e1ticas. Este segmento \u00e9 dividido em duas partes:<ul> <li>Segmento de Dados Inicializado: Armazena vari\u00e1veis globais e est\u00e1ticas que s\u00e3o inicializadas.</li> <li>BSS (Block Started by Symbol): Armazena vari\u00e1veis globais e est\u00e1ticas n\u00e3o inicializadas.</li> </ul> </li> <li>Segmento de C\u00f3digo: Cont\u00e9m o c\u00f3digo execut\u00e1vel do programa.</li> </ol> <p>Os endere\u00e7os da pilha crescem de cima para baixo, enquanto os endere\u00e7os do heap crescem de baixo para cima, conforme indicado pelas setas de crescimento no diagrama. Essa organiza\u00e7\u00e3o \u00e9 essencial para o gerenciamento eficiente da mem\u00f3ria e para garantir a integridade e desempenho do programa</p> <p></p> <p>Os caches, subdivididos em L1, L2 e L3, s\u00e3o mem\u00f3rias r\u00e1pidas de diferentes tamanhos e velocidades. O L1 \u00e9 o mais r\u00e1pido e menor, localizado dentro do n\u00facleo da CPU. O L2 \u00e9 maior e mais lento que o L1, mas ainda mais r\u00e1pido que a RAM, enquanto o L3, compartilhado entre os n\u00facleos do processador, \u00e9 maior e mais lento que o L2. Os registradores, pequenas quantidades de mem\u00f3ria dentro da CPU, s\u00e3o extremamente r\u00e1pidos e usados para opera\u00e7\u00f5es imediatas e tempor\u00e1rias.</p> <p></p> <ul> <li>Registradores: Pequenas quantidades de mem\u00f3ria dentro da CPU, extremamente r\u00e1pidas, usadas para opera\u00e7\u00f5es imediatas e tempor\u00e1rias. Tamanho: 64-128 bits.</li> <li>Cache L1: O cache mais r\u00e1pido e muito pequeno, localizado dentro do n\u00facleo da CPU. Tamanho: 32 KB.</li> <li>Cache L2: Maior e mais lento que o L1, mas ainda muito r\u00e1pido. Tamanho: 256 KB - 512 KB.</li> <li>Cache L3: Compartilhado entre os n\u00facleos do processador, \u00e9 maior e mais lento que o L2, mas ainda mais r\u00e1pido que a RAM. Tamanho: 2 MB - 16 MB.</li> <li>RAM: A mem\u00f3ria principal do sistema, maior em tamanho e a mais lenta em termos de velocidade comparada aos caches e registradores. Tamanho: 4 GB - 64 GB ou mais.</li> </ul> <p></p> <p>No contexto de HPC, escolher os tipos de dados adequados em C++ \u00e9 crucial por v\u00e1rias raz\u00f5es. </p> <ul> <li>Vari\u00e1veis menores ocupam menos espa\u00e7o, permitindo que mais dados sejam armazenados no cache ou na RAM, melhorando a localidade de cache e resultando em acessos mais r\u00e1pidos.</li> <li>A velocidade de processamento tamb\u00e9m \u00e9 impactada pela escolha dos tipos na declara\u00e7\u00e3o da vari\u00e1vel. A CPU processa tipos menores mais rapidamente, e instru\u00e7\u00f5es SIMD (Single Instruction, Multiple Data) podem processar m\u00faltiplos dados em paralelo se os tipos forem pequenos o suficiente para caberem nos registradores.</li> <li>A precis\u00e3o dos c\u00e1lculos \u00e9 outra considera\u00e7\u00e3o importante. Para c\u00e1lculos cient\u00edficos, a precis\u00e3o adicional dos <code>double</code> pode ser necess\u00e1ria para evitar erros num\u00e9ricos significativos, enquanto em gr\u00e1ficos e outras aplica\u00e7\u00f5es, <code>float</code> pode ser suficiente e mais eficiente em termos de mem\u00f3ria e processamento.</li> <li>Usar tipos menores de vari\u00e1veis reduzem a quantidade de dados transferidos entre n\u00f3s em um cluster, diminuindo a lat\u00eancia e a sobrecarga de comunica\u00e7\u00e3o.</li> </ul> <p>Considerar corretamente os tipos na cria\u00e7\u00e3o das vari\u00e1veis \u00e9 importante para maximizar a efici\u00eancia de uso de mem\u00f3ria, melhorar a velocidade e a precis\u00e3o dos c\u00e1lculos, otimizar o desempenho computacional, minimizar a fragmenta\u00e7\u00e3o de mem\u00f3ria, aproveitar melhor o paralelismo e reduzir a lat\u00eancia de comunica\u00e7\u00e3o, al\u00e9m de melhorar a localidade de cache e o acesso \u00e0 mem\u00f3ria. Compreender o mapa de mem\u00f3ria do computador e como os diferentes tipos de dados interagem com a CPU e a mem\u00f3ria pode levar a melhorias significativas no desempenho dos seus algoritmos.</p>"},{"location":"teoria/aula01/flags-compilacao/","title":"Flags de compila\u00e7\u00e3o (-O1, -O2, -O3, -Ofast).","text":"<p>As flags de compila\u00e7\u00e3o s\u00e3o op\u00e7\u00f5es fornecidas ao compilador para controlar o n\u00edvel de otimiza\u00e7\u00e3o aplicada ao c\u00f3digo durante o processo de compila\u00e7\u00e3o. Diferentes n\u00edveis de otimiza\u00e7\u00e3o podem influenciar o desempenho e o tamanho do c\u00f3digo resultante. Vamos explorar as principais flags de otimiza\u00e7\u00e3o usadas com o compilador GCC (GNU Compiler Collection): <code>-O1</code>, <code>-O2</code>, <code>-O3</code>, e <code>-Ofast</code>.</p>"},{"location":"teoria/aula01/flags-compilacao/#1-flag-o1","title":"1. Flag <code>O1</code>","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>N\u00edvel B\u00e1sico de Otimiza\u00e7\u00e3o: Aplica otimiza\u00e7\u00f5es que melhoram o desempenho do c\u00f3digo sem aumentar significativamente o tempo de compila\u00e7\u00e3o.</li> </ul> <p>Otimiza\u00e7\u00f5es Comuns:</p> <ul> <li>Remo\u00e7\u00e3o de c\u00f3digo morto.</li> <li>Simplifica\u00e7\u00e3o de express\u00f5es.</li> <li>Inlining b\u00e1sico de fun\u00e7\u00f5es.</li> </ul> <p>Quando Usar:</p> <ul> <li>Quando o tempo de compila\u00e7\u00e3o \u00e9 uma preocupa\u00e7\u00e3o, mas algum n\u00edvel de otimiza\u00e7\u00e3o \u00e9 desejado.</li> </ul> <pre><code>g++ -O1 -o meu_programa meu_programa.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#2-flag-o2","title":"2. Flag <code>O2</code>","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>N\u00edvel Moderado de Otimiza\u00e7\u00e3o: Aplica um conjunto mais agressivo de otimiza\u00e7\u00f5es que melhoram ainda mais o desempenho do c\u00f3digo.</li> <li>Maior tempo de compila\u00e7\u00e3o comparado ao <code>O1</code>, mas melhor desempenho do c\u00f3digo.</li> </ul> <p>Otimiza\u00e7\u00f5es Comuns:</p> <ul> <li>Inclui todas as otimiza\u00e7\u00f5es do <code>O1</code>.</li> <li>Otimiza\u00e7\u00f5es de loop (desenrolamento, fus\u00e3o de loops).</li> <li>Melhorias na aloca\u00e7\u00e3o de registradores.</li> <li>Otimiza\u00e7\u00f5es de fluxo de controle.</li> </ul> <p>Quando Usar:</p> <ul> <li>Para a maioria dos casos onde o desempenho \u00e9 mais cr\u00edtico do que o tempo de compila\u00e7\u00e3o.</li> <li>Quando se quer um bom desempenho na performance do c\u00f3digo.</li> </ul> <pre><code>g++ -O2 -o meu_programa meu_programa.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#3-flag-o3","title":"3. Flag <code>O3</code>","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>N\u00edvel Alto de Otimiza\u00e7\u00e3o: Aplica otimiza\u00e7\u00f5es muito agressivas que podem aumentar significativamente o tempo de compila\u00e7\u00e3o e o uso de mem\u00f3ria.</li> <li>Foco em maximizar o desempenho do c\u00f3digo, mesmo que isso aumente o tempo de compila\u00e7\u00e3o.</li> </ul> <p>Otimiza\u00e7\u00f5es Comuns:</p> <ul> <li>Inclui todas as otimiza\u00e7\u00f5es do <code>O2</code>.</li> <li>Inlining mais agressivo de fun\u00e7\u00f5es.</li> <li>Vetoriza\u00e7\u00e3o (uso de SIMD).</li> <li>Transforma\u00e7\u00f5es mais avan\u00e7adas de loop.</li> </ul> <p>Quando Usar:</p> <ul> <li>Quando o desempenho m\u00e1ximo do c\u00f3digo \u00e9 crucial e o tempo de compila\u00e7\u00e3o \u00e9 menos importante.</li> <li>Em aplica\u00e7\u00f5es onde cada gota de desempenho \u00e9 necess\u00e1ria.</li> </ul> <pre><code>g++ -O3 -o meu_programa meu_programa.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#4-flag-ofast","title":"4. Flag <code>Ofast</code>","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>N\u00edvel M\u00e1ximo de Otimiza\u00e7\u00e3o: Aplica todas as otimiza\u00e7\u00f5es do <code>O3</code> e desconsidera a conformidade estrita com os padr\u00f5es, o que pode levar a um desempenho ainda maior.</li> </ul> <p>Otimiza\u00e7\u00f5es Comuns:</p> <ul> <li>Inclui todas as otimiza\u00e7\u00f5es do <code>O3</code>.</li> <li>Otimiza\u00e7\u00f5es de matem\u00e1tica r\u00e1pida (por exemplo, assume que n\u00e3o h\u00e1 overflow de ponto flutuante).</li> <li>Desconsidera o padr\u00e3o IEEE para opera\u00e7\u00f5es de ponto flutuante.</li> </ul> <p>Quando Usar:</p> <ul> <li>Quando o desempenho \u00e9 a \u00fanica prioridade e a conformidade estrita com os padr\u00f5es n\u00e3o \u00e9 uma preocupa\u00e7\u00e3o.</li> <li>Em cen\u00e1rios de HPC onde a precis\u00e3o pode ser ligeiramente sacrificada por ganhos de desempenho.</li> </ul> <pre><code>g++ -Ofast -o meu_programa meu_programa.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-dos-niveis-de-otimizacao","title":"Compara\u00e7\u00e3o dos N\u00edveis de Otimiza\u00e7\u00e3o","text":"Flag Tempo de Compila\u00e7\u00e3o Desempenho Seguran\u00e7a e Conformidade -O1 Baixo Moderado Alta -O2 Moderado Alto Alta -O3 Alto Muito Alto Alta -Ofast Muito Alto M\u00e1ximo M\u00e9dia/Baixa <p>As flags de otimiza\u00e7\u00e3o s\u00e3o ferramentas poderosas que podem ajudar a melhorar significativamente o desempenho do seu c\u00f3digo C++. Entender como e quando us\u00e1-las \u00e9 essencial para aproveitar ao m\u00e1ximo os recursos de seu ambiente de compila\u00e7\u00e3o e execu\u00e7\u00e3o.</p>"},{"location":"teoria/aula01/flags-compilacao/#exemplos-de-compilacao-com-diferentes-flags-de-otimizacao","title":"Exemplos de Compila\u00e7\u00e3o com Diferentes Flags de Otimiza\u00e7\u00e3o","text":"<p>Para demonstrar os efeitos das diferentes flags de otimiza\u00e7\u00e3o (<code>-O1</code>, <code>-O2</code>, <code>-O3</code>, <code>-Ofast</code>) no desempenho de c\u00f3digos C++, vamos utilizar tr\u00eas exemplos representativos de HPC.</p>"},{"location":"teoria/aula01/flags-compilacao/#exemplo-1-multiplicacao-de-matrizes","title":"Exemplo 1: Multiplica\u00e7\u00e3o de Matrizes","text":"<p>A multiplica\u00e7\u00e3o de matrizes \u00e9 uma opera\u00e7\u00e3o computacionalmente intensiva com muitas aplica\u00e7\u00f5es em HPC.</p>"},{"location":"teoria/aula01/flags-compilacao/#codigo-base","title":"C\u00f3digo Base","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nvoid multiplyMatrices(const std::vector&lt;std::vector&lt;double&gt;&gt;&amp; A, const std::vector&lt;std::vector&lt;double&gt;&gt;&amp; B, std::vector&lt;std::vector&lt;double&gt;&gt;&amp; C, int N) {\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            C[i][j] = 0;\n            for (int k = 0; k &lt; N; ++k) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n}\n\nint main() {\n    const int N = 1000;\n    std::vector&lt;std::vector&lt;double&gt;&gt; A(N, std::vector&lt;double&gt;(N, 1.0));\n    std::vector&lt;std::vector&lt;double&gt;&gt; B(N, std::vector&lt;double&gt;(N, 1.0));\n    std::vector&lt;std::vector&lt;double&gt;&gt; C(N, std::vector&lt;double&gt;(N, 0.0));\n\n    auto start = std::chrono::high_resolution_clock::now();\n    multiplyMatrices(A, B, C, N);\n    auto end = std::chrono::high_resolution_clock::now();\n\n    std::chrono::duration&lt;double&gt; duration = end - start;\n    std::cout &lt;&lt; \"Duration: \" &lt;&lt; duration.count() &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#compilacao-e-execucao","title":"Compila\u00e7\u00e3o e Execu\u00e7\u00e3o","text":"<ol> <li>Compila\u00e7\u00e3o com <code>O1</code>:</li> </ol> <pre><code>g++ -O1 -o matrix_multiplication_O1 matrix_multiplication.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O2</code>:</li> </ol> <pre><code>g++ -O2 -o matrix_multiplication_O2 matrix_multiplication.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O3</code>:</li> </ol> <pre><code>g++ -O3 -o matrix_multiplication_O3 matrix_multiplication.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>Ofast</code>:</li> </ol> <pre><code>g++ -Ofast -o matrix_multiplication_Ofast matrix_multiplication.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-de-desempenho","title":"Compara\u00e7\u00e3o de Desempenho","text":"<p>Execute cada vers\u00e3o do programa compilado e compare a dura\u00e7\u00e3o relatada:</p> <pre><code>time ./matrix_multiplication_O1\ntime ./matrix_multiplication_O2\ntime ./matrix_multiplication_O3\ntime ./matrix_multiplication_Ofast\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#explicando-o-output-do-time","title":"Explicando o Output do <code>time</code>","text":"<p>Quando voc\u00ea usa o comando <code>time</code> para medir o tempo de execu\u00e7\u00e3o de um programa, ele fornece tr\u00eas valores principais no output: real, user, e sys. Esses valores representam diferentes aspectos do tempo de execu\u00e7\u00e3o do programa.</p>"},{"location":"teoria/aula01/flags-compilacao/#exemplo-de-output-do-time","title":"Exemplo de Output do <code>time</code>","text":"<pre><code>real    0m10.123s\nuser    0m8.456s\nsys     0m1.234s\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#o-que-cada-valor-representa","title":"O Que Cada Valor Representa","text":""},{"location":"teoria/aula01/flags-compilacao/#1-real","title":"1. real","text":"<ul> <li>Tempo Real: Representa o tempo total que passou desde o in\u00edcio at\u00e9 o fim da execu\u00e7\u00e3o do comando. Esse valor inclui todo o tempo de espera do programa, como I/O (input/output), troca de contexto, e tempo de espera por recursos.</li> </ul> <p>Se voc\u00ea iniciar o programa e cronometra-lo com um cron\u00f4metro, o valor real \u00e9 o que voc\u00ea veria no cron\u00f4metro.</p> <p>Fatores que Afetam:</p> <ul> <li>Tempo gasto aguardando acesso ao disco.</li> <li>Tempo de espera na fila da CPU.</li> <li>Troca de contexto e outros tempos de espera.</li> </ul>"},{"location":"teoria/aula01/flags-compilacao/#2-user","title":"2. user","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>Tempo de Usu\u00e1rio: Representa a quantidade de tempo que a CPU gastou executando o c\u00f3digo do programa em modo usu\u00e1rio. Esse tempo n\u00e3o inclui o tempo gasto em chamadas de sistema (system calls) ou o tempo gasto aguardando opera\u00e7\u00f5es de I/O.</li> </ul> <p>Medida de quanto tempo de CPU foi usado para executar as instru\u00e7\u00f5es do seu programa.</p> <p>Fatores que Afetam:</p> <ul> <li>Processamento computacional pesado.</li> <li>C\u00e1lculos matem\u00e1ticos e loops intensivos.</li> </ul>"},{"location":"teoria/aula01/flags-compilacao/#3-sys","title":"3. sys","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>Tempo de Sistema: Representa a quantidade de tempo que a CPU gastou executando o c\u00f3digo do kernel em nome do seu programa. Isso inclui o tempo gasto em chamadas de sistema, como opera\u00e7\u00f5es de I/O, gerenciamento de mem\u00f3ria, e outras opera\u00e7\u00f5es de kernel.</li> </ul> <p>Tempo de CPU gasto para executar fun\u00e7\u00f5es de sistema solicitadas pelo seu programa.</p> <p>Fatores que Afetam:</p> <ul> <li>Opera\u00e7\u00f5es de leitura/escrita de disco.</li> <li>Opera\u00e7\u00f5es de rede.</li> <li>Aloca\u00e7\u00e3o e gerenciamento de mem\u00f3ria.</li> </ul>"},{"location":"teoria/aula01/flags-compilacao/#interpretacao-do-output","title":"Interpreta\u00e7\u00e3o do Output","text":"<p>Vamos considerar novamente o exemplo de output:</p> <pre><code>real    0m10.123s\nuser    0m8.456s\nsys     0m1.234s\n</code></pre> <p>Interpreta\u00e7\u00e3o:</p> <ul> <li>real (0m10.123s): O programa levou 10.123 segundos para ser executado do in\u00edcio ao fim. Isso inclui todo o tempo de espera.</li> <li>user (0m8.456s): A CPU gastou 8.456 segundos executando o c\u00f3digo do seu programa.</li> <li>sys (0m1.234s): A CPU gastou 1.234 segundos executando fun\u00e7\u00f5es do sistema em nome do seu programa.</li> </ul>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-de-desempenho-com-diferentes-flags-de-compilacao","title":"Compara\u00e7\u00e3o de Desempenho com Diferentes Flags de Compila\u00e7\u00e3o","text":"<p>Ao usar <code>time</code> para comparar programas compilados com diferentes flags de otimiza\u00e7\u00e3o (<code>-O1</code>, <code>-O2</code>, <code>-O3</code>, <code>-Ofast</code>), voc\u00ea deve prestar aten\u00e7\u00e3o principalmente ao valor real para ver o impacto geral no tempo de execu\u00e7\u00e3o. No entanto, os valores user e sys tamb\u00e9m s\u00e3o importantes para entender como as otimiza\u00e7\u00f5es afetam o uso da CPU e o tempo gasto em opera\u00e7\u00f5es do sistema.</p>"},{"location":"teoria/aula01/flags-compilacao/#_1","title":"Flags de compila\u00e7\u00e3o (-O1, -O2, -O3, -Ofast).","text":"<pre><code># Compila\u00e7\u00e3o com -O3\ng++ -O3 -o matrix_multiplication_O3 matrix_multiplication.cpp\n\n# Medi\u00e7\u00e3o de tempo de execu\u00e7\u00e3o\ntime ./matrix_multiplication_O3\n</code></pre> <p>Output esperado:</p> <pre><code>real    0m7.123s\nuser    0m6.789s\nsys     0m0.234s\n</code></pre> <p>Interpreta\u00e7\u00e3o:</p> <ul> <li>real (0m7.123s): O tempo total de execu\u00e7\u00e3o foi de 7.123 segundos.</li> <li>user (0m6.789s): A CPU gastou 6.789 segundos executando o c\u00f3digo do programa.</li> <li>sys (0m0.234s): A CPU gastou 0.234 segundos em chamadas de sistema.</li> </ul> <p>Os valores fornecidos pelo comando <code>time</code> ajudam a entender o comportamento do seu programa e o impacto das otimiza\u00e7\u00f5es no desempenho geral. Analisar esses valores pode revelar gargalos e oportunidades de otimiza\u00e7\u00e3o adicional.</p>"},{"location":"teoria/aula01/flags-compilacao/#exemplo-2-regressao-linear-ia","title":"Exemplo 2: Regress\u00e3o Linear (IA)","text":"<p>A regress\u00e3o linear \u00e9 um algoritmo b\u00e1sico de aprendizado de m\u00e1quina comumente usado em IA.</p>"},{"location":"teoria/aula01/flags-compilacao/#codigo-base_1","title":"C\u00f3digo Base","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\ndouble linearRegression(const std::vector&lt;double&gt;&amp; X, const std::vector&lt;double&gt;&amp; Y) {\n    double sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;\n    int n = X.size();\n    for (int i = 0; i &lt; n; ++i) {\n        sumX += X[i];\n        sumY += Y[i];\n        sumXY += X[i] * Y[i];\n        sumX2 += X[i] * X[i];\n    }\n    return (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);\n}\n\nint main() {\n    const int N = 1000000;\n    std::vector&lt;double&gt; X(N, 1.0);\n    std::vector&lt;double&gt; Y(N, 2.0);\n\n    auto start = std::chrono::high_resolution_clock::now();\n    double slope = linearRegression(X, Y);\n    auto end = std::chrono::high_resolution_clock::now();\n\n    std::chrono::duration&lt;double&gt; duration = end - start;\n    std::cout &lt;&lt; \"Slope: \" &lt;&lt; slope &lt;&lt; \", Duration: \" &lt;&lt; duration.count() &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#compilacao-e-execucao_1","title":"Compila\u00e7\u00e3o e Execu\u00e7\u00e3o","text":"<ol> <li>Compila\u00e7\u00e3o com <code>O1</code>:</li> </ol> <pre><code>g++ -O1 -o linear_regression_O1 linear_regression.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O2</code>:</li> </ol> <pre><code>g++ -O2 -o linear_regression_O2 linear_regression.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O3</code>:</li> </ol> <pre><code>g++ -O3 -o linear_regression_O3 linear_regression.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>Ofast</code>:</li> </ol> <pre><code>g++ -Ofast -o linear_regression_Ofast linear_regression.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-de-desempenho_1","title":"Compara\u00e7\u00e3o de Desempenho","text":"<p>Execute cada vers\u00e3o do programa compilado e compare a dura\u00e7\u00e3o relatada:</p> <pre><code>time ./linear_regression_O1\ntime ./linear_regression_O2\ntime ./linear_regression_O3\ntime ./linear_regression_Ofast\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#exemplo-3-processamento-de-grandes-conjuntos-de-dados-data-science","title":"Exemplo 3: Processamento de Grandes Conjuntos de Dados (Data Science)","text":"<p>Um exemplo comum em Data Science \u00e9 a normaliza\u00e7\u00e3o de um grande conjunto de dados.</p>"},{"location":"teoria/aula01/flags-compilacao/#codigo-base_2","title":"C\u00f3digo Base","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;cmath&gt;\n\nvoid normalize(std::vector&lt;double&gt;&amp; data) {\n    double mean = 0.0;\n    double stddev = 0.0;\n    int n = data.size();\n\n    for (int i = 0; i &lt; n; ++i) {\n        mean += data[i];\n    }\n    mean /= n;\n\n    for (int i = 0; i &lt; n; ++i) {\n        stddev += (data[i] - mean) * (data[i] - mean);\n    }\n    stddev = std::sqrt(stddev / n);\n\n    for (int i = 0; i &lt; n; ++i) {\n        data[i] = (data[i] - mean) / stddev;\n    }\n}\n\nint main() {\n    const int N = 10000000;\n    std::vector&lt;double&gt; data(N, 1.0);\n\n    auto start = std::chrono::high_resolution_clock::now();\n    normalize(data);\n    auto end = std::chrono::high_resolution_clock::now();\n\n    std::chrono::duration&lt;double&gt; duration = end - start;\n    std::cout &lt;&lt; \"Duration: \" &lt;&lt; duration.count() &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#compilacao-e-execucao_2","title":"Compila\u00e7\u00e3o e Execu\u00e7\u00e3o","text":"<ol> <li>Compila\u00e7\u00e3o com <code>O1</code>:</li> </ol> <pre><code>g++ -O1 -o normalize_O1 normalize.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O2</code>:</li> </ol> <pre><code>g++ -O2 -o normalize_O2 normalize.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O3</code>:</li> </ol> <pre><code>g++ -O3 -o normalize_O3 normalize.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>Ofast</code>:</li> </ol> <pre><code>g++ -Ofast -o normalize_Ofast normalize.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-de-desempenho_2","title":"Compara\u00e7\u00e3o de Desempenho","text":"<p>Execute cada vers\u00e3o do programa compilado e compare a dura\u00e7\u00e3o relatada:</p> <pre><code>time ./normalize_O1\ntime ./normalize_O2\ntime ./normalize_O3\ntime ./normalize_Ofast\n</code></pre> <p>Depois de compilar e executar os programas com diferentes flags de otimiza\u00e7\u00e3o, compare os tempos de execu\u00e7\u00e3o relatados por cada um. Isso ajudar\u00e1 a entender como diferentes n\u00edveis de otimiza\u00e7\u00e3o afetam o desempenho de opera\u00e7\u00f5es computacionalmente intensivas.</p>"},{"location":"teoria/aula01/funcoes-inline/","title":"Fun\u00e7\u00f5es Inline","text":"<p>As fun\u00e7\u00f5es inline s\u00e3o usadas para reduzir a sobrecarga das chamadas de fun\u00e7\u00e3o, que pode ser significativa em programas de alto desempenho onde fun\u00e7\u00f5es s\u00e3o chamadas repetidamente. Em vez de realizar uma chamada de fun\u00e7\u00e3o, que envolve empilhar argumentos, saltar para a localiza\u00e7\u00e3o da fun\u00e7\u00e3o, executar a fun\u00e7\u00e3o, e ent\u00e3o retornar, o compilador substitui a chamada da fun\u00e7\u00e3o pelo pr\u00f3prio corpo da fun\u00e7\u00e3o. Isso pode resultar em um c\u00f3digo mais r\u00e1pido e eficiente.</p>"},{"location":"teoria/aula01/funcoes-inline/#vantagens-de-usar-funcoes-inline","title":"Vantagens de Usar Fun\u00e7\u00f5es Inline","text":"<ol> <li>Redu\u00e7\u00e3o da Sobrecarga de Chamada de Fun\u00e7\u00e3o:<ul> <li>As chamadas de fun\u00e7\u00e3o envolvem opera\u00e7\u00f5es adicionais de empilhamento de argumentos e desvio de controle, que podem se tornar um gargalo se as fun\u00e7\u00f5es forem chamadas repetidamente.</li> <li>Fun\u00e7\u00f5es inline eliminam essa sobrecarga, substituindo a chamada pelo pr\u00f3prio c\u00f3digo da fun\u00e7\u00e3o.</li> </ul> </li> <li>Melhoria do Desempenho:<ul> <li>A execu\u00e7\u00e3o de fun\u00e7\u00f5es inline pode ser mais r\u00e1pida, especialmente em loops intensivos onde pequenas fun\u00e7\u00f5es s\u00e3o chamadas repetidamente.</li> <li>Pode resultar em otimiza\u00e7\u00f5es adicionais pelo compilador, como a elimina\u00e7\u00e3o de vari\u00e1veis tempor\u00e1rias e a fus\u00e3o de c\u00f3digo.</li> </ul> </li> <li>Efici\u00eancia do Cache:<ul> <li>Em alguns casos, a inser\u00e7\u00e3o de fun\u00e7\u00f5es inline pode melhorar a localidade de refer\u00eancia e a efici\u00eancia do cache, embora isso dependa da natureza do c\u00f3digo e do hardware.</li> </ul> </li> </ol>"},{"location":"teoria/aula01/funcoes-inline/#contextos-ideais-para-aplicar-funcoes-inline","title":"Contextos Ideais para Aplicar Fun\u00e7\u00f5es Inline","text":"<ol> <li> <p>Fun\u00e7\u00f5es Pequenas e Simples:</p> <ul> <li>Fun\u00e7\u00f5es que s\u00e3o curtas e t\u00eam poucas opera\u00e7\u00f5es s\u00e3o ideais para serem inline. Por exemplo, fun\u00e7\u00f5es matem\u00e1ticas simples como <code>soma</code>, <code>subtrai</code>, <code>multiplica</code> ou <code>divide</code>.</li> </ul> <pre><code>inline int soma(int a, int b) {\n    return a + b;\n}\n</code></pre> </li> <li> <p>Fun\u00e7\u00f5es Chamadas Frequentemente:</p> <ul> <li>Fun\u00e7\u00f5es que s\u00e3o chamadas repetidamente em loops intensivos s\u00e3o boas candidatas para serem inline, pois a elimina\u00e7\u00e3o da sobrecarga da chamada de fun\u00e7\u00e3o pode ter um impacto significativo no desempenho.</li> </ul> <pre><code>inline int quadrado(int x) {\n    return x * x;\n}\n</code></pre> </li> <li> <p>Fun\u00e7\u00f5es que Acessam Membros de Classe:</p> <ul> <li>M\u00e9todos de classe que s\u00e3o simples e frequentemente chamados podem se beneficiar de serem inline. Em C++, m\u00e9todos definidos dentro da declara\u00e7\u00e3o de uma classe s\u00e3o implicitamente inline.</li> </ul> <pre><code>class Ponto {\npublic:\n    inline int getX() const { return x; }\n    inline int getY() const { return y; }\nprivate:\n    int x, y;\n};\n</code></pre> </li> </ol>"},{"location":"teoria/aula01/funcoes-inline/#exemplo","title":"Exemplo","text":"<p>Vamos considerar um exemplo onde uma fun\u00e7\u00e3o inline \u00e9 usada para calcular o quadrado de um n\u00famero em um loop intensivo. Isso \u00e9 comum em opera\u00e7\u00f5es cient\u00edficas e de engenharia, onde c\u00e1lculos matem\u00e1ticos simples s\u00e3o realizados repetidamente.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\nusing namespace std::chrono;\n\n// Fun\u00e7\u00e3o inline para calcular o quadrado de um n\u00famero\ninline int quadrado(int x) {\n    return x * x;\n}\n\nint main() {\n    const int N = 1000000; // N\u00famero de elementos\n    vector&lt;int&gt; dados(N, 2); // Inicializa um vetor com N elementos, todos iguais a 2\n    vector&lt;int&gt; resultados(N);\n\n    auto inicio = high_resolution_clock::now();\n\n    // Loop intensivo que usa a fun\u00e7\u00e3o inline\n    for (int i = 0; i &lt; N; ++i) {\n        resultados[i] = quadrado(dados[i]);\n    }\n\n    auto fim = high_resolution_clock::now();\n    auto duracao = duration_cast&lt;milliseconds&gt;(fim - inicio).count();\n\n    cout &lt;&lt; \"Tempo para calcular quadrados: \" &lt;&lt; duracao &lt;&lt; \"ms\" &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes-inline/#consideracoes-ao-usar-funcoes-inline","title":"Considera\u00e7\u00f5es ao Usar Fun\u00e7\u00f5es Inline","text":"<ol> <li>Tamanho da Fun\u00e7\u00e3o:<ul> <li>Fun\u00e7\u00f5es inline devem ser pequenas e simples. Fun\u00e7\u00f5es grandes inline podem aumentar significativamente o tamanho do c\u00f3digo bin\u00e1rio, o que pode ter um efeito negativo na efici\u00eancia do cache.</li> </ul> </li> <li>Otimiza\u00e7\u00f5es do Compilador:<ul> <li>O compilador pode ignorar a sugest\u00e3o de inline se achar que n\u00e3o ser\u00e1 ben\u00e9fico. Isso \u00e9 apenas uma sugest\u00e3o ao compilador.</li> </ul> </li> <li>Manutenibilidade:<ul> <li>Excesso de fun\u00e7\u00f5es inline pode tornar o c\u00f3digo mais dif\u00edcil de ler e manter. Use inline judiciosamente, apenas onde os benef\u00edcios de desempenho s\u00e3o claros.</li> </ul> </li> </ol> <p>As fun\u00e7\u00f5es inline s\u00e3o uma ferramenta valiosa em High-Performance Computing para reduzir a sobrecarga de chamadas de fun\u00e7\u00e3o e melhorar o desempenho em loops intensivos e c\u00e1lculos repetitivos. Elas devem ser usadas em fun\u00e7\u00f5es pequenas e frequentemente chamadas para obter os maiores benef\u00edcios. Ao combinar fun\u00e7\u00f5es inline com a sobrecarga de fun\u00e7\u00f5es, podemos otimizar ainda mais o c\u00f3digo para diferentes tipos de dados, mantendo a legibilidade e a organiza\u00e7\u00e3o.</p>"},{"location":"teoria/aula01/funcoes/","title":"Passagem de Par\u00e2metros","text":"<p>Par\u00e2metros podem ser passados por valor, por refer\u00eancia ou por ponteiro. No contexto de HPC, passar par\u00e2metros por refer\u00eancia ou ponteiro \u00e9 geralmente prefer\u00edvel para evitar c\u00f3pias desnecess\u00e1rias de dados, que podem ser custosas em termos de tempo e mem\u00f3ria.</p>"},{"location":"teoria/aula01/funcoes/#passagem-de-parametros-por-valor","title":"Passagem de Par\u00e2metros por Valor","text":"<p>Passar por valor significa que uma c\u00f3pia do argumento \u00e9 passada para a fun\u00e7\u00e3o. Qualquer modifica\u00e7\u00e3o feita ao par\u00e2metro dentro da fun\u00e7\u00e3o n\u00e3o afeta o argumento original.</p> <pre><code>// Fun\u00e7\u00e3o que recebe um par\u00e2metro por valor\nvoid exemploValor(int x) {\n    x = 10; // Modifica\u00e7\u00e3o local, n\u00e3o afeta o argumento original\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes/#passagem-por-referencia-e-passagem-por-ponteiro","title":"Passagem por Refer\u00eancia e Passagem por Ponteiro","text":"<p>Passagem por refer\u00eancia e passagem por ponteiro s\u00e3o duas formas de passar argumentos para fun\u00e7\u00f5es em C++, permitindo que a fun\u00e7\u00e3o modifique o argumento original. Apesar de terem prop\u00f3sitos similares, elas diferem em sintaxe e uso. Vamos explorar essas diferen\u00e7as detalhadamente.</p>"},{"location":"teoria/aula01/funcoes/#passagem-por-referencia","title":"Passagem por Refer\u00eancia","text":"<p>Passar um argumento por refer\u00eancia significa que a fun\u00e7\u00e3o recebe uma refer\u00eancia ao argumento original, permitindo modificar diretamente o valor do argumento. A sintaxe usa o operador <code>&amp;</code> no par\u00e2metro da fun\u00e7\u00e3o.</p>"},{"location":"teoria/aula01/funcoes/#sintaxe-e-exemplo","title":"Sintaxe e Exemplo","text":"<pre><code>#include &lt;iostream&gt;\n\n// Fun\u00e7\u00e3o que recebe um par\u00e2metro por refer\u00eancia\nvoid alteraPorReferencia(int&amp; x) {\n    x = 10; // Modifica\u00e7\u00e3o afeta o argumento original\n}\n\nint main() {\n    int valor = 5;\n    std::cout &lt;&lt; \"Antes da fun\u00e7\u00e3o: \" &lt;&lt; valor &lt;&lt; std::endl;\n    alteraPorReferencia(valor);\n    std::cout &lt;&lt; \"Depois da fun\u00e7\u00e3o: \" &lt;&lt; valor &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Sintaxe Limpa: A sintaxe \u00e9 mais clara e f\u00e1cil de ler, pois n\u00e3o envolve o uso expl\u00edcito de ponteiros.</li> <li>Seguran\u00e7a: Reduz o risco de manipula\u00e7\u00e3o incorreta de ponteiros (como desreferenciamento de ponteiros nulos).</li> <li>N\u00e3o Nulo: Refer\u00eancias devem ser inicializadas e n\u00e3o podem ser nulas.</li> </ul>"},{"location":"teoria/aula01/funcoes/#passagem-por-ponteiro","title":"Passagem por Ponteiro","text":"<p>Passar um argumento por ponteiro significa que a fun\u00e7\u00e3o recebe o endere\u00e7o do argumento original. A sintaxe usa o operador <code>*</code> no par\u00e2metro da fun\u00e7\u00e3o e o operador <code>&amp;</code> ao passar o argumento.</p>"},{"location":"teoria/aula01/funcoes/#sintaxe-e-exemplo_1","title":"Sintaxe e Exemplo","text":"<pre><code>#include &lt;iostream&gt;\n\n// Fun\u00e7\u00e3o que recebe um par\u00e2metro por ponteiro\nvoid alteraPorPonteiro(int* x) {\n    *x = 10; // Modifica\u00e7\u00e3o afeta o argumento original\n}\n\nint main() {\n    int valor = 5;\n    std::cout &lt;&lt; \"Antes da fun\u00e7\u00e3o: \" &lt;&lt; valor &lt;&lt; std::endl;\n    alteraPorPonteiro(&amp;valor);\n    std::cout &lt;&lt; \"Depois da fun\u00e7\u00e3o: \" &lt;&lt; valor &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes/#caracteristicas_1","title":"Caracter\u00edsticas","text":"<ul> <li>Flexibilidade: Permite a passagem de valores nulos (ponteiros nulos).</li> <li>Controle Expl\u00edcito: Fornece controle expl\u00edcito sobre a mem\u00f3ria, podendo ser \u00fatil em contextos onde manipula\u00e7\u00e3o direta de endere\u00e7os \u00e9 necess\u00e1ria.</li> <li>Complexidade: A sintaxe pode ser mais complexa e propensa a erros, como desreferenciamento de ponteiros nulos ou incorretos.</li> </ul>"},{"location":"teoria/aula01/funcoes/#quando-usar-cada-um","title":"Quando Usar Cada Um","text":"<ul> <li>Passagem por Refer\u00eancia: Use quando voc\u00ea precisa modificar o argumento original e quer uma sintaxe mais limpa e segura. Ideal para a maioria dos casos onde a refer\u00eancia n\u00e3o precisa ser nula.</li> <li>Passagem por Ponteiro: Use quando h\u00e1 a necessidade de manipular diretamente endere\u00e7os de mem\u00f3ria ou quando o valor passado pode ser opcional (nulo).</li> </ul>"},{"location":"teoria/aula01/funcoes/#exemplo-comparativo","title":"Exemplo Comparativo","text":"<p>Vamos comparar um exemplo onde modificamos um valor usando ambas as abordagens.</p>"},{"location":"teoria/aula01/funcoes/#passagem-por-referencia_1","title":"Passagem por Refer\u00eancia","text":"<pre><code>#include &lt;iostream&gt;\n\nvoid incrementaReferencia(int&amp; x) {\n    x++; // Incrementa o valor\n}\n\nint main() {\n    int valor = 5;\n    std::cout &lt;&lt; \"Antes: \" &lt;&lt; valor &lt;&lt; std::endl;\n    incrementaReferencia(valor);\n    std::cout &lt;&lt; \"Depois: \" &lt;&lt; valor &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes/#passagem-por-ponteiro_1","title":"Passagem por Ponteiro","text":"<pre><code>#include &lt;iostream&gt;\n\nvoid incrementaPonteiro(int* x) {\n    if (x) { // Verifica se o ponteiro n\u00e3o \u00e9 nulo\n        (*x)++; // Incrementa o valor\n    }\n}\n\nint main() {\n    int valor = 5;\n    std::cout &lt;&lt; \"Antes: \" &lt;&lt; valor &lt;&lt; std::endl;\n    incrementaPonteiro(&amp;valor);\n    std::cout &lt;&lt; \"Depois: \" &lt;&lt; valor &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <p>Ambos os exemplos acima modificam o valor original de <code>valor</code>, mas a abordagem de refer\u00eancia \u00e9 mais limpa, enquanto a abordagem de ponteiro oferece maior flexibilidade em termos de manipula\u00e7\u00e3o de endere\u00e7os e valores nulos.</p>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/","title":"Loops  e La\u00e7os","text":"<p>No contexto de HPC, onde a efici\u00eancia e a performance s\u00e3o cruciais, as estruturas de controle (loops e la\u00e7os) desempenham pap\u00e9is vitais:</p> <ol> <li>Otimiza\u00e7\u00e3o de Algoritmos<ul> <li>As estruturas de controle permitem que algoritmos sejam implementados de forma eficiente. Condicionais e loops bem utilizados podem reduzir o n\u00famero de opera\u00e7\u00f5es e evitar c\u00e1lculos desnecess\u00e1rios, otimizando o tempo de execu\u00e7\u00e3o.</li> </ul> </li> <li>Paralelismo<ul> <li>Em HPC, o paralelismo \u00e9 frequentemente utilizado para acelerar a execu\u00e7\u00e3o dos programas. Estruturas de controle s\u00e3o essenciais para dividir tarefas entre diferentes threads ou processos.</li> <li>O uso adequado de condicionais pode garantir que as tarefas sejam distribu\u00eddas eficientemente entre os recursos computacionais, evitando sobrecarga em um \u00fanico n\u00f3 de processamento.</li> </ul> </li> <li>Balanceamento de Carga<ul> <li>Estruturas de controle podem ajudar no balanceamento de carga, distribuindo o trabalho de maneira uniforme entre os processadores. Por exemplo, condicionais podem ser usados para verificar a carga de trabalho em diferentes n\u00f3s e ajustar dinamicamente a distribui\u00e7\u00e3o das tarefas.</li> <li>Isso \u00e9 crucial para evitar situa\u00e7\u00f5es onde alguns processadores ficam ociosos enquanto outros est\u00e3o sobrecarregados, maximizando a utiliza\u00e7\u00e3o de recursos e melhorando a performance geral.</li> </ul> </li> <li>Gerenciamento de Recursos<ul> <li>Condicionais e loops podem ser usados para gerenciar recursos, como aloca\u00e7\u00e3o de mem\u00f3ria e acesso a dispositivos de I/O. Em ambientes HPC, onde grandes volumes de dados s\u00e3o manipulados, o gerenciamento eficiente de mem\u00f3ria \u00e9 fundamental. Estruturas de controle podem ajudar a evitar desperd\u00edcio de mem\u00f3ria e garantir que os recursos sejam utilizados de maneira eficiente.</li> </ul> </li> </ol>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estruturas-de-controle-condicionais-if-else-if-else","title":"Estruturas de controle condicionais (<code>if</code>, <code>else if</code>, <code>else</code> ):","text":"<p>Exemplo: Encontrar o valor m\u00e1ximo em uma matriz</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    // Define a vari\u00e1vel max_value com o primeiro valor da matriz\n    int max_value = matrix[0][0];\n\n    // Percorre cada linha da matriz\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Percorre cada coluna da matriz\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Se o valor atual da matriz for maior que max_value, atualiza max_value\n            if (matrix[i][j] &gt; max_value) {\n                max_value = matrix[i][j];\n            }\n        }\n    }\n\n    // Imprime o valor m\u00e1ximo encontrado na matriz\n    std::cout &lt;&lt; \"O valor m\u00e1ximo na matriz \u00e9: \" &lt;&lt; max_value &lt;&lt; std::endl;\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estrutura-de-controle-condicional-switch","title":"Estrutura de controle condicional <code>switch</code> :","text":"<p>Exemplo: Imprimir a posi\u00e7\u00e3o de um n\u00famero espec\u00edfico na matriz</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    // Define o valor alvo a ser encontrado\n    int target = 5;\n\n    // Percorre cada linha da matriz\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Percorre cada coluna da matriz\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Verifica o valor atual da matriz usando switch\n            switch(matrix[i][j]) {\n                case 5:\n                    // Se o valor for 5, imprime a posi\u00e7\u00e3o e sai do switch\n                    std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" encontrado em: (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j &lt;&lt; \")\" &lt;&lt; std::endl;\n                    break;\n                default:\n                    // Caso padr\u00e3o do switch, n\u00e3o faz nada\n                    break;\n            }\n        }\n    }\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estrutura-de-controle-loop-for","title":"Estrutura de controle loop <code>for</code> :","text":"<p>Exemplo Somar todos os elementos de uma matriz :</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    // Inicializa a vari\u00e1vel sum com 0\n    int sum = 0;\n\n    // Percorre cada linha da matriz\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Percorre cada coluna da matriz\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Adiciona o valor atual da matriz \u00e0 sum\n            sum += matrix[i][j];\n        }\n    }\n\n    // Imprime a soma de todos os elementos na matriz\n    std::cout &lt;&lt; \"A soma de todos os elementos na matriz \u00e9: \" &lt;&lt; sum &lt;&lt; std::endl;\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estrutura-de-controle-loop-while","title":"Estrutura de controle loop <code>while</code> :","text":"<p>Encontrar um n\u00famero espec\u00edfico na matriz </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    // Define o valor alvo a ser encontrado\n    int target = 5;\n    bool found = false; // Flag para indicar se o valor foi encontrado\n    size_t i = 0; // \u00cdndice para as linhas\n\n    // Loop externo para percorrer as linhas\n    while (i &lt; matrix.size() &amp;&amp; !found) {\n        size_t j = 0; // \u00cdndice para as colunas\n        // Loop interno para percorrer as colunas\n        while (j &lt; matrix[i].size() &amp;&amp; !found) {\n            // Se o valor atual da matriz for igual ao alvo, imprime a posi\u00e7\u00e3o\n            if (matrix[i][j] == target) {\n                std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" encontrado em: (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j &lt;&lt; \")\" &lt;&lt; std::endl;\n                found = true; // Atualiza a flag\n            }\n            ++j; // Incrementa o \u00edndice das colunas\n        }\n        ++i; // Incrementa o \u00edndice das linhas\n    }\n\n    // Se o valor n\u00e3o foi encontrado, imprime uma mensagem\n    if (!found) {\n        std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" n\u00e3o encontrado na matriz.\" &lt;&lt; std::endl;\n    }\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estrutura-de-controle-loop-do-while","title":"Estrutura de controle loop <code>do-while</code> :","text":"<p>Verificar se todos os elementos da matriz s\u00e3o positivos </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    bool all_positive = true; // Flag para indicar se todos os elementos s\u00e3o positivos\n    size_t i = 0; // \u00cdndice para as linhas\n\n    // Loop externo do-while para percorrer as linhas\n    do {\n        size_t j = 0; // \u00cdndice para as colunas\n        // Loop interno do-while para percorrer as colunas\n        do {\n            // Se o valor atual da matriz for menor ou igual a 0, atualiza a flag e sai do loop\n            if (matrix[i][j] &lt;= 0) {\n                all_positive = false;\n                break;\n            }\n            ++j; // Incrementa o \u00edndice das colunas\n        } while (j &lt; matrix[i].size());\n        ++i; // Incrementa o \u00edndice das linhas\n    } while (i &lt; matrix.size() &amp;&amp; all_positive);\n\n    // Imprime o resultado da verifica\u00e7\u00e3o\n    if (all_positive) {\n        std::cout &lt;&lt; \"Todos os elementos da matriz s\u00e3o positivos.\" &lt;&lt; std::endl;\n    } else {\n        std::cout &lt;&lt; \"Nem todos os elementos da matriz s\u00e3o positivos.\" &lt;&lt; std::endl;\n    }\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#controladores-de-loop-break","title":"Controladores de loop <code>break</code> :","text":"<p>Interromper a busca ao encontrar um n\u00famero espec\u00edfico (<code>break</code>)</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    int target = 5; // Define o valor alvo a ser encontrado\n    bool found = false; // Flag para indicar se o valor foi encontrado\n\n    // Loop externo para percorrer as linhas\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Loop interno para percorrer as colunas\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Se o valor atual da matriz for igual ao alvo, imprime a posi\u00e7\u00e3o\n            if (matrix[i][j] == target) {\n                std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" encontrado em: (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j &lt;&lt; \")\" &lt;&lt; std::endl;\n                found = true; // Atualiza a flag\n                break; // Interrompe o loop interno\n            }\n        }\n        if (found) {\n            break; // Interrompe o loop externo\n        }\n    }\n\n    // Se o valor n\u00e3o foi encontrado, imprime uma mensagem\n    if (!found) {\n        std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" n\u00e3o encontrado na matriz.\" &lt;&lt; std::endl;\n    }\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#controladores-de-loop-continue","title":"Controladores de loop continue :","text":"<p>Ignorar n\u00fameros negativos ao somar elementos de uma matriz (<code>continue</code>)</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros, incluindo n\u00fameros negativos\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, -2, 3},\n        {-4, 5, -6},\n        {7, -8, 9}\n    };\n\n    int sum = 0; // Inicializa a vari\u00e1vel sum com 0\n\n    // Loop externo para percorrer as linhas\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Loop interno para percorrer as colunas\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Se o valor atual da matriz for negativo, ignora-o e continua para a pr\u00f3xima itera\u00e7\u00e3o\n            if (matrix[i][j] &lt; 0) {\n                continue; // Ignora n\u00fameros negativos\n            }\n            // Adiciona o valor atual da matriz \u00e0 soma\n            sum += matrix[i][j];\n        }\n    }\n\n    // Imprime a soma de todos os elementos positivos na matriz\n    std::cout &lt;&lt; \"A soma de todos os elementos positivos na matriz \u00e9: \" &lt;&lt; sum &lt;&lt; std::endl;\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/","title":"Manipula\u00e7\u00e3o de Vetores","text":"<p>Manipula\u00e7\u00e3o b\u00e1sica de vetores em C++ envolve opera\u00e7\u00f5es comuns como inicializa\u00e7\u00e3o, acesso a elementos, modifica\u00e7\u00e3o, itera\u00e7\u00e3o, inser\u00e7\u00e3o, remo\u00e7\u00e3o, e c\u00f3pia de vetores. Esses conceitos s\u00e3o fundamentais, pois constituem a base para a manipula\u00e7\u00e3o de dados em grande escala.</p>"},{"location":"teoria/aula01/manipulacao-vetores/#inicializacao-de-vetores-declaracao-e-inicializacao","title":"Inicializa\u00e7\u00e3o de Vetores \u2192 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec1;                // Declara um vetor vazio de inteiros\n    std::vector&lt;int&gt; vec2(10);            // Declara um vetor de 10 inteiros inicializados com zero\n    std::vector&lt;int&gt; vec3(10, 5);         // Declara um vetor de 10 inteiros, todos inicializados com 5\n\n    // Exemplo de inicializa\u00e7\u00e3o de vetor com valores espec\u00edficos\n    std::vector&lt;int&gt; vec4 = {1, 2, 3, 4, 5};\n\n    // Imprime os elementos do vetor vec4\n    for (int val : vec4) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#acesso-e-modificacao-de-elementos","title":"Acesso e Modifica\u00e7\u00e3o de Elementos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Acessa elementos usando o operador []\n    std::cout &lt;&lt; \"Primeiro elemento: \" &lt;&lt; vec[0] &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Terceiro elemento: \" &lt;&lt; vec[2] &lt;&lt; std::endl;\n\n    // Acessa elementos usando o m\u00e9todo at()\n    std::cout &lt;&lt; \"Segundo elemento: \" &lt;&lt; vec.at(1) &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#modificacao-de-elementos","title":"Modifica\u00e7\u00e3o de Elementos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Modifica elementos usando o operador []\n    vec[0] = 10;\n    vec[2] = 30;\n\n    // Modifica elementos usando o m\u00e9todo at()\n    vec.at(1) = 20;\n\n    // Imprime os elementos modificados\n    for (int val : vec) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#iteracao-usando-loop","title":"Itera\u00e7\u00e3o Usando Loop","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Itera sobre os elementos usando um loop tradicional\n    for (size_t i = 0; i &lt; vec.size(); ++i) {\n        std::cout &lt;&lt; vec[i] &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#insercao-de-elementos","title":"Inser\u00e7\u00e3o de Elementos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Insere elementos no final do vetor\n    vec.push_back(6);\n    vec.push_back(7);\n\n    // Insere um elemento na posi\u00e7\u00e3o espec\u00edfica\n    vec.insert(vec.begin() + 2, 10); // Insere o valor 10 na terceira posi\u00e7\u00e3o\n\n    // Imprime os elementos ap\u00f3s a inser\u00e7\u00e3o\n    for (int val : vec) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#remocao-de-elementos","title":"Remo\u00e7\u00e3o de Elementos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Remove o \u00faltimo elemento\n    vec.pop_back();\n\n    // Remove um elemento na posi\u00e7\u00e3o espec\u00edfica\n    vec.erase(vec.begin() + 1); // Remove o segundo elemento\n\n    // Imprime os elementos ap\u00f3s a remo\u00e7\u00e3o\n    for (int val : vec) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#copiando-vetores","title":"Copiando Vetores","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec1 = {1, 2, 3, 4, 5};\n\n    // Cria uma c\u00f3pia de vec1\n    std::vector&lt;int&gt; vec2 = vec1;\n\n    // Modifica a c\u00f3pia\n    vec2[0] = 10;\n\n    // Imprime os elementos dos dois vetores\n    std::cout &lt;&lt; \"vec1: \";\n    for (int val : vec1) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    std::cout &lt;&lt; \"vec2: \";\n    for (int val : vec2) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#contextos-uteis-para-hpc","title":"Contextos \u00dateis para HPC","text":"<p>Manipula\u00e7\u00f5es b\u00e1sicas de vetores s\u00e3o frequentemente utilizadas em HPC para inicializar e processar grandes conjuntos de dados. Aqui est\u00e3o alguns contextos \u00fateis:</p> <ol> <li>Inicializa\u00e7\u00e3o de Dados:<ul> <li>Vetores podem ser usados para armazenar dados de entrada para simula\u00e7\u00f5es ou c\u00e1lculos.</li> </ul> </li> <li>Opera\u00e7\u00f5es em S\u00e9rie:<ul> <li>Aplicar opera\u00e7\u00f5es matem\u00e1ticas b\u00e1sicas em todos os elementos de um vetor \u00e9 uma tarefa comum em HPC.</li> </ul> </li> <li>Armazenamento de Resultados Intermedi\u00e1rios:<ul> <li>Vetores s\u00e3o \u00fateis para armazenar resultados intermedi\u00e1rios em algoritmos iterativos.</li> </ul> </li> </ol>"},{"location":"teoria/aula01/manipulacao-vetores/#exemplo-uso-de-vector-com-classe-e-inline","title":"Exemplo: Uso de <code>Vector</code> com Classe e Inline","text":"<p>A utiliza\u00e7\u00e3o de classes para encapsular a l\u00f3gica de manipula\u00e7\u00e3o de vetores, junto com o uso de aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria e fun\u00e7\u00f5es <code>inline</code>, permite a cria\u00e7\u00e3o de estruturas de dados flex\u00edveis e de alto desempenho. Neste exemplo, implementaremos uma classe <code>Vector</code> que demonstrar\u00e1 esses conceitos.</p>"},{"location":"teoria/aula01/manipulacao-vetores/#conceitos-fundamentais","title":"Conceitos Fundamentais","text":"<p>Aloca\u00e7\u00e3o Din\u00e2mica de Mem\u00f3ria: A aloca\u00e7\u00e3o din\u00e2mica permite que a mem\u00f3ria para o vetor seja alocada em tempo de execu\u00e7\u00e3o, proporcionando flexibilidade na gest\u00e3o do tamanho do vetor. Utilizamos <code>new</code> para alocar mem\u00f3ria e <code>delete[]</code> para liber\u00e1-la, garantindo que o uso de mem\u00f3ria seja eficiente e controlado.</p> <p>Ponteiros: Os ponteiros s\u00e3o utilizados para manipular diretamente a mem\u00f3ria alocada dinamicamente. No nosso exemplo, <code>int* dados</code> \u00e9 um ponteiro para o array que armazenar\u00e1 os elementos do vetor.</p> <p>Fun\u00e7\u00f5es Inline: Fun\u00e7\u00f5es <code>inline</code> s\u00e3o usadas para otimizar o desempenho, especialmente em m\u00e9todos curtos e frequentemente chamados. A declara\u00e7\u00e3o <code>inline</code> sugere ao compilador que expanda o c\u00f3digo da fun\u00e7\u00e3o no local da chamada, reduzindo a sobrecarga de chamadas de fun\u00e7\u00e3o.</p> <p>Redimensionamento Din\u00e2mico: Redimensionar dinamicamente o vetor permite que ele cres\u00e7a conforme necess\u00e1rio. Implementamos um m\u00e9todo que duplica a capacidade do vetor quando necess\u00e1rio, copiando os dados existentes para um novo espa\u00e7o de mem\u00f3ria alocado.</p>"},{"location":"teoria/aula01/manipulacao-vetores/#implementacao-da-classe-vector","title":"Implementa\u00e7\u00e3o da Classe <code>Vector</code>","text":"<p>A seguir, apresentamos a implementa\u00e7\u00e3o detalhada da classe <code>Vector</code>, que inclui m\u00e9todos para inicializa\u00e7\u00e3o, acesso, modifica\u00e7\u00e3o, inser\u00e7\u00e3o e remo\u00e7\u00e3o de elementos, al\u00e9m de um m\u00e9todo para redimensionamento din\u00e2mico.</p> <pre><code>#include &lt;iostream&gt;\n\nclass Vector {\npublic:\n    Vector(int tamanho);                  // Construtor que inicializa o vetor\n    ~Vector();                            // Destrutor que libera a mem\u00f3ria alocada\n    void inicializa(int valor);           // M\u00e9todo para inicializar o vetor\n    inline int get(int index) const;      // M\u00e9todo inline para acessar um elemento\n    inline void set(int index, int valor); // M\u00e9todo inline para modificar um elemento\n    void inserir(int index, int valor);   // M\u00e9todo para inserir um elemento\n    void remover(int index);              // M\u00e9todo para remover um elemento\n    void imprime() const;                 // M\u00e9todo para imprimir o vetor\n    inline int tamanho() const;           // M\u00e9todo inline para obter o tamanho do vetor\n\nprivate:\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#definicao-da-classe-vector","title":"Defini\u00e7\u00e3o da Classe <code>Vector</code>","text":"<p>Vamos adicionar fun\u00e7\u00f5es inline e algumas otimiza\u00e7\u00f5es para melhorar o desempenho onde for poss\u00edvel.</p> <ol> <li>Atributos:<ul> <li><code>int* dados</code>: Ponteiro para o array din\u00e2mico que armazena os elementos do vetor.</li> <li><code>int tam</code>: Tamanho atual do vetor.</li> <li><code>int capacidade</code>: Capacidade m\u00e1xima do vetor antes de precisar redimensionar.</li> </ul> </li> </ol> <pre><code>#include &lt;iostream&gt;\n\nclass Vector {\npublic:\n    Vector(int tamanho);                  // Construtor que inicializa o vetor\n    ~Vector();                            // Destrutor que libera a mem\u00f3ria alocada\n    void inicializa(int valor);           // M\u00e9todo para inicializar o vetor\n    inline int get(int index) const;      // M\u00e9todo inline para acessar um elemento\n    inline void set(int index, int valor); // M\u00e9todo inline para modificar um elemento\n    void inserir(int index, int valor);   // M\u00e9todo para inserir um elemento\n    void remover(int index);              // M\u00e9todo para remover um elemento\n    void imprime() const;                 // M\u00e9todo para imprimir o vetor\n    inline int tamanho() const;           // M\u00e9todo inline para obter o tamanho do vetor\n\nprivate:\n    int* dados;                           // Ponteiro para os dados do vetor\n    int tam;                              // Tamanho atual do vetor\n    int capacidade;                       // Capacidade m\u00e1xima do vetor\n    void redimensiona(int novaCapacidade); // M\u00e9todo para redimensionar o vetor\n};\n</code></pre> <ol> <li> <p>Construtor e Destrutor:</p> <ul> <li> <p><code>Vector(int tamanho)</code>: Inicializa o vetor com o tamanho especificado e aloca mem\u00f3ria dinamicamente.</p> <pre><code>Vector::Vector(int tamanho)\n    : tam(tamanho), capacidade(tamanho), dados(new int[tamanho]) {}\n</code></pre> </li> <li> <p><code>~Vector()</code>: Libera a mem\u00f3ria alocada para evitar vazamentos de mem\u00f3ria.</p> <pre><code>Vector::~Vector() {\n    delete[] dados; // Libera a mem\u00f3ria alocada\n}\n</code></pre> </li> </ul> </li> <li> <p>M\u00e9todos B\u00e1sicos:</p> <ul> <li> <p><code>inicializa(int valor)</code>: Inicializa todos os elementos do vetor com o valor especificado.</p> <pre><code>void Vector::inicializa(int valor) {\n    for (int i = 0; i &lt; tam; ++i) {\n        dados[i] = valor; // Inicializa cada elemento do vetor com o valor especificado\n    }\n}\n</code></pre> </li> <li> <p><code>get(int index) const</code>: M\u00e9todo inline para acessar um elemento na posi\u00e7\u00e3o especificada.</p> <pre><code>inline int Vector::get(int index) const {\n    if (index &gt;= 0 &amp;&amp; index &lt; tam) {\n        return dados[index]; // Retorna o elemento na posi\u00e7\u00e3o especificada\n    } else {\n        std::cerr &lt;&lt; \"\u00cdndice fora do intervalo!\" &lt;&lt; std::endl;\n        return -1; // Valor de erro\n    }\n}\n</code></pre> </li> <li> <p><code>set(int index, int valor)</code>: M\u00e9todo inline para modificar um elemento na posi\u00e7\u00e3o especificada.</p> <pre><code>inline void Vector::set(int index, int valor) {\n    if (index &gt;= 0 &amp;&amp; index &lt; tam) {\n        dados[index] = valor; // Modifica o elemento na posi\u00e7\u00e3o especificada\n    } else {\n        std::cerr &lt;&lt; \"\u00cdndice fora do intervalo!\" &lt;&lt; std::endl;\n    }\n}\n</code></pre> </li> <li> <p><code>inserir(int index, int valor)</code>: Insere um elemento na posi\u00e7\u00e3o especificada.</p> <pre><code>void Vector::inserir(int index, int valor) {\n    if (index &gt;= 0 &amp;&amp; index &lt;= tam) {\n        if (tam &gt;= capacidade) {\n            redimensiona(2 * capacidade); // Redimensiona o vetor se necess\u00e1rio\n        }\n        for (int i = tam; i &gt; index; --i) {\n            dados[i] = dados[i - 1]; // Move os elementos para a direita\n        }\n        dados[index] = valor; // Insere o novo elemento\n        tam++; // Incrementa o tamanho do vetor\n    } else {\n        std::cerr &lt;&lt; \"\u00cdndice fora do intervalo!\" &lt;&lt; std::endl;\n    }\n}\n</code></pre> </li> </ul> </li> <li> <p><code>remover(int index)</code>: Remove um elemento na posi\u00e7\u00e3o especificada.</p> <pre><code>void Vector::remover(int index) {\n    if (index &gt;= 0 &amp;&amp; index &lt; tam) {\n        for (int i = index; i &lt; tam - 1; ++i) {\n            dados[i] = dados[i + 1]; // Move os elementos para a esquerda\n        }\n        tam--; // Decrementa o tamanho do vetor\n    } else {\n        std::cerr &lt;&lt; \"\u00cdndice fora do intervalo!\" &lt;&lt; std::endl;\n    }\n}\n</code></pre> </li> <li> <p><code>imprime() const</code>: Imprime todos os elementos do vetor.</p> <pre><code>void Vector::imprime() const {\n    for (int i = 0; i &lt; tam; ++i) {\n        std::cout &lt;&lt; dados[i] &lt;&lt; \" \"; // Imprime cada elemento do vetor\n    }\n    std::cout &lt;&lt; std::endl;\n}\n</code></pre> </li> <li> <p><code>tamanho() const</code>: M\u00e9todo inline para obter o tamanho atual do vetor.</p> <pre><code>inline int Vector::tamanho() const {\n    return tam; // Retorna o tamanho atual do vetor\n}\n</code></pre> </li> <li> <p><code>redimensiona(int novaCapacidade)</code>: Redimensiona o vetor para a nova capacidade especificada, alocando nova mem\u00f3ria e copiando os dados existentes.</p> <pre><code>void Vector::redimensiona(int novaCapacidade) {\n    int* novoDados = new int[novaCapacidade]; // Aloca nova mem\u00f3ria\n    for (int i = 0; i &lt; tam; ++i) {\n        novoDados[i] = dados[i]; // Copia os dados antigos\n    }\n    delete[] dados; // Libera a mem\u00f3ria antiga\n    dados = novoDados; // Atualiza o ponteiro para os novos dados\n    capacidade = novaCapacidade; // Atualiza a capacidade do vetor\n}\n</code></pre> </li> </ol>"},{"location":"teoria/aula01/manipulacao-vetores/#uso-da-classe-vector","title":"Uso da Classe <code>Vector</code>","text":"<ol> <li> <p>Inicializa\u00e7\u00e3o e Impress\u00e3o:</p> <ul> <li>Criamos um vetor de tamanho 5 e inicializamos todos os elementos com 0.</li> <li> <p>Imprimimos o vetor inicializado.</p> <pre><code>int main() {\n    Vector vec(5); // Cria um vetor de tamanho 5\n    vec.inicializa(0); // Inicializa todos os elementos com 0\n\n    std::cout &lt;&lt; \"Vetor inicializado: \";\n    vec.imprime(); // Imprime o vetor inicializado\n</code></pre> </li> </ul> </li> <li> <p>Modifica\u00e7\u00e3o:</p> <ul> <li> <p>Modificamos o terceiro elemento para 10 e imprimimos o vetor.</p> <pre><code>    vec.set(2, 10); // Modifica o terceiro elemento para 10\n    std::cout &lt;&lt; \"Ap\u00f3s modificar o terceiro elemento para 10: \";\n    vec.imprime(); // Imprime o vetor ap\u00f3s a modifica\u00e7\u00e3o\n</code></pre> </li> </ul> </li> <li> <p>Inser\u00e7\u00e3o:</p> <ul> <li> <p>Inserimos o valor 20 na terceira posi\u00e7\u00e3o e imprimimos o vetor.</p> <pre><code>    vec.inserir(2, 20); // Insere o valor 20 na terceira posi\u00e7\u00e3o\n    std::cout &lt;&lt; \"Ap\u00f3s inserir 20 na terceira posi\u00e7\u00e3o: \";\n    vec.imprime(); // Imprime o vetor ap\u00f3s a inser\u00e7\u00e3o\n</code></pre> </li> </ul> </li> <li> <p>Remo\u00e7\u00e3o:</p> <ul> <li> <p>Removemos o segundo elemento e imprimimos o vetor.</p> <pre><code>    vec.remover(1); // Remove o segundo elemento\n    std::cout &lt;&lt; \"Ap\u00f3s remover o segundo elemento: \";\n    vec.imprime(); // Imprime o vetor ap\u00f3s a remo\u00e7\u00e3o\n</code></pre> </li> </ul> </li> <li> <p>Tamanho:</p> <ul> <li> <p>Imprimimos o tamanho atual do vetor.</p> <pre><code>    std::cout &lt;&lt; \"Tamanho do vetor: \" &lt;&lt; vec.tamanho() &lt;&lt; std::endl; // Imprime o tamanho do vetor\n\n    return 0;\n}\n</code></pre> </li> </ul> </li> </ol> <p>Neste exemplo, usamos aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria e ponteiros para criar e manipular vetores em C++ usando classes e objetos. Tamb\u00e9m adicionamos fun\u00e7\u00f5es inline para melhorar o desempenho em opera\u00e7\u00f5es comuns como acesso e modifica\u00e7\u00e3o de elementos.</p>"},{"location":"teoria/aula01/memoria-dinamica/","title":"Aloca\u00e7\u00e3o de Mem\u00f3ria Din\u00e2mica","text":"<p>A aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica \u00e9 uma pr\u00e1tica que permite aos programadores alocar e desalocar mem\u00f3ria durante a execu\u00e7\u00e3o do programa. Quando lidamos com grandes volumes de dados e opera\u00e7\u00f5es computacionalmente intensivas, a gest\u00e3o eficiente da mem\u00f3ria \u00e9 crucial para o desempenho e a escalabilidade das aplica\u00e7\u00f5es.</p> <p>Em C++, a mem\u00f3ria din\u00e2mica \u00e9 gerenciada usando os operadores <code>new</code> e <code>delete</code> para alocar e desalocar mem\u00f3ria, respectivamente.</p>"},{"location":"teoria/aula01/memoria-dinamica/#exemplo-1-alocacao-e-manipulacao-de-matrizes-dinamicas","title":"Exemplo 1: Aloca\u00e7\u00e3o e Manipula\u00e7\u00e3o de Matrizes Din\u00e2micas","text":"<p>Vamos considerar um exemplo de aloca\u00e7\u00e3o din\u00e2mica de uma matriz e sua utiliza\u00e7\u00e3o em opera\u00e7\u00f5es de HPC.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\nusing namespace std::chrono;\n\nint main() {\n    int N = 1000; // Tamanho da matriz\n\n    // Aloca mem\u00f3ria para uma matriz din\u00e2mica\n    int** matriz = new int*[N];\n    for (int i = 0; i &lt; N; ++i) {\n        matriz[i] = new int[N];\n    }\n\n    // Inicializa a matriz com valores\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            matriz[i][j] = i + j;\n        }\n    }\n\n    // Realiza uma opera\u00e7\u00e3o de soma simples na matriz\n    auto inicio = high_resolution_clock::now();\n    long long soma = 0;\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            soma += matriz[i][j];\n        }\n    }\n    auto fim = high_resolution_clock::now();\n    auto duracao = duration_cast&lt;milliseconds&gt;(fim - inicio).count();\n\n    cout &lt;&lt; \"Soma de todos os elementos: \" &lt;&lt; soma &lt;&lt; endl;\n    cout &lt;&lt; \"Tempo de execu\u00e7\u00e3o: \" &lt;&lt; duracao &lt;&lt; \"ms\" &lt;&lt; endl;\n\n    // Libera a mem\u00f3ria alocada para a matriz\n    for (int i = 0; i &lt; N; ++i) {\n        delete[] matriz[i];\n    }\n    delete[] matriz;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/memoria-dinamica/#alocacao-da-matriz","title":"Aloca\u00e7\u00e3o da Matriz:","text":"<ul> <li><code>int** matriz = new int*[N];</code> aloca mem\u00f3ria para um array de ponteiros.</li> <li>O loop <code>for</code> interno aloca mem\u00f3ria para cada linha da matriz.</li> <li>Inicializa\u00e7\u00e3o e Opera\u00e7\u00f5es:<ul> <li>A matriz \u00e9 inicializada com a soma dos \u00edndices.</li> <li>Realiza uma opera\u00e7\u00e3o de soma em todos os elementos da matriz, medindo o tempo de execu\u00e7\u00e3o.</li> </ul> </li> <li>Desaloca\u00e7\u00e3o da Mem\u00f3ria:<ul> <li>A mem\u00f3ria alocada para cada linha \u00e9 liberada usando <code>delete[]</code>.</li> <li>A mem\u00f3ria alocada para o array de ponteiros \u00e9 liberada usando <code>delete[]</code>.</li> </ul> </li> </ul>"},{"location":"teoria/aula01/memoria-dinamica/#alocacao-de-memoria-com-stdvector","title":"Aloca\u00e7\u00e3o de Mem\u00f3ria com <code>std::vector</code>","text":"<p>Usar <code>std::vector</code> \u00e9 uma alternativa eficiente e segura para a aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica manual em C++. <code>std::vector</code> gerencia automaticamente a mem\u00f3ria, reduzindo o risco de vazamentos de mem\u00f3ria e outros erros.</p>"},{"location":"teoria/aula01/memoria-dinamica/#exemplo-com-stdvector","title":"Exemplo com <code>std::vector</code>","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\nusing namespace std::chrono;\n\nint main() {\n    int N = 1000; // Tamanho da matriz\n\n    // Aloca mem\u00f3ria para uma matriz din\u00e2mica usando std::vector\n    vector&lt;vector&lt;int&gt;&gt; matriz(N, vector&lt;int&gt;(N));\n\n    // Inicializa a matriz com valores\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            matriz[i][j] = i + j;\n        }\n    }\n\n    // Realiza uma opera\u00e7\u00e3o de soma simples na matriz\n    auto inicio = high_resolution_clock::now();\n    long long soma = 0;\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            soma += matriz[i][j];\n        }\n    }\n    auto fim = high_resolution_clock::now();\n    auto duracao = duration_cast&lt;milliseconds&gt;(fim - inicio).count();\n\n    cout &lt;&lt; \"Soma de todos os elementos: \" &lt;&lt; soma &lt;&lt; endl;\n    cout &lt;&lt; \"Tempo de execu\u00e7\u00e3o: \" &lt;&lt; duracao &lt;&lt; \"ms\" &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/memoria-dinamica/#consideracoes-de-desempenho-em-hpc","title":"Considera\u00e7\u00f5es de Desempenho em HPC","text":"<ol> <li>Localidade de Dados:<ul> <li>A localidade de refer\u00eancia \u00e9 importante para o desempenho da cache. Matrizes alocadas dinamicamente podem ter menor localidade de refer\u00eancia do que matrizes est\u00e1ticas ou <code>std::vector</code>, especialmente se cada linha for alocada separadamente.</li> </ul> </li> <li>Fragmenta\u00e7\u00e3o de Mem\u00f3ria:<ul> <li>A aloca\u00e7\u00e3o din\u00e2mica pode levar \u00e0 fragmenta\u00e7\u00e3o de mem\u00f3ria, especialmente se a mem\u00f3ria for alocada e desalocada frequentemente. Isso pode ser mitigado usando pools de mem\u00f3ria ou alocadores personalizados.</li> </ul> </li> <li>Parallelismo:<ul> <li>Aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica pode introduzir sobrecarga em ambientes paralelos devido \u00e0 necessidade de sincroniza\u00e7\u00e3o. Em HPC, \u00e9 comum usar t\u00e9cnicas avan\u00e7adas para gerenciar a aloca\u00e7\u00e3o de mem\u00f3ria de forma eficiente em ambientes paralelos.</li> </ul> </li> </ol> <p>A aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica \u00e9 uma pr\u00e1tica fundamental em C++ que permite gerenciar a mem\u00f3ria de forma flex\u00edvel durante a execu\u00e7\u00e3o do programa. No contexto de HPC, a gest\u00e3o eficiente da mem\u00f3ria \u00e9 crucial para o desempenho e a escalabilidade das aplica\u00e7\u00f5es. Usar t\u00e9cnicas como aloca\u00e7\u00e3o manual com <code>new</code> e <code>delete</code> ou aloca\u00e7\u00e3o autom\u00e1tica com <code>std::vector</code> pode ajudar a escrever c\u00f3digo eficiente e seguro.</p>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/","title":"Sobrecarga de Fun\u00e7\u00f5es em C++","text":"<p>Sobrecarga de fun\u00e7\u00f5es \u00e9 um recurso da linguagem C++ que permite definir m\u00faltiplas fun\u00e7\u00f5es com o mesmo nome, mas com diferentes listas de par\u00e2metros. Isso significa que voc\u00ea pode ter v\u00e1rias fun\u00e7\u00f5es que realizam tarefas semelhantes, mas aceitam diferentes tipos ou n\u00fameros de argumentos.</p> <p>No contexto de HPC, a sobrecarga de fun\u00e7\u00f5es pode ser usada para otimizar opera\u00e7\u00f5es em diferentes tipos de dados (por exemplo, opera\u00e7\u00f5es em inteiros, floats e doubles) sem duplicar o c\u00f3digo. Isso pode ajudar a escrever c\u00f3digo mais limpo e eficiente.</p>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/#regras-para-sobrecarga-de-funcoes","title":"Regras para Sobrecarga de Fun\u00e7\u00f5es","text":"<p>Para que duas ou mais fun\u00e7\u00f5es sejam sobrecarregadas corretamente, elas devem ser diferentes em pelo menos um dos seguintes aspectos:</p> <ol> <li>N\u00famero de par\u00e2metros: As fun\u00e7\u00f5es devem ter um n\u00famero diferente de par\u00e2metros.</li> <li>Tipo de par\u00e2metros: As fun\u00e7\u00f5es devem ter tipos diferentes de par\u00e2metros.</li> </ol> <p>A sobrecarga de fun\u00e7\u00f5es n\u00e3o pode ser feita apenas com base no tipo de retorno das fun\u00e7\u00f5es.</p>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/#exemplo-basico-de-sobrecarga-de-funcoes","title":"Exemplo B\u00e1sico de Sobrecarga de Fun\u00e7\u00f5es","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;string&gt;\n\n// Fun\u00e7\u00e3o que imprime um inteiro\nvoid imprimir(int valor) {\n    std::cout &lt;&lt; \"Inteiro: \" &lt;&lt; valor &lt;&lt; std::endl;\n}\n\n// Fun\u00e7\u00e3o que imprime um float\nvoid imprimir(float valor) {\n    std::cout &lt;&lt; \"Float: \" &lt;&lt; valor &lt;&lt; std::endl;\n}\n\n// Fun\u00e7\u00e3o que imprime uma string\nvoid imprimir(std::string valor) {\n    std::cout &lt;&lt; \"String: \" &lt;&lt; valor &lt;&lt; std::endl;\n}\n\nint main() {\n    imprimir(10);          // Chama a fun\u00e7\u00e3o que imprime um inteiro\n    imprimir(3.14f);       // Chama a fun\u00e7\u00e3o que imprime um float\n    imprimir(\"Hello\");     // Chama a fun\u00e7\u00e3o que imprime uma string\n\n    return 0;\n}\n</code></pre> <p>Neste exemplo, a fun\u00e7\u00e3o <code>imprimir</code> \u00e9 sobrecarregada para aceitar diferentes tipos de argumentos: <code>int</code>, <code>float</code> e <code>std::string</code></p> <p>Vamos considerar um exemplo de sobrecarga de fun\u00e7\u00f5es para calcular o produto escalar de vetores de diferentes tipos.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\n// Fun\u00e7\u00e3o para calcular o produto escalar de vetores de inteiros\nint produtoEscalar(const std::vector&lt;int&gt;&amp; v1, const std::vector&lt;int&gt;&amp; v2) {\n    int produto = 0;\n    for (size_t i = 0; i &lt; v1.size(); ++i) {\n        produto += v1[i] * v2[i];\n    }\n    return produto;\n}\n\n// Fun\u00e7\u00e3o para calcular o produto escalar de vetores de floats\nfloat produtoEscalar(const std::vector&lt;float&gt;&amp; v1, const std::vector&lt;float&gt;&amp; v2) {\n    float produto = 0.0f;\n    for (size_t i = 0; i &lt; v1.size(); ++i) {\n        produto += v1[i] * v2[i];\n    }\n    return produto;\n}\n\n// Fun\u00e7\u00e3o para calcular o produto escalar de vetores de doubles\ndouble produtoEscalar(const std::vector&lt;double&gt;&amp; v1, const std::vector&lt;double&gt;&amp; v2) {\n    double produto = 0.0;\n    for (size_t i = 0; i &lt; v1.size(); ++i) {\n        produto += v1[i] * v2[i];\n    }\n    return produto;\n}\n\nint main() {\n    std::vector&lt;int&gt; v1_int = {1, 2, 3};\n    std::vector&lt;int&gt; v2_int = {4, 5, 6};\n\n    std::vector&lt;float&gt; v1_float = {1.0f, 2.0f, 3.0f};\n    std::vector&lt;float&gt; v2_float = {4.0f, 5.0f, 6.0f};\n\n    std::vector&lt;double&gt; v1_double = {1.0, 2.0, 3.0};\n    std::vector&lt;double&gt; v2_double = {4.0, 5.0, 6.0};\n\n    std::cout &lt;&lt; \"Produto Escalar (int): \" &lt;&lt; produtoEscalar(v1_int, v2_int) &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Produto Escalar (float): \" &lt;&lt; produtoEscalar(v1_float, v2_float) &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Produto Escalar (double): \" &lt;&lt; produtoEscalar(v1_double, v2_double) &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/#sobrecarga-de-funcoes-e-templates","title":"Sobrecarga de Fun\u00e7\u00f5es e Templates","text":"<p>Outra abordagem para lidar com opera\u00e7\u00f5es semelhantes em diferentes tipos de dados \u00e9 o uso de templates de fun\u00e7\u00f5es. Templates podem ser usados para evitar a necessidade de sobrecarregar fun\u00e7\u00f5es manualmente para cada tipo de dado.</p>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/#exemplo-de-template-de-funcao","title":"Exemplo de Template de Fun\u00e7\u00e3o","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\n// Template de fun\u00e7\u00e3o para calcular o produto escalar de vetores\ntemplate &lt;typename T&gt;\nT produtoEscalar(const std::vector&lt;T&gt;&amp; v1, const std::vector&lt;T&gt;&amp; v2) {\n    T produto = 0;\n    for (size_t i = 0; i &lt; v1.size(); ++i) {\n        produto += v1[i] * v2[i];\n    }\n    return produto;\n}\n\nint main() {\n    std::vector&lt;int&gt; v1_int = {1, 2, 3};\n    std::vector&lt;int&gt; v2_int = {4, 5, 6};\n\n    std::vector&lt;float&gt; v1_float = {1.0f, 2.0f, 3.0f};\n    std::vector&lt;float&gt; v2_float = {4.0f, 5.0f, 6.0f};\n\n    std::vector&lt;double&gt; v1_double = {1.0, 2.0, 3.0};\n    std::vector&lt;double&gt; v2_double = {4.0, 5.0, 6.0};\n\n    std::cout &lt;&lt; \"Produto Escalar (int): \" &lt;&lt; produtoEscalar(v1_int, v2_int) &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Produto Escalar (float): \" &lt;&lt; produtoEscalar(v1_float, v2_float) &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Produto Escalar (double): \" &lt;&lt; produtoEscalar(v1_double, v2_double) &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>A sobrecarga de fun\u00e7\u00f5es em C++ permite a defini\u00e7\u00e3o de m\u00faltiplas fun\u00e7\u00f5es com o mesmo nome, mas com diferentes listas de par\u00e2metros. Isso melhora a legibilidade, manuten\u00e7\u00e3o e facilidade de uso do c\u00f3digo. No contexto de HPC, a sobrecarga de fun\u00e7\u00f5es pode ser usada para otimizar opera\u00e7\u00f5es em diferentes tipos de dados, evitando duplica\u00e7\u00e3o de c\u00f3digo e melhorando a efici\u00eancia. Alternativamente, templates de fun\u00e7\u00f5es podem ser usados para alcan\u00e7ar resultados similares com menos c\u00f3digo.</p>"},{"location":"teoria/aula01/uso-de-constantes/","title":"Const Correctness em HPC","text":"<p>Const Correctness (uso de constantes) \u00e9 um conceito em C++ que garante que os dados n\u00e3o sejam modificados quando n\u00e3o deveriam ser. Usar <code>const</code> corretamente pode melhorar a legibilidade do c\u00f3digo, evitar erros e permitir otimiza\u00e7\u00f5es pelo compilador. </p>"},{"location":"teoria/aula01/uso-de-constantes/#usos-comuns-de-const","title":"Usos Comuns de <code>const</code>","text":""},{"location":"teoria/aula01/uso-de-constantes/#1-variaveis-locais","title":"1. Vari\u00e1veis Locais","text":"<p>Declarar vari\u00e1veis locais como <code>const</code> se voc\u00ea n\u00e3o pretende modificar o valor delas.</p> <pre><code>const int valor = 10;\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#2-parametros-de-funcao","title":"2. Par\u00e2metros de Fun\u00e7\u00e3o","text":"<p>Usar <code>const</code> em par\u00e2metros de fun\u00e7\u00e3o para garantir que os argumentos n\u00e3o sejam modificados.</p> <pre><code>void imprimeValor(const int valor) {\n    std::cout &lt;&lt; \"Valor: \" &lt;&lt; valor &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#3-ponteiros-e-referencias","title":"3. Ponteiros e Refer\u00eancias","text":"<p>Declarar ponteiros e refer\u00eancias como <code>const</code> para garantir que os dados apontados ou referenciados n\u00e3o sejam alterados.</p> <pre><code>void imprimeValor(const int* ptr) {\n    std::cout &lt;&lt; \"Valor: \" &lt;&lt; *ptr &lt;&lt; std::endl;\n}\n\nvoid imprimeValor(const int&amp; ref) {\n    std::cout &lt;&lt; \"Valor: \" &lt;&lt; ref &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#4-metodos-de-classe","title":"4. M\u00e9todos de Classe","text":"<p>Declarar m\u00e9todos como <code>const</code> para garantir que eles n\u00e3o modifiquem o estado do objeto.</p> <pre><code>class Ponto {\npublic:\n    Ponto(int x, int y) : x(x), y(y) {}\n\n    int getX() const { return x; }\n    int getY() const { return y; }\n\nprivate:\n    int x, y;\n};\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#exemplo-multiplicacao-de-matrizes-com-const-correctness","title":"Exemplo: Multiplica\u00e7\u00e3o de Matrizes com Const Correctness","text":"<p>Vamos considerar um exemplo de multiplica\u00e7\u00e3o de matrizes onde aplicamos const correctness para garantir que os dados de entrada n\u00e3o sejam modificados.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\nusing namespace std::chrono;\n\n// Fun\u00e7\u00e3o para multiplicar duas matrizes com const correctness\nvoid multiplicaMatriz(const vector&lt;vector&lt;int&gt;&gt;&amp; A, const vector&lt;vector&lt;int&gt;&gt;&amp; B, vector&lt;vector&lt;int&gt;&gt;&amp; C) {\n    int N = A.size();\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            C[i][j] = 0;\n            for (int k = 0; k &lt; N; ++k) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n}\n\nint main() {\n    int N = 100; // Tamanho da matriz\n    vector&lt;vector&lt;int&gt;&gt; A(N, vector&lt;int&gt;(N, 1));\n    vector&lt;vector&lt;int&gt;&gt; B(N, vector&lt;int&gt;(N, 1));\n    vector&lt;vector&lt;int&gt;&gt; C(N, vector&lt;int&gt;(N, 0));\n\n    auto inicio = high_resolution_clock::now();\n\n    // Chama a fun\u00e7\u00e3o de multiplica\u00e7\u00e3o de matrizes\n    multiplicaMatriz(A, B, C);\n\n    auto fim = high_resolution_clock::now();\n    auto duracao = duration_cast&lt;milliseconds&gt;(fim - inicio).count();\n\n    cout &lt;&lt; \"Tempo de multiplica\u00e7\u00e3o de matrizes: \" &lt;&lt; duracao &lt;&lt; \"ms\" &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#const-correctness-em-classes","title":"Const Correctness em Classes","text":"<p>No contexto de HPC, classes frequentemente encapsulam dados e opera\u00e7\u00f5es. Garantir const correctness em m\u00e9todos de classe \u00e9 essencial.</p>"},{"location":"teoria/aula01/uso-de-constantes/#exemplo-classe-de-matriz-com-metodos-const","title":"Exemplo: Classe de Matriz com M\u00e9todos Const","text":"<pre><code>class Matriz {\npublic:\n    Matriz(int N) : data(N, vector&lt;int&gt;(N, 0)) {}\n\n    const vector&lt;int&gt;&amp; operator[](int index) const {\n        return data[index];\n    }\n\n    vector&lt;int&gt;&amp; operator[](int index) {\n        return data[index];\n    }\n\n    void imprime() const {\n        for (const auto&amp; linha : data) {\n            for (int valor : linha) {\n                cout &lt;&lt; valor &lt;&lt; \" \";\n            }\n            cout &lt;&lt; endl;\n        }\n    }\n\nprivate:\n    vector&lt;vector&lt;int&gt;&gt; data;\n};\n\nint main() {\n    Matriz matriz(3);\n\n    matriz[0][0] = 1;\n    matriz[1][1] = 2;\n    matriz[2][2] = 3;\n\n    cout &lt;&lt; \"Matriz:\" &lt;&lt; endl;\n    matriz.imprime();\n\n    return 0;\n}\n</code></pre> <p>Aplicar const correctness pode prevenir erros e permitir otimiza\u00e7\u00f5es adicionais pelo compilador. Usar <code>const</code> de maneira apropriada em vari\u00e1veis, par\u00e2metros de fun\u00e7\u00e3o, ponteiros, refer\u00eancias e m\u00e9todos de classe \u00e9 uma pr\u00e1tica recomendada para escrever c\u00f3digo robusto e eficiente.</p>"},{"location":"teoria/aula02/","title":"Contextos e Curiosidades","text":"<p>O que \u00e9 um Supercomputador?</p> <p>El Capitan atualmente, o Supercomputador mais r\u00e1pido do mundo!</p> <p>Santos Dumont o Supercomputador BR que vamos usar no projeto 2!</p> <p>LNCC - Laborat\u00f3rio Nacional de Computa\u00e7\u00e3o Ci\u00eantifica</p> <p>SINAPAD -  Sistema Nacional de Processamento de Alto Desempenho </p>"},{"location":"teoria/aula02/#o-que-e-hpc","title":"O que \u00e9 HPC?","text":"<p>High-Performance Computing (HPC) refere-se ao uso de supercomputadores e clusters de computadores para resolver problemas computacionalmente complexos. HPC \u00e9 essencial em campos como ci\u00eancia, engenharia e finan\u00e7as, onde grandes volumes de dados precisam ser processados rapidamente.</p>"},{"location":"teoria/aula02/#top-500","title":"TOP 500","text":"<p>Supercomputador Fugaku https://spectrum.ieee.org/japans-fugaku-supercomputer-is-first-in-the-world-to-simultaneously-top-all-high-performance-benchmarks</p> <p>O TOP 500 \u00e9 uma lista semestral que classifica os 500 supercomputadores mais poderosos do mundo com base no benchmark LINPACK, que mede a capacidade de resolver sistemas de equa\u00e7\u00f5es lineares. A lista \u00e9 um indicador importante do progresso em tecnologia de supercomputa\u00e7\u00e3o. Varia\u00e7\u00f5es da lista incluem:</p> <ul> <li>Green500: Classifica supercomputadores pela efici\u00eancia energ\u00e9tica.</li> <li>Graph500: Mede o desempenho em tarefas de an\u00e1lise de gr\u00e1ficos.</li> <li>HPCG: Avalia supercomputadores usando um benchmark alternativo ao LINPACK, mais representativo de cargas de trabalho reais em HPC.</li> </ul>"},{"location":"teoria/aula02/#que-tipo-de-problema-e-computacionalmente-complexo","title":"Que tipo de problema \u00e9 computacionalmente complexo?","text":"<p>Problemas computacionalmente complexos exigem grande capacidade de processamento e mem\u00f3ria para serem resolvidos eficientemente. Exemplos incluem:</p> <ul> <li>Simula\u00e7\u00f5es clim\u00e1ticas</li> <li>Modelagem molecular</li> <li>Processamento de grandes conjuntos de dados (Big Data)</li> <li>An\u00e1lise gen\u00f4mica</li> <li>Renderiza\u00e7\u00e3o de gr\u00e1ficos em alta resolu\u00e7\u00e3o</li> <li>Aprendizado de m\u00e1quina e intelig\u00eancia artificial</li> </ul>"},{"location":"teoria/aula02/#o-que-e-um-supercomputador","title":"O que \u00e9 um supercomputador?","text":"<p>Um supercomputador \u00e9 um sistema computacional de alto desempenho projetado para processar grandes volumes de dados e realizar c\u00e1lculos complexos muito rapidamente. Ele consiste em milhares de n\u00f3s de computa\u00e7\u00e3o interconectados, cada um contendo m\u00faltiplos processadores, grande quantidade de mem\u00f3ria e armazenamento r\u00e1pido.</p>"},{"location":"teoria/aula02/#o-que-e-um-cluster","title":"O que \u00e9 um Cluster?","text":"<p>Um cluster \u00e9 um conjunto de computadores (n\u00f3s) conectados que trabalham juntos como se fossem um \u00fanico sistema. Cada n\u00f3 em um cluster \u00e9 um computador independente, mas o sistema inteiro \u00e9 gerenciado para atuar em conjunto, distribuindo tarefas e compartilhando recursos.</p>"},{"location":"teoria/aula02/#qual-a-diferenca-de-um-supercomputador-para-um-cluster","title":"Qual a diferen\u00e7a de um supercomputador para um cluster?","text":"<p>A principal diferen\u00e7a entre um supercomputador e um cluster est\u00e1 na integra\u00e7\u00e3o e desempenho:</p> <ul> <li>Supercomputador: Um sistema integrado de alto desempenho projetado especificamente para computa\u00e7\u00e3o intensa. Possui uma arquitetura otimizada e interconex\u00f5es de alta velocidade.</li> <li>Cluster: S\u00e3o computadores independentes conectados para trabalhar juntos. Pode ser composto por hardware de mercado e geralmente \u00e9 mais flex\u00edvel e expans\u00edvel.</li> </ul> <p>OBS: Muitos supercomputadores modernos s\u00e3o de fato clusters, utilizando milhares de n\u00f3s interconectados para alcan\u00e7ar um desempenho extremamente alto.</p>"},{"location":"teoria/aula02/#cluster-franky","title":"Cluster Franky","text":"<p>Cluster Franky - Laborat\u00f3rio de Redes e Supercomputa\u00e7\u00e3o do Insper </p> <p>Nosso objetivo \u00e9 preparar voc\u00ea com as habilidades necess\u00e1rias para utilizar sistemas de HPC em situa\u00e7\u00f5es reais. Inspirado no supercomputador Santos Dumont, o Cluster Franky oferece um ambiente robusto e seguro para realizar simula\u00e7\u00f5es complexas e an\u00e1lises de grandes volumes de dados.</p>"},{"location":"teoria/aula02/#como-o-sistema-funciona","title":"Como o Sistema Funciona","text":"<p>Para que voc\u00ea compreenda melhor como o Cluster Franky opera, veja a figura abaixo que detalha a arquitetura do sistema:</p> <p></p>"},{"location":"teoria/aula02/#1-conexao-e-autenticacao","title":"1. Conex\u00e3o e Autentica\u00e7\u00e3o","text":"<p>O processo de intera\u00e7\u00e3o com o Cluster Franky come\u00e7a quando voc\u00ea se conecta ao Cluster via SSH atrav\u00e9s da rede do Insper, em seguida, voc\u00ea ser\u00e1 direcionado ao Login Node, que serve como o ponto de entrada para o cluster. Para acessar o sistema, \u00e9 necess\u00e1rio passar por um processo de autentica\u00e7\u00e3o usando pares de chaves p\u00fablicas e privadas, configurados previamente por nossa equipe t\u00e9cnica.</p>"},{"location":"teoria/aula02/#2-envio-e-gerenciamento-de-tarefas-jobs","title":"2. Envio e Gerenciamento de Tarefas (Jobs)","text":"<p>Uma vez autenticado, voc\u00ea interage com o cluster atrav\u00e9s do Slurm. O Slurm \u00e9 respons\u00e1vel por gerenciar a execu\u00e7\u00e3o das tarefas que voc\u00ea submete, distribuindo-as eficientemente pelos recursos de computa\u00e7\u00e3o dispon\u00edveis, que s\u00e3o divididos em:</p> <ul> <li>N\u00f3 de Computa\u00e7\u00e3o CPU: Composto por cinco n\u00f3s, cada um com 24 threads e 64 GB de RAM.</li> <li>N\u00f3 de Computa\u00e7\u00e3o GPU: Composto por quatro n\u00f3s, cada um equipado com uma GPU NVIDIA A1000 com 8GB de VRAM, uma CPU com 64 GB de RAM e 32 threads.</li> <li>N\u00f3 de Computa\u00e7\u00e3o Monstr\u00e3o: Composto por um n\u00f3 equipado com 4 GPU NVIDIA V100 com 32GB de VRAM, uma CPU com 1TB de RAM e 20 threads</li> </ul> <p>Os daemons de controle cada n\u00f3 de computa\u00e7\u00e3o gerencia a execu\u00e7\u00e3o das tarefas, garantindo que os recursos sejam alocados de forma otimizada. Isso significa que, independentemente de voc\u00ea estar executando simula\u00e7\u00f5es simples ou tarefas intensivas de processamento de dados, o sistema est\u00e1 configurado para maximizar a efici\u00eancia e minimizar o tempo de execu\u00e7\u00e3o.</p>"},{"location":"teoria/aula02/#3-armazenamento-e-gestao-de-dados","title":"3. Armazenamento e Gest\u00e3o de Dados","text":"<p>Durante suas atividades, voc\u00ea deve utilizar a pasta SCRATCH para armazenar temporariamente os arquivos e dados necess\u00e1rios para suas tarefas. \u00c9 importante lembrar que essa pasta \u00e9 destinada ao armazenamento tempor\u00e1rio, portanto, certifique-se de salvar seus dados em um local seguro ap\u00f3s concluir suas atividades.</p> <p>O sistema de arquivos atual do Cluster Franky utiliza o NFS (Network File System), que facilita o acesso aos dados entre os n\u00f3s de computa\u00e7\u00e3o. No futuro, planejamos migrar para o sistema de arquivos Lustre, que oferecer\u00e1 maior efici\u00eancia e melhor desempenho no manuseio de grandes volumes de dados.</p>"},{"location":"teoria/aula02/#porque-usar-o-cluster-franky","title":"Porque usar o Cluster Franky?","text":"<p>Utilizar o Cluster Franky oferece v\u00e1rios benef\u00edcios que v\u00e3o prepar\u00e1-lo para desafios reais em HPC:</p> <ul> <li> <p>Experi\u00eancia Pr\u00e1tica em HPC: Ao trabalhar com o Cluster Franky, voc\u00ea ter\u00e1 a oportunidade de realizar tarefas que simulam cen\u00e1rios reais encontrados em supercomputadores como o Santos Dumont. Isso inclui a execu\u00e7\u00e3o de simula\u00e7\u00f5es complexas, a otimiza\u00e7\u00e3o de recursos e o uso inteligente das ferramentas dispon\u00edveis.</p> </li> <li> <p>Desenvolvimento de Habilidades T\u00e9cnicas: Aprender a utilizar ferramentas avan\u00e7adas como o Slurm e a interagir com ambientes de computa\u00e7\u00e3o distribu\u00edda ir\u00e1 equip\u00e1-lo com habilidades t\u00e9cnicas valiosas, amplamente aplic\u00e1veis em diversas \u00e1reas de pesquisa e ind\u00fastria.</p> </li> <li> <p>Prepara\u00e7\u00e3o para o Mundo Real: A experi\u00eancia adquirida com o Cluster Franky ser\u00e1 um diferencial no mercado de trabalho, pois voc\u00ea estar\u00e1 familiarizado com pr\u00e1ticas e tecnologias utilizadas em sistemas de HPC de ponta.</p> </li> </ul> <p>O Cluster Franky n\u00e3o \u00e9 apenas uma ferramenta de aprendizado; \u00e9 uma porta de entrada para o mundo da computa\u00e7\u00e3o de alto desempenho. Aproveite essa oportunidade para expandir seus conhecimentos, experimentar e se preparar para enfrentar desafios de HPC. Se precisar de ajuda ou tiver d\u00favidas, procure um de n\u00f3s!</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/","title":"Cluster Franky","text":"<p>Nosso objetivo \u00e9 preparar voc\u00ea com as habilidades necess\u00e1rias para utilizar sistemas de HPC em situa\u00e7\u00f5es reais. Inspirado no supercomputador Santos Dumont, o Cluster Franky oferece um ambiente robusto e seguro para realizar simula\u00e7\u00f5es complexas e an\u00e1lises de grandes volumes de dados.</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#como-o-sistema-funciona","title":"Como o Sistema Funciona","text":"<p>Para que voc\u00ea compreenda melhor como o Cluster Franky opera, veja a figura abaixo que detalha a arquitetura do sistema:</p> <p></p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#1-conexao-e-autenticacao","title":"1. Conex\u00e3o e Autentica\u00e7\u00e3o","text":"<p>O processo de intera\u00e7\u00e3o com o Cluster Franky come\u00e7a quando voc\u00ea se conecta ao Cluster via SSH atrav\u00e9s da rede do Insper, em seguida, voc\u00ea ser\u00e1 direcionado ao Login Node, que serve como o ponto de entrada para o cluster. Para acessar o sistema, \u00e9 necess\u00e1rio passar por um processo de autentica\u00e7\u00e3o usando pares de chaves p\u00fablicas e privadas, configurados previamente por nossa equipe t\u00e9cnica.</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#2-envio-e-gerenciamento-de-tarefas-jobs","title":"2. Envio e Gerenciamento de Tarefas (Jobs)","text":"<p>Uma vez autenticado, voc\u00ea interage com o cluster atrav\u00e9s do Slurm. O Slurm \u00e9 respons\u00e1vel por gerenciar a execu\u00e7\u00e3o das tarefas que voc\u00ea submete, distribuindo-as eficientemente pelos recursos de computa\u00e7\u00e3o dispon\u00edveis, que s\u00e3o divididos em:</p> <ul> <li>N\u00f3 de Computa\u00e7\u00e3o CPU: Composto por cinco n\u00f3s, cada um com 24 threads e 64 GB de RAM.</li> <li>N\u00f3 de Computa\u00e7\u00e3o GPU: Composto por um n\u00f3s, equipado com uma GPU NVIDIA 1080 Ti, 16 GB de RAM e 8 threads.</li> </ul> <p>Os daemons de controle cada n\u00f3 de computa\u00e7\u00e3o gerencia a execu\u00e7\u00e3o das tarefas, garantindo que os recursos sejam alocados de forma otimizada. Isso significa que, independentemente de voc\u00ea estar executando simula\u00e7\u00f5es simples ou tarefas intensivas de processamento de dados, o sistema est\u00e1 configurado para maximizar a efici\u00eancia e minimizar o tempo de execu\u00e7\u00e3o.</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#3-armazenamento-e-gestao-de-dados","title":"3. Armazenamento e Gest\u00e3o de Dados","text":"<p>Durante suas atividades, voc\u00ea deve utilizar a pasta SCRATCH para armazenar temporariamente os arquivos e dados necess\u00e1rios para suas tarefas. \u00c9 importante lembrar que essa pasta \u00e9 destinada ao armazenamento tempor\u00e1rio, portanto, certifique-se de salvar seus dados em um local seguro ap\u00f3s concluir suas atividades.</p> <p>O sistema de arquivos atual do Cluster Franky utiliza o NFS (Network File System), que facilita o acesso aos dados entre os n\u00f3s de computa\u00e7\u00e3o. No futuro, planejamos migrar para o sistema de arquivos Lustre, que oferecer\u00e1 maior efici\u00eancia e melhor desempenho no manuseio de grandes volumes de dados.</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#porque-usar-o-cluster-franky","title":"Porque usar o Cluster Franky?","text":"<p>Utilizar o Cluster Franky oferece v\u00e1rios benef\u00edcios que v\u00e3o prepar\u00e1-lo para desafios reais em HPC:</p> <ul> <li> <p>Experi\u00eancia Pr\u00e1tica em HPC: Ao trabalhar com o Cluster Franky, voc\u00ea ter\u00e1 a oportunidade de realizar tarefas que simulam cen\u00e1rios reais encontrados em supercomputadores como o Santos Dumont. Isso inclui a execu\u00e7\u00e3o de simula\u00e7\u00f5es complexas, a otimiza\u00e7\u00e3o de recursos e o uso inteligente das ferramentas dispon\u00edveis.</p> </li> <li> <p>Desenvolvimento de Habilidades T\u00e9cnicas: Aprender a utilizar ferramentas avan\u00e7adas como o Slurm e a interagir com ambientes de computa\u00e7\u00e3o distribu\u00edda ir\u00e1 equip\u00e1-lo com habilidades t\u00e9cnicas valiosas, amplamente aplic\u00e1veis em diversas \u00e1reas de pesquisa e ind\u00fastria.</p> </li> <li> <p>Prepara\u00e7\u00e3o para o Mundo Real: A experi\u00eancia adquirida com o Cluster Franky ser\u00e1 um diferencial no mercado de trabalho, pois voc\u00ea estar\u00e1 familiarizado com pr\u00e1ticas e tecnologias utilizadas em sistemas de HPC de ponta.</p> </li> </ul> <p>O Cluster Franky n\u00e3o \u00e9 apenas uma ferramenta de aprendizado; \u00e9 uma porta de entrada para o mundo da computa\u00e7\u00e3o de alto desempenho. Aproveite essa oportunidade para expandir seus conhecimentos, experimentar e se preparar para enfrentar desafios de HPC. Se precisar de ajuda ou tiver d\u00favidas, procure um de n\u00f3s!</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/","title":"Contextualizando o HPC","text":""},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-hpc","title":"O que \u00e9 HPC?","text":"<p>High-Performance Computing (HPC) refere-se ao uso de supercomputadores e clusters de computadores para resolver problemas computacionalmente complexos. HPC \u00e9 essencial em campos como ci\u00eancia, engenharia e finan\u00e7as, onde grandes volumes de dados precisam ser processados rapidamente.</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#top-500","title":"TOP 500","text":"<p>Supercomputador Fugaku Fonte:https://spectrum.ieee.org/japans-fugaku-supercomputer-is-first-in-the-world-to-simultaneously-top-all-high-performance-benchmarks</p> <p>O TOP 500 \u00e9 uma lista semestral que classifica os 500 supercomputadores mais poderosos do mundo com base no benchmark LINPACK, que mede a capacidade de resolver sistemas de equa\u00e7\u00f5es lineares. A lista \u00e9 um indicador importante do progresso em tecnologia de supercomputa\u00e7\u00e3o. Varia\u00e7\u00f5es da lista incluem:</p> <ul> <li>Green500: Classifica supercomputadores pela efici\u00eancia energ\u00e9tica.</li> <li>Graph500: Mede o desempenho em tarefas de an\u00e1lise de gr\u00e1ficos.</li> <li>HPCG: Avalia supercomputadores usando um benchmark alternativo ao LINPACK, mais representativo de cargas de trabalho reais em HPC.</li> </ul>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#que-tipo-de-problema-e-computacionalmente-complexo","title":"Que tipo de problema \u00e9 computacionalmente complexo?","text":"<p>Problemas computacionalmente complexos exigem grande capacidade de processamento e mem\u00f3ria para serem resolvidos eficientemente. Exemplos incluem:</p> <ul> <li>Simula\u00e7\u00f5es clim\u00e1ticas</li> <li>Modelagem molecular</li> <li>Processamento de grandes conjuntos de dados (Big Data)</li> <li>An\u00e1lise gen\u00f4mica</li> <li>Renderiza\u00e7\u00e3o de gr\u00e1ficos em alta resolu\u00e7\u00e3o</li> <li>Aprendizado de m\u00e1quina e intelig\u00eancia artificial</li> </ul>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-um-supercomputador","title":"O que \u00e9 um supercomputador?","text":"<p>Monstr\u00e3o - Supercomputador do Insper Fonte:https://www.insper.edu.br/noticias/conhece-o-monstrao-saiba-mais-sobre-o-supercomputador-do-insper/</p> <p>Um supercomputador \u00e9 um sistema computacional de alto desempenho projetado para processar grandes volumes de dados e realizar c\u00e1lculos complexos muito rapidamente. Ele consiste em milhares de n\u00f3s de computa\u00e7\u00e3o interconectados, cada um contendo m\u00faltiplos processadores, grande quantidade de mem\u00f3ria e armazenamento r\u00e1pido.</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-um-cluster","title":"O que \u00e9 um Cluster?","text":"<p>Cluster Franky - Laborat\u00f3rio de Redes e Supercomputa\u00e7\u00e3o do Insper</p> <p>Um cluster \u00e9 um conjunto de computadores (n\u00f3s) conectados que trabalham juntos como se fossem um \u00fanico sistema. Cada n\u00f3 em um cluster \u00e9 um computador independente, mas o sistema inteiro \u00e9 gerenciado para atuar em conjunto, distribuindo tarefas e compartilhando recursos.</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#qual-a-diferenca-de-um-supercomputador-para-um-cluster","title":"Qual a diferen\u00e7a de um supercomputador para um cluster?","text":"<p>A principal diferen\u00e7a entre um supercomputador e um cluster est\u00e1 na integra\u00e7\u00e3o e desempenho:</p> <ul> <li>Supercomputador: Um sistema integrado de alto desempenho projetado especificamente para computa\u00e7\u00e3o intensa. Possui uma arquitetura otimizada e interconex\u00f5es de alta velocidade.</li> <li>Cluster: S\u00e3o computadores independentes conectados para trabalhar juntos. Pode ser composto por hardware de mercado e geralmente \u00e9 mais flex\u00edvel e expans\u00edvel.</li> </ul> <p>OBS: Muitos supercomputadores modernos s\u00e3o de fato clusters, utilizando milhares de n\u00f3s interconectados para alcan\u00e7ar um desempenho extremamente alto.</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-preciso-saber-para-utilizar-o-cluster","title":"O que \u00e9 preciso saber para utilizar o Cluster?","text":"<p>Para utilizar um cluster eficientemente, \u00e9 importante entender:</p> <ul> <li>Acesso e Conex\u00e3o: Como se conectar ao cluster e configurar as credenciais de acesso.</li> <li>Gerenciamento de Recursos: Como usar o sistema de gerenciamento de SLURM para submeter e monitorar jobs.</li> <li>Sistema de Arquivos: Navega\u00e7\u00e3o e uso do sistema de arquivos do cluster.</li> <li>Compila\u00e7\u00e3o e Execu\u00e7\u00e3o: Compilar c\u00f3digo e executar programas no ambiente do cluster.</li> <li>Paraleliza\u00e7\u00e3o: Como paralelizar c\u00f3digo usando bibliotecas como OpenMP e MPI.</li> </ul>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-preciso-saber-para-resolver-problemas-em-hpc","title":"O que \u00e9 preciso saber para resolver problemas em HPC?","text":"<p>Para resolver problemas em HPC, \u00e9 essencial ter conhecimento em:</p> <ul> <li>Arquitetura de Computadores: Compreender a arquitetura do sistema, incluindo hierarquia de mem\u00f3ria e caches, para escrever c\u00f3digo eficiente.</li> <li>Otimiza\u00e7\u00e3o de C\u00f3digo: T\u00e9cnicas de otimiza\u00e7\u00e3o, uso eficiente da mem\u00f3ria, uso efici\u00eante do compilador.</li> <li>Profiling: Ferramentas e t\u00e9cnicas para identificar gargalos de desempenho e medir a efici\u00eancia do c\u00f3digo.</li> <li>Gerenciamento de Recursos: Usar ferramentas de gerenciamento como SLURM para alocar recursos adequadamente.</li> <li>Programa\u00e7\u00e3o Paralela: Usar OpenMP para paraleliza\u00e7\u00e3o em mem\u00f3ria compartilhada e MPI para mem\u00f3ria distribu\u00edda.</li> </ul>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#recursos-adicionais","title":"Recursos Adicionais","text":"<ul> <li>Documenta\u00e7\u00e3o do SLURM: SLURM User Guide</li> <li>Tutoriais de MPI: MPI Tutorial</li> <li>OpenMP: OpenMP Official Site</li> <li>Profiling Tools: Gprof, Valgrind</li> </ul>"}]}