{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SuperComputa\u00e7\u00e3o","text":"<p>Bem-vindo ao curso de SuperComputa\u00e7\u00e3o 2025/2!</p> <p>Essa p\u00e1gina cont\u00e9m os materiais de apoio para o curso de SuperComputa\u00e7\u00e3o do Insper.</p> <p>Hor\u00e1rios das Aulas</p> <p>Aulas:</p> <p>Segunda -&gt; 16h30 -- 18h30</p> <p>Sexta -&gt; 14h15 -- 16h15</p> <p>Atendimento:</p> <p>Segunda -&gt; 18h30 -- 20h00</p>"},{"location":"#estrutura-do-curso","title":"Estrutura do Curso","text":"<p>O curso \u00e9 estruturado da seguinte forma:</p> <p>Estrutura do Curso</p> <ol> <li>Programa\u00e7\u00e3o paralela e distribu\u00edda em CPU</li> <li>Projeto 1</li> <li>Programa\u00e7\u00e3o paralela e distribu\u00edda em GPU</li> <li>Projeto 2</li> </ol>"},{"location":"#objetivos-de-aprendizagem","title":"Objetivos de aprendizagem","text":"<p>No Insper, cada disciplina \u00e9 guiada por objetivos de aprendizagem. Para evoluir na mat\u00e9ria e ser aprovado, \u00e9 essencial que voc\u00ea atinja esses objetivos. Todos os conte\u00fados, atividades e projetos est\u00e3o conectados diretamente a esses objetivos.  Voc\u00ea pode consultar o detalhamento completo do curso neste link.</p> <p>Notas</p> <ul> <li>Atividades - 15%.</li> <li>Projeto 1 - 10%</li> <li>Avalia\u00e7\u00e3o Intermedi\u00e1ria - 25%</li> <li>Projeto 2 - 20%</li> <li>Avalia\u00e7\u00e3o Final - 30%</li> </ul>"},{"location":"#equipe","title":"Equipe","text":"<p>Equipe atual</p> <ul> <li> L\u00edcia Sales Professora</li> <li> Ana Laiz Ninja</li> <li> Victor Cordeiro T\u00e9cnico do lab.</li> </ul>"},{"location":"sobre/","title":"Burocracias","text":"<p>Hor\u00e1rios</p> <p>Aulas:</p> <p>Segunda -&gt; 16h30 -- 18h30</p> <p>Sexta -&gt; 14h15 -- 16h15</p> <p>Atendimento:</p> <p>Segunda -&gt; 18h30 -- 20h00</p> Objetivos de Aprendizagem <p>Ao final da disciplina, o estudante ser\u00e1 capaz de:</p> <p>Obj 1. Desenvolver algoritmos usando recursos de computa\u00e7\u00e3o paralela e distribu\u00edda para obter ganhos de desempenho na aplica\u00e7\u00e3o final.</p> <p>Obj 2. Aplicar estruturas l\u00f3gicas de computa\u00e7\u00e3o distribu\u00edda no desenvolvimento de algoritmos multitarefa.</p> <p>Obj 3. Usar GPGPU (General-Purpose computing on Graphics Processing Units) para computa\u00e7\u00e3o num\u00e9rica e comparar seu desempenho com solu\u00e7\u00f5es baseadas em CPU.</p> <p>Obj 4. Planejar e projetar sistemas de computa\u00e7\u00e3o de alto desempenho, considerando aspectos de hardware, escalabilidade, e aloca\u00e7\u00e3o de recursos.</p> <p>Obj 5. Analisar a complexidade de algoritmos paralelos e a efici\u00eancia de implementa\u00e7\u00f5es espec\u00edficas, identificando as m\u00e9tricas de desempenho mais adequadas para essa an\u00e1lise.</p> <p>Obj 6. Aplicar recursos espec\u00edficos de sistemas operacionais (como escalonadores, controle de threads e gerenciamento de mem\u00f3ria) para melhorar o desempenho de algoritmos.</p> <p>Obj 7. Desenvolver aplica\u00e7\u00f5es que utilizam protocolos otimizados para paraleliza\u00e7\u00e3o, como MPI, OpenMP e CUDA.</p> Plano de Aulas - Supercomputa\u00e7\u00e3o (2025.2) Data Aula T\u00f3picos Abordados Atividades 11/ago (seg) Aula 01 Problemas de HPC; mapa de mem\u00f3ria; Python \u00d7 C++; desempenho; objetivos da disciplina; passagem de argumentos; recursos de C++ Transcri\u00e7\u00e3o de c\u00f3digos Python para C++; compara\u00e7\u00e3o de desempenho entre linguagens. 15/ago (sex) Aula 02 Sistemas de HPC; rede, hardware, filas, jobs; SLURM; clusters no Brasil e no mundo Testes com SLURM no Cluster Franky; compara\u00e7\u00e3o de desempenho em diferentes filas. 18/ago (seg) Aula 03 Hierarquia de mem\u00f3ria (L1, L2, L3); t\u00e9cnica de Tiling (fateamento em blocos); princ\u00edpios de localidade espacial e temporal Aplicar tiling para melhorar o uso de cache; reorganizar estruturas de dados para melhor localidade. 22/ago (sex) Aula 04 Aleatoriedade, heur\u00edsticas, aloca\u00e7\u00e3o de mem\u00f3ria Ajustes em heur\u00edsticas, estrutura de dados e uso da mem\u00f3ria de forma eficiente. 25/ago (seg) Aula 05 Paralelismo em CPU; threads; cores; OpenMP; vari\u00e1veis privadas e compartilhadas; scheduling Paralelismo com OpenMP; compartilhamento entre threads; efeitos do scheduler. 29/ago (sex) Aula 06 Efeitos colaterais do paralelismo; racing conditions; depend\u00eancias; recurs\u00e3o Estudo de caso: mapear problemas, levantar hip\u00f3teses de otimiza\u00e7\u00e3o e comparar desempenho. 01/set (seg) Aula 07 Mem\u00f3ria distribu\u00edda; comunica\u00e7\u00e3o com MPI; ponto-a-ponto e coletiva; grupos e comunicadores Paralelismo com MPI; comunica\u00e7\u00e3o entre n\u00f3s. 05/set (sex) Aula 08 Estrat\u00e9gias h\u00edbridas MPI + OpenMP Estudo de caso com MPI + OpenMP, levantamento de gargalos e poss\u00edveis otimiza\u00e7\u00f5es. 08/set (seg) Aula 09 Aula est\u00fadio Suporte ao Projeto 1 \u2013 Minera\u00e7\u00e3o de criptomoedas em CPU 12/set (sex) Aula 10 Palestra NVIDIA - CUDA Palestra NVIDIA - CUDA 15/set (seg) Aula 11 Aula est\u00fadio Suporte ao Projeto 1 \u2013 Minera\u00e7\u00e3o de criptomoedas em CPU 19/set (sex) Aula 12 Devolutiva do Projeto 1 Discuss\u00e3o das solu\u00e7\u00f5es apresentadas e feedback. 22/set (seg) Aula 13 Aula est\u00fadio Ajustes finais no Projeto 1 \u2013 Minera\u00e7\u00e3o de criptomoedas em CPU 26/set (sex) Aula 14 Prova Intermedi\u00e1ria Avalia\u00e7\u00e3o dos conte\u00fados at\u00e9 Estrat\u00e9gias h\u00edbridas MPI + OpenMP. 29/set (seg) Aula 15 Profiling em GPU; warps e SIMD; diverg\u00eancia; aloca\u00e7\u00e3o de mem\u00f3ria Atividade pr\u00e1tica de Profiling em GPU, an\u00e1lise de diverg\u00eancias e uso de mem\u00f3ria. 06/out (seg) Aula 16 Histogramming; data race em GPU; atomic; throughput Estudo de caso aplicado. 10/out (sex) Aula 17 T\u00e9cnicas stencil; convolu\u00e7\u00e3o; tile boundaries; agendamento de threads Estudo de caso aplicado. 13/out (seg) Aula 18 Estabilidade num\u00e9rica; ponto flutuante; controle de erro Estudo de caso aplicado. 17/out (sex) Aula 19 Estrat\u00e9gias h\u00edbridas com MPI + CUDA; gerenciamento de dados Atividade pr\u00e1tica com m\u00faltiplas GPUs. 20/out (seg) Aula 20 Resumo das estrat\u00e9gias de otimiza\u00e7\u00e3o; discuss\u00e3o sobre aplica\u00e7\u00e3o em projeto Discuss\u00e3o coletiva de estrat\u00e9gias de otimiza\u00e7\u00e3o. 24/out (sex) Aula 21 Apresenta\u00e7\u00e3o do Projeto 2 Discuss\u00e3o sobre estrat\u00e9gias de otimiza\u00e7\u00e3o para aplica\u00e7\u00e3o no projeto. 27/out (seg) Aula 22 Aula est\u00fadio Suporte ao Projeto 2 \u2013 Minera\u00e7\u00e3o de criptomoedas em GPU 31/out (sex) Aula 23 Palestra NVIDIA \u2013 OpenACC Introdu\u00e7\u00e3o ao OpenACC 03/nov (seg) Aula 24 Aula est\u00fadio Suporte ao Projeto 2 \u2013 Minera\u00e7\u00e3o de criptomoedas em GPU 07/nov (sex) Aula 25 Aula est\u00fadio Suporte ao Projeto 2 \u2013 Minera\u00e7\u00e3o de criptomoedas em GPU 10/nov (seg) Aula 26 Devolutiva do Projeto 2 Ajustes finais ap\u00f3s feedback ao Projeto 2 14/nov (sex) Aula 27 Simulado da Avalia\u00e7\u00e3o Final Revis\u00e3o pr\u00e1tica. 17/nov (seg) Aula 28 Avalia\u00e7\u00e3o Final Avalia\u00e7\u00e3o Final 24/nov (seg) Aula 29 Avalia\u00e7\u00e3o Final Encerramento e avalia\u00e7\u00e3o final Atividades (Individual) 15% Percentual de Atividades Conceito Com Participa\u00e7\u00e3o Volunt\u00e1ria 50% C C+ 70% B B+ 90% A A+ Projeto 1 (Grupo) 10% Projeto 2 (Individual) 20% <p>Projeto Minerador em GPU  Neste projeto, o foco \u00e9 explorar o uso de paralelismo e estrat\u00e9gias de otimiza\u00e7\u00e3o em GPU para maximizar o desempenho computacional.</p> <p>Objetivos principais:</p> <ul> <li> <p>Executar o projeto utilizando o sistema de HPC SDumont, do LNCC;</p> </li> <li> <p>Implementar estrat\u00e9gias de paralelismo e distribui\u00e7\u00e3o em GPUs;</p> </li> <li> <p>Aumentar a dificuldade da minera\u00e7\u00e3o (n\u00famero de zeros);</p> </li> <li> <p>Comparar desempenho, efici\u00eancia e consumo de recursos entre as vers\u00f5es CPU e GPU;</p> </li> </ul>"},{"location":"sobre/#mineracao-de-criptomoedas-em-cpu","title":"Minera\u00e7\u00e3o de criptomoedas em CPU","text":"<p>Este projeto consiste na implementa\u00e7\u00e3o e otimiza\u00e7\u00e3o de um minerador de criptomoedas que roda em CPU. Aplicando t\u00e9cnicas de paralelismo para melhorar desempenho no cluster Franky. A dificuldade da minera\u00e7\u00e3o \u00e9 ajustada pela quantidade de zeros no hash, aumentando o desafio computacional conforme otimizimos a aplica\u00e7\u00e3o.</p> Rubrica Crit\u00e9rios T\u00e9cnicos C Executa o c\u00f3digo minerador ass\u00edncrono no cluster Franky com dificuldade **5 zeros e pelo menos 5 gera\u00e7\u00f5es diferentes de async_gen`. B Executa o c\u00f3digo minerador ass\u00edncrono no cluster Franky com dificuldade 6 zeros e pelo menos 5 gera\u00e7\u00f5es diferentes de <code>async_gen</code>; utiliza paralelismo ou distribui\u00e7\u00e3o do c\u00f3digo em CPU. A Executa o c\u00f3digo minerador ass\u00edncrono no cluster Franky com dificuldade 7 zeros e pelo menos 5 gera\u00e7\u00f5es diferentes de <code>async_gen</code>; realiza paraleliza\u00e7\u00e3o e distribui\u00e7\u00e3o do c\u00f3digo em CPU."},{"location":"sobre/#entrega","title":"Entrega","text":"<p>C\u00f3digo-fonte funcional, comentado e documentado. Relat\u00f3rio t\u00e9cnico com: </p> <ul> <li>Diagn\u00f3stico dos gargalos;</li> <li>Proposta de otimiza\u00e7\u00e3o;</li> <li>Hip\u00f3tese de melhoria;</li> <li>Implementa\u00e7\u00e3o da hip\u00f3tese;</li> <li>Compara\u00e7\u00e3o de desempenho;</li> <li>Discuss\u00e3o dos resultados.</li> </ul>"},{"location":"sobre/#bonus-por-qualidade","title":"B\u00f4nus por Qualidade","text":"Conceito Base Com B\u00f4nus C C+ B B+ A A+"},{"location":"sobre/#rubrica-de-avaliacao","title":"R\u00fabrica de Avalia\u00e7\u00e3o","text":"N\u00edvel Crit\u00e9rios T\u00e9cnicos Complexidade Computacional Esperado R\u00fabrica C Parte da otimiza\u00e7\u00e3o realizada em CPU e parte implementada em GPU, executada no SDumont 7 zeros R\u00fabrica B Paralelismo e distribui\u00e7\u00e3o em CPU, com parte da otimiza\u00e7\u00e3o feita em GPU, utilizando o SDumont 8 zeros R\u00fabrica A Paralelismo e distribui\u00e7\u00e3o focados principalmente em GPU, com tarefas simples executadas em CPU, utilizando o sistema SDumont 9 zeros"},{"location":"sobre/#entrega_1","title":"Entrega","text":"<p>C\u00f3digo-fonte funcional, comentado e documentado. Relat\u00f3rio t\u00e9cnico com: </p> <ul> <li>Diagn\u00f3stico dos gargalos;</li> <li>Proposta de otimiza\u00e7\u00e3o;</li> <li>Hip\u00f3tese de melhoria;</li> <li>Implementa\u00e7\u00e3o da hip\u00f3tese;</li> <li>Compara\u00e7\u00e3o de desempenho;</li> <li>Discuss\u00e3o dos resultados.</li> </ul>"},{"location":"sobre/#bonus-por-qualidade_1","title":"B\u00f4nus por Qualidade","text":"Conceito Base Com B\u00f4nus C C+ B B+ A A+"},{"location":"aulas/aula01/","title":"Aula 01 - Problemas de HPC","text":"<p>Durante a aula, vimos que problemas computacionalmente complexos podem ser:</p> <ul> <li> <p>Grandes: uma quantidade de dados absurda, que n\u00e3o cabe em um computador de trabalho comum</p> </li> <li> <p>Intensivo: Realiza calculos complexos e demorados, demandando horas ou dias de processamento intensivo</p> </li> <li> <p>Combo: As vezes o problema tem as duas caracteristicas, tem uma grande quantidade de dados, demanda c\u00e1lculos intesivos.</p> </li> </ul> <p>Para resolver problemas desse tipo, precisamos fazer um bom uso do hardware, podemos come\u00e7ar usando uma linguagem de programa\u00e7\u00e3o mais eficiente e planejando melhor o nosso c\u00f3digo, usando as caracter\u00edsticas da linguagem a nosso favor.</p> <p>Conte\u00fado te\u00f3rico de apoio - Aula 01</p> <p>Eu fui legal e organizei aqui tudo aqui pra voc\u00ea!</p>"},{"location":"aulas/aula01/#atividade-01-python-x-c","title":"Atividade 01 \u2014 Python x C++","text":"<p>Voc\u00ea est\u00e1 trabalhando com sensores industriais que geram milh\u00f5es de medi\u00e7\u00f5es por dia, como temperatura, press\u00e3o e vibra\u00e7\u00e3o. Monitorar apenas a \u00faltima medi\u00e7\u00e3o n\u00e3o \u00e9 confi\u00e1vel: leituras oscilam naturalmente devido a ru\u00eddos ou pequenas flutua\u00e7\u00f5es.</p> <p>Para obter informa\u00e7\u00f5es mais est\u00e1veis e \u00fateis, usamos m\u00e9dias m\u00f3veis: ao inv\u00e9s de olhar um valor isolado, olhamos a tend\u00eancia local dos dados.</p> <p>Exemplo: Se a temperatura medida for <code>[85.1, 84.9, 85.0, 93.2, 85.1, 85.0]</code>, um \u00fanico pico (93.2) poderia gerar alarme falso. A m\u00e9dia m\u00f3vel suaviza esse ru\u00eddo.</p>"},{"location":"aulas/aula01/#desafio","title":"Desafio","text":"<p>Simular o processamento de dados de sensores, implementando o c\u00e1lculo da m\u00e9dia m\u00f3vel simples. A partir disso, comparar diferentes vers\u00f5es do c\u00f3digo para analisar os ganhos de desempenho obtidos com otimiza\u00e7\u00f5es e com o uso dos recursos da linguagem C++.</p> <p>Implementa\u00e7\u00e3o em Python <pre><code>import time\nimport random\n\n# N = 100 milh\u00f5es de leituras\nN = 100_000_000\n\n# Janela K = 10\nK = 10\n\n# Gera os dados\nstart_gen = time.time()\ndados = [random.uniform(12.0, 189.98) for _ in range(N)]\nprint(\"Tempo para gerar os dados:\", time.time() - start_gen)\n\n# Calcula m\u00e9dia m\u00f3vel\nstart_avg = time.time()\nmedia = []\nsoma = sum(dados[:K])\nmedia.append(soma / K)\n\nfor i in range(1, N - K):\n    soma = soma - dados[i - 1] + dados[i + K - 1]\n    media.append(soma / K)\n\nprint(\"Tempo para calcular m\u00e9dia m\u00f3vel:\", time.time() - start_avg)\n</code></pre></p> <ol> <li> <p>Fa\u00e7a um c\u00f3digo em c+++ que gera um vetor com <code>100000000</code> valores de leitura do tipo <code>double</code>, variando entre <code>12.0</code> e <code>189.98</code></p> </li> <li> <p>Implemente o c\u00e1lculo da m\u00e9dia m\u00f3vel simples com janela <code>k = 10</code>, ou seja:</p> </li> </ol> <p>$$    M_i = \\frac{1}{k} \\sum_{j=i}^{i+k-1} v_j    $$</p> <ol> <li>Fa\u00e7a a passagem dos dados para o c\u00e1lculo da m\u00e9dia m\u00f3vel simples de 3 formas diferentes:</li> <li>Passagem por valor</li> <li>Passagem por refer\u00eancia</li> <li> <p>Passagem por ponteiro</p> </li> <li> <p>Use <code>const</code> para garantir seguran\u00e7a e desempenho (const correctness) onde fizer sentido.</p> </li> <li> <p>Compile usando diferentes flags de otimiza\u00e7\u00e3o:</p> </li> <li> <p>Me\u00e7a e compare os tempos de execu\u00e7\u00e3o</p> </li> <li> <p>Compare com a implementa\u00e7\u00e3o em python.</p> </li> </ol> <p>Esqueleto do c\u00f3digo \u2013 <code>media.cpp</code></p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\n\n// =========================================\n// Constantes globais\n// =========================================\nconst size_t N = 100'000'000; // N\u00famero total de amostras\nconst size_t K = 10;          // Tamanho da janela da m\u00e9dia m\u00f3vel\n\n// =========================================\n// Fun\u00e7\u00e3o para gerar um vetor com valores aleat\u00f3rios\n// =========================================\nvector&lt;double&gt; gerar_leituras(size_t tamanho) {\n    // TODO: Criar um vetor de tamanho `tamanho`\n    // TODO: Criar gerador de n\u00fameros aleat\u00f3rios com seed fixa\n    // TODO: Definir distribui\u00e7\u00e3o entre 12.0 e 189.98\n    // TODO: Preencher o vetor com n\u00fameros aleat\u00f3rios\n\n    // DICA: use std::vector&lt;double&gt; e uniform_real_distribution\n\n    return {}; // Substitua pelo vetor preenchido\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por valor)\n// =========================================\nvector&lt;double&gt; media_movel_por_valor() {\n    // TODO: Calcular a m\u00e9dia m\u00f3vel simples sobre o vetor recebido por valor\n    // TODO: Retornar um vetor com os resultados\n\n    return {};\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por refer\u00eancia)\n// =========================================\nvector&lt;double&gt; media_movel_por_referencia() {\n    // TODO: Igual \u00e0 vers\u00e3o anterior, mas recebendo os dados por refer\u00eancia constante\n\n    return {};\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para calcular a m\u00e9dia m\u00f3vel (passagem por ponteiro)\n// =========================================\nvector&lt;double&gt; media_movel_por_ponteiro() {\n    // TODO: Usar aritm\u00e9tica de ponteiros para calcular a m\u00e9dia m\u00f3vel\n    // TODO: Retornar um vetor com os resultados\n\n    return {};\n}\n\n// =========================================\n// Fun\u00e7\u00e3o para medir tempo de execu\u00e7\u00e3o\n// =========================================\ntemplate &lt;typename Func, typename... Args&gt;\ndouble medir_tempo(Func funcao, Args&amp;&amp;... args) {\n    auto inicio = chrono::high_resolution_clock::now();\n    funcao(forward&lt;Args&gt;(args)...);\n    auto fim = chrono::high_resolution_clock::now();\n    chrono::duration&lt;double&gt; duracao = fim - inicio;\n    return duracao.count();\n}\n\n// =========================================\n// Fun\u00e7\u00e3o principal\n// =========================================\nint main() {\n    // Etapa 1: Gerar os dados\n    cout &lt;&lt; \"Gerando dados...\" &lt;&lt; endl;\n    vector&lt;double&gt; leituras = gerar_leituras(N);\n\n    // Etapa 2: C\u00e1lculo por valor\n    cout &lt;&lt; \"M\u00e9dia m\u00f3vel (por valor):\" &lt;&lt; endl;\n    double tempo_valor = medir_tempo(media_movel_por_valor, leituras, K);\n    cout &lt;&lt; \"\u2192 Tempo: \" &lt;&lt; tempo_valor &lt;&lt; \" s\" &lt;&lt; endl;\n\n    // Etapa 3: C\u00e1lculo por refer\u00eancia\n    cout &lt;&lt; \"M\u00e9dia m\u00f3vel (por refer\u00eancia):\" &lt;&lt; endl;\n    double tempo_ref = medir_tempo(media_movel_por_referencia, leituras, K);\n    cout &lt;&lt; \"\u2192 Tempo: \" &lt;&lt; tempo_ref &lt;&lt; \" s\" &lt;&lt; endl;\n\n    // Etapa 4: C\u00e1lculo por ponteiro\n    cout &lt;&lt; \"M\u00e9dia m\u00f3vel (por ponteiro):\" &lt;&lt; endl;\n    const double* ptr = leituras.data();\n    double tempo_ptr = medir_tempo(media_movel_por_ponteiro, ptr, N, K);\n    cout &lt;&lt; \"\u2192 Tempo: \" &lt;&lt; tempo_ptr &lt;&lt; \" s\" &lt;&lt; endl;\n\n    // Etapa 5: Compile com diferentes flags e compare os tempos\n    // Exemplo:\n    //   g++ media.cpp -o sem_otimizacao\n    //   g++ -O2 media.cpp -o otimizacao_O2\n    //   g++ -O3 media.cpp -o otimizacao_O23\n    //   g++ -Ofast media.cpp -o otimizacao_Ofast\n    return 0;\n}\n</code></pre>"},{"location":"aulas/aula01/#entrega-da-atividade-01","title":"Entrega da Atividade 01","text":"<p>No arquivo README.md do Classroom, inclua:</p> <ul> <li> <p>C\u00f3digo-fonte em C++: o programa utilizado para os testes. </p> </li> <li> <p>Tabela comparativa: com os resultados de todas as execu\u00e7\u00f5es</p> </li> <li> <p>Gr\u00e1fico comparativo: representando visualmente os resultados obtidos.</p> </li> <li> <p>An\u00e1lise de desempenho: coment\u00e1rios explicando quais fatores influenciaram o desempenho</p> </li> </ul> <p>Entrega at\u00e9 quinta 23h59 pelo link do GitHub Classroom</p> <p>Lembre-se de preencher o foruml\u00e1rio para criar o seu acesso ao Cluster Franky, ele ser\u00e1 usado a partir da pr\u00f3xima aula!</p> <p>Dica!</p> <p>Lembre-se de consultar o material dispon\u00edvel em Conte\u00fado te\u00f3rico de apoio - Aula 01</p> <p>Links \u00fateis</p> <p>Rand\u00f4micos aqui, aqui e aqui Vetores aqui e aqui Passagem de valor por refer\u00eancia - aqui e aqui Ponteiros aqui e aqui Aritim\u00e9tica de ponteiros</p>"},{"location":"aulas/aula02/","title":"Aula 02: Acessando o Cluster Franky","text":"<p>Na Atividade 2, voc\u00ea ir\u00e1 executar as implementa\u00e7\u00f5es que foram testadas na Atividade 1, mas agora no ambiente de um cluster HPC usando SLURM. O objetivo \u00e9 observar como o ambiente de cluster, com suas diferentes arquiteturas de hardware, pode impactar o desempenho das opera\u00e7\u00f5es computacionalmente intensivas que voc\u00ea j\u00e1 explorou.</p>"},{"location":"aulas/aula02/#parte-0-configurando-seu-acesso-ao-cluster-franky","title":"Parte 0: Configurando seu acesso ao Cluster Franky","text":"<p>Para ter acesso ao Cluster Franky voc\u00ea precisa configurar suas credenciais de acesso e realizar acesso remoto via SSH.</p> <p>As chaves foram enviadas para o seu email Insper, Fa\u00e7a o download da pasta completa, que cont\u00e9m os arquivos <code>id_rsa</code> (chave privada) e <code>id_rsa.pub</code> (chave p\u00fablica). Dependendo do sistema operacional que voc\u00ea utiliza, siga as instru\u00e7\u00f5es abaixo para configurar corretamente seu acesso ao cluster Franky.</p>"},{"location":"aulas/aula02/#para-macbook-ou-linux","title":"Para Macbook ou Linux:","text":"<p>Abra o terminal, navegue at\u00e9 a pasta onde a chave privada (<code>id_rsa</code>) foi baixada, mova a chave para o diret\u00f3rio <code>.ssh</code> em sua home:</p> <pre><code>mv id_rsa ~/.ssh/\n</code></pre> <p>Garanta que apenas voc\u00ea possa ler o arquivo:</p> <pre><code>chmod 400 ~/.ssh/id_rsa\n</code></pre> <p>Conecte-se ao cluster utilizando o comando SSH:</p> <p>O login \u00e9 o seu \"usuario Insper\", o endere\u00e7o de IP foi fornecido durante a aula.</p> <p><pre><code>ssh -i ~/.ssh/id_rsa login@ip_do_cluster\n</code></pre> ou</p> <pre><code>ssh login@ip_do_cluster\n</code></pre>"},{"location":"aulas/aula02/#para-windows","title":"Para Windows:","text":"<p>Usando MobaXTerm</p> <p>Baixe o MobaXterm Home Edition em: https://mobaxterm.mobatek.net/download-home-edition.html</p> <p>Execute a aplica\u00e7\u00e3o, com o MobaXterm aberto, clique em Session, depois em SSH. </p> <p>Preencha todos os campos marcados em vermelho </p> <p>Estabele\u00e7a a conex\u00e3o, se tudo der certo, voc\u00ea ver\u00e1 algo como: </p>"},{"location":"aulas/aula02/#configurar-o-vs-code-para-acesso-remoto-ao-cluster","title":"Configurar o VS Code para Acesso Remoto ao Cluster","text":"<p>Instale a Extens\u00e3o Remote - SSH:</p> <p>Abra o VS Code, v\u00e1 para a aba de extens\u00f5es (\u00edcone de quadrado no lado esquerdo). Pesquise por \"Remote - SSH\" e instale a extens\u00e3o oficial da Microsoft.</p> <p>Configurar o Acesso Remoto:</p> <p>Pressione <code>Ctrl+Shift+P</code> (ou <code>Cmd+Shift+P</code> no Mac) para abrir o painel de comandos.</p> <p>Digite <code>Remote-SSH: Add New SSH Host...</code> e selecione a op\u00e7\u00e3o.</p> <p>Insira o comando SSH para conex\u00e3o com o Franky: <pre><code>ssh -i Endere\u00e7o_da_cahve/id_rsa login@ip_do_cluster\n</code></pre> Escolha o arquivo de configura\u00e7\u00e3o padr\u00e3o (<code>~/.ssh/config</code> para Mac/Linux ou <code>C:\\Users\\seu_usuario\\.ssh\\config</code> para Windows).</p> <p>Pressione <code>Ctrl+Shift+P</code> (ou <code>Cmd+Shift+P</code> no Mac) novamente e digite <code>Remote-SSH: Connect to Host...</code>. Selecione o host configurado.</p> <p>O VS Code abrir\u00e1 uma nova janela conectada ao ambiente remoto do cluster.</p> <p></p> <p>Gerenciar Projetos Remotamente:</p> <p>Ap\u00f3s a conex\u00e3o, voc\u00ea pode abrir pastas e arquivos no cluster diretamente pelo VS Code.</p> <p>Voc\u00ea pode utilizar os recursos do VS Code, como o terminal integrado e o debug para trabalhar no cluster Franky.</p>"},{"location":"aulas/aula02/#executando-a-atividade-no-cluster-franky-usando-slurm","title":"Executando a Atividade no Cluster Franky usando SLURM","text":"<p>Um arquivo .slurm \u00e9 usado para \"lan\u00e7ar jobs\" no sistema SLURM, especificando os recursos necess\u00e1rios para a execu\u00e7\u00e3o, como mem\u00f3ria, n\u00famero de m\u00e1quinas e n\u00facleos. Nesse arquivo, tamb\u00e9m definimos como desejamos o output do execut\u00e1vel e onde o sistema pode encontrar o arquivo a ser executado. Como a equipe que gerencia o Cluster definiu que os jobs sejam lan\u00e7ados apenas da pasta SCRATCH, podemos omitir o caminho do arquivo nos nossos arquivos .slurm.</p> <p>Warning</p> <p>Quando voc\u00ea escreve um script para ser executado pelo SLURM o gerenciador de jobs SLURM interpreta <code>#SBATCH</code> como diretivas que definem como o job deve ser executado.</p>"},{"location":"aulas/aula02/#conhecendo-o-sistema","title":"Conhecendo o Sistema","text":"<p>Antes de come\u00e7ar a fazer pedidos de recursos pro SLURM, vamos conhecer os diferentes hardwares que temos dispon\u00edvel no Franky. Vamos utilizar alguns comandos de sistema operacional para ler os recursos de CPU, mem\u00f3ria e GPU dispon\u00edveis</p>"},{"location":"aulas/aula02/#comandos-utilizados","title":"Comandos utilizados","text":"<ul> <li><code>lscpu</code>: mostra detalhes da CPU (n\u00facleos, threads, mem\u00f3ria cache...)</li> <li><code>cat /proc/meminfo</code>: mostra detalhes sobre a mem\u00f3ria RAM </li> <li><code>nvidia-smi</code>: mostra detalhes de GPU, se dispon\u00edvel</li> </ul>"},{"location":"aulas/aula02/#comando-srun","title":"Comando SRUN","text":"<pre><code>srun --partition=normal --ntasks=1 --cpus-per-task=1 --mem=1G --time=00:05:00 \\\n--pty bash -c \"hostname &amp;&amp; \\\ncat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' &amp;&amp; \\\nlscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache' &amp;&amp; \\\n{ command -v nvidia-smi &amp;&gt; /dev/null &amp;&amp; nvidia-smi || echo 'nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada'; }\" \n</code></pre> <p>Voc\u00ea deve ver algo como:</p> <p></p> <p><code>srun</code></p> <p>\u00c9 o comando do SLURM usado para executar uma tarefa interativamente em um n\u00f3 do cluster.</p> <p><code>--partition=normal</code></p> <p>Indica em qual fila (parti\u00e7\u00e3o) o job ser\u00e1 executado. No seu caso, <code>normal</code> pode ser substitu\u00eddo por qualquer outra fila do sistema</p> <p><code>--ntasks=1</code></p> <p>Solicita 1 tarefa (processo). Se voc\u00ea estivesse rodando um c\u00f3digo paralelo, faz sentido trocar esse valor.</p> <p><code>--cpus-per-task=1</code></p> <p>Cada tarefa receber\u00e1 1 CPU (core). Quando estiver usando paralelismo com v\u00e1rias threads , faz sentido aumentar esse valor.</p> <p><code>--mem=1G</code></p> <p>Aloca 1 gigabyte de mem\u00f3ria RAM para essa tarefa. Se ultrapassar esse limite, o job ser\u00e1 encerrado.</p> <p><code>--time=00:05:00</code></p> <p>Define um tempo m\u00e1ximo de execu\u00e7\u00e3o de 5 minutos. Depois disso, o SLURM mata o processo automaticamente.</p> <p><code>--pty bash</code></p> <p>Solicita um terminal para o SLURM dentro do n\u00f3 de computa\u00e7\u00e3o. Interessante para fazer testes no c\u00f3digo ou realizar debugs</p> <p><code>{ command -v nvidia-smi &amp;&gt; /dev/null &amp;&amp; nvidia-smi || echo 'nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada'; }</code></p> <p>Esse trecho verifica se o comando <code>nvidia-smi</code> est\u00e1 dispon\u00edvel no sistema (ou seja, se h\u00e1 driver NVIDIA instalado e uma GPU NVIDIA acess\u00edvel).</p> <ul> <li>Se <code>nvidia-smi</code> estiver dispon\u00edvel, ele ser\u00e1 executado e mostrar\u00e1 as informa\u00e7\u00f5es da(s) GPU(s) no n\u00f3 (como nome, mem\u00f3ria, uso, driver etc).</li> <li>Se n\u00e3o estiver dispon\u00edvel (por exemplo, em n\u00f3s sem GPU ou sem driver instalado), exibir\u00e1 a mensagem:   <code>\"nvidia-smi n\u00e3o dispon\u00edvel ou GPU n\u00e3o detectada\"</code>.</li> </ul> <p>Tip</p> <ul> <li>Em n\u00f3s CPU-only (como os da parti\u00e7\u00e3o <code>normal</code>), \u00e9 esperado que <code>nvidia-smi</code> n\u00e3o esteja presente.</li> <li>Para testar o comando em um n\u00f3 com GPU, use <code>--partition=gpu</code> ou <code>--partition=monstrao</code>  para alocar n\u00f3s com placas NVIDIA.</li> </ul> <p>O comando abaixo faz exatamente a mesma coisa, mas eu coloquei ele dentro de um shell script para ter uma formata\u00e7\u00e3o melhor no display:</p> <pre><code>srun --partition=normal --ntasks=1 --pty bash -c \\\n\"echo '=== HOSTNAME ==='; hostname; echo; \\\n echo '=== MEMORIA (GB) ==='; \\\n cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' | \\\n awk '{printf \\\"%s %.2f GB\\\\n\\\", \\$1, \\$2 / 1048576}'; \\\n echo; \\\n echo '=== CPU INFO ==='; \\\n lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\n echo '=== GPU INFO ==='; \\\n if command -v nvidia-smi &amp;&gt; /dev/null; then nvidia-smi; else echo 'nvidia-smi n\u00e3o dispon\u00edvel'; fi\"\n</code></pre> <p></p> <p>O comando <code>sinfo</code> mostra quais s\u00e3o as filas e quais s\u00e3o os status dos n\u00f3s </p> <p><pre><code>sinfo\n</code></pre> O comando abaixo mostra detalhes sobre os recursos de cada fila</p> <pre><code>scontrol show partition\n</code></pre> <p>Recomendo que voc\u00ea mude o nome da fila (partition) no comando abaixo para se ambientar no Cluster Franky e desconrir quais s\u00e3o as diferen\u00e7as entre as filas</p> <pre><code>srun --partition=normal --ntasks=1 --cpus-per-task=1 --mem=1G --time=00:05:00 \\\n     --pty bash -c \"hostname &amp;&amp; cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' &amp;&amp; lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\"\n</code></pre>"},{"location":"aulas/aula02/#atividade-02","title":"Atividade 02","text":"<p>Na aula passada n\u00f3s vimos que a linguagem importa, al\u00e9m disso, existem recursos da linguagem que tem o poder de acelerar o nosso c\u00f3digo, e mais ainda, podemos usar otimiza\u00e7\u00f5es a n\u00edvel de compila\u00e7\u00e3o para ir al\u00e9m e conseguir uma otimiza\u00e7\u00e3o ainda maior. Agora vamos executar os scripts da aula passada no Cluster Franky para verificar o quanto o hardware impacta nessa abordagem, como ser\u00e1 que ficar\u00e1 o desempenho ao executar os c\u00f3digos em diferentes arquiteturas de computadores?</p> <p>Vamos utilizar o SLURM para pedir recursos computacionais do nosso Cluster, agora que voc\u00ea ja conhece o hardware que tem em cada fila, fa\u00e7a as suas escolhas de recursos e teste o seu c\u00f3digo!</p> <p>Script SLURM para o c\u00f3digo em Python:</p> <p>media_py.slurm</p> <pre><code>#!/bin/bash\n#As instru\u00e7\u00f5es SBATCH n\u00e3o devem ser descomentadas\n\n#SBATCH --job-name=OLHA_EU\n# define o nome do job. Esse nome aparece nas listas de jobs e \u00e9 \u00fatil para identificar o job.\n\n#SBATCH --output=media_py%j.out\n# Especifica o arquivo onde a sa\u00edda padr\u00e3o (stdout) do job ser\u00e1 salva.\n\n#SBATCH --ntasks=1\n# Define o n\u00famero de tarefas que o job executar\u00e1. Neste caso, o job executa uma \u00fanica tarefa.\n\n#SBATCH --time=00:10:00\n# Define o tempo m\u00e1ximo de execu\u00e7\u00e3o para o job. Neste caso, o job tem um tempo limite de 10 minutos. Se o job exceder esse tempo, ele ser\u00e1 automaticamente encerrado.\n\n#SBATCH --partition=normal\n# Especifica a parti\u00e7\u00e3o (ou fila) onde o job ser\u00e1 submetido. Aqui.\n\ntime python3 media_movel.py\n#Executa o programa dentro do n\u00f3 de computa\u00e7\u00e3o.\n</code></pre> <p>Script SLURM para arquivos C++:</p> <p>Como o C++ \u00e9 uma linguagem que requer compila\u00e7\u00e3o, precisamos gerar o execut\u00e1vel antes de preparar o arquivo .slurm.</p> <p>Dentro da pasta SCRATCH, compile seu c\u00f3digo .cpp para gerar o bin\u00e1rio.</p> <pre><code>g++ media_movel.cpp -o sem_otimizacao\ng++ -O2 media_movel.cpp -o otimizacao_O2\ng++ -O3 media_movel.cpp -o otimizacao_O3\ng++ -Ofast media_movel.cpp -o otimizacao_Ofast\n</code></pre> <p>media_cpp.slurm <pre><code>#!/bin/bash\n#SBATCH --job=OI_GALERA\n# Define o nome do job. Esse nome aparece nas listas de jobs e \u00e9 \u00fatil para identificar o job.\n\n#SBATCH --output=media_cpp%j.out\n# Especifica o arquivo onde a sa\u00edda padr\u00e3o (stdout) do job ser\u00e1 salva.\n\n#SBATCH --ntasks=1\n# Define o n\u00famero de tarefas que o job executar\u00e1. Neste caso, o job executa uma \u00fanica tarefa.\n\n#SBATCH --time=00:10:00\n# Define o tempo m\u00e1ximo de execu\u00e7\u00e3o para o job. Neste caso, o job tem um tempo limite de 10 minutos. Se o job exceder esse tempo, ele ser\u00e1 automaticamente encerrado.\n\n#SBATCH --partition=normal\n# Especifica a parti\u00e7\u00e3o (ou fila) onde o job ser\u00e1 submetido. Aqui, o job ser\u00e1 submetido a fila \"normal\".\n\n\necho \"========== SEM OTIMIZACAAAOOOO ========\"\ntime ./sem_otimizacao\n\necho \"========= OTIMIZACAO 02 ===============\"\ntime ./otimizacao_O2\n\necho \"======== OTIMIZACAO O3 ===============\"\ntime ./otimizacao_O3\n\necho \"=========== OFAST ESSA ===============\"\ntime ./otimizacao_Ofast\n\n# Executa os bin\u00e1rios dentro do n\u00f3 de computa\u00e7\u00e3o.\n</code></pre></p>"},{"location":"aulas/aula02/#parte-2-execucao-das-implementacoes-no-cluster","title":"Parte 2: Execu\u00e7\u00e3o das Implementa\u00e7\u00f5es no Cluster","text":"<p>Submiss\u00e3o dos Jobs:</p> <p>Utilize o comando <code>sbatch</code> para submeter cada script SLURM ao cluster.</p> <p>Exemplo:</p> <pre><code>sbatch media_py.slurm\nsbatch media_cpp.slurm\n</code></pre> <p>Monitoramento dos Jobs:</p> <p>Use o comando <code>squeue</code> para monitorar o status dos jobs.</p> <p>Exemplo:</p> <pre><code>squeue \n</code></pre> <p>An\u00e1lise dos Resultados:</p> <p>Ap\u00f3s a execu\u00e7\u00e3o dos jobs, os resultados estar\u00e3o dispon\u00edveis nos arquivos <code>.out</code>  especificados em cada script SLURM.</p> <ul> <li> <p>Compare os tempos de execu\u00e7\u00e3o dos programas no cluster.</p> </li> <li> <p>Troque a fila de submiss\u00e3o no arquivo .slurm e compare o desempenho dos programas novamente</p> </li> <li> <p>Analise como as diferentes arquiteturas de hardware dentro do cluster impactam o desempenho do c\u00f3digo, compare tamb\u00e9m com os seus resultados obtidos na atividade 1, executando na sua m\u00e1quina local.</p> </li> </ul> <p>Tip</p> <p>Se quiser explorar mais os comandos do SLURM, temos uma material aqui que pode te ajudar</p> <p>Links \u00fateis</p> <p>Guia do Slurm - CENAPAD Documenta\u00e7\u00e3o Oficial SLURM Guia de Comandos SLURM</p>"},{"location":"aulas/aula02/#esta-atividade-nao-tem-entrega-bom-final-de-semana","title":"Esta atividade n\u00e3o tem entrega, Bom final de semana!","text":""},{"location":"aulas/aula03/","title":"Aula 03 - Otimiza\u00e7\u00e3o e Tiling","text":""},{"location":"aulas/aula03/#objetivo","title":"Objetivo","text":"<p>Explorar t\u00e9cnicas de otimiza\u00e7\u00e3o de c\u00f3digo sequencial em C++ a partir da an\u00e1lise de desempenho. O foco ser\u00e1:</p> <ul> <li>Compreender a rela\u00e7\u00e3o entre hierarquia de mem\u00f3ria (L1, L2, L3) e desempenho.</li> <li>Aplicar tiling (fateamento em blocos) para melhorar o aproveitamento da mem\u00f3ria cache.</li> <li>Reorganizar estruturas de dados para um melhor aproveitamento do principio da localidade espacial.</li> </ul>"},{"location":"aulas/aula03/#contexto","title":"Contexto","text":"<p>Vamos tomar como base o hardware do monstr\u00e3o, ele tem um processador Intel Xeon Gold 5215, que possui:</p> <ul> <li>L1d cache: 32 KiB por n\u00facleo</li> <li>L2 cache: 1 MiB por n\u00facleo</li> <li>L3 cache: 13.75 MiB por socket</li> </ul> <p>Na multiplica\u00e7\u00e3o de matrizes, o maior gargalo costuma se o acesso a mem\u00f3ria. Para otimizar o desempenho de um algoritmo como esse,  dividimos a matriz em blocos que cabem na mem\u00f3ria cache, porque ela \u00e9 a que est\u00e1 mais proxima da CPU. No nosso caso, cada submatriz de tamanho <code>B\u00d7B</code> precisa caber na cache junto com mais dois blocos (A, B e C). A f\u00f3rmula para calcular o tamanho m\u00e1ximo do bloco \u00e9:</p>  B \\leq \\sqrt{\\frac{\\text{Capacidade da Cache}}{24}}  <p>(onde 24 = 3 matrizes \u00d7 8 bytes por double).</p> <p>Analise o c\u00f3digo <code>matmul_seq.cpp</code>:</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;cstdlib&gt;\n#include &lt;algorithm&gt;\n\n\n#define TAM_MATRIZ 1000\n/*\n ============================================================\n   OBJETIVO\n   -----------------------------------------------------------\n   Este programa faz a multiplica\u00e7\u00e3o de matrizes aninhadas\n   de forma SEQUENCIAL e mede o tempo de execu\u00e7\u00e3o.\n\n   Ele pode rodar em dois modos:\n   - Vers\u00e3o INGENUA (sem otimiza\u00e7\u00f5es)\n   - Vers\u00e3o com TILING (fateamento em blocos), onde o tamanho\n     do bloco B \u00e9 passado como par\u00e2metro na linha de comando.\n\n   O objetivo \u00e9 observar como o tamanho do bloco B influencia:\n   - O tempo de execu\u00e7\u00e3o\n   - O uso de cache\n\n ============================================================\n*/\n\n/* Definicoes para melhorar a legibilidade*/\n\nusing Matriz = std::vector&lt;std::vector&lt;double&gt;&gt;;\n\ninline Matriz criaMatriz(int size, double value){\n    return Matriz(size, std::vector&lt;double&gt;(size, value));\n}\n\n/**\n * @brief Vers\u00e3o ing\u00eanua da multiplica\u00e7\u00e3o de matrizes.\n * \n * Implementa a multiplica\u00e7\u00e3o com tr\u00eas loops aninhados (i, j, k) sem uso de tiling.\n * O acesso \u00e0s matrizes \u00e9 feito de forma direta, sem otimiza\u00e7\u00f5es de cache.\n */\ninline void versaoIngenua(){\n\n    // Cria tr\u00eas matrizes NxN em mem\u00f3ria, preenchidas com valores fixos\n    // - A inicializada com 1.0\n    // - Bmat inicializada com 2.0\n    // - C inicializada com 0.0 (resultado)\n\n    Matriz A    = criaMatriz(TAM_MATRIZ, 1.0);\n    Matriz Bmat = criaMatriz(TAM_MATRIZ, 2.0);\n    Matriz C    = criaMatriz(TAM_MATRIZ, 0.0);\n\n    for (int i = 0; i &lt; TAM_MATRIZ; i++) {\n        for (int j = 0; j &lt; TAM_MATRIZ; j++) {\n            for (int k = 0; k &lt; TAM_MATRIZ; k++) {\n                C[i][j] += A[i][k] * Bmat[k][j];\n            }\n        }\n    }\n}\n\n/**\n * @brief Multiplica\u00e7\u00e3o de matrizes utilizando a t\u00e9cnica de tiling (blocking).\n * \n * Realiza a multiplica\u00e7\u00e3o de matrizes dividindo as matrizes em blocos (tiles) de tamanho `tamBloco`.\n * Otimiza o uso da cache ao trabalhar com submatrizes menores que cabem na hierarquia de mem\u00f3ria.\n * \n * @param tamBloco Tamanho do bloco (tile) usado para dividir as matrizes na multiplica\u00e7\u00e3o.\n */\ninline void versaoTiling(int tamBloco){\n\n    // Cria tr\u00eas matrizes NxN em mem\u00f3ria, preenchidas com valores fixos\n    // - A inicializada com 1.0\n    // - Bmat inicializada com 2.0\n    // - C inicializada com 0.0 (resultado)\n\n    Matriz A    = criaMatriz(TAM_MATRIZ, 1.0);\n    Matriz Bmat = criaMatriz(TAM_MATRIZ, 2.0);\n    Matriz C    = criaMatriz(TAM_MATRIZ, 0.0);\n\n    for (int ii = 0; ii &lt; TAM_MATRIZ; ii += tamBloco) {        // blocos de linhas\n        for (int jj = 0; jj &lt; TAM_MATRIZ; jj += tamBloco) {    // blocos de colunas\n            for (int kk = 0; kk &lt; TAM_MATRIZ; kk += tamBloco) {// blocos intermedi\u00e1rios\n                // Multiplica\u00e7\u00e3o de submatrizes tamBloco x tamBloco\n                // Ordem j -&gt; i -&gt; k\n                for (int j = jj; j &lt; std::min(jj + tamBloco, TAM_MATRIZ); j++) {\n                    for (int i = ii; i &lt; std::min(ii + tamBloco, TAM_MATRIZ); i++) {\n                        double sum = C[i][j];\n                        for (int k = kk; k &lt; std::min(kk + tamBloco, TAM_MATRIZ); k++) {\n                            sum += A[i][k] * Bmat[k][j];\n                        }\n                        C[i][j] = sum;\n                    }\n                }\n            }\n        }\n    }\n}\n\n\n\nint main(int argc, char* argv[]) {\n    int tamBloco = 0; // Tamanho do bloco. Se for 0 \u2192 vers\u00e3o ing\u00eanua.\n\n    // L\u00ea o tamanho do bloco da linha de comando\n    // Exemplo: ./matmul_seq 200  \u2192 roda com blocos 200\u00d7200\n    if (argc &gt; 1) {\n        // Atualiza o valor de tamBloco de acordo com o par\u00e2metro de entrada\n        tamBloco = std::atoi(argv[1]);\n    }\n\n    // Marca o in\u00edcio da medi\u00e7\u00e3o de tempo\n    auto start = std::chrono::high_resolution_clock::now();\n\n    if (tamBloco &lt;= 0) {\n        versaoIngenua();\n    } \n    else {\n        versaoTiling(tamBloco);\n    }\n\n    // Marca o fim da medi\u00e7\u00e3o\n    auto end = std::chrono::high_resolution_clock::now();\n\n    // Calcula e imprime o tempo total em milissegundos\n    std::cout &lt;&lt; \"Execu\u00e7\u00e3o (\"\n              &lt;&lt; (tamBloco &lt;= 0 ? \"ing\u00eanua\" : \"tiling tamBloco=\" + std::to_string(tamBloco))\n              &lt;&lt; \"): \"\n              &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(end - start).count()\n              &lt;&lt; \" ms\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"aulas/aula03/#missoes","title":"Miss\u00f5es:","text":""},{"location":"aulas/aula03/#1-compilacao","title":"1. Compila\u00e7\u00e3o","text":"<p>Compile o c\u00f3digo no terminal do head-node <code>matmul_seq.cpp</code>:</p> <pre><code>g++ -O2  matmul_seq.cpp -o matmul_seq\n</code></pre>"},{"location":"aulas/aula03/#2-execucao","title":"2. Execu\u00e7\u00e3o","text":"<p>Crie o lan\u00e7ador do SLURM como em <code>tiling.slurm</code>:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=monstrao_tiling\n#SBATCH --output=monstrao_tiling%j.out\n#SBATCH --error=monstrao_tiling%j.err\n#SBATCH --partition=monstrao\n#SBATCH --ntasks=1\n#SBATCH --time=00:05:00\n#SBATCH --mem=2G\n\necho \"=============== FILA MONSTRAO==============\"\n\necho \"=== Execu\u00e7\u00e3o vers\u00e3o ing\u00eanua ===\"\ntime ./matmul_seq 0\n\necho \"=== Execu\u00e7\u00e3o com blocos L1 (~36x36) ===\"\ntime ./matmul_seq 36\n\necho \"=== Execu\u00e7\u00e3o com blocos L2 (~200x200) ===\"\ntime ./matmul_seq 200\n\necho \"=== Execu\u00e7\u00e3o com blocos L3 (~768x768) ===\"\ntime ./matmul_seq 768\n</code></pre> <p>Execute com:</p> <pre><code>sbatch tiling.slurm\n</code></pre>"},{"location":"aulas/aula03/#explorando-ordenacao-de-loops-e-flags-de-otimizacao-em-diferentes-filas","title":"Explorando Ordena\u00e7\u00e3o de Loops e Flags de Otimiza\u00e7\u00e3o em Diferentes Filas","text":"<p>Voc\u00ea j\u00e1 visualizou o efeito do tiling. Agora, o objetivo \u00e9 entender como a organiza\u00e7\u00e3o dos loops e as otimiza\u00e7\u00f5es do compilador influenciam o desempenho do mesmo c\u00f3digo.</p>"},{"location":"aulas/aula03/#1-alterando-a-ordem-dos-loops","title":"1. Alterando a Ordem dos Loops","text":"<p>Modifique o c\u00f3digo <code>matmul_seq.cpp</code> para usar a ordem i \u2192 k \u2192 j no lugar da ordem original j \u2192 i \u2192 k. Essa mudan\u00e7a melhora a localidade espacial dos acessos \u00e0 matriz B, e tamb\u00e9m beneficia os acessos \u00e0s matrizes A e C.</p>"},{"location":"aulas/aula03/#2-testar-diferentes-flags-de-otimizacao","title":"2. Testar Diferentes Flags de Otimiza\u00e7\u00e3o","text":"<p>Encontre a flag de Otimiza\u00e7\u00e3o com o melhor resultado para esse algoritmo (O2, O3, Ofast)</p>"},{"location":"aulas/aula03/#3-rodar-em-diferentes-filas-do-cluster","title":"3. Rodar em Diferentes Filas do Cluster","text":"<p>Ap\u00f3s identificar as melhores combina\u00e7\u00f5es de loop e flags de otimiza\u00e7\u00e3o no monstrao, identifique quais s\u00e3o os tamanhos das mem\u00f3rias L1, L2 e L3 na fila GPU e repita os testes.</p>"},{"location":"aulas/aula03/#perguntas-para-responder-no-relatorio","title":"Perguntas para responder no relat\u00f3rio:","text":"<ol> <li>A troca de ordem dos loops melhorou ou piorou o tempo de execu\u00e7\u00e3o? Por qu\u00ea?</li> <li>Houveram diferen\u00e7as entre os n\u00f3s monstrao e gpu? Quais?</li> <li>Qual o tamanho de bloco que apresentou o melhor equil\u00edbrio entre tempo de execu\u00e7\u00e3o e aproveitamento de cache em cada fila?</li> </ol>"},{"location":"aulas/aula03/#entregaveis","title":"Entreg\u00e1veis:","text":"<p>Submeta via Classroom um relat\u00f3rio contendo obrigatoriamente:</p> <ul> <li> <p>Identifica\u00e7\u00e3o: seu nome completo</p> </li> <li> <p>Tabelas comparativas: contendo os resultados obtidos</p> </li> <li> <p>Gr\u00e1ficos comparativos: que ilustrem as diferen\u00e7as de desempenho entre as vers\u00f5es testadas</p> </li> <li> <p>Respostas \u00e0s perguntas: an\u00e1lise com base nos resultados observados </p> </li> </ul> <p>Fa\u00e7a a submiss\u00e3o do relat\u00f3rio at\u00e9 22/08, 08h30 pelo link do Github Classromm</p>"},{"location":"aulas/aula04/","title":"Aula 04 - Heur\u00edsticas e Aleatoriedade","text":""},{"location":"aulas/aula04/#objetivo","title":"Objetivo","text":"<p>Ao final desta atividade, voc\u00ea ser\u00e1 capaz de:</p> <ul> <li>Analisar heur\u00edsticas com aleatoriedade para reduzir o espa\u00e7o de busca e fugir de m\u00ednimos locais.</li> <li>Usar aleatoriedade para guiar a busca de solu\u00e7\u00f5es.</li> </ul> <p>Warning</p> <p>Clique aqui para ter acesso ao relat\u00f3rio completo do Emil</p>"},{"location":"aulas/aula04/#um-pouco-de-teoria-o-que-e-nonce","title":"Um pouco de teoria: O que \u00e9 Nonce?","text":"<p>Um nonce \u00e9 um n\u00famero que s\u00f3 pode ser usado uma \u00fanica vez dentro de um determinado contexto. A palavra vem da express\u00e3o inglesa \u201cnumber used once\u201d. O nonce tem um papel fundamental dentro do mecanismo conhecido como Proof of Work.</p> <p>No sistema de Proof of Work, que \u00e9 usado por diversas criptomoedas como o Bitcoin, o objetivo principal \u00e9 garantir que novos blocos de transa\u00e7\u00f5es s\u00f3 sejam adicionados \u00e0 blockchain mediante a realiza\u00e7\u00e3o de um trabalho computacional significativo. Esse trabalho \u00e9 feito pelos mineradores, que tentam encontrar um valor de nonce que, quando combinado com os dados de um bloco e passado por uma fun\u00e7\u00e3o hash (o SHA-256), gere um resultado que satisfa\u00e7a uma condi\u00e7\u00e3o espec\u00edfica de dificuldade. Essa condi\u00e7\u00e3o normalmente exige que o hash gerado comece com um certo n\u00famero de zeros, quanto mais zeros, mais dif\u00edcil o problema.</p> <p>Para encontrar esse nonce, o minerador precisa testar diferentes valores, um a um, recalculando o hash a cada tentativa. Como a fun\u00e7\u00e3o hash \u00e9 determin\u00edstica, mas seu resultado parece aleat\u00f3rio mesmo com pequenas mudan\u00e7as nos dados de entrada, n\u00e3o h\u00e1 como prever qual nonce gerar\u00e1 um hash v\u00e1lido. Isso significa que a \u00fanica forma de resolver o problema \u00e9 por tentativa e erro, o que exige muito poder computacional e tempo.</p> <p>Tip</p> <p>Quer saber mais? Assista esse v\u00eddeo sobre nonce</p>"},{"location":"aulas/aula04/#por-que-usar-heuristicas-com-aleatoriedade","title":"Por que usar heur\u00edsticas com aleatoriedade?","text":"<p>Em contextos como Proof of Work, usar heur\u00edsticas com aleatoriedade \u00e9 interessante porque o espa\u00e7o de busca \u00e9 enorme e imprevis\u00edvel. A fun\u00e7\u00e3o hash se comporta como uma caixa-preta: pequenas mudan\u00e7as no nonce geram resultados totalmente diferentes, sem padr\u00e3o aparente. Isso torna estrat\u00e9gias determin\u00edsticas (como testar de 0 em diante) ineficientes e vulner\u00e1veis a colis\u00f5es entre mineradores.</p> <p>A aleatoriedade permite explorar regi\u00f5es diferentes do espa\u00e7o de busca, reduzindo repeti\u00e7\u00e3o de esfor\u00e7os e aumentando a chance de sucesso. Al\u00e9m disso, torna o processo menos previs\u00edvel, dificultando ataques ou manipula\u00e7\u00f5es. Em um problema onde n\u00e3o h\u00e1 como saber onde est\u00e1 a solu\u00e7\u00e3o, tentar caminhos variados aleatoriamente \u00e9 uma boa forma de encontrar uma resposta mais r\u00e1pido.</p> <p>Analise o c\u00f3digo exemplo <code>mineracao.cpp</code></p> <pre><code>#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;random&gt;\n#include &lt;chrono&gt;\n#include &lt;iomanip&gt;\n#include &lt;sstream&gt;\n#include &lt;functional&gt;\n#include &lt;climits&gt;\n\n// -------------------------------------------------------------\n// - Retorna string hex com 16 bytes (64 bits) -&gt; 16 d\u00edgitos hex em ambientes 64 bits.\n// -------------------------------------------------------------\nstd::string sha256(const std::string&amp; input) {\n    std::hash&lt;std::string&gt; hasher;     // Functor de hash da STL\n    size_t h = hasher(input);          // Aplica o hash de 64 bits \u00e0 string\n    unsigned long long v = static_cast&lt;unsigned long long&gt;(h); // Normaliza para 64 bits\n\n    // Converte o valor inteiro para string hexadecimal com padding \u00e0 esquerda\n    // Para 64 bits -&gt; 16 d\u00edgitos hex (2 por byte * 8 bytes)\n    std::ostringstream os;\n    os &lt;&lt; std::hex &lt;&lt; std::nouppercase &lt;&lt; std::setfill('0') &lt;&lt; std::setw(16) &lt;&lt; v;\n    return os.str(); // Ex.: \"00af3c...\"; comprimento t\u00edpico: 16 chars em 64 bits\n}\n\n// -------------------------------------------------------------\n// Verifica se o \"hash\" (string hex) come\u00e7a com 'dificuldade' zeros.\n// -------------------------------------------------------------\nbool validaHash(const std::string&amp; hash, int dificuldade) {\n    if (dificuldade &lt;= 0) return true;               // dificuldade 0 sempre passa\n    if (dificuldade &gt; static_cast&lt;int&gt;(hash.size())) // n\u00e3o pode exigir mais zeros do que o tamanho do hash\n        return false;\n    return hash.rfind(std::string(dificuldade, '0'), 0) == 0; // true se come\u00e7a com zeros\n}\n\n// -------------------------------------------------------------\n// Estrat\u00e9gia 1: Busca linear \u2014 testa nonces em ordem: 0, 1, 2, ...\n// -------------------------------------------------------------\nvoid minerar_linear(const std::string&amp; bloco, int dificuldade) {\n    auto start = std::chrono::high_resolution_clock::now(); // Marca in\u00edcio do cron\u00f4metro\n\n    unsigned long long nonce = 0;        // Come\u00e7a do 0\n    unsigned long long tentativas = 0;   // Contador de tentativas\n\n    while (true) {\n        // Monta a entrada \"bloco || nonce\"\n        std::string tentativa = bloco + std::to_string(nonce);\n        // Calcula o \"hash\" da tentativa\n        std::string hash = sha256(tentativa);\n        ++tentativas;\n\n        // Se atendeu \u00e0 dificuldade (come\u00e7a com N zeros), reporta e encerra\n        if (validaHash(hash, dificuldade)) {\n            auto end = std::chrono::high_resolution_clock::now();\n            double tempo = std::chrono::duration&lt;double&gt;(end - start).count();\n            std::cout &lt;&lt; \"[LINEAR] Nonce: \" &lt;&lt; nonce &lt;&lt; \"\\nHash: \" &lt;&lt; hash\n                      &lt;&lt; \"\\nTentativas: \" &lt;&lt; tentativas &lt;&lt; \"\\nTempo: \" &lt;&lt; tempo &lt;&lt; \"s\\n\\n\";\n            break;\n        }\n        ++nonce; // Tenta o pr\u00f3ximo nonce\n    }\n}\n\n// -------------------------------------------------------------\n// Estrat\u00e9gia 2: Busca aleat\u00f3ria com heur\u00edstica simples\n// - Gera nonces aleat\u00f3rios em 64 bits\n// - Heur\u00edstica: s\u00f3 segue para valida\u00e7\u00e3o completa se o hash come\u00e7ar com '0'\n// - maxTentativas: evita loop \"infinito\" \n// -------------------------------------------------------------\nvoid minerar_random_heuristica(const std::string&amp; bloco, int dificuldade, unsigned long long maxTentativas) {\n    auto start = std::chrono::high_resolution_clock::now(); // Cron\u00f4metro\n\n    // Prepara\u00e7\u00e3o do gerador aleat\u00f3rio:\n    std::random_device rd;                          // Fonte de entropia (seed)\n    std::mt19937_64 gen(rd());                      // Gerador de aleat\u00f3rios\n    std::uniform_int_distribution&lt;unsigned long long&gt; distrib(0, ULLONG_MAX); // Uniforme em [0, 2^64-1]\n\n    unsigned long long tentativas = 0; // Contador de tentativas\n\n    while (tentativas &lt; maxTentativas) {\n        // Sorteia um nonce (explora\u00e7\u00e3o aleat\u00f3ria do espa\u00e7o de busca)\n        unsigned long long nonce = distrib(gen);\n\n        // Monta a tentativa e calcula o hash simulado\n        std::string tentativa = bloco + std::to_string(nonce);\n        std::string hash = sha256(tentativa);\n        ++tentativas;\n\n        // Heur\u00edstica: se o primeiro d\u00edgito n\u00e3o \u00e9 '0', provavelmente n\u00e3o atende a dificuldades maiores\n        if (hash[0] != '0') continue;\n\n        // Verifica\u00e7\u00e3o completa do crit\u00e9rio de dificuldade\n        if (validaHash(hash, dificuldade)) {\n            auto end = std::chrono::high_resolution_clock::now();\n            double tempo = std::chrono::duration&lt;double&gt;(end - start).count();\n            std::cout &lt;&lt; \"[HEURISTICA-RANDOM] Nonce: \" &lt;&lt; nonce &lt;&lt; \"\\nHash: \" &lt;&lt; hash\n                      &lt;&lt; \"\\nTentativas: \" &lt;&lt; tentativas &lt;&lt; \"\\nTempo: \" &lt;&lt; tempo &lt;&lt; \"s\\n\\n\";\n            return; // Sucesso: encerra a fun\u00e7\u00e3o\n        }\n    }\n\n    // Se n\u00e3o encontrou dentro do limite de tentativas, informa\n    std::cout &lt;&lt; \"[HEURISTICA-RANDOM] N\u00e3o encontrou nonce v\u00e1lido em \" &lt;&lt; maxTentativas &lt;&lt; \" tentativas.\\n\\n\";\n}\n\n// -------------------------------------------------------------\n// main: executa as duas estrat\u00e9gias para compara\u00e7\u00e3o \n// -------------------------------------------------------------\nint main() {\n    std::string bloco = \"transacao_simples\"; // Simula\u00e7\u00e3o de transa\u00e7\u00e3o\n    int dificuldade = 5;                     // N\u00ba de zeros \u00e0 esquerda no hash simulado\n    unsigned long long limite_random = 500000; // Limite de tentativas para a estrat\u00e9gia aleat\u00f3ria\n\n    std::cout &lt;&lt; \"=== Minera\u00e7\u00e3o  | dificuldade = \" &lt;&lt; dificuldade &lt;&lt; \" ===\\n\\n\";\n\n    // Estrat\u00e9gia linear \n    minerar_linear(bloco, dificuldade);\n\n    // Estrat\u00e9gia aleat\u00f3ria + heur\u00edstica\n    minerar_random_heuristica(bloco, dificuldade, limite_random);\n\n    return 0; \n}\n</code></pre>"},{"location":"aulas/aula04/#desafio","title":"Desafio!","text":"<p>Objetivo: Analisar e aprimorar a heur\u00edstica exemplo.</p> <p>Execute o c\u00f3digo acima 5 vezes. Compare:</p> <ul> <li> <p>O n\u00famero de tentativas e o tempo da busca linear.</p> </li> <li> <p>O n\u00famero de tentativas e o tempo da busca aleat\u00f3ria com heur\u00edstica.</p> </li> <li> <p>Qual das duas abordagem acerta mais?</p> </li> </ul> <p>Interprete os resultados:</p> <ul> <li> <p>A heur\u00edstica sempre \u00e9 mais r\u00e1pida?</p> </li> <li> <p>Em qual cen\u00e1rio a heuristica aleat\u00f3ria pode ser pior?</p> </li> <li> <p>O que fazer para que a busca aleat\u00f3ria com heur\u00edstica encontre o nonce com mais frequ\u00eancia?</p> </li> <li> <p>Por que usar aleatoriedade e filtros simples (como descartar hashes que n\u00e3o come\u00e7am com '0') pode acelerar a busca por um hash v\u00e1lido?</p> </li> </ul> <p>Pergunta para reflex\u00e3o:</p> <p>Quais melhorias poderiam ser implementadas neste algoritmo para ter uma heuristica mais eficiente?</p>"},{"location":"aulas/aula04/#esta-atividade-nao-tem-entrega-bom-final-de-semana","title":"Esta atividade n\u00e3o tem entrega, bom final de semana!","text":""},{"location":"aulas/aula05/","title":"Paralelismo em CPU com OpenMP","text":""},{"location":"aulas/aula05/#objetivo","title":"Objetivo","text":"<ul> <li>Paralelismo em CPU: como dividir o trabalho entre m\u00faltiplos cores.</li> <li>Threads: cada thread executa uma parte do trabalho.</li> <li>OpenMP: diretivas em OpenMP para paralelizar loops.</li> <li>Scheduling: forma como as itera\u00e7\u00f5es do loop s\u00e3o distribu\u00eddas entre threads (<code>static</code>, <code>dynamic</code>, <code>guided</code>).</li> </ul> <p>Os processadores atuais possuem m\u00faltiplos n\u00facleos de execu\u00e7\u00e3o (cores). Para aproveitar essa capacidade, podemos dividir o trabalho em partes menores que possam ser executadas simultaneamente. Essa divis\u00e3o \u00e9 feita por meio de threads, onde cada thread executa uma fra\u00e7\u00e3o das instru\u00e7\u00f5es.</p> <p>No caso de la\u00e7os de repeti\u00e7\u00e3o, o paralelismo \u00e9 obtido ao repartir as itera\u00e7\u00f5es entre v\u00e1rias threads. Em vez de uma \u00fanica thread percorrer todo o la\u00e7o, cada thread recebe um subconjunto de itera\u00e7\u00f5es, reduzindo o tempo total de execu\u00e7\u00e3o. O OpenMP facilita esse processo por meio de diretivas como <code>#pragma omp parallel for</code>.</p> <p>Tip</p> <p>Para saber mais, veja o material dispon\u00edvel em Guia de Pragmas OpnMP </p>"},{"location":"aulas/aula05/#scheduling-no-openmp","title":"Scheduling no OpenMP","text":"<p>Quando um la\u00e7o \u00e9 paralelizado, \u00e9 preciso definir como as itera\u00e7\u00f5es ser\u00e3o distribu\u00eddas entre as threads. Essa estrat\u00e9gia \u00e9 chamada de schedule (escalonamento).</p> <ul> <li>static \u2192 divide as itera\u00e7\u00f5es em blocos fixos, atribu\u00eddos antecipadamente a cada thread.</li> <li>dynamic \u2192 as itera\u00e7\u00f5es s\u00e3o distribu\u00eddas em blocos sob demanda, conforme as threads terminam suas tarefas.</li> <li>guided \u2192 inicia com blocos maiores e reduz gradualmente o tamanho, equilibrando a carga de trabalho.</li> <li>auto \u2192 delega ao compilador a escolha da estrat\u00e9gia.</li> <li>runtime \u2192 a estrat\u00e9gia \u00e9 definida em tempo de execu\u00e7\u00e3o pela vari\u00e1vel de ambiente <code>OMP_SCHEDULE</code>.</li> </ul> <p>A escolha do escalonamento n\u00e3o altera o resultado final da computa\u00e7\u00e3o, mas impacta diretamente o desempenho e o balanceamento da carga de trabalho.</p> <p>O programa <code>omp_schedulers.cpp</code> \u00e9 um c\u00f3digo exemplo para visualizar a distribui\u00e7\u00e3o das itera\u00e7\u00f5es de um la\u00e7o entre threads em diferentes estrat\u00e9gias de <code>schedule</code>.</p> <p>Para cada pol\u00edtica de escalonamento, o programa registra quais itera\u00e7\u00f5es foram executadas por cada thread e exibe uma sa\u00edda gr\u00e1fica com <code>*</code>, indicando a distribui\u00e7\u00e3o.</p> <p>Dessa forma, \u00e9 poss\u00edvel observar o comportamento de cada pol\u00edtica:</p> <p><code>omp_schedulers.cpp</code> <pre><code>#include &lt;iostream&gt;   \n#include &lt;string&gt;     \n#include &lt;vector&gt;     \n#include &lt;algorithm&gt;  \n#include &lt;omp.h&gt;      // OpenMP (omp_get_thread_num, diretivas)\n\n// -----------------------------------------------------------------------------\n// print_iterations:\n//   - Recebe uma descri\u00e7\u00e3o, um vetor de vetores 'vectors' (4 vetores, um por thread),\n//     e 'n' (n\u00famero total de itera\u00e7\u00f5es do la\u00e7o).\n//   - Constr\u00f3i 4 strings com '*' indicando quais itera\u00e7\u00f5es cada thread executou.\n//   - Imprime a distribui\u00e7\u00e3o para visualizar o efeito do 'schedule'.\n// -----------------------------------------------------------------------------\nvoid print_iterations(const std::string&amp; description,\n                      const std::vector&lt; std::vector&lt;int&gt; &gt;&amp; vectors,\n                      const int n)\n{\n    std::vector&lt;std::string&gt; strings(4, std::string()); // 4 linhas de sa\u00edda, uma por thread\n    for (int i = 0; i != n; i++)                        // varre todas as itera\u00e7\u00f5es 0..n-1\n    {\n        for (int j = 0; j != 4; j++)                   // para cada \"thread\" (0..3)\n        {\n            const auto&amp; vector = vectors[j];           // vetor com as itera\u00e7\u00f5es que a thread j executou\n            auto it = std::find(vector.begin(), vector.end(), i); // procura o i dentro do vetor da thread j\n            if (it != vector.end())\n            {\n                strings[j] += \"*\";                     // se a thread j executou a itera\u00e7\u00e3o i, marca '*'\n            }\n            else\n            { \n                strings[j] += \" \";                     // caso contr\u00e1rio, espa\u00e7o em branco\n            }\n        }\n    }\n    std::cout &lt;&lt; description &lt;&lt; std::endl;             // t\u00edtulo/descri\u00e7\u00e3o da experi\u00eancia\n    for (auto&amp; s : strings)                            // imprime as 4 linhas (uma por thread)\n    {\n        std::cout &lt;&lt; s &lt;&lt; \"\\n\";\n    }\n    std::cout &lt;&lt; std::endl;\n}\n\n// -----------------------------------------------------------------------------\n// schedule (template):\n//   - Fun\u00e7\u00e3o \"driver\" que recebe outra fun\u00e7\u00e3o 'function' (uma pol\u00edtica de agendamento),\n//     a descri\u00e7\u00e3o e 'n'.\n//   - Aloca 'vectors' (4 vetores: um por thread) e chama 'function' para preench\u00ea-los.\n//   - Depois imprime o resultado com print_iterations.\n// -----------------------------------------------------------------------------\ntemplate &lt;typename T&gt;\nvoid schedule(T function, \n              const std::string&amp; description, \n              const int n)\n{\n    std::vector&lt;std::vector&lt;int&gt;&gt; vectors(4, std::vector&lt;int&gt;()); // 4 threads simuladas\n    function(vectors, n);                                         // executa a pol\u00edtica (preenche vectors)\n    print_iterations(description, vectors, n);                    // visualiza distribui\u00e7\u00e3o\n}\n\n// -----------------------------------------------------------------------------\n// Cada fun\u00e7\u00e3o 'scheduleXYZ' abaixo:\n//   - Abre uma regi\u00e3o paralela com 4 threads (num_threads(4))\n//   - Faz um for paralelo '#pragma omp for' sobre i = 0..n-1\n//   - Cada thread registra a itera\u00e7\u00e3o 'i' que executou em vectors[tid]\n//   Observa\u00e7\u00e3o did\u00e1tica: push_back em 'vectors[tid]' \u00e9 aceit\u00e1vel aqui para fins\n//   de visualiza\u00e7\u00e3o (em geral, acessos concorrentes a containers exigem cuidado).\n// -----------------------------------------------------------------------------\n\n// Default: sem especificar 'schedule' explicitamente (deixa o runtime decidir)\nvoid scheduleDefault(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i); // registra a itera\u00e7\u00e3o i sob a thread atual\n        }\n    }\n}\n\n// schedule(static): divide as itera\u00e7\u00f5es em blocos fixos, um por thread (tamanho auto)\nvoid scheduleStatic(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(static)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(static, 4): blocos fixos de 4 itera\u00e7\u00f5es por vez\nvoid scheduleStatic4(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(static, 4)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(static, 8): blocos fixos de 8 itera\u00e7\u00f5es por vez\nvoid scheduleStatic8(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(static, 8)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(dynamic): threads pegam blocos sob demanda (tamanho padr\u00e3o do runtime)\nvoid scheduleDynamic(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(dynamic, 1): blocos din\u00e2micos de 1 itera\u00e7\u00e3o (alto overhead, \u00f3timo balanceamento)\nvoid scheduleDynamic1(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(dynamic, 1)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(dynamic, 4): blocos din\u00e2micos de 4 itera\u00e7\u00f5es\nvoid scheduleDynamic4(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(dynamic, 4)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(dynamic, 8): blocos din\u00e2micos de 8 itera\u00e7\u00f5es\nvoid scheduleDynamic8(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(dynamic, 8)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(guided): blocos come\u00e7am grandes e v\u00e3o diminuindo (bom p/ carga irregular)\nvoid scheduleGuided(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(guided)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(guided, 2): guided com bloco m\u00ednimo de 2\nvoid scheduleGuided2(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(guided, 2)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(guided, 4): guided com bloco m\u00ednimo de 4\nvoid scheduleGuided4(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(guided, 4)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(guided, 8): guided com bloco m\u00ednimo de 8\nvoid scheduleGuided8(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(guided, 8)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(auto): deixa o runtime escolher o melhor esquema\nvoid scheduleAuto(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(auto)\n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\n// schedule(auto): deixa o compilador escolher a melhor estrat\u00e9gia\nvoid scheduleRuntime(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; vectors, int n)\n{\n    #pragma omp parallel num_threads(4) shared(vectors, n)\n    {    \n        #pragma omp for schedule(auto) \n        for (int i = 0; i &lt; n; i++)\n        {\n            vectors[omp_get_thread_num()].push_back(i);\n        }\n    }\n}\n\nint main()\n{\n    const int n = 64; // n\u00famero de itera\u00e7\u00f5es do la\u00e7o a serem distribu\u00eddas entre 4 threads\n\n    // Executa cada pol\u00edtica de agendamento e imprime a \u201cfaixa\u201d de itera\u00e7\u00f5es por thread.\n    schedule(scheduleDefault,  \"default:               \", n);\n    schedule(scheduleStatic,   \"schedule(static):      \", n);\n    schedule(scheduleStatic4,  \"schedule(static, 4):   \", n);\n    schedule(scheduleStatic8,  \"schedule(static, 8):   \", n);\n    schedule(scheduleDynamic,  \"schedule(dynamic):     \", n);\n    schedule(scheduleDynamic1, \"schedule(dynamic, 1):  \", n);\n    schedule(scheduleDynamic4, \"schedule(dynamic, 4):  \", n);\n    schedule(scheduleDynamic8, \"schedule(dynamic, 8):  \", n);\n    schedule(scheduleGuided,   \"schedule(guided):      \", n);\n    schedule(scheduleGuided2,  \"schedule(guided, 2):   \", n);\n    schedule(scheduleGuided4,  \"schedule(guided, 4):   \", n);\n    schedule(scheduleGuided8,  \"schedule(guided, 8):   \", n);\n    schedule(scheduleAuto,     \"schedule(auto):        \", n);\n    schedule(scheduleRuntime,  \"schedule(runtime):     \", n);\n\n    return 0;\n}\n</code></pre></p> <p>Compilar o c\u00f3digo com OpenMP</p> <pre><code>g++ -fopenmp omp_schedulers.cpp -o omp_schedulers\n</code></pre> <p>Rodar no cluster com SLURM definindo o n\u00famero de threads:</p> <pre><code>srun --partition=normal --ntasks=1 --cpus-per-task=4 ./omp_schedulers\n</code></pre> <p>ou</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=omp_scheduler_test   # nome do job\n#SBATCH --output=output_omp_schedulers.out  # arquivo de sa\u00edda\n#SBATCH --ntasks=1                      # 1 processo (1 task MPI)\n#SBATCH --cpus-per-task=4               # 4 CPUs para essa task \u2192 4 threads OMP\n#SBATCH --time=00:05:00                 # tempo m\u00e1ximo de execu\u00e7\u00e3o\n#SBATCH --mem=2G                        # Mem\u00f3ria total do job (ex.: 2 GB)\n\n# garante que o OpenMP use exatamente os recursos alocados pelo SLURM\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}\n\n# executa o bin\u00e1rio\n./omp_schedulers\n</code></pre>"},{"location":"aulas/aula05/#analisando-os-schedulers-no-openmp","title":"Analisando os Schedulers no OpenMP","text":"<p>Cada scheduler do OpenMP se comporta de maneira diferente, e voc\u00ea deve observar o impacto de cada um:</p> <p>static: As itera\u00e7\u00f5es s\u00e3o divididas igualmente entre as threads.</p> <p>dynamic: As threads pegam blocos de itera\u00e7\u00f5es conforme terminam o trabalho.</p> <p>guided: Distribui blocos maiores no in\u00edcio e menores no final, equilibrando a carga.</p> <p>auto: Deixa o compilador escolher a melhor estrat\u00e9gia.</p> <p>runtime: Usa a estrat\u00e9gia definida em tempo de execu\u00e7\u00e3o.</p>"},{"location":"aulas/aula05/#atividade-03-paralelismo-com-openmp","title":"Atividade 03 - Paralelismo com OpenMP","text":"<p>C\u00f3digo base para a atividade 03:</p> <p><code>paralelo.cpp</code> <pre><code>// Compile: g++ -FlagDeOtimiza\u00e7\u00e3o -fopenmp paralelo.cpp -o paralelo\n// Execute: ./paralelo [N]  (N padr\u00e3o = 10'000'000)\n\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;algorithm&gt; \n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n    // ------------------------------\n    // Par\u00e2metros e dados de entrada\n    // ------------------------------\n    const int N = (argc &gt;= 2 ? std::stoi(argv[1]) : 10'000'000);\n    std::cout &lt;&lt; \"N = \" &lt;&lt; N &lt;&lt; \"\\n\";\n\n    // Vetor base (valores aleat\u00f3rios em [0,1))\n    std::vector&lt;float&gt; a(N);\n    {\n        std::mt19937 rng(123);                // seed fixa s\u00f3 p/ reprodutibilidade\n        std::uniform_real_distribution&lt;&gt; U(0.0, 1.0);\n        for (int i = 0; i &lt; N; ++i) a[i] = static_cast&lt;float&gt;(U(rng));\n    }\n\n    // =========================================================\n    // TAREFA A: Transforma\u00e7\u00e3o elemento-a-elemento (map)\n    // =========================================================\n    const float alpha = 2.0f, beta = 35.5f;\n    std::vector&lt;float&gt; c(N);\n\n    double t0 = omp_get_wtime();\n\n    for (int i = 0; i &lt; N; ++i) {\n        c[i] = alpha * a[i] + beta;\n    }\n\n    double t1 = omp_get_wtime();\n    std::cout &lt;&lt; \"[A] tempo = \" &lt;&lt; (t1 - t0) &lt;&lt; \" s\\n\";\n    int idx = N/2; // pega o elemento do meio do vetor\n    std::cout &lt;&lt; \"[A] c[\" &lt;&lt; idx &lt;&lt; \"] = \" &lt;&lt; c[idx] &lt;&lt; \"\\n\";\n\n    // =========================================================\n    // TAREFA B: Soma (redu\u00e7\u00e3o) da norma L2 parcial\n    // =========================================================\n    t0 = omp_get_wtime();\n\n    double soma = 0.0;\n    for (int i = 0; i &lt; N; ++i) {\n        soma += static_cast&lt;double&gt;(c[i]) * static_cast&lt;double&gt;(c[i]);\n    }\n\n    t1 = omp_get_wtime();\n    std::cout &lt;&lt; \"[B] tempo = \" &lt;&lt; (t1 - t0) &lt;&lt; \" s | soma  = \" &lt;&lt; soma &lt;&lt; \"\\n\";\n    return 0;\n}\n</code></pre> Para Compilar:</p> <pre><code>g++ -FlagDeOtimiza\u00e7\u00e3o -fopenmp paralelo.cpp -o paralelo\n</code></pre> <p>Para Executar: <pre><code>#!/bin/bash\n#SBATCH --job-name=paralelo_todo      # Nome do job\n#SBATCH --output=paralelo.txt         # nome do arquivo de saida\n#SBATCH --ntasks=1                    # Sempre 1 processo (o programa roda s\u00f3 uma vez)\n#SBATCH --cpus-per-task=4             # Esse processo tem 4 CPUs dispon\u00edveis para usar\n#SBATCH --mem=2G                      # Mem\u00f3ria solicitada\n#SBATCH --time=00:05:00               # Tempo solicitado (hh:mm:ss)\n#SBATCH --partition=normal            # fila\n\n# ------------------------------\n# Configura\u00e7\u00f5es OpenMP\n# ------------------------------\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}   # OpenMP abre 4 threads e distribui o trabalho entre elas\nexport OMP_PLACES=cores                         # Fixa threads em cores\nexport OMP_PROC_BIND=close                      # Coloca threads pr\u00f3ximas (melhor cache)\n\n# Troque aqui o Schedule do seu teste\nexport OMP_SCHEDULE=static\n\necho \"==== Configura\u00e7\u00e3o de Execu\u00e7\u00e3o ====\"\necho \"Job ID          : $SLURM_JOB_ID\"\necho \"CPUs-per-task   : $SLURM_CPUS_PER_TASK\"\necho \"Mem\u00f3ria total   : $SLURM_MEM_PER_NODE MB\"\necho \"OMP_NUM_THREADS : $OMP_NUM_THREADS\"\necho \"OMP_SCHEDULE    : $OMP_SCHEDULE\"\necho \"==================================\"\n\n# ------------------------------\n# Executa o programa\n# ------------------------------\n# paralelo (4 threads, por ex.)\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}   # OpenMP abre 4 threads e distribui o trabalho entre elas\n./paralelo \n</code></pre></p>"},{"location":"aulas/aula05/#objetivo_1","title":"Objetivo","text":"<p>Paralelizar la\u00e7os com OpenMP, comparar o efeito de <code>schedule</code> no desempenho.</p>"},{"location":"aulas/aula05/#tarefa-a-map-transformacao-elemento-a-elemento","title":"Tarefa A - Map: transforma\u00e7\u00e3o elemento-a-elemento","text":"<p>Solicita\u00e7\u00f5es de Implementa\u00e7\u00e3o</p> <ol> <li>Paralelize o c\u00f3digo correspondente a Tarefa A.</li> <li>Registre tempo e valor da conta em 3 execu\u00e7\u00f5es para cada <code>OMP_SCHEDULE = static</code>, <code>dynamic</code>, <code>guided</code>.</li> <li>O que est\u00e1 sendo paralelizado nesse for? O que est\u00e1 sendo distribuido entre as threads?</li> </ol>"},{"location":"aulas/aula05/#tarefa-b-reducao-ingenua-soma-de-quadrados","title":"Tarefa B - Redu\u00e7\u00e3o ing\u00eanua: soma de quadrados","text":"<p>Solicita\u00e7\u00f5es de Implementa\u00e7\u00e3o</p> <ol> <li>Paralelize o c\u00f3digo correspondente a Tarefa B.</li> <li>Registre tempo e valor da soma em 3 execu\u00e7\u00f5es para cada <code>OMP_SCHEDULE = static</code>, <code>dynamic</code>, <code>guided</code>.</li> <li>Compare com a execu\u00e7\u00e3o sequencial (threads=1).</li> <li>O que est\u00e1 sendo paralelizado nesse for? O que est\u00e1 sendo distribuido entre as threads?</li> </ol>"},{"location":"aulas/aula05/#coleta-de-resultados-minimo","title":"Coleta de Resultados (m\u00ednimo)","text":"<ul> <li>Tabela tempos (Parte 1): <code>scheduler</code>, <code>execu\u00e7\u00e3o</code>, <code>tempo (s)</code>.</li> <li>Tabela tempos (Parte 2): <code>schedule</code>, <code>threads</code>, <code>m\u00e9dia (s)</code>, <code>desvio</code>.</li> <li>Tabela soma (Parte 3): <code>schedule</code>, <code>tempo (s)</code>, <code>soma obtida</code>.</li> </ul>"},{"location":"aulas/aula05/#parametros-de-execucao","title":"Par\u00e2metros de Execu\u00e7\u00e3o","text":"<ul> <li>Varie <code>OMP_NUM_THREADS</code> em {1, 2, 4, 8} (quando solicitado).</li> <li>Mantenha os mesmos N (tamanho do problema) em todas as compara\u00e7\u00f5es do mesmo grupo.</li> </ul> <p>Perguntas de An\u00e1lise</p> <ul> <li>Houve speedup com mais threads? At\u00e9 onde?</li> <li><code>static</code> vs <code>dynamic</code> vs <code>guided</code>: quem foi melhor? Alguma diferen\u00e7a relevante?</li> <li>Alguma mudan\u00e7a no resultado das contas? </li> </ul> <p>Fa\u00e7a um relat\u00f3rio com as suas an\u00e1lises e entregue at\u00e9 as 23h59 de 28/08 pelo GitHub Classroom </p>"},{"location":"aulas/aula06/","title":"Efeitos Colaterais do Paralelismo","text":"<p>Nesta atividade vamos explorar os problemas que aparecem quando paralelizamos de forma ing\u00eanua e ver como corrigir logo em seguida. </p>"},{"location":"aulas/aula06/#tarefa-a-transformacao-elemento-a-elemento-map","title":"TAREFA A: Transforma\u00e7\u00e3o elemento-a-elemento (map)","text":"<p>Na aula passada foi pedido que voc\u00ea paralelizasse e analisasse este la\u00e7o:</p> <pre><code>#pragma omp parallel for schedule(runtime)\nfor (int i = 0; i &lt; N; i++) {\n    c[i] = alpha * a[i] + beta;\n}\n</code></pre> <ul> <li>Voc\u00ea executou com 1, 2, 4 e 8 threads.</li> <li>Testou diferentes <code>OMP_SCHEDULE</code> (<code>static</code>, <code>dynamic</code>, <code>guided</code>).</li> <li>Observou que o resultado n\u00e3o muda nunca, apenas o tempo de execu\u00e7\u00e3o varia.</li> </ul> <p>Este \u00e9 um exemplo de paralelismo seguro, pois cada itera\u00e7\u00e3o escreve em posi\u00e7\u00f5es diferentes do vetor <code>c</code>.</p> <p>Pergunta para pensar: por que este la\u00e7o \u00e9 naturalmente paraleliz\u00e1vel sem dar problemas?</p>"},{"location":"aulas/aula06/#tarefa-b-soma-reducao-da-norma-l2-parcial","title":"TAREFA B: Soma (redu\u00e7\u00e3o) da norma L2 parcial","text":"<p>Outro la\u00e7o analisado na aula passada foi:</p> <pre><code>double soma = 0.0;\n#pragma omp parallel for schedule(runtime)\nfor (int i = 0; i &lt; N; i++) {\n    soma += static_cast&lt;double&gt;(c[i]) * static_cast&lt;double&gt;(c[i]); // &lt;- condi\u00e7\u00e3o de corrida\n}\n</code></pre> <p>Neste caso os valores da soma ficaram inconsistentes. Isso acontece porque v\u00e1rias threads tentam atualizar a mesma vari\u00e1vel ao mesmo tempo \u2192 condi\u00e7\u00e3o de corrida (race condition).</p> <p>Pergunta para pensar: se for pedido ao SLURM cpus-per-task=1 n\u00e3o vemos inconsist\u00eancias no resultado da conta?</p>"},{"location":"aulas/aula06/#corrigindo-com-reduction","title":"Corrigindo com reduction","text":"<p>A corre\u00e7\u00e3o \u00e9 simples: usar uma redu\u00e7\u00e3o.</p> <pre><code>double soma = 0.0;\n#pragma omp parallel for schedule(runtime) reduction(+:soma)\nfor (int i = 0; i &lt; N; i++) {\n    soma += (double)c[i] * c[i]; // &lt;- corrigido\n}\n</code></pre> <p>Agora cada thread acumula uma soma local e no final todas s\u00e3o combinadas. O resultado fica est\u00e1vel e correto em qualquer n\u00famero de threads.</p>"},{"location":"aulas/aula06/#dependencia-de-dados","title":"Depend\u00eancia de dados","text":"<p>Nem todos os la\u00e7os podem ser paralelizados:</p> <pre><code>for (int i = 1; i &lt; N; i++) {\n    a[i] = a[i-1] + 1; // depende da itera\u00e7\u00e3o anterior\n}\n</code></pre> <p>Aqui h\u00e1 uma depend\u00eancia entre itera\u00e7\u00f5es: para calcular <code>a[i]</code> \u00e9 necess\u00e1rio j\u00e1 ter calculado <code>a[i-1]</code>. Paralelizar assim gera resultado incorreto.</p> <p>S\u00f3 \u00e9 poss\u00edvel resolver reformulando o algoritmo. O objetivo \u00e9 apenas perceber que nem todo loop \u00e9 paraleliz\u00e1vel.</p> <p>Maaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaas se observarmos bem, esse c\u00e1lculo \u00e9 apenas uma progress\u00e3o aritm\u00e9tica:</p> <ul> <li><code>a[1] = a[0] + 1</code></li> <li><code>a[2] = a[0] + 2</code></li> <li><code>a[3] = a[0] + 3</code></li> <li>\u2026</li> <li><code>a[i] = a[0] + i</code></li> </ul> <p>Ou seja, o valor de <code>a[i]</code> n\u00e3o precisa necessariamente <code>a[i-1]</code>, pode ser calculado diretamente.</p>"},{"location":"aulas/aula06/#versao-paralelizavel","title":"Vers\u00e3o paraleliz\u00e1vel:","text":"<pre><code>#pragma omp parallel for schedule(dynamic)\nfor (int i = 1; i &lt; N; i++) {\n    a[i] = a[0] + i;\n}\n</code></pre> <p>O loop original tem depend\u00eancia sequencial, mas ao analisar o padr\u00e3o, vemos que \u00e9 uma progress\u00e3o. Reformulando o c\u00e1lculo, eliminamos a depend\u00eancia, agora cada itera\u00e7\u00e3o \u00e9 independente e pode ser distribu\u00edda entre threads sem problemas. Esse exemplo \u00e9 \u00f3timo para mostrar que paralelizar n\u00e3o \u00e9 s\u00f3 usar <code>#pragma</code>, \u00e0s vezes \u00e9 preciso pensar no algoritmo.</p>"},{"location":"aulas/aula06/#recursao-com-tasks","title":"Recurs\u00e3o com tasks","text":"<p>O OpenMP tamb\u00e9m permite paralelizar recurs\u00e3o, mas com cuidado.</p> <p>Exemplo: Fibonacci recursivo.</p> <pre><code>int fib(int n) {\n    if (n &lt;= 1) return n;\n    int x, y;\n\n    #pragma omp task shared(x)\n    x = fib(n-1);\n\n    #pragma omp task shared(y)\n    y = fib(n-2);\n\n    #pragma omp taskwait\n    return x + y;\n}\n</code></pre> <p>Se voc\u00ea testar <code>fib(30)</code> ou <code>fib(35)</code>. Ver\u00e1 que muitas tasks pequenas podem at\u00e9 piorar o tempo, devido ao overhead.</p> <p>Pois \u00e9, nem sempre mais paralelismo significa mais velocidade.</p>"},{"location":"aulas/aula06/#conclusao","title":"Conclus\u00e3o","text":"<p>Na aula de hoje vimos que nem todo problema \u00e9 igual. No caso da transforma\u00e7\u00e3o elemento a elemento (map), o paralelismo funciona sem complica\u00e7\u00f5es porque cada itera\u00e7\u00e3o \u00e9 totalmente independente. J\u00e1 na soma parcial, o acesso simult\u00e2neo a uma vari\u00e1vel compartilhada gera condi\u00e7\u00f5es de corrida, que precisam ser resolvidas com mecanismos como <code>reduction</code>.</p> <p>Tamb\u00e9m vimos que alguns la\u00e7os possuem depend\u00eancia entre itera\u00e7\u00f5es, nestes casos, n\u00e3o basta inserir diretivas OpenMP: \u00e9 necess\u00e1rio repensar o algoritmo para eliminar a depend\u00eancia.</p> <p>Por fim, a experi\u00eancia com recurs\u00e3o e tasks mostrou que o paralelismo pode gerar overhead se n\u00e3o for bem controlado. Criar muitas tarefas pequenas pode ser pior do que executar de forma sequencial.</p> <p>Esta atividade n\u00e3o tem entrega, bom fim de semana!!!</p>"},{"location":"aulas/aula07/","title":"Aula 07 - Programa\u00e7\u00e3o Distribu\u00edda","text":"<p>Message Passing Interface (MPI) \u00e9 um padr\u00e3o para comunica\u00e7\u00e3o de dados em computa\u00e7\u00e3o paralela. Existem v\u00e1rias modalidades de computa\u00e7\u00e3o paralela, e dependendo do problema que se est\u00e1 tentando resolver, pode ser necess\u00e1rio passar informa\u00e7\u00f5es entre os v\u00e1rios processadores ou n\u00f3s de um cluster, e o MPI oferece uma infraestrutura para essa tarefa.</p> <p>Para iniciarmos o nosso estudo de MPI, implemente os desafios abaixo, entendendo como encadear sends e receives, e o impacto nos resultados.</p>"},{"location":"aulas/aula07/#ping-pong","title":"Ping-pong","text":"<p>A ideia \u00e9 medir a lat\u00eancia de comunica\u00e7\u00e3o ponto a ponto.</p> <p>Implemente o ping-pong: rank 0 envia uma mensagem ao rank 1, que responde. Fa\u00e7a duas vers\u00f5es:</p> <ul> <li>Bloqueante (<code>MPI_Send/MPI_Recv</code>)</li> <li>N\u00e3o-bloqueante (<code>MPI_Isend/Irecv + MPI_Wait</code>)</li> </ul> <p>Rode os testes:</p> <ul> <li>Mensagens de 16 B, 1 KB, 64 KB, 1 MB</li> <li>Em 2, 3 e 4 n\u00f3s </li> </ul> <p>Dica!</p> <p>Lembre-se, cada double ocupa 8 bytes, cada float ocupa 4 bytes, cada int ocupa 4 bytes, cada char, 1 byte.</p> <p>Analise: </p> <ul> <li>Para mensagens pequenas, o que domina: lat\u00eancia fixa ou tamanho da mensagem?</li> <li>A partir de que tamanho de mensagem o gargalo passa a ser a largura de banda da rede?</li> </ul> <p>C\u00f3digo base: <pre><code>#include &lt;mpi.h&gt;        // Biblioteca principal do MPI para comunica\u00e7\u00e3o entre processos\n#include &lt;iostream&gt;    \n#include &lt;cstring&gt;      \n\nint main(int argc, char** argv) {\n    int rank;               // Vari\u00e1vel que armazenar\u00e1 o \"rank\" (identificador) do processo\n    MPI_Status status;      // Estrutura que armazenar\u00e1 o status da comunica\u00e7\u00e3o MPI\n    char mensagem[100];     // Vetor de caracteres para armazenar a mensagem a ser enviada/recebida\n\n    // Inicializa o ambiente MPI (todos os processos s\u00e3o iniciados)\n    MPI_Init(&amp;argc, &amp;argv);\n\n    // Descobre o \"rank\" do processo atual dentro do comunicador global (MPI_COMM_WORLD)\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n\n    // Se este for o processo de rank 0 (emissor inicial)\n    if (rank == 0) {\n        // Copia a string \"Ol\u00e1\" para a vari\u00e1vel mensagem\n        std::strcpy(mensagem, \"Ol\u00e1\");\n\n        // Envia a mensagem para o processo de rank 1\n        // Par\u00e2metros: buffer, tamanho, tipo, destino, tag, comunicador\n        MPI_Send(mensagem, std::strlen(mensagem) + 1, MPI_CHAR, 1, 0, MPI_COMM_WORLD);\n\n        // Imprime no terminal que a mensagem foi enviada\n        std::cout &lt;&lt; \"Processo 0 enviou: \" &lt;&lt; mensagem &lt;&lt; std::endl;\n\n        // Aguarda a resposta do processo 1\n        // Par\u00e2metros: buffer, tamanho m\u00e1ximo, tipo, origem, tag, comunicador, status\n        MPI_Recv(mensagem, 100, MPI_CHAR, 1, 0, MPI_COMM_WORLD, &amp;status);\n\n        // Imprime a mensagem recebida\n        std::cout &lt;&lt; \"Processo 0 recebeu: \" &lt;&lt; mensagem &lt;&lt; std::endl;\n    }\n\n    // Se este for o processo de rank 1 (receptor inicial)\n    else if (rank == 1) {\n        // Recebe a mensagem enviada pelo processo 0\n        MPI_Recv(mensagem, 100, MPI_CHAR, 0, 0, MPI_COMM_WORLD, &amp;status);\n\n        // Imprime a mensagem recebida\n        std::cout &lt;&lt; \"Processo 1 recebeu: \" &lt;&lt; mensagem &lt;&lt; std::endl;\n\n        // Prepara a resposta \"Oi\"\n        std::strcpy(mensagem, \"Oi\");\n\n        // Envia a resposta de volta ao processo 0\n        MPI_Send(mensagem, std::strlen(mensagem) + 1, MPI_CHAR, 0, 0, MPI_COMM_WORLD);\n\n        // Imprime que a mensagem foi enviada\n        std::cout &lt;&lt; \"Processo 1 enviou: \" &lt;&lt; mensagem &lt;&lt; std::endl;\n    }\n\n    else {\n        // Todos os outros processos apenas informam que est\u00e3o ociosos\n        std::cout &lt;&lt; \"Processo \" &lt;&lt; rank &lt;&lt; \" est\u00e1 ocioso neste exerc\u00edcio.\" &lt;&lt; std::endl;\n    }\n\n    // Finaliza o ambiente MPI (todos os processos encerram)\n    MPI_Finalize();\n\n    return 0;\n}\n</code></pre></p>"},{"location":"aulas/aula07/#carregue-o-modulo","title":"Carregue o modulo","text":"<pre><code>spack load openmpi\n</code></pre>"},{"location":"aulas/aula07/#teste-para-ver-se-o-modulo-foi-carregado-corretamente","title":"Teste para ver se o modulo foi carregado corretamente","text":"<pre><code>mpicc --version\n</code></pre>"},{"location":"aulas/aula07/#deve-aparecer-algo-como","title":"Deve aparecer algo como:","text":"<pre><code>gcc (GCC) 14.2.0\nCopyright (C) 2024 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre>"},{"location":"aulas/aula07/#compile-o-programa","title":"Compile o programa:","text":"<pre><code>mpic++ -FlagdeOtimiza\u00e7\u00e3o seu_codigo.cpp -o seu_binario\n</code></pre>"},{"location":"aulas/aula07/#script-slurm","title":"Script SLURM","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=mpi_hello\n#SBATCH --output=saida%j.txt\n#SBATCH --partition=express\n#SBATCH --mem=1GB\n#SBATCH --nodes=2\n#SBATCH --ntasks=5\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:02:00\n#SBATCH --export=ALL\n\n\n# Fa\u00e7a load nos m\u00f3dulos dentro do n\u00f3 de computa\u00e7\u00e3o\nsource /etc/profile\n. /opt/spack/share/spack/setup-env.sh\nmodule use /opt/spack/share/spack/lmod/linux-rocky9-x86_64/Core\nmodule --ignore_cache load openmpi/5.0.8-gcc-14.2.0\n\n# Execute o seu bin\u00e1rio com o MPI\nmpirun -np $SLURM_NTASKS ./seu_binario\n</code></pre>"},{"location":"aulas/aula07/#submeta-o-job-com-slurm","title":"Submeta o job com SLURM:","text":"<pre><code>sbatch SeuSlurm.slurm\n</code></pre>"},{"location":"aulas/aula07/#voce-deve-ver-algo-como-isso","title":"Voc\u00ea deve ver algo como isso:","text":"<pre><code>[liciascl@head-node mpi]$ cat saida.txt\n/usr/bin/id: cannot find name for user ID 1018\n/var/spool/slurmd/job06957/slurm_script: line 15: /opt/spack/share/spack/setup-env.sh: No such file or directory\nLmod has detected the following error: The following module(s) are unknown:\n\"openmpi/5.0.8-gcc-14.2.0\"\n\nPlease check the spelling or version number. Also try \"module spider ...\"\nIt is also possible your cache file is out-of-date; it may help to try:\n  $ module --ignore_cache load \"openmpi/5.0.8-gcc-14.2.0\"\n\nAlso make sure that all modulefiles written in TCL start with the string\n\nProcesso 2 est\u00e1 ocioso neste exerc\u00edcio.\nProcesso 3 est\u00e1 ocioso neste exerc\u00edcio.\nProcesso 0 enviou: Ol\u00e1\nProcesso 0 recebeu: Oi\nProcesso 1 recebeu: Ol\u00e1\nProcesso 1 enviou: Oi\nProcesso 4 est\u00e1 ocioso neste exerc\u00edcio.\n</code></pre> <p>Ignore os warnings, o ponto \u00e9 que o Rank0 est\u00e1 conversando com o Rank1 conforme o c\u00f3digo exemplo, agora \u00e9 a sua vez!  Fa\u00e7a as altera\u00e7\u00f5es no c\u00f3digo exemplo e implemente as outras formas de comunica\u00e7\u00e3o entre n\u00f3s usando MPI</p>"},{"location":"aulas/aula07/#token-em-anel","title":"Token em anel","text":"<p>A ideia \u00e9 perceber o custo de coletar informa\u00e7\u00f5es sequencialmente.</p> <p>Implemente o token em anel: cada rank adiciona uma informa\u00e7\u00e3o nova ao vetor e passa adiante. Execute em 2, 3 e 4 n\u00f3s . Compare com o mesmo problema usando <code>MPI_Gather</code>.</p> <p>Analise:</p> <ul> <li>Como cresce o tempo do anel com o n\u00famero de processos?</li> <li>Qual o gargalo de percorrer todos em sequ\u00eancia?</li> <li>Qual a vantagem de usar <code>MPI_Gather</code>?</li> </ul>"},{"location":"aulas/aula07/#alternancia","title":"Altern\u00e2ncia","text":"<p>A ideia \u00e9 entender como funciona uma distribui\u00e7\u00e3o de tarefas.</p> <p>Rank 0 possui 13 tarefas cada uma com diferentes niveis de complexidade. Implemente uma distribui\u00e7\u00e3o din\u00e2mica de tarefas, o worker que terminar primeiro recebe a pr\u00f3xima tarefa.</p> <p>O que acontece quando as tarefas variam muito de custo?</p>"},{"location":"aulas/aula07/#o-que-voce-deve-entregar","title":"O que voc\u00ea deve entregar:","text":"<p>Para cada exerc\u00edcio:</p> <ol> <li>C\u00f3digo (dispon\u00edvel no reposit\u00f3rio do github).</li> <li>Tabela de resultados (par\u00e2metros usados, tempos medidos).</li> <li>Discuss\u00e3o: An\u00e1lise dos resultados</li> </ol> <p>Envie o seu relat\u00f3rio com as suas an\u00e1lises at\u00e9 as 23h59 de 08/09 pelo GitHub Classroom </p>"},{"location":"projetos/","title":"Projeto da disciplina","text":"<p>O projeto da nossa disciplina est\u00e1 dispon\u00edvel nesse link</p>"},{"location":"projetos/exaustiva/","title":"Busca Exaustiva para Alinhamento de Sequencias","text":"<p>A busca exaustiva, conforme vista aula, gera todas as solu\u00e7\u00f5es vi\u00e1veis para um problema e, de acordo com um crit\u00e9rio de otimalidade, elege uma solu\u00e7\u00e3o \u00f3tima para o problema. Especificamente para o problema de alinhamento de sequencias, ele pode ser especificado da seguinte forma:</p> <pre><code>ALGORITMO BUSCA EXAUSTIVA\nEntrada: Duas sequencias de DNA a e b\n        Pesos wmat, wmis e wgap para match, mismatch e gap respectivamente\nSa\u00edda: Score de um alinhamento das sequencias\n      Subsequencias alinhadas\n\n1. Gerar todas as subsequencias a\u00b4 e b\u00b4 n\u00e3o-nulas de a e b, respectivamente.\n2. Calcular os alinhamentos de cada par de subsequencias (a\u00b4, b\u00b4) com os pesos wmat, wmis e wgap\n3. Devolver o score m\u00e1ximo m entre os scores do passo (2) e as subsequencias associadas a ele\n</code></pre> <p>Observe que, no passo (2), as subsequencias podem n\u00e3o ter o mesmo tamanho. Assim, n\u00e3o ser\u00e1 poss\u00edvel calcular diretamente um score simples. Podemos usar, por exemplo:</p> <ul> <li> a estrat\u00e9gia vista no primeiro projeto (Alinhamento Local de Smith-Waterman) para comparar duas subsequencias          <li> um truncamento da subsequencia maior pelo tamanho da subsequencia menor e calcular o score simples entre as duas subsequencias resultantes          <li> o Alinhamento Local de Smith-Waterman quando as subsequencias forem de tamanhos diferentes e, quando forem de tamanho igual, a estrat\u00e9gia aleat\u00f3ria do Projeto II.                    <p>A partir desta descri\u00e7\u00e3o, nosso terceiro projeto ter\u00e1 duas tarefas:</p> <ul> <li> Implementar um programa C++ para ler um arquivo contendo os tamanhos de duas sequencias de DNA, seguidos das duas sequencias, uma por linha. Calcular o score m\u00e1ximo utilizando o algoritmo acima, assim como as subsequencias associadas a ele.    <li> Implementar duas estrat\u00e9gias diferentes para calcular os alinhamentos entre os pares de subsequencias do passo (2).  No diret\u00f3rio do projeto, h\u00e1 um gerador de entradas disponibilizado como um notebook Python. Como se trata de uma busca exaustiva, recomenda-se come\u00e7ar a testar com tamanhos pequenos e      ir aumentando gradativamente at\u00e9 atingir o tamanho m\u00e1ximo que a sua plataforma ainda consiga executar."},{"location":"projetos/gpu/","title":"Paralelismo com GPU","text":"<p>Esta etapa do projeto consiste em resolver nosso problema por meio da biblioteca Thrust. Vamos come\u00e7ar revendo a formaliza\u00e7\u00e3o de nosso problema:</p> <p>Entrada:</p> <p>Um inteiro N representando o n\u00famero de filmes dispon\u00edveis para assistir. Tr\u00eas vetores H, F e C de tamanho N, onde H[i] \u00e9 a hora de in\u00edcio, F[i] \u00e9 a hora de t\u00e9rmino e C[i] \u00e9 a categoria do i-\u00e9simo filme. Um inteiro M representando o n\u00famero de categorias. Um vetor L de tamanho M, onde L[j] \u00e9 o n\u00famero m\u00e1ximo de filmes que podem ser assistidos na categoria j.</p> <p>Sa\u00edda:</p> <p>Um inteiro representando o n\u00famero m\u00e1ximo de filmes que podem ser assistidos de acordo com as restri\u00e7\u00f5es de hor\u00e1rios e n\u00famero m\u00e1ximo por categoria.</p> <p>Para resolver esse problema utilizando a biblioteca thrust, podemos utilizar um algoritmo de programa\u00e7\u00e3o din\u00e2mica para construir a solu\u00e7\u00e3o de forma eficiente. O algoritmo consiste em criar uma matriz dp de tamanho (N+1) x (M+1) para armazenar o n\u00famero m\u00e1ximo de filmes que podem ser assistidos at\u00e9 o filme i e a categoria j.</p> <p>Segue abaixo um pseudo-c\u00f3digo (incompleto) para resolver o problema</p> <pre><code>// Carregar os dados do arquivo de entrada na mem\u00f3ria da GPU\nthrust::device_vector&lt;int&gt; start_times(N);\nthrust::device_vector&lt;int&gt; end_times(N);\nthrust::device_vector&lt;int&gt; categories(N);\n\n// Ler os dados do arquivo de entrada\n// ...\n\n// Criar a matriz de programa\u00e7\u00e3o din\u00e2mica\nthrust::device_vector&lt;int&gt; dp((N+1) * (M+1), 0);\n\n// Inicializar a primeira linha da matriz com zeros\nthrust::fill(dp.begin(), dp.begin() + M + 1, 0);\n\n// Preencher a matriz com as solu\u00e7\u00f5es para subproblemas menores\nfor (int i = 1; i &lt;= N; i++) {\n  for (int j = 1; j &lt;= M; j++) {\n    // Encontrar o n\u00famero m\u00e1ximo de filmes que podem ser assistidos at\u00e9 o filme i e categoria j\n    int max_count = 0;\n    for (int k = 0; k &lt; i; k++) {\n      if (categories[k] == j &amp;&amp; end_times[k] &lt;= start_times[i] &amp;&amp; dp[(k*(M+1)) + j-1] + 1 &lt;= L[j-1]) {\n        max_count = max(max_count, dp[(k*(M+1)) + j-1] + 1);\n      } else {\n        max_count = max(max_count, dp[(k*(M+1)) + j]);\n      }\n    }\n    dp[(i*(M+1)) + j] = max_count;\n  }\n}\n\n// Encontrar o n\u00famero m\u00e1ximo de filmes que podem ser assistidos\nint max_count = 0;\nfor (int j = 1; j &lt;= M; j++) {\n  max_count = max(max_count, dp[(N*(M+1)) + j]);\n}\n\n// Escrever o resultado no arquivo de sa\u00edda\n// ...\n</code></pre> <p>A ideia do algoritmo \u00e9 criar uma matriz dp de tamanho (N+1) x (M+1) para armazenar o n\u00famero m\u00e1ximo de filmes que podem ser assistidos at\u00e9 o filme i e a categoria j. O algoritmo preenche a matriz com as solu\u00e7\u00f5es para subproblemas menores, at\u00e9 chegar na solu\u00e7\u00e3o do problema original.</p> <p>Para cada c\u00e9lula (i,j) da matriz dp, o algoritmo verifica se \u00e9 poss\u00edvel adicionar o filme i \u00e0 categoria j, respeitando as restri\u00e7\u00f5es de hor\u00e1rio e limite m\u00e1ximo de filmes por categoria. Em seguida, o algoritmo verifica se \u00e9 melhor adicionar o filme i \u00e0 categoria j ou manter a solu\u00e7\u00e3o anterior sem o filme i. O n\u00famero m\u00e1ximo de filmes que podem ser assistidos \u00e9 o valor da c\u00e9lula (N, j) da matriz dp, onde j \u00e9 a categoria que maximiza o n\u00famero de filmes assistidos.</p> <p>Sua tarefa \u00e9 realizar essa implementa\u00e7\u00e3o em C++ com a Thrust e comparar o desempenho frente as demais implementa\u00e7\u00f5es. </p>"},{"location":"projetos/heuristico/","title":"Heur\u00edstica Gulosa","text":"<p>A primeira implementa\u00e7\u00e3o da heur\u00edstica para nosso projeto consiste em uma implementa\u00e7\u00e3o gulosa (Greedy).</p> <p>Implemente uma vers\u00e3o gulosa que ordena os filmes por hora de fim crescente e escolhe aqueles que come\u00e7am primeiro e n\u00e3o conflitam com os filmes j\u00e1 escolhidos, al\u00e9m de verificar se h\u00e1 vagas dispon\u00edveis na categoria do filme.</p>"},{"location":"projetos/local/","title":"Aleatoriedade","text":"<p>Como vimos em aula, aleatoriedade \u00e9 uma estrat\u00e9gia bastante comum para constru\u00e7\u00e3o de algoritmos de busca local, podendo ser usada de forma isolada ou de forma complementar a outra estrat\u00e9gia de varredura de um espa\u00e7o de solu\u00e7\u00f5es. </p> <p>Essa implementa\u00e7\u00e3o consiste na adapta\u00e7\u00e3o da heur\u00edstica gulosa de nosso projeto. A proposta \u00e9 que voc\u00ea modifique a sua heur\u00edstica gulosa de modo que ao longo da sele\u00e7\u00e3o de um filme voc\u00ea tenha 25% de chance de pegar outro filme qualquer que respeite o hor\u00e1rio. Isso far\u00e1 com que sua heur\u00edstica tenha um pouco mais de exploration e possamos ter alguns resultados melhores. </p> <p>Importante: \u00e9 essencial que voc\u00ea guarde todos os inputs usados ao longo do projeto, para que possa comparar o desempenho de seus algoritmos conforme mudamos a heur\u00edstica. Ou seja, todas as heur\u00edsticas devem ser submetidas aos mesmos arquivos de input. O seu resultado deve ser comparado sob duas perspectivas, no m\u00ednimo: (i) tempo de execu\u00e7\u00e3o em fun\u00e7\u00e3o do aumento de filmes e de categorias e (ii) tempo de tela (isto \u00e9, ser\u00e1 que estamos conseguindo ocupar bem as 24h do dia assitindo filmes?).</p>"},{"location":"projetos/openmp/","title":"Paralelismo com OpenMP","text":"<p>At\u00e9 agora experimentamos heur\u00edsticas que buscaram resolver o nosso problema em um tempo razo\u00e1vel, sem garantias de otimalidade. \u00c9 chegado o momento de incorporar o paralelismo de tarefas em nossas alternativas de resolu\u00e7\u00e3o.</p> <p>Para isso, voc\u00ea deve modificar a vers\u00e3o exaustiva de sua implementa\u00e7\u00e3o. Voc\u00ea pode fazer uso da diretiva <code>#pragma omp parallel for</code> para distribuir as itera\u00e7\u00f5es de um loop entre as threads dispon\u00edveis. Dentro do loop, voc\u00ea pode fazer a verifica\u00e7\u00e3o de cada filme e, caso ele esteja dentro das restri\u00e7\u00f5es de hor\u00e1rio e categoria, incrementar uma vari\u00e1vel compartilhada <code>count</code>. Observe que por ser uma vari\u00e1vel compartilhada, voc\u00ea precisa preservar essa regi\u00e3o cr\u00edtica entre as threads. </p> <p>Vale ressaltar que o uso do OpenMP n\u00e3o necessariamente ir\u00e1 garantir um desempenho melhor, pois a paraleliza\u00e7\u00e3o tem um overhead que pode acabar diminuindo a performance do programa em alguns casos. \u00c9 importante fazer testes para verificar se a utiliza\u00e7\u00e3o do OpenMP \u00e9 realmente ben\u00e9fica para o problema em quest\u00e3o.</p>"},{"location":"projetos/relatorio_parcial/","title":"Relat\u00f3rio Parcial","text":"<p>O relat\u00f3rio parcial \u00e9 a entrega intermedi\u00e1ria do projeto, a qual deve ser feita pelo blackboard at\u00e9 a data da prova intermedi\u00e1ria.</p> <p>Seu relat\u00f3rio dever\u00e1 conter as implementa\u00e7\u00f5es gulosa e aleat\u00f3ria. </p> <p>O que voc\u00ea dever\u00e1 fazer:</p> <ul> <li> <p>No blackboard, voc\u00ea deve fazer upload de todos os c\u00f3digos-fonte, arquivos de input, arquivos de output para cada heur\u00edtica. Caso opte por enviar um link do github com o reposit\u00f3rio completo, tamb\u00e9m poder\u00e1 faze-lo, desde que garanta que teremos acesso aos arquivos no seu reposit\u00f3rio;</p> </li> <li> <p>Voc\u00ea deve elaborar um relat\u00f3rio parcial contendo as seguintes se\u00e7\u00f5es:</p> <ul> <li> <p>Para cada heur\u00edstica voc\u00ea deve explicar como implementou a heur\u00edstica (detalhe como voc\u00ea tratou o input, qual a l\u00f3gica do seu output, quais invariantes existem em suas heur\u00edsticas), apresentar (i) o c\u00f3digo-fonte comentado, (ii) fazer considera\u00e7\u00f5es sobre o profiling (valgrind) do c\u00f3digo-fonte (use apenas 1 arquivo de input para isso, n\u00e3o h\u00e1 necessidade de fazer esse profiling para v\u00e1rios inputs), (iii) o resultado compartivo entre as heur\u00edsticas quando voc\u00ea varia o input (o input deve variar na quantidade de filmes e de categorias).</p> </li> <li> <p>Seu relat\u00f3rio deve ser gr\u00e1ficos e tabelas que subsidem as suas considera\u00e7\u00f5es</p> </li> <li> <p>\u00c9 permitido criar um programa em python ou outra linguagem que automatize a gera\u00e7\u00e3o de seus resultados, isto \u00e9, que execute seus c\u00f3digos C++ em fun\u00e7\u00e3o dos diferentes inputs.</p> </li> </ul> </li> </ul> <p>Preferencialmente o relat\u00f3rio deve ser apresentado em formato html. </p>"},{"location":"projetos/2021-2/","title":"Alinhamento de Sequencias de DNA","text":"<p>Em Bioinform\u00e1tica, o problema de alinhamento de sequ\u00eancias de DNA consiste no processo de comparar duas ou mais sequ\u00eancias de bases de forma a se observar seu n\u00edvel de similaridade. Trata-se de um problema extremamente importante no contexto atual, pois permite comparar sequencias virais de SARS-COV2 em bancos de dados gen\u00f4micos para detec\u00e7\u00e3o de novas muta\u00e7\u00f5es.</p> <p>O n\u00edvel de similaridade pode ser calculado com base em acertos (match) e erros (gap e mismatch). Os acertos contribuem com sinal positivo (+) para o n\u00edvel de similaridade e, os erros, com sinal negativo (-). Abaixo temos um exemplo de c\u00e1lculo do n\u00edvel similaridade:</p> <p></p> <p>Vamos associar a pontua\u00e7\u00e3o +1 (match) e as penalidades -1 (gap) e -4 (mismatch). Assim, teremos o seguinte n\u00edvel de similaridade:</p> <p>23 matches x (+1) + 4 gaps x (-1) + 3 mismatches x (-4) = 23-4-12 = 7</p> <p>Neste contexto, o problema de alinhamento de sequencias de DNA pode ser colocado da seguinte forma:</p> <pre><code>Dadas duas sequencias de DNA, com as bases A,T,G,C e - para indicar gap, \nencontrar o alinhamento que maximize o n\u00edvel de similaridade. \n</code></pre> <p>Neste projeto, seu objetivo ser\u00e1 construir programas para encontrar este alinhamento de n\u00edvel m\u00e1ximo de similaridade, utilizando v\u00e1rias estrat\u00e9gias. </p> <p>Cada um dos seus programas tomar\u00e1 como entrada a seguinte estrutura: a primeira linha cont\u00e9m dois n\u00fameros <code>n</code> e <code>m</code>, onde <code>n</code> \u00e9 o tamanho da primeira sequencia e, <code>m</code>, o tamanho da segunda. Assuma <code>n \u2264 200</code> e <code>m \u2264 200</code>. A segunda linha cont\u00e9m as bases da primeira sequencia e, a terceira linha, as bases da segunda.</p> <pre><code>5 7\nAT-CC\nTTTCCAA\n</code></pre> <p>A sa\u00edda deve ser uma linha com um n\u00famero inteiro indicando o n\u00edvel m\u00e1ximo de similaridade.</p> <p><pre><code>2\n</code></pre> Neste caso, este n\u00edvel m\u00e1ximo de similaridade pode ser associado ao alinhamento T-CC/TTCC (1-1+1+1=2) ou a CC/CC(1+1=2). Voc\u00ea pode usar o c\u00f3digo python abaixo para gerar inst\u00e2ncias aleat\u00f3rias para seus testes.</p> <pre><code>import random\nn = 10 # tamanho da primeira sequ\u00eancia\nm = 40 # tamanho da segunda sequ\u00eancia\nfile = 'dna.seq' # nome do arquivo a ser gerado\nf = open(file, 'w')\nseq=[str(n)+'\\n',\n     str(m)+'\\n',\n     ''.join(random.choices(['A','T','C','G','-'],k=n))+'\\n',\n     ''.join(random.choices(['A','T','C','G','-'],k=m))]\nf.writelines(seq)\nf.close()\nprint(''.join(seq))\n</code></pre> <p>Um poss\u00edvel output para este c\u00f3digo acima \u00e9:</p> <pre><code>10\n40\nTGGCGAT--C\nAGC-TCTCTTC--ATT--CAC-TACACCGACA-CGC-G-A\n</code></pre>"},{"location":"projetos/2021-2/#estrategias-a-serem-estudadas-e-correcao-automatica","title":"Estrat\u00e9gias a serem estudadas e corre\u00e7\u00e3o autom\u00e1tica","text":"<p>Para cada estrat\u00e9gia que vamos estudar, implementaremos um programa correspondente no projeto. Veja abaixo as datas de entrega e descri\u00e7\u00f5es de cada estrat\u00e9gia a ser implementada. Em geral, o enunciado de uma parte \u00e9 liberado ap\u00f3s a data de entrega da parte anterior.</p> <ol> <li>Solu\u00e7\u00e3o Heur\u00edstica (18/03)</li> <li>Busca Local (01/04)</li> <li>Busca Exaustiva (15/04)</li> <li>Relat\u00f3rio Preliminar (29/04)</li> <li>Paralelismo Multicore (13/05)</li> <li>Paralelismo GPU (27/05)</li> <li>Relat\u00f3rio Final (03/06)</li> </ol>"},{"location":"projetos/2021-2/#avaliacao","title":"Avalia\u00e7\u00e3o","text":"<p>O projeto ser\u00e1 avaliado usando rubricas para as entregas b\u00e1sicas. As rubricas de avalia\u00e7\u00e3o dos relat\u00f3rios estar\u00e3o descritas em suas p\u00e1ginas de entrega.</p>"},{"location":"projetos/2021-2/#conceito-d","title":"Conceito D","text":"<p>Algum dos seguintes itens n\u00e3o foi entregue corretamente ou possui problemas s\u00e9rios (no caso do relat\u00f3rio final).</p> <ol> <li>Solu\u00e7\u00e3o heur\u00edstica</li> <li>Busca local</li> <li>Busca exaustiva</li> <li>Busca local paralela (CPU)</li> <li>Busca local paralela (GPU)</li> <li>Relat\u00f3rio preliminar</li> <li>Relat\u00f3rio final</li> </ol>"},{"location":"projetos/2021-2/#conceito-c","title":"Conceito C","text":"<p>Todas as atividades abaixo foram validadas pelo corretor e (no caso do relat\u00f3rio final) alcan\u00e7aram qualidade m\u00ednima exigida.</p> <ol> <li>Solu\u00e7\u00e3o heur\u00edstica</li> <li>Busca local</li> <li>Busca exaustiva</li> <li>Busca local paralela (CPU)</li> <li>Busca local paralela (GPU)</li> <li>Relat\u00f3rio preliminar</li> <li>Relat\u00f3rio final</li> </ol>"},{"location":"projetos/2021-2/#conceito-c_1","title":"Conceito C+","text":"<p>Al\u00e9m do j\u00e1 validado no conceito C, os relat\u00f3rios entregues n\u00e3o tinham nenhum ponto em desenvolvimento ou insatisfat\u00f3rio na rubrica do relat\u00f3rio.</p>"},{"location":"projetos/2021-2/#conceitos-avancados","title":"Conceitos avan\u00e7ados","text":"<p>A partir do  conceito C+ cada atividade avan\u00e7ada vale meio conceito. Elas ser\u00e3o listadas aqui conforme o semestre avan\u00e7a e ser\u00e3o testadas pela checagem de resultados dispon\u00edvel no reposit\u00f3rio de entregas.</p>"},{"location":"projetos/2021-2/busca-exaustiva/","title":"Solu\u00e7\u00e3o Busca exaustiva - Branch and Bound","text":"<p>Fa\u00e7a agora uma implementa\u00e7\u00e3o de busca exaustiva para o problema do min-set-cover. Assuma inicialmente que todos os subconjuntos s\u00e3o necess\u00e1rios. Para cada subconjunto da solu\u00e7\u00e3o, remova ele a solu\u00e7\u00e3o em quest\u00e3o e verifique se a propriedade de cobertura \u00e9 mantida. Fa\u00e7a isso para todos os elementos na ordem do vetor de solu\u00e7\u00f5es, enquanto a propriedade for v\u00e1lida. Se a propriedade ficar inv\u00e1lida, voc\u00ea deve interromper essa linha de processamento, executando ent\u00e3o uma nova estrutura de possibilidades em que considera esse conjunto vital para a continuidade do problema. </p> <p>Para auxiliar na sua implementa\u00e7\u00e3o, voc\u00ea pode se basear no pseudoc\u00f3digo abaixo. Assuma que custos \u00e9 um vetor unit\u00e1rio de cardinalidade igual ao vetor que armazena os subconjuntos. H\u00e1 um programa Python disponibilizado neste link para que voc\u00ea possa simular a implementa\u00e7\u00e3o desse pseudoc\u00f3digo. </p> <p>Avalie: H\u00e1 garantia de que o resultado \u00f3timo \u00e9 obtido? Justifique. </p> <p></p>"},{"location":"projetos/2021-2/busca-local/","title":"Solu\u00e7\u00e3o Busca local","text":"<p>A busca local consiste em uma metaheur\u00edstica usada para resolver problemas de otimiza\u00e7\u00e3o computacionalmente dif\u00edceis. Esse tipo de algoritmo percorre o espa\u00e7o de busca movendo-se iterativamente de uma solu\u00e7\u00e3o candidata para outra, seguindo um caminho atrav\u00e9s da rela\u00e7\u00e3o de vizinhan\u00e7a, at\u00e9 que uma solu\u00e7\u00e3o considerada boa o suficiente seja encontrada ou um limite de tempo decorrido. Normalmente todo candidato possui mais de uma solu\u00e7\u00e3o de vizinho e a escolha entre elas \u00e9 feita com o aux\u00edlio de informa\u00e7\u00f5es locais e experi\u00eancia anterior.</p> <p>A solu\u00e7\u00e3o por busca local  tenta maximizar o n\u00famero de elementos com o m\u00ednimo de subconjuntos poss\u00edvel. Precisamos capturar esse crit\u00e9rio por meio de uma fun\u00e7\u00e3o de fitness. Uma maneira poss\u00edvel de fazer isso \u00e9 construir uma fun\u00e7\u00e3o de fitness calculando o n\u00famero de elementos capturados pelos subconjuntos de uma solu\u00e7\u00e3o candidata e, em seguida, dividindo-o pelo n\u00famero de subconjuntos que cont\u00e9m. Essa fun\u00e7\u00e3o de pontua\u00e7\u00e3o favorecer\u00e1 as solu\u00e7\u00f5es que acumulam a maioria dos elementos do universo U com o m\u00ednimo de subconjuntos.</p> <p>Para isso, implemente as seguintes altera\u00e7\u00f5es em seu projeto:</p> <ol> <li>Gerar uma solu\u00e7\u00e3o aleat\u00f3ria para o problema do min-set-cover;</li> <li>Percorra novamente os conjuntos os elementos da sua solu\u00e7\u00e3o e, de maneira rand\u00f4mica, troque at\u00e9 r (r entre 1 e 3) elementos da sua solu\u00e7\u00e3o por subconjuntos que ficaram de fora da solu\u00e7\u00e3o. </li> <li>Se a solu\u00e7\u00e3o tiver melhor escore, mantenha ela. </li> </ol> <p>Para verificar o desempenho, construa um cen\u00e1rio com ao menos 200 elementos e 80 subconjuntos, de at\u00e9 40 elementos cada.  Fa\u00e7a tr\u00eas varia\u00e7\u00f5es desse cen\u00e1rio (elementos, subconjuntos, n\u00famero de elementos em subconjuntos) e avalie o desempenho e a efetividade em encontrar uma solu\u00e7\u00e3o \u00f3tima.</p> <p>Para a entrega, usaremos o site codePost, voc\u00ea recebeu na sala de aula o link para criar sua conta. A submiss\u00e3o ser\u00e1 feita unicamente por ele. Caso tenha alguma d\u00favida, entre em contato.</p>"},{"location":"projetos/2021-2/heuristico/","title":"Solu\u00e7\u00e3o heur\u00edstica","text":"<p>Um dos melhores estrat\u00e9gias para resolu\u00e7\u00e3o do problema min-set-cover \u00e9 a estrat\u00e9gia gulosa. O algoritmo guloso encontra uma solu\u00e7\u00e3o para o problema de cobertura de conjunto escolhendo iterativamente um conjunto que cobre o maior n\u00famero poss\u00edvel de vari\u00e1veis descobertas restantes.</p> <p>Sua tarefa: implemente a estrat\u00e9gia gulosa para o problema do min-set-cover. A cada itera\u00e7\u00e3o, o algoritmo deve selecionar o subconjunto de F que ir\u00e1 cobrir o maior n\u00famero de elementos de U que estavam descobertos.</p> <p>Veja abaixo um pseudo-c\u00f3digo da estrat\u00e9gia gulosa que voc\u00ea deve implementar.</p> <p></p> <p>Fa\u00e7a testes para diversos tipos de entradas, e foque principalmente em uma grande quantidade de elementos e subconjuntos (n &gt; 250).</p> <p>Voc\u00ea deve entregar, al\u00e9m de c\u00f3digo-fonte e todas as entradas e sa\u00eddas geradas para o seu programa, um arquivo contendo o resultado do programa <code>verify</code> ( que voc\u00ea implementou ) e comentar sobre o n\u00famero de vezes em que voc\u00ea conseguiu encontrar uma solu\u00e7\u00e3o para o problema. Comente tamb\u00e9m sobre o tempo de execu\u00e7\u00e3o de sua implementa\u00e7\u00e3o. </p> <p>Para a entrega, usaremos o site codePost, voc\u00ea recebeu na sala de aula o link para criar sua conta. A submiss\u00e3o ser\u00e1 feita unicamente por ele. Caso tenha alguma d\u00favida, entre em contato.</p>"},{"location":"projetos/2021-2/paralelismo-gpu/","title":"Paralelismo em GPU","text":"<p>Seu trabalho nesta atividade ser\u00e1 criar uma implementa\u00e7\u00e3o paralela em GPU do algoritmo de busca local.</p>"},{"location":"projetos/2021-2/paralelismo-gpu/#compilacao-do-programa","title":"Compila\u00e7\u00e3o do programa","text":"<p>Voc\u00ea dever\u00e1 colocar o c\u00f3digo de seu programa em um arquivo com extens\u00e3o .cu na pasta da busca local. Este programa ser\u00e1 compilado com <code>nvcc -O3</code>. </p> <p>Para a entrega, usaremos o site codePost.</p> <p>\u2192</p>"},{"location":"projetos/2021-2/paralelismo-multicore/","title":"Paralelismo multi-core","text":"<p>Seu trabalho nesta atividade ser\u00e1 criar uma implementa\u00e7\u00e3o paralela do algoritmo de busca local.</p>"},{"location":"projetos/2021-2/paralelismo-multicore/#compilacao-do-programa","title":"Compila\u00e7\u00e3o do programa","text":"<p>Seu programa multi-core dever\u00e1 ser gerado a partir do mesmo c\u00f3digo fonte do sequencial. Ou seja, compilar com <code>-fopenmp</code> habilita o programa paralelo. Compilar sem essa flag obtem os resultados sequenciais. Caso seu programa use as chamadas do OpenMP para c\u00f3digos auxiliares (aloca\u00e7\u00e3o de mem\u00f3ria, etc), voc\u00ea pode checar se seu programa foi compilado com esta flag seguindo o exemplo abaixo.</p> <pre><code>#ifdef _OPENMP\n    // c\u00f3digo espec\u00edfico para multi-core aqui\n#else\n    // c\u00f3digo espec\u00edfico para sequencia aqui\n#endif\n</code></pre> <p>Para a entrega, usaremos o site codePost.</p>"},{"location":"projetos/2021-2/relatorio-1/","title":"Relat\u00f3rio - v1","text":"<p>Nesta primeira parte do relat\u00f3rio iremos analisar as implementa\u00e7\u00f5es j\u00e1 criadas com rela\u00e7\u00e3o a sua velocidade e qualidade da solu\u00e7\u00e3o. Os objetivos deste relat\u00f3rio s\u00e3o </p> <ul> <li>criar entradas de tamanho adequado para os prop\u00f3sitos dos testes</li> <li>estudar o efeito do n\u00famero de pessoas e do n\u00famero de objetos nas medidas de interesse (tempo e qualidade da solu\u00e7\u00e3o)</li> <li>comparar o desempenho dos algoritmos implementados at\u00e9 o momento em rela\u00e7\u00e3o a essas duas medidas.</li> </ul> <p>Seu trabalhou dever\u00e1 ser entregue como um arquivo PDF chamado relatorio-intermediario.pdf na pasta relatorios do reposit\u00f3rio. Ele poder\u00e1 ser gerado a partir de um Jupyter notebook (como feito na aula 01) ou usando a ferramenta pweave (recomendado). A rubrica de avalia\u00e7\u00e3o est\u00e1 dispon\u00edvel abaixo e tamb\u00e9m neste link.</p> <p>Data de entrega: 31/10/2021, pelo blackboard.</p> <p></p>"},{"location":"projetos/2022-1/","title":"Alinhamento de Sequencias de DNA","text":"<p>Em Bioinform\u00e1tica, o problema de alinhamento de sequ\u00eancias de DNA consiste no processo de comparar duas ou mais sequ\u00eancias de bases de forma a se observar seu n\u00edvel de similaridade. Trata-se de um problema extremamente importante no contexto atual, pois permite comparar sequencias virais de SARS-COV2 em bancos de dados gen\u00f4micos para detec\u00e7\u00e3o de novas muta\u00e7\u00f5es.</p> <p>O n\u00edvel de similaridade pode ser calculado com base em acertos (match) e erros (gap e mismatch). Os acertos contribuem com sinal positivo (+) para o n\u00edvel de similaridade e, os erros, com sinal negativo (-). Abaixo temos um exemplo de c\u00e1lculo do n\u00edvel similaridade:</p> <p></p> <p>Vamos associar a pontua\u00e7\u00e3o +1 (match) e as penalidades -1 (gap) e -4 (mismatch). Assim, teremos o seguinte n\u00edvel de similaridade:</p> <p>23 matches x (+1) + 4 gaps x (-1) + 3 mismatches x (-4) = 23-4-12 = 7</p> <p>Neste contexto, o problema de alinhamento de sequencias de DNA pode ser colocado da seguinte forma:</p> <pre><code>Dadas duas sequencias de DNA, com as bases A,T,G,C e - para indicar gap, \nencontrar o alinhamento que maximize o n\u00edvel de similaridade. \n</code></pre> <p>Neste projeto, seu objetivo ser\u00e1 construir programas para encontrar este alinhamento de n\u00edvel m\u00e1ximo de similaridade, utilizando v\u00e1rias estrat\u00e9gias. </p> <p>Cada um dos seus programas tomar\u00e1 como entrada a seguinte estrutura: a primeira linha cont\u00e9m dois n\u00fameros <code>n</code> e <code>m</code>, onde <code>n</code> \u00e9 o tamanho da primeira sequencia e, <code>m</code>, o tamanho da segunda. Assuma <code>n \u2264 200</code> e <code>m \u2264 200</code>. A segunda linha cont\u00e9m as bases da primeira sequencia e, a terceira linha, as bases da segunda.</p> <pre><code>5 7\nAT-CC\nTTTCCAA\n</code></pre> <p>A sa\u00edda deve ser uma linha com um n\u00famero inteiro indicando o n\u00edvel m\u00e1ximo de similaridade.</p> <p><pre><code>2\n</code></pre> Neste caso, este n\u00edvel m\u00e1ximo de similaridade pode ser associado ao alinhamento T-CC/TTCC (1-1+1+1=2) ou a CC/CC(1+1=2). Voc\u00ea pode usar o notebook SequenceGenerator.ipynb para gerar inst\u00e2ncias aleat\u00f3rias para seus testes.</p>"},{"location":"projetos/2022-1/#estrategias-a-serem-estudadas-e-correcao-automatica","title":"Estrat\u00e9gias a serem estudadas e corre\u00e7\u00e3o autom\u00e1tica","text":"<p>Para cada estrat\u00e9gia que vamos estudar, implementaremos um programa correspondente no projeto. Veja abaixo as datas de entrega e descri\u00e7\u00f5es de cada estrat\u00e9gia a ser implementada. Em geral, o enunciado de uma parte \u00e9 liberado ap\u00f3s a data de entrega da parte anterior.</p> <ol> <li>Solu\u00e7\u00e3o Heur\u00edstica (18/03)</li> <li>Busca Local(01/04)</li> <li>Busca Exaustiva(15/04)</li> <li>Relat\u00f3rio Preliminar (29/04)</li> <li>Paralelismo Multicore (13/05)</li> <li>Paralelismo GPU (27/05)</li> <li>Relat\u00f3rio Final (03/06)</li> </ol>"},{"location":"projetos/2022-1/#avaliacao","title":"Avalia\u00e7\u00e3o","text":"<p>O projeto ser\u00e1 avaliado usando rubricas para as entregas b\u00e1sicas. As rubricas de avalia\u00e7\u00e3o dos relat\u00f3rios estar\u00e3o descritas em suas p\u00e1ginas de entrega.</p>"},{"location":"projetos/2022-1/#conceito-d","title":"Conceito D","text":"<p>Algum dos seguintes itens n\u00e3o foi entregue corretamente ou possui problemas s\u00e9rios (no caso do relat\u00f3rio final).</p> <ol> <li>Solu\u00e7\u00e3o heur\u00edstica</li> <li>Busca local</li> <li>Busca exaustiva</li> <li>Busca local paralela (CPU)</li> <li>Busca local paralela (GPU)</li> <li>Relat\u00f3rio preliminar</li> <li>Relat\u00f3rio final</li> </ol>"},{"location":"projetos/2022-1/#conceito-c","title":"Conceito C","text":"<p>Todas as atividades abaixo foram validadas pelo corretor e (no caso do relat\u00f3rio final) alcan\u00e7aram qualidade m\u00ednima exigida.</p> <ol> <li>Solu\u00e7\u00e3o heur\u00edstica</li> <li>Busca local</li> <li>Busca exaustiva</li> <li>Busca local paralela (CPU)</li> <li>Busca local paralela (GPU)</li> <li>Relat\u00f3rio preliminar</li> <li>Relat\u00f3rio final</li> </ol>"},{"location":"projetos/2022-1/#conceito-c_1","title":"Conceito C+","text":"<p>Al\u00e9m do j\u00e1 validado no conceito C, os relat\u00f3rios entregues n\u00e3o tinham nenhum ponto em desenvolvimento ou insatisfat\u00f3rio na rubrica do relat\u00f3rio.</p>"},{"location":"projetos/2022-1/#conceitos-avancados","title":"Conceitos avan\u00e7ados","text":"<p>A partir do  conceito C+ cada atividade avan\u00e7ada vale meio conceito. Elas ser\u00e3o listadas aqui conforme o semestre avan\u00e7a e ser\u00e3o testadas pela checagem de resultados dispon\u00edvel no reposit\u00f3rio de entregas.</p>"},{"location":"projetos/2022-1/SequenceGenerator/","title":"SequenceGenerator","text":"<p>GERADOR DE INST\u00c2NCIAS PARA COMPARA\u00c7\u00c3O DE SEQUENCIAS DE DNA</p> <p>Para usar este gerador, voc\u00ea deve fornecer tr\u00eas par\u00e2metros:</p> <p>n = tamanho da primeira sequencia </p> <p>m = tamanho da segunda inst\u00e2ncia </p> <p>file = nome do arquivo da inst\u00e2ncia a ser gerada</p> <pre><code>import random\nn = 10\nm = 40\nfile = 'dna.seq'\nf = open(file, 'w')\nseq=[str(n)+'\\n',\n     str(m)+'\\n',\n     ''.join(random.choices(['A','T','C','G','-'],k=n))+'\\n',\n     ''.join(random.choices(['A','T','C','G','-'],k=m))]\nf.writelines(seq)\nf.close()\nprint(''.join(seq))\n</code></pre> <pre>\n<code>10\n40\nTGGCGAT--C\nAGC-TCTCTTC--ATT--CAC-TACACCGACA-CGC-G-A\n</code>\n</pre>"},{"location":"projetos/2022-1/heuristico/","title":"Heur\u00edstica de Alinhamento Local de Smith-Waterman","text":"<p>Um algoritmo ing\u00eanuo para fazer o alinhamento local de duas sequencias de DNA poderia ser:</p> <ol> <li>Gere todas as subsequ\u00eancias, de tamanho 1 at\u00e9 o tamanho total de cada sequ\u00eancia</li> <li>Compare todos os pares de subsequencias, sempre escolhendo uma subsequencia de um DNA e do outro DNA, calculado seus scores</li> <li>Escolha uma que produza o score m\u00e1ximo</li> </ol> <p>Nao \u00e9 dif\u00edcil ver que este algoritmo ing\u00eanuo pode demorar muito tempo para executar quando aumentamos o tamanho das sequencias de DNA.</p> <p>Uma heur\u00edstica sequencial bastante interessante para reduzir o tempo de obten\u00e7\u00e3o dos alinhamentos foi proposta por Smith e Waterman (1981), utilizando programa\u00e7\u00e3o din\u00e2mica. Abaixo, temos a descri\u00e7\u00e3o do algoritmo desta estrat\u00e9gia:</p> <pre>\nALGORITMO SMITH-WATERMAN\nEntrada: Duas sequencias de DNA a[i] e b[j], de tamanhos n e m respectivamente\nSa\u00edda: score m\u00e1ximo de alinhamento \n\n1. Inicializar H[i,0]=0, 0\u2264i\u2264n\n2. Inicializar H[0,j]=0, 0\u2264j\u2264m\n3. Para cada 1\u2264i\u2264n e 1\u2264j\u2264m:\n4.     Calcular diagonal = H[i-1,j-1] + w(a[i],b[j]), onde w(a[i],b[j])=2 se houve match, \n                           w(a[i],b[j])= -1 se houve mismatch e  \n                           w(a[i],b[j])= -1 se houve gap\n5.     Calcular dele\u00e7\u00e3o  = H[i-1,j] - 1\n6.     Calcular inser\u00e7\u00e3o = H[i,j-1] - 1\n7.     Calcular H[i,j]=m\u00e1ximo (0, diagonal, dele\u00e7\u00e3o, inser\u00e7\u00e3o)\n9. Retornar o m\u00e1ximo de H[_,_]\n</pre> <p>Os passos diagonal, dele\u00e7\u00e3o e inser\u00e7\u00e3o s\u00e3o chamados, respectivamente, de salto em diagonal, salto de cima para baixo e salto da esquerda para a direita, e representam movimenta\u00e7\u00f5es para obten\u00e7\u00e3o do alinhamento local \u00f3timo. </p> <p>No link abaixo, \u00e9 poss\u00edvel simular este algoritmo para diversos valores de pesos:</p> <p>http://rna.informatik.uni-freiburg.de/Teaching/index.jsp?toolName=Smith-Waterman</p> <p>Abaixo temos um exemplo da matriz H calculada para as sequ\u00eancias AGCACACA e ACACACTA:</p> <p></p> <p>Para obter o alinhamento local \u00f3timo, come\u00e7amos com o maior valor na matriz (i,j). Ent\u00e3o, n\u00f3s vamos para tr\u00e1s para uma das posi\u00e7\u00f5es (i-1,j), (i,j-1) ou (i-1,j-1), dependendo da dire\u00e7\u00e3o de movimento usado para construir a matriz. Mantemos o processo at\u00e9 chegar a um c\u00e9lula da matriz com valor zero, ou o valor na posi\u00e7\u00e3o (0,0).</p> <p>No exemplo, o valor mais alto corresponde \u00e0 c\u00e9lula na posi\u00e7\u00e3o (8,8). A caminhada de volta corresponde a (8,8), (7,7), (7,6), (6,5), (5,4), (4,3), (3,2), (2,1), (1,1), e (0,0),</p> <p>Uma vez que tenhamos terminado, reconstruimos o alinhamento da seguinte forma: Come\u00e7ando com o \u00faltimo valor, chegamos a (i,j) usando o caminho previamente calculado. Um salto na diagonal implica que h\u00e1 um alinhamento (ou uma correspond\u00eancia ou uma n\u00e3o correspond\u00eancia). Um salto de cima para baixo implica que h\u00e1 uma dele\u00e7\u00e3o. Um salto da esquerda para a direita implica que h\u00e1 uma inser\u00e7\u00e3o. Assim, para a reconstru\u00e7\u00e3o, \u00e9 importante guardar durante a montagem da tabela H qual o tipo de salto foi utilizado.</p> <p>Para o exemplo das sequencias acima, obtemos o seguinte alinhamento local \u00f3timo (em rela\u00e7\u00e3o aos pesos dados para match, mismatch e gap):</p> <pre>\nSequ\u00eancia 1 = A-CACACTA\nSequ\u00eancia 2 = AGCACAC-A\n</pre> <p>A partir desta descri\u00e7\u00e3o, nosso primeiro projeto ter\u00e1 duas tarefas:</p> <ul> <li> Implementar um programa C++ para ler um arquivo contendo os tamanhos de duas sequencias de DNA, seguidos das duas sequencias, uma por linha. Calcular o score m\u00e1ximo de alinhamento local usando a heur\u00edstica de Smith-Waterman. As informa\u00e7\u00f5es para reconstru\u00e7\u00e3o dever\u00e3o ser armazenadas no formato de struct.   <li> a partir do score m\u00e1ximo, reconstruir e exibir o alinhamento local \u00f3timo das duas sequencias.  <p>No diret\u00f3rio do projeto, h\u00e1 um gerador de entradas disponibilizado como um notebook Python.</p> <p>Para quem estiver interessado no artigo original da heur\u00edstica de Smith-Waterman, basta consultar o link http://arep.med.harvard.edu/pdf/Smith81.pdf.</p>"},{"location":"teoria/","title":"Materiais e Guias para estudo","text":"<p>Material Te\u00f3rico para estudo</p> <p>Contextualizando HPC</p> <p>Cluster Franky</p> <p>SLURM</p> <p>Conceitos B\u00e1sicos de HW</p> <p>Conceitos B\u00e1sicos de C++</p> <p>Como compilar e executar c\u00f3digos em C++</p> <p>Loops e La\u00e7os</p> <p>Passagens de par\u00e2metros (por refer\u00eancia, por ponteiro)</p> <p>Const Correctness em HPC</p> <p>Aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica</p> <p>Sobrecarga de fun\u00e7\u00f5es C++</p> <p>Classes e Objetos</p> <p>Manipula\u00e7\u00e3o de Vetores</p> <p>Flags de compila\u00e7\u00e3o</p> <p>Profiling</p>"},{"location":"teoria/MPI/","title":"MPI","text":""},{"location":"teoria/MPI/#conceitos-basicos-de-mpi","title":"Conceitos b\u00e1sicos de MPI","text":"<p>MPI (Message Passing Interface) \u00e9 um padr\u00e3o para programa\u00e7\u00e3o paralela em mem\u00f3ria compartilhada, o seja, em v\u00e1rios n\u00f3s de computa\u00e7\u00e3o. Cada processo \u00e9 identificado por um rank (um n\u00famero de 0 at\u00e9 <code>size-1</code>), todos os processos de um programa MPI formam um comunicador (por padr\u00e3o <code>MPI_COMM_WORLD</code>).</p>"},{"location":"teoria/MPI/#comunicacao-ponto-a-ponto","title":"Comunica\u00e7\u00e3o ponto a ponto","text":""},{"location":"teoria/MPI/#envio-e-recebimento-bloqueantes","title":"Envio e recebimento bloqueantes","text":"<pre><code>MPI_Send(buffer, count, MPI_CHAR, destino, tag, MPI_COMM_WORLD);\nMPI_Recv(buffer, count, MPI_CHAR, origem, tag, MPI_COMM_WORLD, &amp;status);\n</code></pre> <ul> <li><code>buffer</code>: ponteiro para os dados.</li> <li><code>count</code>: n\u00famero de elementos.</li> <li><code>MPI_CHAR</code>, <code>MPI_INT</code>, <code>MPI_DOUBLE</code> etc.</li> <li><code>destino</code> / <code>origem</code>: rank do processo de envio/recebimento.</li> <li><code>tag</code>: identificador da mensagem (permite diferenciar mensagens).</li> <li><code>status</code>: metadados sobre a recep\u00e7\u00e3o.</li> </ul>"},{"location":"teoria/MPI/#envio-e-recebimento-nao-bloqueantes","title":"Envio e recebimento n\u00e3o-bloqueantes","text":"<pre><code>MPI_Request req;\nMPI_Isend(buffer, count, MPI_INT, destino, tag, MPI_COMM_WORLD, &amp;req);\nMPI_Wait(&amp;req, MPI_STATUS_IGNORE);\n</code></pre> <pre><code>MPI_Request req;\nMPI_Irecv(buffer, count, MPI_INT, origem, tag, MPI_COMM_WORLD, &amp;req);\nMPI_Wait(&amp;req, MPI_STATUS_IGNORE);\n</code></pre> <ul> <li>Permitem sobrepor comunica\u00e7\u00e3o e computa\u00e7\u00e3o.</li> <li>Precisa sempre de <code>MPI_Wait</code> (ou <code>MPI_Test</code>).</li> </ul>"},{"location":"teoria/MPI/#comunicacao-coletiva","title":"Comunica\u00e7\u00e3o coletiva","text":"<ul> <li>Broadcast</li> </ul> <pre><code>MPI_Bcast(buffer, count, MPI_INT, root, MPI_COMM_WORLD);\n</code></pre> <p>Envia <code>buffer</code> do processo <code>root</code> para todos.</p> <ul> <li>Scatter</li> </ul> <pre><code>MPI_Scatter(sendbuf, count, MPI_INT, recvbuf, count, MPI_INT, root, MPI_COMM_WORLD);\n</code></pre> <p>Distribui partes de um vetor do root para todos.</p> <ul> <li>Gather</li> </ul> <pre><code>MPI_Gather(sendbuf, count, MPI_INT, recvbuf, count, MPI_INT, root, MPI_COMM_WORLD);\n</code></pre> <p>Cada processo envia dados para o root.</p> <ul> <li>Reduce</li> </ul> <pre><code>MPI_Reduce(&amp;valor_local, &amp;valor_total, 1, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n</code></pre> <p>Combina valores de todos os processos (soma, m\u00e1ximo, m\u00ednimo, etc.).</p> <ul> <li>Barrier</li> </ul> <pre><code>MPI_Barrier(MPI_COMM_WORLD);\n</code></pre> <p>Todos os processos param at\u00e9 que todos cheguem aqui.</p>"},{"location":"teoria/MPI/#medicao-de-tempo","title":"Medi\u00e7\u00e3o de tempo","text":"<pre><code>double t0 = MPI_Wtime();\n// ... c\u00f3digo ...\ndouble t1 = MPI_Wtime();\nif(rank==0) std::cout &lt;&lt; \"Tempo = \" &lt;&lt; (t1-t0) &lt;&lt; \" segundos\\n\";\n</code></pre>"},{"location":"teoria/MPI/#estruturas-uteis","title":"Estruturas \u00fateis","text":"<ul> <li>MPI_Status \u2192 cont\u00e9m informa\u00e7\u00f5es de mensagens recebidas (como rank origem).</li> </ul> <pre><code>MPI_Status status;\nMPI_Recv(buf, n, MPI_INT, origem, tag, MPI_COMM_WORLD, &amp;status);\nint origem_real; MPI_Get_count(&amp;status, MPI_INT, &amp;origem_real);\n</code></pre> <ul> <li>Tags \u2192 permitem diferenciar mensagens diferentes em paralelo.</li> </ul>"},{"location":"teoria/MPI/#carregue-o-modulo","title":"Carregue o modulo","text":"<pre><code>spack load openmpi\n</code></pre>"},{"location":"teoria/MPI/#teste-para-ver-se-o-modulo-foi-carregado-corretamente","title":"Teste para ver se o modulo foi carregado corretamente","text":"<pre><code>mpicc --version\n</code></pre>"},{"location":"teoria/MPI/#deve-aparecer-algo-como","title":"Deve aparecer algo como:","text":"<pre><code>gcc (GCC) 14.2.0\nCopyright (C) 2024 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre>"},{"location":"teoria/MPI/#compile-o-programa","title":"Compile o programa:","text":"<pre><code>mpic++ -FlagdeOtimiza\u00e7\u00e3o seu_codigo.cpp -o seu_binario\n</code></pre> <p>Executar com SLURM (arquivo <code>job.slurm</code>):</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=mpi_hello\n#SBATCH --output=saida%j.txt\n#SBATCH --partition=express\n#SBATCH --mem=1GB\n#SBATCH --nodes=2\n#SBATCH --ntasks=5\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:02:00\n#SBATCH --export=ALL\n\n\n# Fa\u00e7a load nos m\u00f3dulos dentro do n\u00f3 de computa\u00e7\u00e3o\nsource /etc/profile\n. /opt/spack/share/spack/setup-env.sh\nmodule use /opt/spack/share/spack/lmod/linux-rocky9-x86_64/Core\nmodule --ignore_cache load openmpi/5.0.8-gcc-14.2.0\n\n# Execute o seu bin\u00e1rio com o MPI\nmpirun -np $SLURM_NTASKS ./seu_binario\n</code></pre> <p>Submit:</p> <pre><code>sbatch job.slurm\n</code></pre> <p>Documenta\u00e7\u00e3o: https://www.physics.rutgers.edu/~haule/509/MPI_Guide_C++.pdf</p>"},{"location":"teoria/comandos-ssh/","title":"Transfer\u00eancia de Arquivos entre sua m\u00e1quina e o Cluster Franky","text":"<p>O comando <code>scp</code> (Secure Copy Protocol) \u00e9 uma ferramenta segura e eficiente para transferir arquivos entre sua m\u00e1quina local e um servidor remoto, como o cluster Franky. Ele utiliza o protocolo SSH para realizar a transfer\u00eancia de arquivos, garantindo a seguran\u00e7a dos dados durante o processo.</p>"},{"location":"teoria/comandos-ssh/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que: - Voc\u00ea tenha acesso ao cluster Franky via SSH. - O comando <code>scp</code> esteja instalado em sua m\u00e1quina (a maioria dos sistemas operacionais baseados em Unix/Linux j\u00e1 possuem o <code>scp</code> por padr\u00e3o).</p>"},{"location":"teoria/comandos-ssh/#transferindo-um-arquivo-da-sua-maquina-para-o-cluster-franky","title":"Transferindo um Arquivo da Sua M\u00e1quina para o Cluster Franky","text":"<p>Para transferir um arquivo do seu computador para o cluster Franky, voc\u00ea pode usar o seguinte comando:</p> <p><pre><code>scp /caminho/local/do/arquivo.txt usuario@ip_do_cluster:/caminho/remoto/destino/\n</code></pre> Este comando copia o arquivo <code>meu_arquivo.txt</code> do diret\u00f3rio local <code>/home/user/</code> para o diret\u00f3rio <code>/home/usuario/destino/</code> no cluster Franky.</p>"},{"location":"teoria/comandos-ssh/#explicacao-dos-parametros","title":"Explica\u00e7\u00e3o dos Par\u00e2metros:","text":"<ul> <li><code>/caminho/local/do/arquivo.txt</code>: Caminho completo do arquivo na sua m\u00e1quina local que voc\u00ea deseja transferir.</li> <li><code>usuario@ip_do_cluster</code>: Seu nome de usu\u00e1rio e o endere\u00e7o de ip do cluster Franky.</li> <li><code>/caminho/remoto/destino/</code>: O diret\u00f3rio de destino no cluster Franky onde voc\u00ea deseja salvar o arquivo.</li> </ul>"},{"location":"teoria/comandos-ssh/#transferindo-um-arquivo-do-cluster-franky-para-sua-maquina","title":"Transferindo um Arquivo do Cluster Franky para sua M\u00e1quina","text":"<p>Para copiar um arquivo do cluster Franky para a sua m\u00e1quina local, use o seguinte comando no seu terminal:</p> <p><pre><code>scp usuario@ip_do_cluster:/caminho/remoto/do/arquivo.txt /caminho/local/destino/\n</code></pre> Este comando copia o arquivo <code>arquivo_remoto.txt</code> do diret\u00f3rio <code>/home/usuario/</code> no cluster Franky para o diret\u00f3rio <code>/home/user/destino_local/</code> na sua m\u00e1quina.</p>"},{"location":"teoria/comandos-ssh/#explicacao-dos-parametros_1","title":"Explica\u00e7\u00e3o dos Par\u00e2metros:","text":"<ul> <li><code>usuario@franky.cluster:/caminho/remoto/do/arquivo.txt</code>: O caminho completo do arquivo no cluster Franky que voc\u00ea deseja transferir para sua m\u00e1quina local.</li> <li> <p><code>/caminho/local/destino/</code>: O diret\u00f3rio de destino na sua m\u00e1quina local onde voc\u00ea deseja salvar o arquivo.</p> </li> <li> <p>Transfer\u00eancia Recursiva: Para transferir diret\u00f3rios inteiros (incluindo subdiret\u00f3rios e arquivos), use a op\u00e7\u00e3o <code>-r</code>:</p> </li> </ul> <pre><code>scp -r /caminho/local/do/diretorio/ usuario@ip_do_cluster:/caminho/remoto/destino/\n</code></pre> <p>O comando <code>scp</code> \u00e9 uma ferramenta poderosa para transferir arquivos entre sua m\u00e1quina e o cluster Franky de forma segura e eficiente. Com as instru\u00e7\u00f5es e exemplos fornecidos neste guia, voc\u00ea deve ser capaz de realizar transfer\u00eancias de arquivos com facilidade.</p>"},{"location":"teoria/comandos/","title":"Lista de Comandos","text":""},{"location":"teoria/comandos/#comandos-slurm","title":"Comandos SLURM","text":""},{"location":"teoria/comandos/#principais-recursos-que-voce-pode-pedir-com-srun","title":"Principais recursos que voc\u00ea pode pedir com <code>srun</code>","text":"O que pedir Op\u00e7\u00e3o do <code>srun</code> Exemplo N\u00famero de tarefas (processos) <code>--ntasks</code> ou <code>-n</code> <code>--ntasks=2</code> CPUs por tarefa <code>--cpus-per-task</code> <code>--cpus-per-task=2</code> Mem\u00f3ria total ou por CPU <code>--mem</code>, <code>--mem-per-cpu</code> <code>--mem=4G</code> ou <code>--mem-per-cpu=2G</code> Tempo de execu\u00e7\u00e3o <code>--time=DD-HH:MM:SS</code> <code>--time=01:12:49</code> N\u00famero de n\u00f3s <code>--nodes</code> <code>--nodes=2</code> N\u00f3 espec\u00edfico <code>--nodelist</code> <code>--nodelist=compute13</code> GPUs <code>--gpus</code> ou <code>--gres=gpu:&lt;num&gt;</code> <code>--gpus=1</code> ou <code>--gres=gpu:2</code> Parti\u00e7\u00e3o (fila) <code>--partition</code> ou <code>-p</code> <code>--partition=gpu</code> Sess\u00e3o interativa <code>--pty bash</code> <code>--pty bash</code> <p>Exemplos</p> <p>Pedido simples de execu\u00e7\u00e3o de tarefa para o SLURM <pre><code>srun --nodelist=compute10 --partition=normal --ntasks=1 --pty bash\n</code></pre> --srun: Comando SLURM para executar tarefas  --nodelist=compute10: for\u00e7a o SLURM a alocar exatamente esse n\u00f3. --partition=normal: indica a parti\u00e7\u00e3o \u00e0 qual o n\u00f3 pertence. --ntasks=1: pede uma tarefa. --pty bash: pede um terminal dentro do n\u00f3.</p> <p>Pedido sem especificar o n\u00f3 exato: <pre><code>srun --partition=normal --ntasks=1 --pty bash\n</code></pre></p> <p>Pedido com varias tasks para executar seu programa direto: <pre><code>srun --partition=normal --ntasks=4 ./meu_programa_paralelo\n</code></pre></p>"},{"location":"teoria/comandos/#principais-recursos-que-voce-pode-pedir-com-sbatch","title":"Principais recursos que voc\u00ea pode pedir com <code>sbatch</code>","text":"O que pedir Op\u00e7\u00e3o do <code>sbatch</code> (no script) Exemplo dentro do script Nome do job <code>--job-name</code> <code>#SBATCH --job-name=teste%j</code> N\u00famero de tarefas (processos) <code>--ntasks</code> ou <code>-n</code> <code>#SBATCH --ntasks=2</code> CPUs por tarefa <code>--cpus-per-task</code> <code>#SBATCH --cpus-per-task=2</code> Mem\u00f3ria total ou por CPU <code>--mem</code>, <code>--mem-per-cpu</code> <code>#SBATCH --mem=4G</code> ou <code>--mem-per-cpu=2G</code> Tempo de execu\u00e7\u00e3o <code>--time=DD-HH:MM:SS</code> <code>#SBATCH --time=01:12:49</code> N\u00famero de n\u00f3s <code>--nodes</code> <code>#SBATCH --nodes=2</code> N\u00f3 espec\u00edfico <code>--nodelist</code> <code>#SBATCH --nodelist=compute13</code> GPUs <code>--gpus</code> ou <code>--gres=gpu:&lt;num&gt;</code> <code>#SBATCH --gpus=1</code> ou <code>#SBATCH --gres=gpu:2</code> Parti\u00e7\u00e3o (fila) <code>--partition</code> ou <code>-p</code> <code>#SBATCH --partition=gpu</code> Sa\u00edda padr\u00e3o (log) <code>--output</code> <code>#SBATCH --output=saida%j.txt</code> Log de Erro do sistema <code>--error</code> <code>#SBATCH --error=erro%j.txt</code> <p>Exemplos</p> <p>Arquivo: <code>job1.slurm</code></p> <pre><code>#!/bin/bash\n#SBATCH --job-name=teste%j\n#SBATCH --partition=normal\n#SBATCH --ntasks=1\n#SBATCH --time=00:10:00\n#SBATCH --output=saida%j.txt\n\n./meu_programa\n</code></pre> <p>Submeter com:</p> <pre><code>sbatch job1.slurm\n</code></pre>"},{"location":"teoria/comandos/#comandos-gerais-do-slurm","title":"Comandos gerais do SLURM","text":"Finalidade Comando Exemplo Ver status das parti\u00e7\u00f5es e n\u00f3s <code>sinfo</code> <code>sinfo -N -l</code> Ver detalhes de um n\u00f3 espec\u00edfico <code>scontrol show node</code> <code>scontrol show node compute24</code> Ver detalhes de uma parti\u00e7\u00e3o <code>scontrol show partition</code> <code>scontrol show partition normal</code> Ver todos os jobs ativos <code>squeue</code> <code>squeue</code> Ver seus pr\u00f3prios jobs <code>squeue -u &lt;usu\u00e1rio&gt;</code> <code>squeue -u liciascl</code> Ver detalhes de um job <code>scontrol show job</code> <code>scontrol show job 12345</code> Cancelar job em execu\u00e7\u00e3o ou na fila <code>scancel</code> <code>scancel 12345</code> Cancelar todos os seus jobs <code>scancel -u &lt;usu\u00e1rio&gt;</code> <code>scancel -u liciascl</code>"},{"location":"teoria/comandos/#ver-todos-os-nos-com-status-detalhado","title":"Ver todos os n\u00f3s com status detalhado","text":"<p><pre><code>sinfo -N -l\n</code></pre> \u00datil para ver quais n\u00f3s est\u00e3o idle, alocados, down ou drain.</p>"},{"location":"teoria/comandos/#ver-informacoes-completas-do-no-compute24","title":"Ver informa\u00e7\u00f5es completas do n\u00f3 <code>compute24</code>","text":"<p><pre><code>scontrol show node compute24\n</code></pre> Mostra: mem\u00f3ria total e usada, CPUs alocadas, jobs em execu\u00e7\u00e3o, estado (<code>IDLE</code>, <code>ALLOCATED</code>, etc.).</p>"},{"location":"teoria/comandos/#ver-configuracoes-de-uma-particao-especifica","title":"Ver configura\u00e7\u00f5es de uma parti\u00e7\u00e3o especifica","text":"<p><pre><code>scontrol show partition normal\n</code></pre> Mostra: tempo m\u00e1ximo de job, n\u00famero de n\u00f3s, limites de mem\u00f3ria/CPU, GPUs, estado da fila.</p>"},{"location":"teoria/comandos/#ver-jobs-no-sistema","title":"Ver jobs no sistema","text":"<p><pre><code>squeue\n</code></pre> Mostra todos os jobs na fila e em execu\u00e7\u00e3o com status <code>R</code> (running), <code>PD</code> (pending), etc.</p>"},{"location":"teoria/comandos/#ver-so-os-jobs-da-usuaria-liciascl","title":"Ver s\u00f3 os jobs da usu\u00e1ria <code>liciascl</code>","text":"<p><pre><code>squeue -u liciascl\n</code></pre> \u00datil para depurar seus pr\u00f3prios jobs (ID, parti\u00e7\u00e3o, status, tempo, n\u00f3, etc.)</p>"},{"location":"teoria/comandos/#ver-informacoes-completas-de-um-job-especifico","title":"Ver informa\u00e7\u00f5es completas de um job espec\u00edfico","text":"<p><pre><code>scontrol show job 12345\n</code></pre> Mostra: usu\u00e1rio, parti\u00e7\u00e3o, CPUs/n\u00f3s alocados, prioridade, estado, tempo usado, comando enviado.</p>"},{"location":"teoria/comandos/#cancelar-job-com-id-12345","title":"Cancelar job com ID <code>12345</code>","text":"<p><pre><code>scancel 12345\n</code></pre> \u00datil se o job travou ou est\u00e1 consumindo recursos indevidamente.</p>"},{"location":"teoria/comandos/#cancelar-todos-os-seus-jobs","title":"Cancelar todos os seus jobs","text":"<p><pre><code>scancel -u $USER\n</code></pre> Cancela em lote \u2014 \u00f3timo em caso de erro em scripts ou submiss\u00f5es mal feitas.</p> <p>Para mais consulte a documenta\u00e7\u00e3o oficial em https://slurm.schedmd.com/documentation.html</p>"},{"location":"teoria/comandos/#pra-verificar-hardware","title":"Pra verificar Hardware","text":""},{"location":"teoria/comandos/#cpu","title":"CPU","text":"<ul> <li>lscpu   Mostra arquitetura, n\u00famero de n\u00facleos, threads, caches.</li> </ul> <pre><code>lscpu\n</code></pre> <p>Exemplo de sa\u00edda:</p> <pre><code>Architecture:           x86_64\nCPU(s):                 40\nThread(s) per core:     2\nCore(s) per socket:     10\nSocket(s):              2\nL1d cache:              32K\nL2 cache:               1M\nL3 cache:               13M\n</code></pre> <p>Lista detalhes por CPU l\u00f3gico (modelo, MHz, cache).</p> <pre><code>cat /proc/cpuinfo \n</code></pre> <p>Mostra o n\u00famero de CPUs dispon\u00edveis.</p> <pre><code>nproc\n</code></pre>"},{"location":"teoria/comandos/#memoria-ram","title":"Mem\u00f3ria RAM","text":"<p>Mostra uso e total de mem\u00f3ria f\u00edsica e swap.</p> <pre><code>free -h\n</code></pre> <p>Detalhes avan\u00e7ados de mem\u00f3ria (MemTotal, MemFree, Buffers, Cached).</p> <pre><code>cat /proc/meminfo | grep -E \"MemTotal|MemFree|MemAvailable|Swap\"\n</code></pre> <p>Estat\u00edsticas de mem\u00f3ria, processos e CPU.</p> <pre><code>vmstat 1 5\n</code></pre>"},{"location":"teoria/comandos/#cache","title":"Cache","text":"<p>Mostra rapidamente o tamanho das caches.</p> <pre><code>lscpu | grep cache\n</code></pre> <p>Lista tamanhos de cada n\u00edvel de cache (por CPU).</p> <pre><code>cat /sys/devices/system/cpu/cpu0/cache/index*/size\n</code></pre> <p>Shell script para trazer de forma resumida informa\u00e7\u00f5es \u00fateis</p> <p><pre><code>echo '=== HOSTNAME ==='; hostname; echo; \\\n echo '=== MEMORIA (GB) ==='; \\\n cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' | \\\n awk '{printf \\\"%s %.2f GB\\\\n\\\", \\$1, \\$2 / 1048576}'; \\\n echo; \\\n echo '=== CPU INFO ==='; \\\n lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\n echo '=== GPU INFO ==='; \\\n if command -v nvidia-smi &amp;&gt; /dev/null; then nvidia-smi; else echo 'nvidia-smi n\u00e3o dispon\u00edvel'; fi\n</code></pre> Para executar dentro de um n\u00f3 de computa\u00e7\u00e3o:</p> <pre><code>srun --partition=normal --ntasks=1 --pty bash -c \\\n\"echo '=== HOSTNAME ==='; hostname; echo; \\\n echo '=== MEMORIA (GB) ==='; \\\n cat /proc/meminfo | grep -E 'MemTotal|MemFree|MemAvailable|Swap' | \\\n awk '{printf \\\"%s %.2f GB\\\\n\\\", \\$1, \\$2 / 1048576}'; \\\n echo; \\\n echo '=== CPU INFO ==='; \\\n lscpu | grep -E 'Model name|Socket|Core|Thread|CPU\\\\(s\\\\)|cache'\n echo '=== GPU INFO ==='; \\\n if command -v nvidia-smi &amp;&gt; /dev/null; then nvidia-smi; else echo 'nvidia-smi n\u00e3o dispon\u00edvel'; fi\"\n</code></pre>"},{"location":"teoria/heuristicas/","title":"M\u00e9todos de Busca Heur\u00edstica","text":"<p>As heur\u00edsticas de busca s\u00e3o estrat\u00e9gias para encontrar solu\u00e7\u00f5es em problemas dif\u00edceis sem precisar explorar todo o espa\u00e7o de possibilidades. Elas n\u00e3o garantem o resultado \u00f3timo, mas entregam respostas \u00fateis com um custo de tempo menor. Temos aqui algumas fam\u00edlias de heur\u00edsticas e uma implementa\u00e7\u00e3o em pseudoc\u00f3digo para servir de inspira\u00e7\u00e3o, mas n\u00e3o se sinta satisfeito apenas com o que temos aqui, existem in\u00fameras heuristicas que n\u00e3o est\u00e3o descritas aqui.</p>"},{"location":"teoria/heuristicas/#heuristicas-construtivas","title":"Heur\u00edsticas construtivas","text":"<p>A ideia \u00e9 construir passo a passo a solu\u00e7\u00e3o seguindo uma regra de decis\u00e3o. Essa regra pode ser gulosa (sempre escolher o melhor incremento local) ou conter aleatoriedade para gerar diversidade. No cacheiro viajante, por exemplo, a cidade mais pr\u00f3xima ainda n\u00e3o visitada \u00e9 escolhida; em mochila, o iten \u00e9 escolhido por melhor rela\u00e7\u00e3o valor/peso at\u00e9 atingir a capacidade m\u00e1xima da mochila.</p> <pre><code>def heuristica_construtiva():\n    S = solucao_vazia()\n    while not solucao_completa(S):\n        candidatos = candidatos_admissiveis(S)\n        # regra gulosa: minimiza custo incremental \n        c_escolhido = min(candidatos, key=lambda c: custo_incremental(S, c))\n        S = inserir(S, c_escolhido)           # atualizar estado parcial\n    return S\n</code></pre>"},{"location":"teoria/heuristicas/#busca-local","title":"Busca local","text":"<p>Partimos de uma solu\u00e7\u00e3o inicial e tentamos melhor\u00e1-la explorando \u201cvizinhos\u201d obtidos por pequenas altera\u00e7\u00f5es. Se um vizinho melhora o custo, aceitamos a mudan\u00e7a e repetimos o processo at\u00e9 n\u00e3o existir mais melhora. </p> <pre><code>def busca_local(S0):\n    S = S0\n    while True:\n        melhorou = False\n        for S_viz in gerar_vizinhos(S):\n            if custo(S_viz) &lt; custo(S):\n                S = S_viz          # estrat\u00e9gia \"first improvement\"\n                melhorou = True\n                break\n        if not melhorou:\n            break\n    return S\n</code></pre>"},{"location":"teoria/heuristicas/#heuristicas-baseadas-em-construcao","title":"Heur\u00edsticas baseadas em constru\u00e7\u00e3o","text":"<p>Combinam constru\u00e7\u00e3o e refino: primeiro geramos uma boa solu\u00e7\u00e3o inicial de forma gulosa ou com aleatoriedade e, em seguida, aplicamos busca local para polir o resultado. </p> <pre><code>def construcao_mais_refino():\n    S = heuristica_construtiva()  # ou uma varia\u00e7\u00e3o com aleatoriedade (RCL)\n    S = busca_local(S)            # refino por movimentos locais\n    return S\n</code></pre>"},{"location":"teoria/heuristicas/#heuristicas-baseadas-em-modificacao","title":"Heur\u00edsticas baseadas em modifica\u00e7\u00e3o","text":"<p>Aqui trabalhamos sobre uma solu\u00e7\u00e3o existente aplicando uma perturba\u00e7\u00e3o para escapar de \u00f3timos locais. Ap\u00f3s perturbar, refinamos novamente com busca local. Esse padr\u00e3o \u00e9 a base do ILS (Iterated Local Search) e do VNS (Variable Neighborhood Search).</p> <pre><code>def modificacao_baseada(S_inicial, max_iter=100):\n    S_best = S_inicial\n    for _ in range(max_iter):\n        S_pert = perturbar(S_best, intensidade=ajustar_intensidade())\n        S_ref = busca_local(S_pert)\n        if custo(S_ref) &lt; custo(S_best):\n            S_best = S_ref\n    return S_best\n</code></pre>"},{"location":"teoria/heuristicas/#heuristicas-baseadas-em-recombinacao","title":"Heur\u00edsticas baseadas em recombina\u00e7\u00e3o","text":"<p>Inspiradas em algoritmos evolutivos, combinam duas (ou mais) solu\u00e7\u00f5es \u201cpais\u201d para gerar uma nova solu\u00e7\u00e3o \u201cfilha\u201d, aproveitando blocos de boa qualidade de cada pai. Depois, refinam a filha com busca local. </p> <pre><code>def recombinacao_baseada(populacao, criterio_parada):\n    P = inicializar_populacao(populacao)\n    while not criterio_parada(P):\n        A, B = selecionar_pais(P)             # torneio, roleta, ranking etc.\n        C = recombinar(A, B)                  # OX/PMX/path-relinking/uni\u00e3o+reparo\n        C = busca_local(C)                    # passo mem\u00e9tico (refino)\n        P = atualizar_populacao(P, C)         # elitismo/substitui\u00e7\u00e3o\n    return melhor_solucao(P)\n</code></pre>"},{"location":"teoria/heuristicas/#hibridizacao-de-heuristicas","title":"Hibridiza\u00e7\u00e3o de heur\u00edsticas","text":"<p>Misturamos estrat\u00e9gias para buffar o algor\u00edtmo: constru\u00e7\u00e3o gulosa aleat\u00f3ria para diversidade, seguida de busca local para intensifica\u00e7\u00e3o, e ILS para escapar de \u00f3timos locais. </p> <pre><code>def hibrida_grasp_ils(max_iter=50):\n    S_best = None\n    for _ in range(max_iter):\n        S = construtiva_aleatoria_com_RCL()   # constru\u00e7\u00e3o com lista restrita de candidatos\n        S = busca_local(S)                    # intensifica\u00e7\u00e3o\n        S = ILS(S)                            # diversifica\u00e7\u00e3o controlada\n        if S_best is None or custo(S) &lt; custo(S_best):\n            S_best = S\n    return S_best\n\ndef ILS(S, limite_sem_melhora=10):\n    sem_melhora = 0\n    while sem_melhora &lt; limite_sem_melhora:\n        S_p = perturbar(S)                    # ex.: ruin&amp;recreate, 3-opt forte, shake(VNS)\n        S_p = busca_local(S_p)\n        if custo(S_p) &lt; custo(S):\n            S = S_p\n            sem_melhora = 0\n        else:\n            sem_melhora += 1\n    return S\n</code></pre>"},{"location":"teoria/heuristicas/#hiper-heuristicas","title":"H\u00edper-heur\u00edsticas","text":"<p>Em vez de desenhar uma \u00fanica heur\u00edstica, criamos um \u201corquestrador\u201d que escolhe dinamicamente qual heur\u00edstica de baixo n\u00edvel aplicar a cada momento, com base em desempenho observado. Assim, o sistema alterna entre operadores como 2-opt, swap e reinser\u00e7\u00e3o, aprendendo quais funcionam melhor ao longo da execu\u00e7\u00e3o.</p> <pre><code>from math import sqrt, log\nimport random\n\ndef hiper_heuristica(S0, heuristicas, T, epsilon=0.1):\n    # heuristicas: lista de fun\u00e7\u00f5es do tipo h(S) -&gt; S'\n    estat = {h: {\"ganho\": 0.0, \"usos\": 0} for h in heuristicas}\n    S = S0\n    for t in range(1, T + 1):\n        if random.random() &lt; epsilon:\n            h = random.choice(heuristicas)    # explora\u00e7\u00e3o\n        else:\n            h = selecionar_por_ucb(estat, t)  # explora\u00e7\u00e3o vs. explora\u00e7\u00e3o\n\n        S_novo = h(S)\n        ganho = max(0.0, custo(S) - custo(S_novo))\n        estat[h][\"ganho\"] += ganho\n        estat[h][\"usos\"]  += 1\n\n        if custo(S_novo) &lt; custo(S):\n            S = S_novo\n    return S\n\ndef selecionar_por_ucb(estat, t):\n    # UCB1 simples: m\u00e9dia + sqrt(2*ln(t)/n)\n    melhor_h, melhor_score = None, float(\"-inf\")\n    for h, info in estat.items():\n        n = max(1, info[\"usos\"])\n        media = info[\"ganho\"] / n\n        bonus = sqrt(2.0 * log(max(2, t)) / n)\n        score = media + bonus\n        if score &gt; melhor_score:\n            melhor_h, melhor_score = h, score\n    return melhor_h\n</code></pre> <p>Entendi! Voc\u00ea quer exemplos de heur\u00edsticas aleat\u00f3rias (estrat\u00e9gias que exploram o espa\u00e7o com escolhas ao acaso) e de heur\u00edsticas com filtro (estrat\u00e9gias que usam algum crit\u00e9rio para selecionar candidatos, descartando op\u00e7\u00f5es ruins). Vou explicar de forma did\u00e1tica e depois te dar exemplos em pseudoc\u00f3digo estilo Python.</p>"},{"location":"teoria/heuristicas/#heuristicas-aleatorias","title":"Heur\u00edsticas aleat\u00f3rias","text":"<p>A ideia aqui \u00e9 simples: em vez de sempre escolher o \u201cmelhor\u201d pr\u00f3ximo passo, escolhemos aleatoriamente uma op\u00e7\u00e3o, ou entre todas, ou entre um subconjunto. Isso permite explorar solu\u00e7\u00f5es diferentes e fugir de caminhos muito determin\u00edsticos.</p> <pre><code>import random\n\ndef heuristica_aleatoria(items, capacidade):\n    mochila = []\n    peso = 0\n    while True:\n        candidatos = [i for i in items if peso + i.peso &lt;= capacidade]\n        if not candidatos:\n            break\n        escolhido = random.choice(candidatos)   # sorteia qualquer candidato vi\u00e1vel\n        mochila.append(escolhido)\n        peso += escolhido.peso\n        items.remove(escolhido)\n    return mochila\n</code></pre>"},{"location":"teoria/heuristicas/#heuristicas-com-filtro","title":"Heur\u00edsticas com filtro","text":"<p>Aqui, em vez de aceitar qualquer candidato, aplicamos um filtro para limitar as op\u00e7\u00f5es a um subconjunto de candidatos considerados \u201cbons\u201d. Depois, escolhemos um deles (\u00e0s vezes aleatoriamente, \u00e0s vezes pelo melhor custo). Essa ideia \u00e9 a base do GRASP.</p> <pre><code>import random\n\ndef heuristica_com_filtro(items, capacidade, alpha=0.3):\n    mochila = []\n    peso = 0\n    while True:\n        candidatos = [i for i in items if peso + i.peso &lt;= capacidade]\n        if not candidatos:\n            break\n        # filtro: mant\u00e9m apenas candidatos dentro do top \u03b1 (percentil de valor/peso)\n        ratio = [i.valor / i.peso for i in candidatos]\n        limite = min(ratio) + alpha * (max(ratio) - min(ratio))\n        RCL = [i for i in candidatos if i.valor / i.peso &gt;= limite]\n\n        escolhido = random.choice(RCL)   # escolhe entre bons candidatos\n        mochila.append(escolhido)\n        peso += escolhido.peso\n        items.remove(escolhido)\n    return mochila\n</code></pre>"},{"location":"teoria/openmp/","title":"Guia de Pragmas OpenMP","text":""},{"location":"teoria/openmp/#funcoes-da-api-openmp","title":"Fun\u00e7\u00f5es da API OpenMP","text":"<ul> <li><code>omp_get_thread_num()</code> \u2192 retorna o ID da thread.</li> <li><code>omp_get_num_threads()</code> \u2192 total de threads na regi\u00e3o paralela.</li> <li><code>omp_get_wtime()</code> \u2192 cron\u00f4metro de alta resolu\u00e7\u00e3o.</li> <li><code>omp_get_max_threads()</code> \u2192 n\u00famero m\u00e1ximo de threads dispon\u00edveis.</li> <li><code>OMP_NUM_THREADS</code> \u2192 n\u00famero de threads usadas no programa</li> <li><code>OMP_SCHEDULE</code> \u2192 define a pol\u00edtica de escalonamento quando se usa <code>schedule(runtime)</code></li> </ul>"},{"location":"teoria/openmp/#criando-regioes-paralelas","title":"Criando regi\u00f5es paralelas","text":"<pre><code>#pragma omp parallel\n{\n    // c\u00f3digo aqui roda em paralelo (todas as threads executam)\n}\n</code></pre>"},{"location":"teoria/openmp/#paralelizando-lacos-for","title":"Paralelizando la\u00e7os (<code>for</code>)","text":"<pre><code>#pragma omp parallel for\nfor (int i = 0; i &lt; N; i++) {\n    a[i] = b[i] + c[i];\n}\n</code></pre> <ul> <li> <p>Cl\u00e1usula <code>schedule</code>: define como dividir as itera\u00e7\u00f5es entre threads</p> </li> <li> <p><code>schedule(static)</code> \u2192 divide blocos iguais e fixos</p> </li> <li><code>schedule(dynamic, chunk)</code> \u2192 distribui em blocos de <code>chunk</code> de forma din\u00e2mica</li> <li><code>schedule(guided, chunk)</code> \u2192 blocos come\u00e7am grandes e v\u00e3o diminuindo</li> <li><code>schedule(runtime)</code> \u2192 definido pela vari\u00e1vel de ambiente <code>OMP_SCHEDULE</code></li> </ul>"},{"location":"teoria/openmp/#variaveis-privadas-e-compartilhadas","title":"Vari\u00e1veis privadas e compartilhadas","text":"<pre><code>#pragma omp parallel for private(x) shared(y)\nfor (int i = 0; i &lt; N; i++) {\n    int x = i;        // cada thread tem sua c\u00f3pia\n    y[i] = f(x);      // y \u00e9 vis\u00edvel por todas\n}\n</code></pre> <ul> <li><code>private(var)</code> \u2192 cada thread cria sua pr\u00f3pria c\u00f3pia</li> <li><code>shared(var)</code> \u2192 todas as threads acessam a mesma vari\u00e1vel</li> </ul>"},{"location":"teoria/openmp/#reducoes-somatorios-produtos-etc","title":"Redu\u00e7\u00f5es (somat\u00f3rios, produtos, etc.)","text":"<pre><code>double soma = 0.0;\n#pragma omp parallel for reduction(+:soma)\nfor (int i = 0; i &lt; N; i++) {\n    soma += a[i];\n}\n</code></pre> <ul> <li><code>+</code> \u2192 soma (ex.: <code>soma += ...</code>)</li> <li><code>*</code> \u2192 produto (ex.: <code>prod *= ...</code>)</li> <li><code>max</code> \u2192 m\u00e1ximo (ex.: encontra o maior valor)</li> <li><code>min</code> \u2192 m\u00ednimo (ex.: encontra o menor valor)</li> <li><code>&amp;&amp;</code> \u2192 AND l\u00f3gico</li> <li><code>||</code> \u2192 OR l\u00f3gico</li> <li><code>^</code>  \u2192 XOR bit a bit</li> </ul>"},{"location":"teoria/openmp/#secoes-paralelas","title":"Se\u00e7\u00f5es paralelas","text":"<pre><code>#pragma omp parallel sections\n{\n    #pragma omp section\n    tarefa1();\n\n    #pragma omp section\n    tarefa2();\n}\n</code></pre> <ul> <li>Divide blocos de c\u00f3digo independentes entre threads.</li> </ul>"},{"location":"teoria/openmp/#areas-criticas-e-exclusao-mutua","title":"\u00c1reas cr\u00edticas e exclus\u00e3o m\u00fatua","text":"<pre><code>#pragma omp critical\n{\n    contador++;\n}\n</code></pre> <ul> <li>Apenas uma thread por vez entra nesse bloco.</li> <li>\u00datil para proteger atualiza\u00e7\u00f5es em vari\u00e1veis compartilhadas.</li> </ul>"},{"location":"teoria/openmp/#diretiva-single","title":"Diretiva <code>single</code>","text":"<pre><code>#pragma omp parallel\n{\n    #pragma omp single\n    {\n        std::cout &lt;&lt; \"Executado por apenas 1 thread\\n\";\n    }\n}\n</code></pre> <ul> <li>Apenas uma thread executa esse trecho, mas as outras esperam.</li> </ul>"},{"location":"teoria/openmp/#barreira-de-sincronizacao","title":"Barreira de sincroniza\u00e7\u00e3o","text":"<pre><code>#pragma omp barrier\n</code></pre> <ul> <li>Faz todas as threads esperarem umas pelas outras antes de seguir adiante.</li> </ul> <p>Sim \ud83d\ude4c al\u00e9m das diretivas b\u00e1sicas que j\u00e1 coloquei no guia, existem outras muito usadas na pr\u00e1tica que valem a pena aparecer num material de refer\u00eancia r\u00e1pida para os alunos. Vou complementar a lista com as mais \u00fateis/did\u00e1ticas:</p>"},{"location":"teoria/openmp/#pragma-omp-parallel-for-collapsen","title":"<code>#pragma omp parallel for collapse(n)</code>","text":"<p>O <code>collapse(n)</code> junta <code>n</code> loops aninhados em um s\u00f3 loop paralelo. Muito \u00fatil em matrizes e tensores.</p> <pre><code>#pragma omp parallel for collapse(2)\nfor (int i = 0; i &lt; N; i++) {\n    for (int j = 0; j &lt; M; j++) {\n        A[i][j] = i + j;\n    }\n}\n</code></pre>"},{"location":"teoria/openmp/#pragma-omp-task","title":"<code>#pragma omp task</code>","text":"<p>Permite criar tarefas ass\u00edncronas dentro de uma regi\u00e3o paralela. Muito usado para grafos, \u00e1rvores e pipelines.</p> <pre><code>#pragma omp parallel\n{\n    #pragma omp single\n    {\n        #pragma omp task\n        f1();\n\n        #pragma omp task\n        f2();\n\n        #pragma omp taskwait   // sincroniza as tasks\n    }\n}\n</code></pre>"},{"location":"teoria/openmp/#pragma-omp-atomic","title":"<code>#pragma omp atomic</code>","text":"<p>Protege uma opera\u00e7\u00e3o simples (ex.: incremento) de condi\u00e7\u00f5es de corrida, com overhead menor que <code>critical</code>.</p> <pre><code>#pragma omp parallel for\nfor (int i = 0; i &lt; N; i++) {\n    #pragma omp atomic\n    soma += a[i];\n}\n</code></pre>"},{"location":"teoria/openmp/#pragma-omp-master-e-pragma-omp-single-nowait","title":"<code>#pragma omp master</code> e <code>#pragma omp single nowait</code>","text":"<ul> <li><code>master</code>: s\u00f3 a thread 0 roda.</li> <li><code>single</code>: apenas uma thread roda (n\u00e3o necessariamente a 0).</li> <li><code>nowait</code>: libera as threads de esperarem.</li> </ul> <pre><code>#pragma omp parallel\n{\n    #pragma omp master\n    { std::cout &lt;&lt; \"Apenas a thread master executa\\n\"; }\n\n    #pragma omp single nowait\n    { std::cout &lt;&lt; \"Uma thread qualquer executa e n\u00e3o h\u00e1 barreira\\n\"; }\n}\n</code></pre>"},{"location":"teoria/openmp/#pragma-omp-simd","title":"<code>#pragma omp simd</code>","text":"<p>For\u00e7a a vetoriza\u00e7\u00e3o SIMD (Single Instruction Multiple Data).  Pode ser combinado com <code>parallel for</code> \u2192 <code>#pragma omp parallel for simd</code>.</p> <pre><code>#pragma omp simd\nfor (int i = 0; i &lt; N; i++) {\n    c[i] = a[i] + b[i];\n}\n</code></pre>"},{"location":"teoria/openmp/#controlando-variaveis","title":"Controlando vari\u00e1veis","text":"<ul> <li><code>firstprivate(var)</code> \u2192 cada thread ganha uma c\u00f3pia inicializada com o valor original.</li> <li><code>lastprivate(var)</code> \u2192 garante que, ao final, o valor da \u00faltima itera\u00e7\u00e3o fique na vari\u00e1vel global.</li> <li><code>default(shared)</code> \u2192 define pol\u00edtica padr\u00e3o de vari\u00e1veis (bom para pegar erros!).</li> </ul> <p>Documenta\u00e7\u00e3o dispon\u00edvel em openmp.org</p>"},{"location":"teoria/profiling/","title":"Profiling","text":"<p>Profiling \u00e9 o processo de medir o comportamento de um programa em termos de consumo de recursos, como tempo de execu\u00e7\u00e3o, uso de CPU, mem\u00f3ria e I/O. As informa\u00e7\u00f5es coletadas durante o profiling ajudam a identificar \"gargalos\" ou partes do c\u00f3digo que s\u00e3o ineficientes.</p> <p>Use o Cluster Franky</p> <pre><code>Acessando o terminal dele via ssh com o comando ssh nome_da_pasta@ip_do_cluster\n</code></pre> <p>ficou com d\u00favida?</p>"},{"location":"teoria/profiling/#ferramentas-para-profiling-em-c","title":"Ferramentas para Profiling em C++","text":"<p>gprof: O gprof (GNU Profiler) \u00e9 uma ferramenta de profiling que faz parte do GNU Compiler Collection (GCC). Ele \u00e9 usado para medir o tempo de execu\u00e7\u00e3o gasto em cada fun\u00e7\u00e3o de um programa e criar um relat\u00f3rio detalhado de como esse tempo \u00e9 distribu\u00eddo entre as v\u00e1rias partes do c\u00f3digo. O gprof \u00e9 \u00fatil para identificar \"gargalos\" de desempenho em um programa, onde otimiza\u00e7\u00f5es podem ser mais eficazes.</p> <p>Valgrind: O Valgrind \u00e9 uma su\u00edte de ferramentas que ajuda a encontrar bugs de mem\u00f3ria e a realizar profiling de programas,tamb\u00e9m \u00e9 usado para medir o desempenho do programa em termos de uso de CPU.</p>"},{"location":"teoria/profiling/#exemplo-1-usando-gprof","title":"Exemplo 1: Usando <code>gprof</code>","text":"<p>Vamos come\u00e7ar com um exemplo b\u00e1sico de como usar o <code>gprof</code>.</p>"},{"location":"teoria/profiling/#codigo-de-exemplo-em-c","title":"C\u00f3digo de Exemplo em C++","text":"<p>O c\u00f3digo exemplo mult_matriz.cpp realiza uma opera\u00e7\u00e3o de multiplica\u00e7\u00e3o de matrizes. Ele multiplica duas matrizes  A  e  B  e armazena o resultado na matriz C.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nvoid multiplyMatrices(const std::vector&lt;std::vector&lt;int&gt;&gt;&amp; A, const std::vector&lt;std::vector&lt;int&gt;&gt;&amp; B, std::vector&lt;std::vector&lt;int&gt;&gt;&amp; C) {\n    int n = A.size();\n    for (int i = 0; i &lt; n; ++i) {\n        for (int j = 0; j &lt; n; ++j) {\n            C[i][j] = 0;\n            for (int k = 0; k &lt; n; ++k) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n}\n\nint main() {\n    int n = 100;\n    std::vector&lt;std::vector&lt;int&gt;&gt; A(n, std::vector&lt;int&gt;(n, 1));\n    std::vector&lt;std::vector&lt;int&gt;&gt; B(n, std::vector&lt;int&gt;(n, 2));\n    std::vector&lt;std::vector&lt;int&gt;&gt; C(n, std::vector&lt;int&gt;(n, 0));\n\n    multiplyMatrices(A, B, C);\n\n    std::cout &lt;&lt; \"Matrix multiplication completed.\" &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/profiling/#compilacao-com-suporte-a-profiling","title":"Compila\u00e7\u00e3o com Suporte a Profiling","text":"<p>Para usar o <code>gprof</code>, precisamos compilar o c\u00f3digo com a flag <code>-pg</code>, que habilita o suporte ao profiling:</p> <pre><code>g++ -pg mult_matriz.cpp -o mult_matriz\n</code></pre>"},{"location":"teoria/profiling/#executando-o-programa","title":"Executando o Programa","text":"<p>Depois de compilar, execute o programa normalmente:</p> <pre><code>./mult_matriz\n</code></pre> <p>Essa execu\u00e7\u00e3o vai gerar um arquivo chamado <code>gmon.out</code>, que cont\u00e9m os dados de profiling.</p>"},{"location":"teoria/profiling/#analisando-os-dados-com-gprof","title":"Analisando os Dados com <code>gprof</code>","text":"<p>Agora, use o <code>gprof</code> para analisar os dados:</p> <pre><code>gprof mult_matriz gmon.out &gt; analise.txt\n</code></pre> <p>Isso cria um relat\u00f3rio detalhado do tempo gasto em cada fun\u00e7\u00e3o e a quantidade de chamadas feitas. O relat\u00f3rio ser\u00e1 salvo no arquivo <code>analise.txt</code>.</p>"},{"location":"teoria/profiling/#entendendo-o-relatorio-de-profiling","title":"Entendendo o Relat\u00f3rio de Profiling","text":"<p>Ap\u00f3s executar o seu programa com <code>gprof</code>, voc\u00ea obter\u00e1 um relat\u00f3rio que cont\u00e9m duas se\u00e7\u00f5es principais: o Flat Profile e o Call Graph. Vamos explorar o significado de cada uma e como interpret\u00e1-las.</p>"},{"location":"teoria/profiling/#flat-profile-identificando-as-funcoes-criticas","title":"Flat Profile: Identificando as Fun\u00e7\u00f5es Cr\u00edticas","text":"<p>O Flat Profile fornece uma vis\u00e3o geral do tempo que cada fun\u00e7\u00e3o consome durante a execu\u00e7\u00e3o do programa. Aqui est\u00e3o os principais elementos do relat\u00f3rio:</p> <ul> <li> <p>% time: Indica a porcentagem do tempo total de execu\u00e7\u00e3o que foi gasto em cada fun\u00e7\u00e3o. Fun\u00e7\u00f5es com valores mais altos s\u00e3o geralmente os principais alvos para otimiza\u00e7\u00e3o.</p> </li> <li> <p>cumulative seconds: \u00c9 o tempo acumulado at\u00e9 essa fun\u00e7\u00e3o ser chamada. Ele ajuda a entender quanto tempo foi gasto no programa at\u00e9 aquele ponto.</p> </li> <li> <p>self seconds: \u00c9 ao tempo gasto exclusivamente dentro da fun\u00e7\u00e3o, sem incluir o tempo das fun\u00e7\u00f5es que ela chama.</p> </li> <li> <p>calls: Mostra quantas vezes a fun\u00e7\u00e3o foi chamada. Fun\u00e7\u00f5es chamadas muitas vezes podem ser boas candidatas para otimiza\u00e7\u00e3o, especialmente se tiverem um tempo significativo por chamada.</p> </li> <li> <p>self ms/call e total ms/call: Esses valores mostram o tempo m\u00e9dio gasto em cada chamada da fun\u00e7\u00e3o. <code>self ms/call</code> \u00e9 o tempo gasto na pr\u00f3pria fun\u00e7\u00e3o, enquanto <code>total ms/call</code> inclui o tempo das fun\u00e7\u00f5es que ela invoca.</p> </li> </ul>"},{"location":"teoria/profiling/#call-graph-compreendendo-as-relacoes-entre-funcoes","title":"Call Graph: Compreendendo as Rela\u00e7\u00f5es Entre Fun\u00e7\u00f5es","text":"<p>O Call Graph mostra a hierarquia de chamadas entre as fun\u00e7\u00f5es do seu programa. Ele detalha como as fun\u00e7\u00f5es est\u00e3o interconectadas e qual o impacto de cada uma no tempo de execu\u00e7\u00e3o total.</p> <ul> <li> <p>Self/Children Time: O tempo \"Self\" \u00e9 o gasto na pr\u00f3pria fun\u00e7\u00e3o, enquanto o tempo \"Children\" \u00e9 o gasto nas fun\u00e7\u00f5es que ela chama.</p> </li> <li> <p>Called: Informa quantas vezes uma fun\u00e7\u00e3o foi chamada, seja diretamente ou indiretamente por outras fun\u00e7\u00f5es.</p> </li> </ul>"},{"location":"teoria/profiling/#analise-do-relatorio-de-profiling","title":"An\u00e1lise do Relat\u00f3rio de Profiling","text":"<p>No relat\u00f3rio gerado, as fun\u00e7\u00f5es relacionadas ao operador <code>operator[]</code> do <code>std::vector</code> aparecem como cr\u00edticas, consumindo cerca de 33% do tempo de execu\u00e7\u00e3o cada. Isso indica que a maneira como os vetores s\u00e3o acessados e manipulados no c\u00f3digo esta consumindo bastante tempo.</p> <p>Al\u00e9m disso, a fun\u00e7\u00e3o <code>multiplyMatrices</code> aparece com um tempo de execu\u00e7\u00e3o acumulado consider\u00e1vel. Como esta fun\u00e7\u00e3o realiza o trabalho pesado da multiplica\u00e7\u00e3o de matrizes, \u00e9 natural que ela seja um foco de aten\u00e7\u00e3o para otimiza\u00e7\u00e3o.</p>"},{"location":"teoria/profiling/#oportunidades-de-otimizacao","title":"Oportunidades de Otimiza\u00e7\u00e3o","text":"<p>Com base no relat\u00f3rio, os poss\u00edveis candidatos a otimiza\u00e7\u00e3o s\u00e3o:</p> <ul> <li> <p>Reduzir Acessos ao Vetor: Como o acesso aos elementos do vetor (<code>operator[]</code>) consome uma parte significativa do tempo de execu\u00e7\u00e3o, podemos tentar reduzir o n\u00famero de acessos diretos ao vetor. </p> </li> <li> <p>Otimizar a Fun\u00e7\u00e3o <code>multiplyMatrices</code>: Esta fun\u00e7\u00e3o \u00e9 o cora\u00e7\u00e3o do processamento e qualquer melhoria aqui ter\u00e1 um grande impacto no desempenho global. Podemos pensar em paralelizar a fun\u00e7\u00e3o para distribuir o trabalho entre m\u00faltiplos n\u00facleos ou m\u00e1quinas, em um ambiente HPC como o Cluster Franky.</p> </li> </ul>"},{"location":"teoria/profiling/#exemplo-2-usando-valgrind-para-profiling-de-memoria","title":"Exemplo 2: Usando Valgrind para Profiling de Mem\u00f3ria","text":"<p>O Valgrind tem um conjunto de ferramentas para an\u00e1lise de programas. Uma de suas funcionalidades mais conhecidas \u00e9 a detec\u00e7\u00e3o de problemas de mem\u00f3ria, mas tamb\u00e9m pode ser usado para profiling de CPU.</p> <p>Vamos usar o mesmo c\u00f3digo de multiplica\u00e7\u00e3o de matrizes do exemplo anterior.</p>"},{"location":"teoria/profiling/#usando-o-valgrind-para-detectar-problemas-de-memoria","title":"Usando o Valgrind para Detectar Problemas de Mem\u00f3ria","text":"<p>Primeiro, compile o c\u00f3digo normalmente, sem flags especiais:</p> <pre><code>g++ mult_matriz.cpp -o mult_matriz\n</code></pre> <p>Agora, execute o programa usando o Valgrind para detectar problemas de mem\u00f3ria:</p> <pre><code>valgrind --leak-check=full ./mult_matriz &amp;&gt;leak-check.txt\n</code></pre> <p>O Valgrind ir\u00e1 executar o programa e relatar quaisquer vazamentos de mem\u00f3ria ou acessos inv\u00e1lidos no arquivo leak-check.txt.</p> <p>No relat\u00f3rio obtido aqui nos meus testes eu tive os seguintes resultados:</p>"},{"location":"teoria/profiling/#interpretacao-do-relatorio-valgrind","title":"Interpreta\u00e7\u00e3o do Relat\u00f3rio Valgrind","text":"<ol> <li>HEAP SUMMARY (Resumo da Pilha)</li> <li> <p>in use at exit: 0 bytes in 0 blocks: Isso significa que, ao final da execu\u00e7\u00e3o do programa, n\u00e3o h\u00e1 blocos de mem\u00f3ria alocados que n\u00e3o foram liberados. Ou seja, toda a mem\u00f3ria que foi alocada foi devidamente liberada.</p> </li> <li> <p>total heap usage: 308 allocs, 308 frees, 202,128 bytes allocated: Este campo indica que, ao longo da execu\u00e7\u00e3o do programa, 308 aloca\u00e7\u00f5es de mem\u00f3ria heap ocorreram, e todas as 308 foram correspondidas por uma libera\u00e7\u00e3o. O total de mem\u00f3ria alocada durante o programa foi de 202,128 bytes.</p> </li> <li> <p>All heap blocks were freed -- no leaks are possible</p> </li> <li> <p>Esta linha confirma que todos os blocos de mem\u00f3ria foram liberados corretamente, portanto, n\u00e3o h\u00e1 vazamentos de mem\u00f3ria poss\u00edveis. Isso significa que o gerenciamento de mem\u00f3ria no programa est\u00e1 sendo feito corretamente.</p> </li> <li> <p>ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)</p> </li> <li>Esta parte do relat\u00f3rio informa que n\u00e3o houve nenhum erro de mem\u00f3ria detectado. Isso inclui erros como acessos inv\u00e1lidos, uso de mem\u00f3ria n\u00e3o inicializada, ou acessos fora dos limites. O Valgrind n\u00e3o encontrou nenhum problema relacionado \u00e0 mem\u00f3ria neste programa.</li> </ol>"},{"location":"teoria/profiling/#usando-o-valgrind-para-profiling-de-cpu-com-callgrind","title":"Usando o Valgrind para Profiling de CPU com <code>callgrind</code>","text":"<p>O Valgrind tamb\u00e9m pode ser usado para profiling de CPU com a ferramenta Callgrind:</p> <pre><code>valgrind --tool=callgrind ./mult_matriz \n</code></pre> <p>Este comando vai resultar em um arquivo de sa\u00edda <code>callgrind.out.&lt;PID&gt;</code>, que cont\u00e9m informa\u00e7\u00f5es detalhadas sobre o uso da CPU por cada fun\u00e7\u00e3o do programa.</p> <p>O relat\u00f3rio que voc\u00ea executou com Callgrind fornece um resumo sobre o desempenho do programa em termos de instru\u00e7\u00f5es executadas. Os elementos principais do relat\u00f3rio s\u00e3o:</p> <ol> <li> <p>Events: Ir: <code>Ir</code> significa \"Instruction References\". Este evento conta o n\u00famero total de instru\u00e7\u00f5es de m\u00e1quina que foram executadas pelo programa. As instru\u00e7\u00f5es de m\u00e1quina s\u00e3o as opera\u00e7\u00f5es mais b\u00e1sicas que a CPU realiza, como somar n\u00fameros, carregar dados da mem\u00f3ria, ou comparar valores. No relat\u00f3rio aqui do meu teste, o valor de <code>Ir</code> \u00e9 128,306,660. Isso significa que o programa executou mais de 128 milh\u00f5es de instru\u00e7\u00f5es durante a multiplica\u00e7\u00e3o de matrizes.</p> </li> <li> <p>Collected: 128,306,660: Este n\u00famero indica que o Callgrind coletou dados sobre todas essas 128 milh\u00f5es de instru\u00e7\u00f5es. \u00c9 uma confirma\u00e7\u00e3o de que todas as instru\u00e7\u00f5es executadas foram monitoradas.</p> </li> <li> <p>I refs: 128,306,660 : <code>I refs</code> \u00e9 uma m\u00e9trica que mostra o n\u00famero total de refer\u00eancias de instru\u00e7\u00e3o que foram feitas durante a execu\u00e7\u00e3o do programa. Como o valor \u00e9 igual ao de <code>Ir</code>, isso indica que cada instru\u00e7\u00e3o foi contabilizada.</p> </li> </ol> <p>O que fazer com essas informa\u00e7\u00f5es?</p> <ul> <li> <p>N\u00famero de Instru\u00e7\u00f5es: Um alto n\u00famero de instru\u00e7\u00f5es (<code>Ir</code>) pode indicar que o programa est\u00e1 realizando muitas opera\u00e7\u00f5es. Em um ambiente HPC, isso pode ser bom ou ruim, dependendo da efici\u00eancia dessas instru\u00e7\u00f5es. Muitas instru\u00e7\u00f5es simples podem ser r\u00e1pidas, enquanto poucas instru\u00e7\u00f5es complexas podem ser mais lentas.</p> </li> <li> <p>Identifica\u00e7\u00e3o de Gargalos: Ao combinar esses dados com outras informa\u00e7\u00f5es, como tempos de execu\u00e7\u00e3o e cache misses (que Callgrind tamb\u00e9m pode monitorar), voc\u00ea pode identificar quais partes do c\u00f3digo consomem mais recursos e otimizar essas \u00e1reas. Por exemplo, se uma fun\u00e7\u00e3o espec\u00edfica estiver gerando um grande n\u00famero de instru\u00e7\u00f5es e utilizando muito cache, ela pode ser um gargalo que precisa ser otimizado.</p> </li> </ul>"},{"location":"teoria/profiling/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<p>Para uma an\u00e1lise mais detalhada, voc\u00ea pode:</p> <p>Usar o KCachegrind (uma interface gr\u00e1fica) para visualizar o resultado detalhadamente:</p> <pre><code>kcachegrind callgrind.out.&lt;PID&gt;\n</code></pre> <p></p> <p>Como podemos ver na imagem, a fun\u00e7\u00e3o <code>multiplyMatrices</code> est\u00e1 destacada em laranja e consome 97.80% do total de instru\u00e7\u00f5es. Isso indica que a multiplica\u00e7\u00e3o de matrizes \u00e9 a opera\u00e7\u00e3o mais intensiva e cr\u00edtica em termos de desempenho no c\u00f3digo. Como essa fun\u00e7\u00e3o domina o uso de CPU, ela \u00e9 o principal alvo para otimiza\u00e7\u00e3o.</p> <p>As fun\u00e7\u00f5es que manipulam <code>std::vector</code> tamb\u00e9m aparecem com destaque:</p> <p><code>std::vector::operator[]</code>: Consome 18.71% das instru\u00e7\u00f5es. Esse operador \u00e9 chamado cada vez que um elemento do vetor \u00e9 acessado. A alta porcentagem indica que muitos acessos ao vetor est\u00e3o ocorrendo, o que pode ser um ponto de otimiza\u00e7\u00e3o.</p> <p><code>std::vector::allocator</code>: Tamb\u00e9m est\u00e1 destacada, indicando que a aloca\u00e7\u00e3o e acesso aos elementos do vetor \u00e9 um fator importante no uso de recursos.</p>"},{"location":"teoria/profiling/#comparacao-entre-gprof-e-valgrind","title":"Compara\u00e7\u00e3o entre Gprof e Valgrind","text":"<p>Gprof e Valgrind s\u00e3o ferramentas de profiling, mas com focos e funcionalidades especificas. Na tabela temos uma compara\u00e7\u00e3o detalhada entre essas duas ferramentas:</p> Aspecto Gprof Valgrind Foco Principal Profiling de desempenho, medindo o tempo gasto em fun\u00e7\u00f5es. Detecta erros de uso de mem\u00f3ria e oferece ferramentas de profiling. Uso T\u00edpico Mapear gargalos de desempenho e identificar o tempo de execu\u00e7\u00e3o das fun\u00e7\u00f5es. Detectar vazamentos de mem\u00f3ria, acessos inv\u00e1lidos, e mapear o uso de CPU e mem\u00f3ria. Complexidade Relativamente simples de usar e interpretar, adequado para profiling inicial. Mais complexo, com v\u00e1rias ferramentas especializadas para diferentes tipos de an\u00e1lise. Overhead de Execu\u00e7\u00e3o Baixo overhead; o programa roda quase na velocidade normal. Alto overhead; o programa pode rodar significativamente mais lento devido \u00e0 an\u00e1lise detalhada. An\u00e1lise de Fun\u00e7\u00f5es Oferece relat\u00f3rios de chamadas (Call Graph) e perfis de fun\u00e7\u00f5es para entender o tempo de execu\u00e7\u00e3o. Oferece gr\u00e1ficos de chamadas detalhados com Callgrind, al\u00e9m de perfis de cache e instru\u00e7\u00f5es. Depura\u00e7\u00e3o de Mem\u00f3ria N\u00e3o fornece suporte para debug de mem\u00f3ria. Ferramenta principal para depura\u00e7\u00e3o de mem\u00f3ria, com suporte para detectar vazamentos e erros. Multithreading Suporta an\u00e1lise b\u00e1sica, mas n\u00e3o \u00e9 especializado em detectar race conditions. Helgrind \u00e9 especializado race conditions em programas multithreaded. Integra\u00e7\u00e3o e Uso Parte do GCC, f\u00e1cil de integrar em fluxos de trabalho de compila\u00e7\u00e3o. Requer execu\u00e7\u00e3o com a ferramenta espec\u00edfica e pode necessitar de ajustes no ambiente para uso eficiente. Ambiente de Uso Ideal para profiling em ambientes de desenvolvimento e produ\u00e7\u00e3o. Melhor utilizado em desenvolvimento e testes devido ao overhead; \u00fatil em produ\u00e7\u00e3o para an\u00e1lise pontual."},{"location":"teoria/profiling/#conclusao","title":"Conclus\u00e3o","text":"<p>Gprof e Valgrind s\u00e3o ferramentas complementares no arsenal de um desenvolvedor:</p> <ul> <li> <p>Gprof \u00e9 uma boa escolha quando o objetivo \u00e9 entender a distribui\u00e7\u00e3o de tempo de execu\u00e7\u00e3o entre as fun\u00e7\u00f5es de um programa. Com seu baixo overhead, \u00e9 ideal para profiling inicial e para identificar rapidamente as \u00e1reas do c\u00f3digo que mais consomem tempo.</p> </li> <li> <p>Valgrind \u00e9 indispens\u00e1vel quando se trata de garantir o bom funcionamento do c\u00f3digo, especialmente em rela\u00e7\u00e3o ao uso de mem\u00f3ria. Embora introduza um overhead significativo, suas ferramentas como Memcheck e Callgrind s\u00e3o essenciais para detectar vazamentos de mem\u00f3ria, acessos inv\u00e1lidos, e para visualizar o desempenho em termos de uso de CPU e cache.</p> </li> </ul> <p>Em ambientes de HPC, usar Gprof para identificar gargalos de desempenho e Valgrind para garantir que o c\u00f3digo esteja livre de erros de mem\u00f3ria e bem otimizado, proporciona uma abordagem robusta para garantir que o software seja tanto r\u00e1pido quanto confi\u00e1vel. </p>"},{"location":"teoria/slurm/","title":"SLURM","text":""},{"location":"teoria/slurm/#o-que-e-slurm","title":"O que \u00e9 SLURM?","text":"<p>SLURM (Simple Linux Utility for Resource Management) \u00e9 um gerenciador de workload open-source amplamente utilizado em clusters de computa\u00e7\u00e3o de alto desempenho (HPC). Ele \u00e9 respons\u00e1vel por alocar recursos de computa\u00e7\u00e3o (como CPUs, mem\u00f3ria e GPUs) aos usu\u00e1rios e suas tarefas, gerenciar filas de jobs, monitorar o uso de recursos e agendar a execu\u00e7\u00e3o de tarefas de forma eficiente.</p>"},{"location":"teoria/slurm/#principais-funcionalidades-do-slurm","title":"Principais Funcionalidades do SLURM","text":"<ol> <li>Aloca\u00e7\u00e3o de Recursos: SLURM distribui recursos de computa\u00e7\u00e3o, como n\u00f3s e processadores, conforme solicitado pelos usu\u00e1rios. Ele assegura que os recursos s\u00e3o utilizados de maneira eficiente e equitativa.</li> <li>Submiss\u00e3o de Jobs: Usu\u00e1rios podem submeter jobs (tarefas de computa\u00e7\u00e3o) ao SLURM, que coloca esses jobs em uma fila e os executa quando os recursos necess\u00e1rios est\u00e3o dispon\u00edveis.</li> <li>Monitoramento e Gerenciamento: SLURM monitoriza o estado dos jobs, n\u00f3s e parti\u00e7\u00f5es do cluster, fornecendo ferramentas para verificar o status e a utiliza\u00e7\u00e3o de recursos.</li> <li>Pol\u00edticas de Prioriza\u00e7\u00e3o: Implementa pol\u00edticas para priorizar jobs com base em v\u00e1rios fatores, como tempo de espera, utiliza\u00e7\u00e3o de recursos e prioridades definidas pelo administrador do cluster.</li> </ol>"},{"location":"teoria/slurm/#comandos-principais-do-slurm","title":"Comandos Principais do SLURM","text":"<p>Alguns dos comandos principais usados no SLURM:</p> <ol> <li>sbatch: \u00c9 um comando do SLURM usado para submeter scripts de jobs para execu\u00e7\u00e3o em um cluster. Esses scripts cont\u00eam instru\u00e7\u00f5es sobre como os recursos devem ser alocados e quais comandos devem ser executados</li> <li>scancel: Cancela um job pendente ou em execu\u00e7\u00e3o.</li> <li>scontrol: Ferramenta administrativa usada para visualizar e/ou modificar o estado do SLURM. Muitos comandos <code>scontrol</code> s\u00f3 podem ser executados pelo adminstrador do sistema.</li> <li>sinfo: Relata o estado das filas e n\u00f3s gerenciados pelo SLURM, com v\u00e1rias op\u00e7\u00f5es de filtragem, ordena\u00e7\u00e3o e formata\u00e7\u00e3o.</li> <li>sprio: Exibe uma vis\u00e3o detalhada dos componentes que afetam a prioridade de um job.</li> <li>squeue: Relata o estado dos jobs em execu\u00e7\u00e3o em ordem de prioridade e depois os jobs pendentes em ordem de prioridade.</li> <li>srun: Submete um job para execu\u00e7\u00e3o e faz o pedido de aloca\u00e7\u00e3o dos recursos da maquina.</li> <li>strigger: Define, obt\u00e9m ou visualiza gatilhos de eventos, como n\u00f3s caindo ou jobs se aproximando do limite de tempo.</li> </ol>"},{"location":"teoria/slurm/#exemplos-de-uso-para-cada-comando-slurm","title":"Exemplos de Uso para Cada Comando SLURM","text":""},{"location":"teoria/slurm/#1-sbatch","title":"1. sbatch","text":"<p>Submete scripts de jobs para execu\u00e7\u00e3o em um cluster. Esses scripts cont\u00eam instru\u00e7\u00f5es sobre como os recursos devem ser alocados e quais comandos devem ser executados.</p> <p>Exemplo de Script:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=meu_job        # Nome do job\n#SBATCH --output=meu_job.out      # Arquivo de sa\u00edda\n#SBATCH --error=meu_job.err       # Arquivo de erro\n#SBATCH --ntasks=1                # N\u00famero de tarefas\n#SBATCH --cpus-per-task=4         # N\u00famero de CPUs por tarefa\n#SBATCH --mem=4G                  # Mem\u00f3ria total alocada para o job\n#SBATCH --time=00:02:00           # Tempo m\u00e1ximo de execu\u00e7\u00e3o (hh:mm:ss)\n#SBATCH --partition=normal        # Fila do cluster\n\necho \"Iniciando o job\"\nsleep 60\necho \"Job finalizado\"\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <p><code>-job-name=meu_job</code>: Define o nome do job como <code>meu_job</code>.</p> <p><code>-output=meu_job.out</code>: Especifica o arquivo onde a sa\u00edda padr\u00e3o do job ser\u00e1 registrada.</p> <p><code>-error=meu_job.err</code>: Especifica o arquivo onde os erros ser\u00e3o registrados.</p> <p><code>-ntasks=1</code>: Define o n\u00famero de tarefas (processos) a serem utilizados pelo job.</p> <p><code>-cpus-per-task=4</code>: Aloca 4 CPUs para cada tarefa.</p> <p><code>-mem=4G</code>: Especifica que 4 GB de mem\u00f3ria ser\u00e3o alocados para o job.</p> <p><code>-time=00:02:00</code>: Define o tempo m\u00e1ximo de execu\u00e7\u00e3o do job como 2 minutos.</p> <p><code>-partition=normal</code>: Especifica a fila do cluster onde o job ser\u00e1 executado.</p>"},{"location":"teoria/slurm/#2-scancel","title":"2. scancel","text":"<p>Cancela um job pendente ou em execu\u00e7\u00e3o.</p> <p>Exemplo:</p> <pre><code>scancel 12345\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <ul> <li><code>12345</code>: Especifica o ID do job que deve ser cancelado.</li> </ul>"},{"location":"teoria/slurm/#3-scontrol","title":"3. scontrol","text":"<p>Ferramenta administrativa usada para visualizar e/ou modificar o estado do SLURM. Muitos comandos <code>scontrol</code> s\u00f3 podem ser executados pelo administrador do sistema.</p> <p>Exemplo:</p> <pre><code>scontrol show job 12345\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <p><code>show job 12345</code>: Exibe informa\u00e7\u00f5es detalhadas sobre o job com ID <code>12345</code>.</p>"},{"location":"teoria/slurm/#4-sinfo","title":"4. sinfo","text":"<p>Relata o estado das filas e n\u00f3s gerenciados pelo SLURM.</p> <p>Exemplo:</p> <pre><code>sinfo\n</code></pre>"},{"location":"teoria/slurm/#5-sprio","title":"5. sprio","text":"<p>Exibe uma vis\u00e3o detalhada dos componentes que afetam a prioridade de um job.</p> <p>Exemplo:</p> <pre><code>sprio\n</code></pre>"},{"location":"teoria/slurm/#6-squeue","title":"6. squeue","text":"<p>Relata o estado dos jobs em execu\u00e7\u00e3o em ordem de prioridade e depois os jobs pendentes em ordem de prioridade.</p> <p>Exemplo:</p> <pre><code>squeue -u username\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <p><code>u username</code>: Filtra a sa\u00edda para mostrar apenas os jobs do usu\u00e1rio <code>username</code>.</p>"},{"location":"teoria/slurm/#7-srun","title":"7. srun","text":"<p>Submete um job para execu\u00e7\u00e3o e faz o pedido de aloca\u00e7\u00e3o dos recursos da m\u00e1quina.</p> <p>Exemplo:</p> <pre><code>srun -N 1 -n 1 --time=00:01:00 ./meu_programa\n</code></pre> <p>Explica\u00e7\u00e3o das Flags:</p> <p><code>N 1</code>: Especifica que 1 n\u00f3 deve ser alocado.</p> <p><code>n 1</code>: Define que 1 tarefa deve ser executadas.</p> <p><code>-time=00:01:00</code>: Define o tempo m\u00e1ximo de execu\u00e7\u00e3o do job como 1 minuto.</p> <p><code>./meu_programa</code>: Especifica o programa a ser executado.</p>"},{"location":"teoria/slurm/#9-strigger","title":"9. strigger","text":"<p>Define, obt\u00e9m ou visualiza gatilhos de eventos, como n\u00f3s caindo ou jobs se aproximando do limite de tempo.</p> <p>Exemplo: Vamos supor que voc\u00ea queira configurar um gatilho (<code>strigger</code>) para monitorar o uso de mem\u00f3ria de um job espec\u00edfico e enviar um alerta quando o uso de mem\u00f3ria ultrapassar um certo limite. Aqui est\u00e1 um exemplo completo:</p> <pre><code>strigger --set --jobid=&lt;JOB_ID&gt; --threshold=500 --action=\"echo 'Aten\u00e7\u00e3o: O uso de mem\u00f3ria ultrapassou 500 MB!'\"\n</code></pre>"},{"location":"teoria/slurm/#explicacao-do-comando","title":"Explica\u00e7\u00e3o do Comando:","text":"<p><code>strigger</code>: Comando para configurar um gatilho no SLURM.</p> <p><code>--set</code>: Indica que estamos criando um novo gatilho.</p> <p><code>--jobid=&lt;JOB_ID&gt;</code>: Especifica o ID do job que queremos monitorar. Substitua <code>&lt;JOB_ID&gt;</code> pelo ID real do job.</p> <p><code>--threshold=500</code>: Define o limiar de 500 MB de uso de mem\u00f3ria. Quando o job usar mais de 500 MB, o gatilho ser\u00e1 ativado.</p> <p><code>--action=\"echo 'Aten\u00e7\u00e3o: O uso de mem\u00f3ria ultrapassou 500 MB!'\"</code>: Define a a\u00e7\u00e3o que ser\u00e1 executada quando o gatilho for ativado. Neste caso, a a\u00e7\u00e3o \u00e9 um simples comando <code>echo</code> que imprime uma mensagem de alerta.</p> <p>Este gatilho ser\u00e1 acionado quando o job especificado pelo <code>&lt;JOB_ID&gt;</code> ultrapassar 500 MB de uso de mem\u00f3ria. A a\u00e7\u00e3o definida (<code>echo</code>) ser\u00e1 executada, e voc\u00ea ver\u00e1 a mensagem \"Aten\u00e7\u00e3o: O uso de mem\u00f3ria ultrapassou 500 MB!\" no terminal ou no arquivo de sa\u00edda do job.</p> <p>Voc\u00ea pode personalizar o comando <code>strigger</code> para outras situa\u00e7\u00f5es, como monitorar o tempo restante de um job, detectar falhas de n\u00f3s, ou monitorar o uso de CPU, simplesmente ajustando os par\u00e2metros e as a\u00e7\u00f5es conforme necess\u00e1rio.</p>"},{"location":"teoria/slurm/#tipos-comuns-de-eventos-monitoraveis-pelo-strigger","title":"Tipos Comuns de Eventos Monitor\u00e1veis pelo <code>strigger</code>:","text":"<p>Tempo Restante (<code>TIME_LIMIT</code>):</p> <p>Aciona o gatilho quando um job se aproxima de seu limite de tempo de execu\u00e7\u00e3o.</p> <p>Uso do <code>--threshold</code>: Especifica o tempo restante em segundos.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --threshold=60 --action=\"echo 'Job est\u00e1 a 60 segundos do limite de tempo!'\"</code></p> <p>Uso de Mem\u00f3ria (<code>MEMORY</code>):</p> <p>Aciona o gatilho quando o uso de mem\u00f3ria de um job ultrapassa um certo limite.</p> <p>Uso do <code>--threshold</code>: Especifica a quantidade de mem\u00f3ria usada, geralmente em megabytes (MB).</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --threshold=1024 --action=\"echo 'Job ultrapassou 1GB de mem\u00f3ria!'\"</code></p> <p>Falha de N\u00f3 (<code>NODE_FAIL</code>):</p> <p>Aciona o gatilho quando um n\u00f3 falha ou fica indispon\u00edvel.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de falha ocorre.</p> <p>Exemplo: <code>strigger --set --node=&lt;NODE_NAME&gt; --event=NODE_FAIL --action=\"echo 'N\u00f3 falhou!'\"</code></p> <p>Falha de Job (<code>JOB_FAIL</code>):</p> <p>Aciona o gatilho quando um job falha por qualquer motivo.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de falha ocorre.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --event=JOB_FAIL --action=\"echo 'Job falhou!'\"</code></p> <p>In\u00edcio de Job (<code>JOB_START</code>):</p> <p>Aciona o gatilho quando um job come\u00e7a a ser executado.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de in\u00edcio ocorre.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --event=JOB_START --action=\"echo 'Job iniciou!'\"</code></p> <p>Finaliza\u00e7\u00e3o de Job (<code>JOB_END</code>):</p> <p>Aciona o gatilho quando um job termina sua execu\u00e7\u00e3o, independentemente de ter sido conclu\u00eddo com sucesso ou n\u00e3o.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de finaliza\u00e7\u00e3o ocorre.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --event=JOB_END --action=\"echo 'Job terminou!'\"</code></p> <p>Limite de CPU (<code>CPU_LIMIT</code>):</p> <p>Aciona o gatilho quando o uso de CPU de um job ultrapassa um certo limite.</p> <p>Uso do <code>--threshold</code>: Especifica o uso de CPU em segundos de CPU ou em porcentagem.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --threshold=80 --action=\"echo 'Job ultrapassou 80% do uso de CPU!'\"</code></p> <p>Submiss\u00e3o de Job (<code>JOB_SUBMIT</code>):</p> <p>Aciona o gatilho quando um job \u00e9 submetido para execu\u00e7\u00e3o.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de submiss\u00e3o ocorre.</p> <p>Exemplo: <code>strigger --set --user=&lt;USER_NAME&gt; --event=JOB_SUBMIT --action=\"echo 'Um job foi submetido!'\"</code></p> <p>Queda de Parti\u00e7\u00e3o (<code>PARTITION_DOWN</code>):</p> <p>Aciona o gatilho quando uma parti\u00e7\u00e3o inteira do cluster cai ou fica indispon\u00edvel.</p> <p>Uso do <code>--threshold</code>: N\u00e3o aplic\u00e1vel diretamente. O gatilho \u00e9 acionado quando o evento de queda da parti\u00e7\u00e3o ocorre.</p> <p>Exemplo: <code>strigger --set --partition=&lt;PARTITION_NAME&gt; --event=PARTITION_DOWN --action=\"echo 'Parti\u00e7\u00e3o caiu!'\"</code></p> <p>Chegada de Job ao Limiar de Tempo (<code>TIME_LIM_REACHED</code>):</p> <p>Similar ao <code>TIME_LIMIT</code>, mas pode ser mais espec\u00edfico para quando o tempo limite \u00e9 alcan\u00e7ado, n\u00e3o apenas quando est\u00e1 pr\u00f3ximo.</p> <p>Uso do <code>--threshold</code>: Especifica o tempo restante ou o evento do tempo limite.</p> <p>Exemplo: <code>strigger --set --jobid=&lt;JOB_ID&gt; --event=TIME_LIM_REACHED --action=\"echo 'Tempo limite alcan\u00e7ado!'\"</code></p>"},{"location":"teoria/aula01/","title":"Conte\u00fado te\u00f3rico de apoio - Aula 01","text":"Mapa de mem\u00f3ria, pilha, essas coisas... <p>Conceitos basicos de arquitetura de computadores</p> Algumas vantagens do C++ <p>Conceitos B\u00e1sicos de C++</p> <p>Loops e La\u00e7os</p> <p>Passagens de par\u00e2metros (por refer\u00eancia, por ponteiro)</p> <p>Const Correctness em HPC</p> <p>Aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica</p> <p>Sobrecarga de fun\u00e7\u00f5es C++</p> <p>Classes e Objetos</p> <p>Manipula\u00e7\u00e3o de Vetores</p> <p>Flags de compila\u00e7\u00e3o</p> Como compilar c\u00f3digos em C++ <p>Como compilar e executar c\u00f3digos em C++</p>"},{"location":"teoria/aula01/classes-e-objetos/","title":"Classes e objetos","text":"<p>Uma classe em C++ \u00e9 uma estrutura que define um conjunto de atributos (dados) e m\u00e9todos (fun\u00e7\u00f5es) que operam sobre esses dados. \u00c9 uma forma de agrupar dados e comportamentos relacionados, facilitando a modularidade e a reutiliza\u00e7\u00e3o do c\u00f3digo. Objetos s\u00e3o inst\u00e2ncias de classes. Eles representam entidades espec\u00edficas que possuem os atributos e m\u00e9todos definidos pela classe.</p>"},{"location":"teoria/aula01/classes-e-objetos/#exemplo-pratico-problema-da-mochila","title":"Exemplo Pr\u00e1tico: Problema da Mochila","text":"<p>No exemplo do problema da mochila, criamos uma classe <code>Knapsack</code> para encapsular a l\u00f3gica do problema. Vamos detalhar cada parte do c\u00f3digo para entender como classes e objetos s\u00e3o utilizados.</p>"},{"location":"teoria/aula01/classes-e-objetos/#declaracao-da-classe","title":"Declara\u00e7\u00e3o da Classe","text":"<p>A classe <code>Knapsack</code> \u00e9 definida com atributos e m\u00e9todos necess\u00e1rios para resolver o problema da mochila.</p> <pre><code>#include &lt;iostream&gt;\n\n// Declara\u00e7\u00e3o da classe Knapsack\nclass Knapsack {\npublic:\n    Knapsack(int capacidade, int numItens);       // Construtor que inicializa a mochila\n    ~Knapsack();                                  // Destrutor que libera a mem\u00f3ria alocada\n    void adicionaItem(int peso, int valor);       // M\u00e9todo para adicionar um item\n    int resolve();                                // M\u00e9todo para resolver o problema da mochila\n    void imprimeItens();                          // M\u00e9todo para imprimir os itens adicionados\n\nprivate:\n    int capacidade;                               // Capacidade m\u00e1xima da mochila\n    int numItens;                                 // N\u00famero total de itens\n    int* pesos;                                   // Vetor din\u00e2mico para armazenar os pesos dos itens\n    int* valores;                                 // Vetor din\u00e2mico para armazenar os valores dos itens\n    int contadorItens;                            // Contador de itens adicionados\n};\n</code></pre> <ul> <li>Atributos:<ul> <li><code>capacidade</code>: Capacidade m\u00e1xima da mochila.</li> <li><code>numItens</code>: N\u00famero total de itens.</li> <li><code>pesos</code>: Ponteiro para um vetor que armazena os pesos dos itens.</li> <li><code>valores</code>: Ponteiro para um vetor que armazena os valores dos itens.</li> <li><code>contadorItens</code>: Contador para acompanhar quantos itens foram adicionados.</li> </ul> </li> <li>M\u00e9todos:<ul> <li><code>Knapsack(int capacidade, int numItens)</code>: Construtor que inicializa os atributos e aloca mem\u00f3ria para os vetores.</li> <li><code>~Knapsack()</code>: Destrutor que libera a mem\u00f3ria alocada para os vetores.</li> <li><code>void adicionaItem(int peso, int valor)</code>: M\u00e9todo para adicionar um item \u00e0 mochila.</li> <li><code>int resolve()</code>: M\u00e9todo para resolver o problema da mochila usando programa\u00e7\u00e3o din\u00e2mica.</li> <li><code>void imprimeItens()</code>: M\u00e9todo para imprimir os itens adicionados \u00e0 mochila.</li> </ul> </li> </ul>"},{"location":"teoria/aula01/classes-e-objetos/#implementacao-do-construtor-e-destrutor","title":"Implementa\u00e7\u00e3o do Construtor e Destrutor","text":"<p>O construtor inicializa os atributos e aloca mem\u00f3ria para os vetores de pesos e valores. O destrutor libera essa mem\u00f3ria.</p> <pre><code>// Implementa\u00e7\u00e3o do construtor\nKnapsack::Knapsack(int capacidade, int numItens)\n    : capacidade(capacidade), numItens(numItens), contadorItens(0) {\n    pesos = new int[numItens];                    // Aloca mem\u00f3ria para os pesos dos itens\n    valores = new int[numItens];                  // Aloca mem\u00f3ria para os valores dos itens\n}\n\n// Implementa\u00e7\u00e3o do destrutor\nKnapsack::~Knapsack() {\n    delete[] pesos;                               // Libera a mem\u00f3ria alocada para os pesos\n    delete[] valores;                             // Libera a mem\u00f3ria alocada para os valores\n}\n</code></pre>"},{"location":"teoria/aula01/classes-e-objetos/#metodo-para-adicionar-itens","title":"M\u00e9todo para Adicionar Itens","text":"<p>O m\u00e9todo <code>adicionaItem</code> permite adicionar itens \u00e0 mochila, atualizando os vetores de pesos e valores.</p> <pre><code>// Implementa\u00e7\u00e3o do m\u00e9todo para adicionar um item\nvoid Knapsack::adicionaItem(int peso, int valor) {\n    if (contadorItens &lt; numItens) {\n        pesos[contadorItens] = peso;              // Adiciona o peso do item\n        valores[contadorItens] = valor;           // Adiciona o valor do item\n        contadorItens++;                          // Incrementa o contador de itens\n    } else {\n        std::cerr &lt;&lt; \"N\u00famero m\u00e1ximo de itens excedido!\" &lt;&lt; std::endl;\n    }\n}\n</code></pre>"},{"location":"teoria/aula01/classes-e-objetos/#metodo-para-resolver-o-problema-da-mochila","title":"M\u00e9todo para Resolver o Problema da Mochila","text":"<p>Programa\u00e7\u00e3o Din\u00e2mica (Dynamic Programming, DP) \u00e9 uma t\u00e9cnica de otimiza\u00e7\u00e3o usada para resolver problemas complexos dividindo-os em subproblemas mais simples. Ela \u00e9 especialmente eficaz para problemas que podem ser divididos em subproblemas menores, onde os resultados de subproblemas anteriores podem ser reutilizados para resolver subproblemas maiores.</p> <p>No problema da mochila, a programa\u00e7\u00e3o din\u00e2mica \u00e9 usada para encontrar a combina\u00e7\u00e3o de itens que maximiza o valor total sem exceder a capacidade da mochila. Construindo uma tabela que armazena os valores m\u00e1ximos poss\u00edveis para diferentes capacidades e conjuntos de itens.</p> <p>A tabela de DP (K) \u00e9 constru\u00edda de forma que cada entrada K[i][w] representa o valor m\u00e1ximo que pode ser obtido usando os primeiros i itens com uma capacidade m\u00e1xima de w.</p>"},{"location":"teoria/aula01/classes-e-objetos/#metodo-resolve","title":"M\u00e9todo resolve","text":"<ol> <li> <p>Inicializa\u00e7\u00e3o da Tabela de DP:</p> <pre><code>int** K = new int*[numItens + 1];             // Aloca mem\u00f3ria para a tabela de DP\nfor (int i = 0; i &lt;= numItens; ++i) {\n    K[i] = new int[capacidade + 1];           // Aloca mem\u00f3ria para cada linha da tabela de DP\n}\n</code></pre> <ul> <li>Alocamos uma tabela <code>K</code> com <code>numItens + 1</code> linhas e <code>capacidade + 1</code> colunas. Cada entrada <code>K[i][w]</code> armazenar\u00e1 o valor m\u00e1ximo poss\u00edvel para a submochila com capacidade <code>w</code> usando os primeiros <code>i</code> itens.</li> <li>Preenchimento da Tabela de DP:</li> </ul> <pre><code>for (int i = 0; i &lt;= numItens; ++i) {\n    for (int w = 0; w &lt;= capacidade; ++w) {\n        if (i == 0 || w == 0) {\n            K[i][w] = 0;                      // Caso base: capacidade 0 ou nenhum item\n        } else if (pesos[i - 1] &lt;= w) {\n            // Escolhe o m\u00e1ximo entre incluir ou n\u00e3o o item atual\n            K[i][w] = std::max(valores[i - 1] + K[i - 1][w - pesos[i - 1]], K[i - 1][w]);\n        } else {\n            K[i][w] = K[i - 1][w];            // N\u00e3o inclui o item atual\n        }\n    }\n}\n</code></pre> <ul> <li>Usamos um loop duplo para preencher a tabela.</li> <li>Caso Base: Se n\u00e3o h\u00e1 itens (<code>i == 0</code>) ou a capacidade \u00e9 zero (<code>w == 0</code>), o valor m\u00e1ximo \u00e9 0.</li> <li>Decis\u00e3o: Para cada item, verificamos se ele pode ser inclu\u00eddo na submochila (<code>pesos[i - 1] &lt;= w</code>). Se puder, escolhemos o m\u00e1ximo entre incluir o item (somando seu valor com o valor da submochila restante) e n\u00e3o inclu\u00ed-lo.</li> <li>Exclus\u00e3o do Item: Se o item n\u00e3o puder ser inclu\u00eddo, simplesmente copiamos o valor da submochila sem ele.</li> <li>Resultado Final:</li> </ul> <pre><code>int resultado = K[numItens][capacidade];      // Resultado final da DP\n</code></pre> <ul> <li>O valor m\u00e1ximo poss\u00edvel para a mochila completa \u00e9 encontrado em <code>K[numItens][capacidade]</code>.</li> <li>Libera\u00e7\u00e3o da Mem\u00f3ria:</li> </ul> <pre><code>for (int i = 0; i &lt;= numItens; ++i) {\n    delete[] K[i];                            // Libera mem\u00f3ria para cada linha\n}\ndelete[] K;                                   // Libera mem\u00f3ria para o vetor de ponteiros\n</code></pre> <ul> <li>Ap\u00f3s o c\u00e1lculo, liberamos a mem\u00f3ria alocada dinamicamente para a tabela <code>K</code>.</li> </ul> </li> </ol> <p>Neste contexto, a programa\u00e7\u00e3o din\u00e2mica (DP) \u00e9 usada para resolver o problema da mochila de maneira eficiente, evitando recomputa\u00e7\u00f5es de subproblemas ao armazenar os resultados intermedi\u00e1rios em uma tabela. A classe <code>Knapsack</code> encapsula a l\u00f3gica do problema, tornando o c\u00f3digo modular e f\u00e1cil de manter. A aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria permite a flexibilidade de lidar com diferentes tamanhos de problemas sem desperdi\u00e7ar mem\u00f3ria.</p>"},{"location":"teoria/aula01/classes-e-objetos/#metodo-para-imprimir-itens","title":"M\u00e9todo para Imprimir Itens","text":"<p>O m\u00e9todo <code>imprimeItens</code> imprime os itens adicionados \u00e0 mochila.</p> <pre><code>// Implementa\u00e7\u00e3o do m\u00e9todo para imprimir os itens adicionados\nvoid Knapsack::imprimeItens() {\n    std::cout &lt;&lt; \"Itens adicionados (peso, valor):\" &lt;&lt; std::endl;\n    for (int i = 0; i &lt; contadorItens; ++i) {\n        std::cout &lt;&lt; \"(\" &lt;&lt; pesos[i] &lt;&lt; \", \" &lt;&lt; valores[i] &lt;&lt; \")\" &lt;&lt; std::endl;\n    }\n}\n</code></pre>"},{"location":"teoria/aula01/classes-e-objetos/#funcao-main","title":"Fun\u00e7\u00e3o <code>main</code>","text":"<p>A fun\u00e7\u00e3o <code>main</code> cria um objeto <code>Knapsack</code>, adiciona itens \u00e0 mochila, imprime os itens adicionados e resolve o problema da mochila.</p> <pre><code>int main() {\n    int capacidade = 50;                           // Capacidade da mochila\n    int numItens = 3;                              // N\u00famero de itens dispon\u00edveis\n\n    Knapsack mochila(capacidade, numItens);\n\n    mochila.adicionaItem(10, 60);                  // Adiciona item (peso, valor)\n    mochila.adicionaItem(20, 100);                 // Adiciona item (peso, valor)\n    mochila.adicionaItem(30, 120);                 // Adiciona item (peso, valor)\n\n    mochila.imprimeItens();                        // Imprime os itens adicionados\n\n    int valorMaximo = mochila.resolve();           // Resolve o problema da mochila\n\n    std::cout &lt;&lt; \"Valor m\u00e1ximo que pode ser levado: \" &lt;&lt; valorMaximo &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>Neste exemplo, a classe <code>Knapsack</code> encapsula todos os dados e m\u00e9todos necess\u00e1rios para resolver o problema da mochila. Usamos aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria para gerenciar os vetores de pesos, valores dos itens, e a tabela de programa\u00e7\u00e3o din\u00e2mica utilizada na solu\u00e7\u00e3o do problema.</p>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/","title":"Compilar/Executar C\u00f3digos C++","text":"<p>Pr\u00e9-requisitos:</p> <ul> <li>Visual Studio Code (VSCode) instalado</li> </ul>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#passos-para-windows","title":"Passos para Windows","text":"<ol> <li> <p>Instalar o Compilador Siga este tutorial</p> </li> <li> <p>Instalar Extens\u00f5es Necess\u00e1rias no VSCode:</p> <ul> <li>Abra o VSCode.</li> <li>V\u00e1 para a aba de extens\u00f5es (\u00edcone de quadrado no lado esquerdo).</li> <li>Pesquise e instale a extens\u00e3o:<ul> <li>C/C++ (Microsoft)</li> </ul> </li> </ul> </li> </ol>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#passos-para-linux","title":"Passos para Linux","text":"<ol> <li> <p>Instalar o Compilador G++:</p> <ul> <li>N\u00e3o precisa, j\u00e1 vem instalado &lt;3</li> </ul> </li> <li> <p>Instalar Extens\u00f5es Necess\u00e1rias no VSCode:</p> <ul> <li>Abra o VSCode.</li> <li>V\u00e1 para a aba de extens\u00f5es (\u00edcone de quadrado no lado esquerdo).</li> <li>Pesquise e instale as seguintes extens\u00e3o:<ul> <li>C/C++ (Microsoft)</li> </ul> </li> </ul> </li> </ol>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#passos-para-macos","title":"Passos para macOS","text":"<ol> <li> <p>Instalar o compilador:</p> <ul> <li>N\u00e3o precisa, j\u00e1 vem instalado &lt;3</li> <li>Mas se quiser saber mais detalhes sobre o Clang, sugiro este material</li> </ul> </li> <li> <p>Instalar Extens\u00f5es Necess\u00e1rias no VSCode:</p> <ul> <li>Abra o VSCode.</li> <li>V\u00e1 para a aba de extens\u00f5es (\u00edcone de quadrado no lado esquerdo).</li> <li>Pesquise e instale a extens\u00f5es:<ul> <li>C/C++ (Microsoft)</li> </ul> </li> </ul> </li> </ol>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#compilando-um-exemplo-em-c-para-testar","title":"Compilando um Exemplo em C++ para Testar","text":"<p>Crie um arquivo <code>main.cpp</code> com o seguinte conte\u00fado:</p> <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nint main() {\n    cout &lt;&lt; \"Hello, World!\" &lt;&lt; endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#windows-compilar-e-executar","title":"Windows \u2192 Compilar e Executar","text":"<pre><code>g++ main.cpp -o main.exe\n./main.exe\n</code></pre>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#linux-compilar-e-executar","title":"Linux \u2192 Compilar e Executar:","text":"<pre><code>g++ main.cpp -o main\n./main\n</code></pre>"},{"location":"teoria/aula01/compilar-executar-C%2B%2B/#macos-compilar-e-executar","title":"MacOS \u2192 Compilar e Executar","text":"<pre><code>clang++ main.cpp -o main\n./main\n</code></pre> <p>Seguindo esses passos, voc\u00ea deve ser capaz de compilar e executar programas C++ em Windows, Linux ou macOS usando o VSCode.</p>"},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/","title":"Conceitos b\u00e1sicos de C++","text":"<p>Esses s\u00e3o os tipos de vari\u00e1veis e seus respectivos tamanhos em C++ </p> Tipo de Dados Tamanho (em bytes) Valor M\u00ednimo Valor M\u00e1ximo bool 1 false true char 1 -128 127 unsigned char 1 0 255 short 2 -32,768 32,767 unsigned short 2 0 65,535 int 4 -2,147,483,648 2,147,483,647 unsigned int 4 0 4,294,967,295 long 8 -9,223,372,036,854,775,808 9,223,372,036,854,775,807 unsigned long 8 0 18,446,744,073,709,551,615 float 4 1.2E-38 3.4E+38 double 8 2.3E-308 1.7E+308 long double 16 3.4E-4932 1.1E+4932 wchar_t 4 0 4,294,967,295  \u26a0\ufe0f Esses tamanhos podem variar dependendo da arquitetura do sistema. Esta tabela assume um sistema de 64 bits."},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/#o-que-e-um-namespace","title":"O que \u00e9 um Namespace?","text":"<p>Um namespace \u00e9 uma forma de agrupar identificadores (nomes de fun\u00e7\u00f5es, classes, objetos, etc.) sob um nome comum, evitando conflitos de nome entre diferentes partes de um programa ou entre diferentes bibliotecas.</p>"},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/#exemplo-simples-de-namespace","title":"Exemplo Simples de Namespace","text":"<p>Imagine duas bibliotecas diferentes que ambas definem uma fun\u00e7\u00e3o chamada <code>print()</code>. Se voc\u00ea incluir ambas as bibliotecas em seu programa, o compilador n\u00e3o saber\u00e1 qual <code>print()</code> usar. Para resolver isso, cada biblioteca pode colocar sua fun\u00e7\u00e3o <code>print()</code> em seu pr\u00f3prio namespace:</p> <pre><code>// Biblioteca A\nnamespace A {\n    void print() {\n        std::cout &lt;&lt; \"Imprimindo da biblioteca A\" &lt;&lt; std::endl;\n    }\n}\n\n// Biblioteca B\nnamespace B {\n    void print() {\n        std::cout &lt;&lt; \"Imprimindo da biblioteca B\" &lt;&lt; std::endl;\n    }\n}\n\nint main() {\n    A::print(); // Chama a fun\u00e7\u00e3o print() da biblioteca A\n    B::print(); // Chama a fun\u00e7\u00e3o print() da biblioteca B\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/#usando-namespaces","title":"Usando Namespaces","text":"<p>Existem v\u00e1rias maneiras de usar namespaces em C++:</p> <ol> <li> <p>Usar o nome completo do namespace (qualifica\u00e7\u00e3o total):</p> <pre><code>#include &lt;iostream&gt;\n\nint main() {\n    std::cout &lt;&lt; \"Hello, World!\" &lt;&lt; std::endl; // Usa std::cout e std::endl\n    return 0;\n}\n</code></pre> </li> <li> <p>Usar a declara\u00e7\u00e3o <code>using</code> para trazer membros espec\u00edficos do namespace para o escopo atual:</p> <pre><code>#include &lt;iostream&gt;\nusing std::cout;\nusing std::endl;\n\nint main() {\n    cout &lt;&lt; \"Hello, World!\" &lt;&lt; endl; // Usa cout e endl sem o prefixo std::\n    return 0;\n}\n</code></pre> </li> <li> <p>Usar a diretiva <code>using</code> para trazer todos os membros do namespace para o escopo atual:</p> <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nint main() {\n    cout &lt;&lt; \"Hello, World!\" &lt;&lt; endl; // Usa cout e endl sem o prefixo std::\n    return 0;\n}\n</code></pre> </li> </ol>"},{"location":"teoria/aula01/conceitos-basicos-C%2B%2B/#o-que-e-std","title":"O que \u00e9 <code>std</code>?","text":"<p><code>std</code> \u00e9 o namespace padr\u00e3o da biblioteca padr\u00e3o C++ (Standard Library). Ele cont\u00e9m a maior parte das fun\u00e7\u00f5es, objetos, tipos e classes fornecidos pela biblioteca padr\u00e3o do C++. Quando voc\u00ea usa recursos da biblioteca padr\u00e3o, como <code>std::vector</code>, <code>std::cout</code>, <code>std::string</code>, etc., voc\u00ea est\u00e1 acessando esses elementos do namespace <code>std</code>.</p> <p>Por exemplo:</p> <ul> <li><code>std::cout</code> \u00e9 o objeto de fluxo de sa\u00edda padr\u00e3o usado para imprimir dados na tela.</li> <li><code>std::vector</code> \u00e9 uma classe de cont\u00eainer que representa um array din\u00e2mico.</li> </ul>"},{"location":"teoria/aula01/conceitos-basicos-hw/","title":"Relembrando conceitos importantes","text":"<p>O mapa de mem\u00f3ria de um computador revela como a mem\u00f3ria \u00e9 organizada e gerenciada, isso \u00e9 essencial para entender o armazenamento, o acesso e a manipula\u00e7\u00e3o de dados pela CPU. A mem\u00f3ria principal do sistema inclui o heap, a stack e os segmentos de dados e c\u00f3digo. </p> <ol> <li>Pilha: Localizada no topo do mapa de mem\u00f3ria, \u00e9 usada para armazenar vari\u00e1veis locais e chamadas de fun\u00e7\u00e3o. Cada thread possui sua pr\u00f3pria pilha.</li> <li>Espa\u00e7o Livre: Espa\u00e7o entre a pilha e o heap, permitindo o crescimento de ambos conforme necess\u00e1rio.</li> <li>Heap: \u00c1rea usada para a aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica. Mem\u00f3ria \u00e9 alocada e desalocada conforme necess\u00e1rio durante a execu\u00e7\u00e3o do programa.</li> <li>Segmento de Dados: Cont\u00e9m vari\u00e1veis globais e est\u00e1ticas. Este segmento \u00e9 dividido em duas partes:<ul> <li>Segmento de Dados Inicializado: Armazena vari\u00e1veis globais e est\u00e1ticas que s\u00e3o inicializadas.</li> <li>BSS (Block Started by Symbol): Armazena vari\u00e1veis globais e est\u00e1ticas n\u00e3o inicializadas.</li> </ul> </li> <li>Segmento de C\u00f3digo: Cont\u00e9m o c\u00f3digo execut\u00e1vel do programa.</li> </ol> <p>Os endere\u00e7os da pilha crescem de cima para baixo, enquanto os endere\u00e7os do heap crescem de baixo para cima, conforme indicado pelas setas de crescimento no diagrama. Essa organiza\u00e7\u00e3o \u00e9 essencial para o gerenciamento eficiente da mem\u00f3ria e para garantir a integridade e desempenho do programa</p> <p></p> <p>Os caches, subdivididos em L1, L2 e L3, s\u00e3o mem\u00f3rias r\u00e1pidas de diferentes tamanhos e velocidades. O L1 \u00e9 o mais r\u00e1pido e menor, localizado dentro do n\u00facleo da CPU. O L2 \u00e9 maior e mais lento que o L1, mas ainda mais r\u00e1pido que a RAM, enquanto o L3, compartilhado entre os n\u00facleos do processador, \u00e9 maior e mais lento que o L2. Os registradores, pequenas quantidades de mem\u00f3ria dentro da CPU, s\u00e3o extremamente r\u00e1pidos e usados para opera\u00e7\u00f5es imediatas e tempor\u00e1rias.</p> <p></p> <ul> <li>Registradores: Pequenas quantidades de mem\u00f3ria dentro da CPU, extremamente r\u00e1pidas, usadas para opera\u00e7\u00f5es imediatas e tempor\u00e1rias. Tamanho: 64-128 bits.</li> <li>Cache L1: O cache mais r\u00e1pido e muito pequeno, localizado dentro do n\u00facleo da CPU. Tamanho: 32 KB.</li> <li>Cache L2: Maior e mais lento que o L1, mas ainda muito r\u00e1pido. Tamanho: 256 KB - 512 KB.</li> <li>Cache L3: Compartilhado entre os n\u00facleos do processador, \u00e9 maior e mais lento que o L2, mas ainda mais r\u00e1pido que a RAM. Tamanho: 2 MB - 16 MB.</li> <li>RAM: A mem\u00f3ria principal do sistema, maior em tamanho e a mais lenta em termos de velocidade comparada aos caches e registradores. Tamanho: 4 GB - 64 GB ou mais.</li> </ul> <p></p> <p>No contexto de HPC, escolher os tipos de dados adequados em C++ \u00e9 crucial por v\u00e1rias raz\u00f5es. </p> <ul> <li>Vari\u00e1veis menores ocupam menos espa\u00e7o, permitindo que mais dados sejam armazenados no cache ou na RAM, melhorando a localidade de cache e resultando em acessos mais r\u00e1pidos.</li> <li>A velocidade de processamento tamb\u00e9m \u00e9 impactada pela escolha dos tipos na declara\u00e7\u00e3o da vari\u00e1vel. A CPU processa tipos menores mais rapidamente, e instru\u00e7\u00f5es SIMD (Single Instruction, Multiple Data) podem processar m\u00faltiplos dados em paralelo se os tipos forem pequenos o suficiente para caberem nos registradores.</li> <li>A precis\u00e3o dos c\u00e1lculos \u00e9 outra considera\u00e7\u00e3o importante. Para c\u00e1lculos cient\u00edficos, a precis\u00e3o adicional dos <code>double</code> pode ser necess\u00e1ria para evitar erros num\u00e9ricos significativos, enquanto em gr\u00e1ficos e outras aplica\u00e7\u00f5es, <code>float</code> pode ser suficiente e mais eficiente em termos de mem\u00f3ria e processamento.</li> <li>Usar tipos menores de vari\u00e1veis reduzem a quantidade de dados transferidos entre n\u00f3s em um cluster, diminuindo a lat\u00eancia e a sobrecarga de comunica\u00e7\u00e3o.</li> </ul> <p>Considerar corretamente os tipos na cria\u00e7\u00e3o das vari\u00e1veis \u00e9 importante para maximizar a efici\u00eancia de uso de mem\u00f3ria, melhorar a velocidade e a precis\u00e3o dos c\u00e1lculos, otimizar o desempenho computacional, minimizar a fragmenta\u00e7\u00e3o de mem\u00f3ria, aproveitar melhor o paralelismo e reduzir a lat\u00eancia de comunica\u00e7\u00e3o, al\u00e9m de melhorar a localidade de cache e o acesso \u00e0 mem\u00f3ria. Compreender o mapa de mem\u00f3ria do computador e como os diferentes tipos de dados interagem com a CPU e a mem\u00f3ria pode levar a melhorias significativas no desempenho dos seus algoritmos.</p>"},{"location":"teoria/aula01/flags-compilacao/","title":"Flags de compila\u00e7\u00e3o (-O1, -O2, -O3, -Ofast).","text":"<p>As flags de compila\u00e7\u00e3o s\u00e3o op\u00e7\u00f5es fornecidas ao compilador para controlar o n\u00edvel de otimiza\u00e7\u00e3o aplicada ao c\u00f3digo durante o processo de compila\u00e7\u00e3o. Diferentes n\u00edveis de otimiza\u00e7\u00e3o podem influenciar o desempenho e o tamanho do c\u00f3digo resultante. Vamos explorar as principais flags de otimiza\u00e7\u00e3o usadas com o compilador GCC (GNU Compiler Collection): <code>-O1</code>, <code>-O2</code>, <code>-O3</code>, e <code>-Ofast</code>.</p>"},{"location":"teoria/aula01/flags-compilacao/#1-flag-o1","title":"1. Flag <code>O1</code>","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>N\u00edvel B\u00e1sico de Otimiza\u00e7\u00e3o: Aplica otimiza\u00e7\u00f5es que melhoram o desempenho do c\u00f3digo sem aumentar significativamente o tempo de compila\u00e7\u00e3o.</li> </ul> <p>Otimiza\u00e7\u00f5es Comuns:</p> <ul> <li>Remo\u00e7\u00e3o de c\u00f3digo morto.</li> <li>Simplifica\u00e7\u00e3o de express\u00f5es.</li> <li>Inlining b\u00e1sico de fun\u00e7\u00f5es.</li> </ul> <p>Quando Usar:</p> <ul> <li>Quando o tempo de compila\u00e7\u00e3o \u00e9 uma preocupa\u00e7\u00e3o, mas algum n\u00edvel de otimiza\u00e7\u00e3o \u00e9 desejado.</li> </ul> <pre><code>g++ -O1 -o meu_programa meu_programa.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#2-flag-o2","title":"2. Flag <code>O2</code>","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>N\u00edvel Moderado de Otimiza\u00e7\u00e3o: Aplica um conjunto mais agressivo de otimiza\u00e7\u00f5es que melhoram ainda mais o desempenho do c\u00f3digo.</li> <li>Maior tempo de compila\u00e7\u00e3o comparado ao <code>O1</code>, mas melhor desempenho do c\u00f3digo.</li> </ul> <p>Otimiza\u00e7\u00f5es Comuns:</p> <ul> <li>Inclui todas as otimiza\u00e7\u00f5es do <code>O1</code>.</li> <li>Otimiza\u00e7\u00f5es de loop (desenrolamento, fus\u00e3o de loops).</li> <li>Melhorias na aloca\u00e7\u00e3o de registradores.</li> <li>Otimiza\u00e7\u00f5es de fluxo de controle.</li> </ul> <p>Quando Usar:</p> <ul> <li>Para a maioria dos casos onde o desempenho \u00e9 mais cr\u00edtico do que o tempo de compila\u00e7\u00e3o.</li> <li>Quando se quer um bom desempenho na performance do c\u00f3digo.</li> </ul> <pre><code>g++ -O2 -o meu_programa meu_programa.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#3-flag-o3","title":"3. Flag <code>O3</code>","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>N\u00edvel Alto de Otimiza\u00e7\u00e3o: Aplica otimiza\u00e7\u00f5es muito agressivas que podem aumentar significativamente o tempo de compila\u00e7\u00e3o e o uso de mem\u00f3ria.</li> <li>Foco em maximizar o desempenho do c\u00f3digo, mesmo que isso aumente o tempo de compila\u00e7\u00e3o.</li> </ul> <p>Otimiza\u00e7\u00f5es Comuns:</p> <ul> <li>Inclui todas as otimiza\u00e7\u00f5es do <code>O2</code>.</li> <li>Inlining mais agressivo de fun\u00e7\u00f5es.</li> <li>Vetoriza\u00e7\u00e3o (uso de SIMD).</li> <li>Transforma\u00e7\u00f5es mais avan\u00e7adas de loop.</li> </ul> <p>Quando Usar:</p> <ul> <li>Quando o desempenho m\u00e1ximo do c\u00f3digo \u00e9 crucial e o tempo de compila\u00e7\u00e3o \u00e9 menos importante.</li> <li>Em aplica\u00e7\u00f5es onde cada gota de desempenho \u00e9 necess\u00e1ria.</li> </ul> <pre><code>g++ -O3 -o meu_programa meu_programa.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#4-flag-ofast","title":"4. Flag <code>Ofast</code>","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>N\u00edvel M\u00e1ximo de Otimiza\u00e7\u00e3o: Aplica todas as otimiza\u00e7\u00f5es do <code>O3</code> e desconsidera a conformidade estrita com os padr\u00f5es, o que pode levar a um desempenho ainda maior.</li> </ul> <p>Otimiza\u00e7\u00f5es Comuns:</p> <ul> <li>Inclui todas as otimiza\u00e7\u00f5es do <code>O3</code>.</li> <li>Otimiza\u00e7\u00f5es de matem\u00e1tica r\u00e1pida (por exemplo, assume que n\u00e3o h\u00e1 overflow de ponto flutuante).</li> <li>Desconsidera o padr\u00e3o IEEE para opera\u00e7\u00f5es de ponto flutuante.</li> </ul> <p>Quando Usar:</p> <ul> <li>Quando o desempenho \u00e9 a \u00fanica prioridade e a conformidade estrita com os padr\u00f5es n\u00e3o \u00e9 uma preocupa\u00e7\u00e3o.</li> <li>Em cen\u00e1rios de HPC onde a precis\u00e3o pode ser ligeiramente sacrificada por ganhos de desempenho.</li> </ul> <pre><code>g++ -Ofast -o meu_programa meu_programa.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-dos-niveis-de-otimizacao","title":"Compara\u00e7\u00e3o dos N\u00edveis de Otimiza\u00e7\u00e3o","text":"Flag Tempo de Compila\u00e7\u00e3o Desempenho Seguran\u00e7a e Conformidade -O1 Baixo Moderado Alta -O2 Moderado Alto Alta -O3 Alto Muito Alto Alta -Ofast Muito Alto M\u00e1ximo M\u00e9dia/Baixa <p>As flags de otimiza\u00e7\u00e3o s\u00e3o ferramentas poderosas que podem ajudar a melhorar significativamente o desempenho do seu c\u00f3digo C++. Entender como e quando us\u00e1-las \u00e9 essencial para aproveitar ao m\u00e1ximo os recursos de seu ambiente de compila\u00e7\u00e3o e execu\u00e7\u00e3o.</p>"},{"location":"teoria/aula01/flags-compilacao/#exemplos-de-compilacao-com-diferentes-flags-de-otimizacao","title":"Exemplos de Compila\u00e7\u00e3o com Diferentes Flags de Otimiza\u00e7\u00e3o","text":"<p>Para demonstrar os efeitos das diferentes flags de otimiza\u00e7\u00e3o (<code>-O1</code>, <code>-O2</code>, <code>-O3</code>, <code>-Ofast</code>) no desempenho de c\u00f3digos C++, vamos utilizar tr\u00eas exemplos representativos de HPC.</p>"},{"location":"teoria/aula01/flags-compilacao/#exemplo-1-multiplicacao-de-matrizes","title":"Exemplo 1: Multiplica\u00e7\u00e3o de Matrizes","text":"<p>A multiplica\u00e7\u00e3o de matrizes \u00e9 uma opera\u00e7\u00e3o computacionalmente intensiva com muitas aplica\u00e7\u00f5es em HPC.</p>"},{"location":"teoria/aula01/flags-compilacao/#codigo-base","title":"C\u00f3digo Base","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nvoid multiplyMatrices(const std::vector&lt;std::vector&lt;double&gt;&gt;&amp; A, const std::vector&lt;std::vector&lt;double&gt;&gt;&amp; B, std::vector&lt;std::vector&lt;double&gt;&gt;&amp; C, int N) {\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            C[i][j] = 0;\n            for (int k = 0; k &lt; N; ++k) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n}\n\nint main() {\n    const int N = 1000;\n    std::vector&lt;std::vector&lt;double&gt;&gt; A(N, std::vector&lt;double&gt;(N, 1.0));\n    std::vector&lt;std::vector&lt;double&gt;&gt; B(N, std::vector&lt;double&gt;(N, 1.0));\n    std::vector&lt;std::vector&lt;double&gt;&gt; C(N, std::vector&lt;double&gt;(N, 0.0));\n\n    auto start = std::chrono::high_resolution_clock::now();\n    multiplyMatrices(A, B, C, N);\n    auto end = std::chrono::high_resolution_clock::now();\n\n    std::chrono::duration&lt;double&gt; duration = end - start;\n    std::cout &lt;&lt; \"Duration: \" &lt;&lt; duration.count() &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#compilacao-e-execucao","title":"Compila\u00e7\u00e3o e Execu\u00e7\u00e3o","text":"<ol> <li>Compila\u00e7\u00e3o com <code>O1</code>:</li> </ol> <pre><code>g++ -O1 -o matrix_multiplication_O1 matrix_multiplication.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O2</code>:</li> </ol> <pre><code>g++ -O2 -o matrix_multiplication_O2 matrix_multiplication.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O3</code>:</li> </ol> <pre><code>g++ -O3 -o matrix_multiplication_O3 matrix_multiplication.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>Ofast</code>:</li> </ol> <pre><code>g++ -Ofast -o matrix_multiplication_Ofast matrix_multiplication.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-de-desempenho","title":"Compara\u00e7\u00e3o de Desempenho","text":"<p>Execute cada vers\u00e3o do programa compilado e compare a dura\u00e7\u00e3o relatada:</p> <pre><code>time ./matrix_multiplication_O1\ntime ./matrix_multiplication_O2\ntime ./matrix_multiplication_O3\ntime ./matrix_multiplication_Ofast\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#explicando-o-output-do-time","title":"Explicando o Output do <code>time</code>","text":"<p>Quando voc\u00ea usa o comando <code>time</code> para medir o tempo de execu\u00e7\u00e3o de um programa, ele fornece tr\u00eas valores principais no output: real, user, e sys. Esses valores representam diferentes aspectos do tempo de execu\u00e7\u00e3o do programa.</p>"},{"location":"teoria/aula01/flags-compilacao/#exemplo-de-output-do-time","title":"Exemplo de Output do <code>time</code>","text":"<pre><code>real    0m10.123s\nuser    0m8.456s\nsys     0m1.234s\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#o-que-cada-valor-representa","title":"O Que Cada Valor Representa","text":""},{"location":"teoria/aula01/flags-compilacao/#1-real","title":"1. real","text":"<ul> <li>Tempo Real: Representa o tempo total que passou desde o in\u00edcio at\u00e9 o fim da execu\u00e7\u00e3o do comando. Esse valor inclui todo o tempo de espera do programa, como I/O (input/output), troca de contexto, e tempo de espera por recursos.</li> </ul> <p>Se voc\u00ea iniciar o programa e cronometra-lo com um cron\u00f4metro, o valor real \u00e9 o que voc\u00ea veria no cron\u00f4metro.</p> <p>Fatores que Afetam:</p> <ul> <li>Tempo gasto aguardando acesso ao disco.</li> <li>Tempo de espera na fila da CPU.</li> <li>Troca de contexto e outros tempos de espera.</li> </ul>"},{"location":"teoria/aula01/flags-compilacao/#2-user","title":"2. user","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>Tempo de Usu\u00e1rio: Representa a quantidade de tempo que a CPU gastou executando o c\u00f3digo do programa em modo usu\u00e1rio. Esse tempo n\u00e3o inclui o tempo gasto em chamadas de sistema (system calls) ou o tempo gasto aguardando opera\u00e7\u00f5es de I/O.</li> </ul> <p>Medida de quanto tempo de CPU foi usado para executar as instru\u00e7\u00f5es do seu programa.</p> <p>Fatores que Afetam:</p> <ul> <li>Processamento computacional pesado.</li> <li>C\u00e1lculos matem\u00e1ticos e loops intensivos.</li> </ul>"},{"location":"teoria/aula01/flags-compilacao/#3-sys","title":"3. sys","text":"<p>Descri\u00e7\u00e3o:</p> <ul> <li>Tempo de Sistema: Representa a quantidade de tempo que a CPU gastou executando o c\u00f3digo do kernel em nome do seu programa. Isso inclui o tempo gasto em chamadas de sistema, como opera\u00e7\u00f5es de I/O, gerenciamento de mem\u00f3ria, e outras opera\u00e7\u00f5es de kernel.</li> </ul> <p>Tempo de CPU gasto para executar fun\u00e7\u00f5es de sistema solicitadas pelo seu programa.</p> <p>Fatores que Afetam:</p> <ul> <li>Opera\u00e7\u00f5es de leitura/escrita de disco.</li> <li>Opera\u00e7\u00f5es de rede.</li> <li>Aloca\u00e7\u00e3o e gerenciamento de mem\u00f3ria.</li> </ul>"},{"location":"teoria/aula01/flags-compilacao/#interpretacao-do-output","title":"Interpreta\u00e7\u00e3o do Output","text":"<p>Vamos considerar novamente o exemplo de output:</p> <pre><code>real    0m10.123s\nuser    0m8.456s\nsys     0m1.234s\n</code></pre> <p>Interpreta\u00e7\u00e3o:</p> <ul> <li>real (0m10.123s): O programa levou 10.123 segundos para ser executado do in\u00edcio ao fim. Isso inclui todo o tempo de espera.</li> <li>user (0m8.456s): A CPU gastou 8.456 segundos executando o c\u00f3digo do seu programa.</li> <li>sys (0m1.234s): A CPU gastou 1.234 segundos executando fun\u00e7\u00f5es do sistema em nome do seu programa.</li> </ul>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-de-desempenho-com-diferentes-flags-de-compilacao","title":"Compara\u00e7\u00e3o de Desempenho com Diferentes Flags de Compila\u00e7\u00e3o","text":"<p>Ao usar <code>time</code> para comparar programas compilados com diferentes flags de otimiza\u00e7\u00e3o (<code>-O1</code>, <code>-O2</code>, <code>-O3</code>, <code>-Ofast</code>), voc\u00ea deve prestar aten\u00e7\u00e3o principalmente ao valor real para ver o impacto geral no tempo de execu\u00e7\u00e3o. No entanto, os valores user e sys tamb\u00e9m s\u00e3o importantes para entender como as otimiza\u00e7\u00f5es afetam o uso da CPU e o tempo gasto em opera\u00e7\u00f5es do sistema.</p>"},{"location":"teoria/aula01/flags-compilacao/#_1","title":"Flags de compila\u00e7\u00e3o (-O1, -O2, -O3, -Ofast).","text":"<pre><code># Compila\u00e7\u00e3o com -O3\ng++ -O3 -o matrix_multiplication_O3 matrix_multiplication.cpp\n\n# Medi\u00e7\u00e3o de tempo de execu\u00e7\u00e3o\ntime ./matrix_multiplication_O3\n</code></pre> <p>Output esperado:</p> <pre><code>real    0m7.123s\nuser    0m6.789s\nsys     0m0.234s\n</code></pre> <p>Interpreta\u00e7\u00e3o:</p> <ul> <li>real (0m7.123s): O tempo total de execu\u00e7\u00e3o foi de 7.123 segundos.</li> <li>user (0m6.789s): A CPU gastou 6.789 segundos executando o c\u00f3digo do programa.</li> <li>sys (0m0.234s): A CPU gastou 0.234 segundos em chamadas de sistema.</li> </ul> <p>Os valores fornecidos pelo comando <code>time</code> ajudam a entender o comportamento do seu programa e o impacto das otimiza\u00e7\u00f5es no desempenho geral. Analisar esses valores pode revelar gargalos e oportunidades de otimiza\u00e7\u00e3o adicional.</p>"},{"location":"teoria/aula01/flags-compilacao/#exemplo-2-regressao-linear-ia","title":"Exemplo 2: Regress\u00e3o Linear (IA)","text":"<p>A regress\u00e3o linear \u00e9 um algoritmo b\u00e1sico de aprendizado de m\u00e1quina comumente usado em IA.</p>"},{"location":"teoria/aula01/flags-compilacao/#codigo-base_1","title":"C\u00f3digo Base","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\ndouble linearRegression(const std::vector&lt;double&gt;&amp; X, const std::vector&lt;double&gt;&amp; Y) {\n    double sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;\n    int n = X.size();\n    for (int i = 0; i &lt; n; ++i) {\n        sumX += X[i];\n        sumY += Y[i];\n        sumXY += X[i] * Y[i];\n        sumX2 += X[i] * X[i];\n    }\n    return (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);\n}\n\nint main() {\n    const int N = 1000000;\n    std::vector&lt;double&gt; X(N, 1.0);\n    std::vector&lt;double&gt; Y(N, 2.0);\n\n    auto start = std::chrono::high_resolution_clock::now();\n    double slope = linearRegression(X, Y);\n    auto end = std::chrono::high_resolution_clock::now();\n\n    std::chrono::duration&lt;double&gt; duration = end - start;\n    std::cout &lt;&lt; \"Slope: \" &lt;&lt; slope &lt;&lt; \", Duration: \" &lt;&lt; duration.count() &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#compilacao-e-execucao_1","title":"Compila\u00e7\u00e3o e Execu\u00e7\u00e3o","text":"<ol> <li>Compila\u00e7\u00e3o com <code>O1</code>:</li> </ol> <pre><code>g++ -O1 -o linear_regression_O1 linear_regression.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O2</code>:</li> </ol> <pre><code>g++ -O2 -o linear_regression_O2 linear_regression.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O3</code>:</li> </ol> <pre><code>g++ -O3 -o linear_regression_O3 linear_regression.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>Ofast</code>:</li> </ol> <pre><code>g++ -Ofast -o linear_regression_Ofast linear_regression.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-de-desempenho_1","title":"Compara\u00e7\u00e3o de Desempenho","text":"<p>Execute cada vers\u00e3o do programa compilado e compare a dura\u00e7\u00e3o relatada:</p> <pre><code>time ./linear_regression_O1\ntime ./linear_regression_O2\ntime ./linear_regression_O3\ntime ./linear_regression_Ofast\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#exemplo-3-processamento-de-grandes-conjuntos-de-dados-data-science","title":"Exemplo 3: Processamento de Grandes Conjuntos de Dados (Data Science)","text":"<p>Um exemplo comum em Data Science \u00e9 a normaliza\u00e7\u00e3o de um grande conjunto de dados.</p>"},{"location":"teoria/aula01/flags-compilacao/#codigo-base_2","title":"C\u00f3digo Base","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;cmath&gt;\n\nvoid normalize(std::vector&lt;double&gt;&amp; data) {\n    double mean = 0.0;\n    double stddev = 0.0;\n    int n = data.size();\n\n    for (int i = 0; i &lt; n; ++i) {\n        mean += data[i];\n    }\n    mean /= n;\n\n    for (int i = 0; i &lt; n; ++i) {\n        stddev += (data[i] - mean) * (data[i] - mean);\n    }\n    stddev = std::sqrt(stddev / n);\n\n    for (int i = 0; i &lt; n; ++i) {\n        data[i] = (data[i] - mean) / stddev;\n    }\n}\n\nint main() {\n    const int N = 10000000;\n    std::vector&lt;double&gt; data(N, 1.0);\n\n    auto start = std::chrono::high_resolution_clock::now();\n    normalize(data);\n    auto end = std::chrono::high_resolution_clock::now();\n\n    std::chrono::duration&lt;double&gt; duration = end - start;\n    std::cout &lt;&lt; \"Duration: \" &lt;&lt; duration.count() &lt;&lt; \" seconds\" &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#compilacao-e-execucao_2","title":"Compila\u00e7\u00e3o e Execu\u00e7\u00e3o","text":"<ol> <li>Compila\u00e7\u00e3o com <code>O1</code>:</li> </ol> <pre><code>g++ -O1 -o normalize_O1 normalize.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O2</code>:</li> </ol> <pre><code>g++ -O2 -o normalize_O2 normalize.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>O3</code>:</li> </ol> <pre><code>g++ -O3 -o normalize_O3 normalize.cpp\n</code></pre> <ol> <li>Compila\u00e7\u00e3o com <code>Ofast</code>:</li> </ol> <pre><code>g++ -Ofast -o normalize_Ofast normalize.cpp\n</code></pre>"},{"location":"teoria/aula01/flags-compilacao/#comparacao-de-desempenho_2","title":"Compara\u00e7\u00e3o de Desempenho","text":"<p>Execute cada vers\u00e3o do programa compilado e compare a dura\u00e7\u00e3o relatada:</p> <pre><code>time ./normalize_O1\ntime ./normalize_O2\ntime ./normalize_O3\ntime ./normalize_Ofast\n</code></pre> <p>Depois de compilar e executar os programas com diferentes flags de otimiza\u00e7\u00e3o, compare os tempos de execu\u00e7\u00e3o relatados por cada um. Isso ajudar\u00e1 a entender como diferentes n\u00edveis de otimiza\u00e7\u00e3o afetam o desempenho de opera\u00e7\u00f5es computacionalmente intensivas.</p>"},{"location":"teoria/aula01/funcoes-inline/","title":"Fun\u00e7\u00f5es Inline","text":"<p>As fun\u00e7\u00f5es inline s\u00e3o usadas para reduzir a sobrecarga das chamadas de fun\u00e7\u00e3o, que pode ser significativa em programas de alto desempenho onde fun\u00e7\u00f5es s\u00e3o chamadas repetidamente. Em vez de realizar uma chamada de fun\u00e7\u00e3o, que envolve empilhar argumentos, saltar para a localiza\u00e7\u00e3o da fun\u00e7\u00e3o, executar a fun\u00e7\u00e3o, e ent\u00e3o retornar, o compilador substitui a chamada da fun\u00e7\u00e3o pelo pr\u00f3prio corpo da fun\u00e7\u00e3o. Isso pode resultar em um c\u00f3digo mais r\u00e1pido e eficiente.</p>"},{"location":"teoria/aula01/funcoes-inline/#vantagens-de-usar-funcoes-inline","title":"Vantagens de Usar Fun\u00e7\u00f5es Inline","text":"<ol> <li>Redu\u00e7\u00e3o da Sobrecarga de Chamada de Fun\u00e7\u00e3o:<ul> <li>As chamadas de fun\u00e7\u00e3o envolvem opera\u00e7\u00f5es adicionais de empilhamento de argumentos e desvio de controle, que podem se tornar um gargalo se as fun\u00e7\u00f5es forem chamadas repetidamente.</li> <li>Fun\u00e7\u00f5es inline eliminam essa sobrecarga, substituindo a chamada pelo pr\u00f3prio c\u00f3digo da fun\u00e7\u00e3o.</li> </ul> </li> <li>Melhoria do Desempenho:<ul> <li>A execu\u00e7\u00e3o de fun\u00e7\u00f5es inline pode ser mais r\u00e1pida, especialmente em loops intensivos onde pequenas fun\u00e7\u00f5es s\u00e3o chamadas repetidamente.</li> <li>Pode resultar em otimiza\u00e7\u00f5es adicionais pelo compilador, como a elimina\u00e7\u00e3o de vari\u00e1veis tempor\u00e1rias e a fus\u00e3o de c\u00f3digo.</li> </ul> </li> <li>Efici\u00eancia do Cache:<ul> <li>Em alguns casos, a inser\u00e7\u00e3o de fun\u00e7\u00f5es inline pode melhorar a localidade de refer\u00eancia e a efici\u00eancia do cache, embora isso dependa da natureza do c\u00f3digo e do hardware.</li> </ul> </li> </ol>"},{"location":"teoria/aula01/funcoes-inline/#contextos-ideais-para-aplicar-funcoes-inline","title":"Contextos Ideais para Aplicar Fun\u00e7\u00f5es Inline","text":"<ol> <li> <p>Fun\u00e7\u00f5es Pequenas e Simples:</p> <ul> <li>Fun\u00e7\u00f5es que s\u00e3o curtas e t\u00eam poucas opera\u00e7\u00f5es s\u00e3o ideais para serem inline. Por exemplo, fun\u00e7\u00f5es matem\u00e1ticas simples como <code>soma</code>, <code>subtrai</code>, <code>multiplica</code> ou <code>divide</code>.</li> </ul> <pre><code>inline int soma(int a, int b) {\n    return a + b;\n}\n</code></pre> </li> <li> <p>Fun\u00e7\u00f5es Chamadas Frequentemente:</p> <ul> <li>Fun\u00e7\u00f5es que s\u00e3o chamadas repetidamente em loops intensivos s\u00e3o boas candidatas para serem inline, pois a elimina\u00e7\u00e3o da sobrecarga da chamada de fun\u00e7\u00e3o pode ter um impacto significativo no desempenho.</li> </ul> <pre><code>inline int quadrado(int x) {\n    return x * x;\n}\n</code></pre> </li> <li> <p>Fun\u00e7\u00f5es que Acessam Membros de Classe:</p> <ul> <li>M\u00e9todos de classe que s\u00e3o simples e frequentemente chamados podem se beneficiar de serem inline. Em C++, m\u00e9todos definidos dentro da declara\u00e7\u00e3o de uma classe s\u00e3o implicitamente inline.</li> </ul> <pre><code>class Ponto {\npublic:\n    inline int getX() const { return x; }\n    inline int getY() const { return y; }\nprivate:\n    int x, y;\n};\n</code></pre> </li> </ol>"},{"location":"teoria/aula01/funcoes-inline/#exemplo","title":"Exemplo","text":"<p>Vamos considerar um exemplo onde uma fun\u00e7\u00e3o inline \u00e9 usada para calcular o quadrado de um n\u00famero em um loop intensivo. Isso \u00e9 comum em opera\u00e7\u00f5es cient\u00edficas e de engenharia, onde c\u00e1lculos matem\u00e1ticos simples s\u00e3o realizados repetidamente.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\nusing namespace std::chrono;\n\n// Fun\u00e7\u00e3o inline para calcular o quadrado de um n\u00famero\ninline int quadrado(int x) {\n    return x * x;\n}\n\nint main() {\n    const int N = 1000000; // N\u00famero de elementos\n    vector&lt;int&gt; dados(N, 2); // Inicializa um vetor com N elementos, todos iguais a 2\n    vector&lt;int&gt; resultados(N);\n\n    auto inicio = high_resolution_clock::now();\n\n    // Loop intensivo que usa a fun\u00e7\u00e3o inline\n    for (int i = 0; i &lt; N; ++i) {\n        resultados[i] = quadrado(dados[i]);\n    }\n\n    auto fim = high_resolution_clock::now();\n    auto duracao = duration_cast&lt;milliseconds&gt;(fim - inicio).count();\n\n    cout &lt;&lt; \"Tempo para calcular quadrados: \" &lt;&lt; duracao &lt;&lt; \"ms\" &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes-inline/#consideracoes-ao-usar-funcoes-inline","title":"Considera\u00e7\u00f5es ao Usar Fun\u00e7\u00f5es Inline","text":"<ol> <li>Tamanho da Fun\u00e7\u00e3o:<ul> <li>Fun\u00e7\u00f5es inline devem ser pequenas e simples. Fun\u00e7\u00f5es grandes inline podem aumentar significativamente o tamanho do c\u00f3digo bin\u00e1rio, o que pode ter um efeito negativo na efici\u00eancia do cache.</li> </ul> </li> <li>Otimiza\u00e7\u00f5es do Compilador:<ul> <li>O compilador pode ignorar a sugest\u00e3o de inline se achar que n\u00e3o ser\u00e1 ben\u00e9fico. Isso \u00e9 apenas uma sugest\u00e3o ao compilador.</li> </ul> </li> <li>Manutenibilidade:<ul> <li>Excesso de fun\u00e7\u00f5es inline pode tornar o c\u00f3digo mais dif\u00edcil de ler e manter. Use inline judiciosamente, apenas onde os benef\u00edcios de desempenho s\u00e3o claros.</li> </ul> </li> </ol> <p>As fun\u00e7\u00f5es inline s\u00e3o uma ferramenta valiosa em High-Performance Computing para reduzir a sobrecarga de chamadas de fun\u00e7\u00e3o e melhorar o desempenho em loops intensivos e c\u00e1lculos repetitivos. Elas devem ser usadas em fun\u00e7\u00f5es pequenas e frequentemente chamadas para obter os maiores benef\u00edcios. Ao combinar fun\u00e7\u00f5es inline com a sobrecarga de fun\u00e7\u00f5es, podemos otimizar ainda mais o c\u00f3digo para diferentes tipos de dados, mantendo a legibilidade e a organiza\u00e7\u00e3o.</p>"},{"location":"teoria/aula01/funcoes/","title":"Passagem de Par\u00e2metros","text":"<p>Par\u00e2metros podem ser passados por valor, por refer\u00eancia ou por ponteiro. No contexto de HPC, passar par\u00e2metros por refer\u00eancia ou ponteiro \u00e9 geralmente prefer\u00edvel para evitar c\u00f3pias desnecess\u00e1rias de dados, que podem ser custosas em termos de tempo e mem\u00f3ria.</p>"},{"location":"teoria/aula01/funcoes/#passagem-de-parametros-por-valor","title":"Passagem de Par\u00e2metros por Valor","text":"<p>Passar por valor significa que uma c\u00f3pia do argumento \u00e9 passada para a fun\u00e7\u00e3o. Qualquer modifica\u00e7\u00e3o feita ao par\u00e2metro dentro da fun\u00e7\u00e3o n\u00e3o afeta o argumento original.</p> <pre><code>// Fun\u00e7\u00e3o que recebe um par\u00e2metro por valor\nvoid exemploValor(int x) {\n    x = 10; // Modifica\u00e7\u00e3o local, n\u00e3o afeta o argumento original\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes/#passagem-por-referencia-e-passagem-por-ponteiro","title":"Passagem por Refer\u00eancia e Passagem por Ponteiro","text":"<p>Passagem por refer\u00eancia e passagem por ponteiro s\u00e3o duas formas de passar argumentos para fun\u00e7\u00f5es em C++, permitindo que a fun\u00e7\u00e3o modifique o argumento original. Apesar de terem prop\u00f3sitos similares, elas diferem em sintaxe e uso. Vamos explorar essas diferen\u00e7as detalhadamente.</p>"},{"location":"teoria/aula01/funcoes/#passagem-por-referencia","title":"Passagem por Refer\u00eancia","text":"<p>Passar um argumento por refer\u00eancia significa que a fun\u00e7\u00e3o recebe uma refer\u00eancia ao argumento original, permitindo modificar diretamente o valor do argumento. A sintaxe usa o operador <code>&amp;</code> no par\u00e2metro da fun\u00e7\u00e3o.</p>"},{"location":"teoria/aula01/funcoes/#sintaxe-e-exemplo","title":"Sintaxe e Exemplo","text":"<pre><code>#include &lt;iostream&gt;\n\n// Fun\u00e7\u00e3o que recebe um par\u00e2metro por refer\u00eancia\nvoid alteraPorReferencia(int&amp; x) {\n    x = 10; // Modifica\u00e7\u00e3o afeta o argumento original\n}\n\nint main() {\n    int valor = 5;\n    std::cout &lt;&lt; \"Antes da fun\u00e7\u00e3o: \" &lt;&lt; valor &lt;&lt; std::endl;\n    alteraPorReferencia(valor);\n    std::cout &lt;&lt; \"Depois da fun\u00e7\u00e3o: \" &lt;&lt; valor &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Sintaxe Limpa: A sintaxe \u00e9 mais clara e f\u00e1cil de ler, pois n\u00e3o envolve o uso expl\u00edcito de ponteiros.</li> <li>Seguran\u00e7a: Reduz o risco de manipula\u00e7\u00e3o incorreta de ponteiros (como desreferenciamento de ponteiros nulos).</li> <li>N\u00e3o Nulo: Refer\u00eancias devem ser inicializadas e n\u00e3o podem ser nulas.</li> </ul>"},{"location":"teoria/aula01/funcoes/#passagem-por-ponteiro","title":"Passagem por Ponteiro","text":"<p>Passar um argumento por ponteiro significa que a fun\u00e7\u00e3o recebe o endere\u00e7o do argumento original. A sintaxe usa o operador <code>*</code> no par\u00e2metro da fun\u00e7\u00e3o e o operador <code>&amp;</code> ao passar o argumento.</p>"},{"location":"teoria/aula01/funcoes/#sintaxe-e-exemplo_1","title":"Sintaxe e Exemplo","text":"<pre><code>#include &lt;iostream&gt;\n\n// Fun\u00e7\u00e3o que recebe um par\u00e2metro por ponteiro\nvoid alteraPorPonteiro(int* x) {\n    *x = 10; // Modifica\u00e7\u00e3o afeta o argumento original\n}\n\nint main() {\n    int valor = 5;\n    std::cout &lt;&lt; \"Antes da fun\u00e7\u00e3o: \" &lt;&lt; valor &lt;&lt; std::endl;\n    alteraPorPonteiro(&amp;valor);\n    std::cout &lt;&lt; \"Depois da fun\u00e7\u00e3o: \" &lt;&lt; valor &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes/#caracteristicas_1","title":"Caracter\u00edsticas","text":"<ul> <li>Flexibilidade: Permite a passagem de valores nulos (ponteiros nulos).</li> <li>Controle Expl\u00edcito: Fornece controle expl\u00edcito sobre a mem\u00f3ria, podendo ser \u00fatil em contextos onde manipula\u00e7\u00e3o direta de endere\u00e7os \u00e9 necess\u00e1ria.</li> <li>Complexidade: A sintaxe pode ser mais complexa e propensa a erros, como desreferenciamento de ponteiros nulos ou incorretos.</li> </ul>"},{"location":"teoria/aula01/funcoes/#quando-usar-cada-um","title":"Quando Usar Cada Um","text":"<ul> <li>Passagem por Refer\u00eancia: Use quando voc\u00ea precisa modificar o argumento original e quer uma sintaxe mais limpa e segura. Ideal para a maioria dos casos onde a refer\u00eancia n\u00e3o precisa ser nula.</li> <li>Passagem por Ponteiro: Use quando h\u00e1 a necessidade de manipular diretamente endere\u00e7os de mem\u00f3ria ou quando o valor passado pode ser opcional (nulo).</li> </ul>"},{"location":"teoria/aula01/funcoes/#exemplo-comparativo","title":"Exemplo Comparativo","text":"<p>Vamos comparar um exemplo onde modificamos um valor usando ambas as abordagens.</p>"},{"location":"teoria/aula01/funcoes/#passagem-por-referencia_1","title":"Passagem por Refer\u00eancia","text":"<pre><code>#include &lt;iostream&gt;\n\nvoid incrementaReferencia(int&amp; x) {\n    x++; // Incrementa o valor\n}\n\nint main() {\n    int valor = 5;\n    std::cout &lt;&lt; \"Antes: \" &lt;&lt; valor &lt;&lt; std::endl;\n    incrementaReferencia(valor);\n    std::cout &lt;&lt; \"Depois: \" &lt;&lt; valor &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/funcoes/#passagem-por-ponteiro_1","title":"Passagem por Ponteiro","text":"<pre><code>#include &lt;iostream&gt;\n\nvoid incrementaPonteiro(int* x) {\n    if (x) { // Verifica se o ponteiro n\u00e3o \u00e9 nulo\n        (*x)++; // Incrementa o valor\n    }\n}\n\nint main() {\n    int valor = 5;\n    std::cout &lt;&lt; \"Antes: \" &lt;&lt; valor &lt;&lt; std::endl;\n    incrementaPonteiro(&amp;valor);\n    std::cout &lt;&lt; \"Depois: \" &lt;&lt; valor &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <p>Ambos os exemplos acima modificam o valor original de <code>valor</code>, mas a abordagem de refer\u00eancia \u00e9 mais limpa, enquanto a abordagem de ponteiro oferece maior flexibilidade em termos de manipula\u00e7\u00e3o de endere\u00e7os e valores nulos.</p>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/","title":"Loops  e La\u00e7os","text":"<p>No contexto de HPC, onde a efici\u00eancia e a performance s\u00e3o cruciais, as estruturas de controle (loops e la\u00e7os) desempenham pap\u00e9is vitais:</p> <ol> <li>Otimiza\u00e7\u00e3o de Algoritmos<ul> <li>As estruturas de controle permitem que algoritmos sejam implementados de forma eficiente. Condicionais e loops bem utilizados podem reduzir o n\u00famero de opera\u00e7\u00f5es e evitar c\u00e1lculos desnecess\u00e1rios, otimizando o tempo de execu\u00e7\u00e3o.</li> </ul> </li> <li>Paralelismo<ul> <li>Em HPC, o paralelismo \u00e9 frequentemente utilizado para acelerar a execu\u00e7\u00e3o dos programas. Estruturas de controle s\u00e3o essenciais para dividir tarefas entre diferentes threads ou processos.</li> <li>O uso adequado de condicionais pode garantir que as tarefas sejam distribu\u00eddas eficientemente entre os recursos computacionais, evitando sobrecarga em um \u00fanico n\u00f3 de processamento.</li> </ul> </li> <li>Balanceamento de Carga<ul> <li>Estruturas de controle podem ajudar no balanceamento de carga, distribuindo o trabalho de maneira uniforme entre os processadores. Por exemplo, condicionais podem ser usados para verificar a carga de trabalho em diferentes n\u00f3s e ajustar dinamicamente a distribui\u00e7\u00e3o das tarefas.</li> <li>Isso \u00e9 crucial para evitar situa\u00e7\u00f5es onde alguns processadores ficam ociosos enquanto outros est\u00e3o sobrecarregados, maximizando a utiliza\u00e7\u00e3o de recursos e melhorando a performance geral.</li> </ul> </li> <li>Gerenciamento de Recursos<ul> <li>Condicionais e loops podem ser usados para gerenciar recursos, como aloca\u00e7\u00e3o de mem\u00f3ria e acesso a dispositivos de I/O. Em ambientes HPC, onde grandes volumes de dados s\u00e3o manipulados, o gerenciamento eficiente de mem\u00f3ria \u00e9 fundamental. Estruturas de controle podem ajudar a evitar desperd\u00edcio de mem\u00f3ria e garantir que os recursos sejam utilizados de maneira eficiente.</li> </ul> </li> </ol>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estruturas-de-controle-condicionais-if-else-if-else","title":"Estruturas de controle condicionais (<code>if</code>, <code>else if</code>, <code>else</code> ):","text":"<p>Exemplo: Encontrar o valor m\u00e1ximo em uma matriz</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    // Define a vari\u00e1vel max_value com o primeiro valor da matriz\n    int max_value = matrix[0][0];\n\n    // Percorre cada linha da matriz\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Percorre cada coluna da matriz\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Se o valor atual da matriz for maior que max_value, atualiza max_value\n            if (matrix[i][j] &gt; max_value) {\n                max_value = matrix[i][j];\n            }\n        }\n    }\n\n    // Imprime o valor m\u00e1ximo encontrado na matriz\n    std::cout &lt;&lt; \"O valor m\u00e1ximo na matriz \u00e9: \" &lt;&lt; max_value &lt;&lt; std::endl;\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estrutura-de-controle-condicional-switch","title":"Estrutura de controle condicional <code>switch</code> :","text":"<p>Exemplo: Imprimir a posi\u00e7\u00e3o de um n\u00famero espec\u00edfico na matriz</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    // Define o valor alvo a ser encontrado\n    int target = 5;\n\n    // Percorre cada linha da matriz\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Percorre cada coluna da matriz\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Verifica o valor atual da matriz usando switch\n            switch(matrix[i][j]) {\n                case 5:\n                    // Se o valor for 5, imprime a posi\u00e7\u00e3o e sai do switch\n                    std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" encontrado em: (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j &lt;&lt; \")\" &lt;&lt; std::endl;\n                    break;\n                default:\n                    // Caso padr\u00e3o do switch, n\u00e3o faz nada\n                    break;\n            }\n        }\n    }\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estrutura-de-controle-loop-for","title":"Estrutura de controle loop <code>for</code> :","text":"<p>Exemplo Somar todos os elementos de uma matriz :</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    // Inicializa a vari\u00e1vel sum com 0\n    int sum = 0;\n\n    // Percorre cada linha da matriz\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Percorre cada coluna da matriz\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Adiciona o valor atual da matriz \u00e0 sum\n            sum += matrix[i][j];\n        }\n    }\n\n    // Imprime a soma de todos os elementos na matriz\n    std::cout &lt;&lt; \"A soma de todos os elementos na matriz \u00e9: \" &lt;&lt; sum &lt;&lt; std::endl;\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estrutura-de-controle-loop-while","title":"Estrutura de controle loop <code>while</code> :","text":"<p>Encontrar um n\u00famero espec\u00edfico na matriz </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    // Define o valor alvo a ser encontrado\n    int target = 5;\n    bool found = false; // Flag para indicar se o valor foi encontrado\n    size_t i = 0; // \u00cdndice para as linhas\n\n    // Loop externo para percorrer as linhas\n    while (i &lt; matrix.size() &amp;&amp; !found) {\n        size_t j = 0; // \u00cdndice para as colunas\n        // Loop interno para percorrer as colunas\n        while (j &lt; matrix[i].size() &amp;&amp; !found) {\n            // Se o valor atual da matriz for igual ao alvo, imprime a posi\u00e7\u00e3o\n            if (matrix[i][j] == target) {\n                std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" encontrado em: (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j &lt;&lt; \")\" &lt;&lt; std::endl;\n                found = true; // Atualiza a flag\n            }\n            ++j; // Incrementa o \u00edndice das colunas\n        }\n        ++i; // Incrementa o \u00edndice das linhas\n    }\n\n    // Se o valor n\u00e3o foi encontrado, imprime uma mensagem\n    if (!found) {\n        std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" n\u00e3o encontrado na matriz.\" &lt;&lt; std::endl;\n    }\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#estrutura-de-controle-loop-do-while","title":"Estrutura de controle loop <code>do-while</code> :","text":"<p>Verificar se todos os elementos da matriz s\u00e3o positivos </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    bool all_positive = true; // Flag para indicar se todos os elementos s\u00e3o positivos\n    size_t i = 0; // \u00cdndice para as linhas\n\n    // Loop externo do-while para percorrer as linhas\n    do {\n        size_t j = 0; // \u00cdndice para as colunas\n        // Loop interno do-while para percorrer as colunas\n        do {\n            // Se o valor atual da matriz for menor ou igual a 0, atualiza a flag e sai do loop\n            if (matrix[i][j] &lt;= 0) {\n                all_positive = false;\n                break;\n            }\n            ++j; // Incrementa o \u00edndice das colunas\n        } while (j &lt; matrix[i].size());\n        ++i; // Incrementa o \u00edndice das linhas\n    } while (i &lt; matrix.size() &amp;&amp; all_positive);\n\n    // Imprime o resultado da verifica\u00e7\u00e3o\n    if (all_positive) {\n        std::cout &lt;&lt; \"Todos os elementos da matriz s\u00e3o positivos.\" &lt;&lt; std::endl;\n    } else {\n        std::cout &lt;&lt; \"Nem todos os elementos da matriz s\u00e3o positivos.\" &lt;&lt; std::endl;\n    }\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#controladores-de-loop-break","title":"Controladores de loop <code>break</code> :","text":"<p>Interromper a busca ao encontrar um n\u00famero espec\u00edfico (<code>break</code>)</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, 2, 3},\n        {4, 5, 6},\n        {7, 8, 9}\n    };\n\n    int target = 5; // Define o valor alvo a ser encontrado\n    bool found = false; // Flag para indicar se o valor foi encontrado\n\n    // Loop externo para percorrer as linhas\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Loop interno para percorrer as colunas\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Se o valor atual da matriz for igual ao alvo, imprime a posi\u00e7\u00e3o\n            if (matrix[i][j] == target) {\n                std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" encontrado em: (\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j &lt;&lt; \")\" &lt;&lt; std::endl;\n                found = true; // Atualiza a flag\n                break; // Interrompe o loop interno\n            }\n        }\n        if (found) {\n            break; // Interrompe o loop externo\n        }\n    }\n\n    // Se o valor n\u00e3o foi encontrado, imprime uma mensagem\n    if (!found) {\n        std::cout &lt;&lt; \"N\u00famero \" &lt;&lt; target &lt;&lt; \" n\u00e3o encontrado na matriz.\" &lt;&lt; std::endl;\n    }\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/loops-e-la%C3%A7os/#controladores-de-loop-continue","title":"Controladores de loop continue :","text":"<p>Ignorar n\u00fameros negativos ao somar elementos de uma matriz (<code>continue</code>)</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    // Inicializa uma matriz 3x3 com valores inteiros, incluindo n\u00fameros negativos\n    std::vector&lt;std::vector&lt;int&gt;&gt; matrix = {\n        {1, -2, 3},\n        {-4, 5, -6},\n        {7, -8, 9}\n    };\n\n    int sum = 0; // Inicializa a vari\u00e1vel sum com 0\n\n    // Loop externo para percorrer as linhas\n    for (size_t i = 0; i &lt; matrix.size(); ++i) {\n        // Loop interno para percorrer as colunas\n        for (size_t j = 0; j &lt; matrix[i].size(); ++j) {\n            // Se o valor atual da matriz for negativo, ignora-o e continua para a pr\u00f3xima itera\u00e7\u00e3o\n            if (matrix[i][j] &lt; 0) {\n                continue; // Ignora n\u00fameros negativos\n            }\n            // Adiciona o valor atual da matriz \u00e0 soma\n            sum += matrix[i][j];\n        }\n    }\n\n    // Imprime a soma de todos os elementos positivos na matriz\n    std::cout &lt;&lt; \"A soma de todos os elementos positivos na matriz \u00e9: \" &lt;&lt; sum &lt;&lt; std::endl;\n\n    return 0; // Termina o programa\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/","title":"Manipula\u00e7\u00e3o de Vetores","text":"<p>Manipula\u00e7\u00e3o b\u00e1sica de vetores em C++ envolve opera\u00e7\u00f5es comuns como inicializa\u00e7\u00e3o, acesso a elementos, modifica\u00e7\u00e3o, itera\u00e7\u00e3o, inser\u00e7\u00e3o, remo\u00e7\u00e3o, e c\u00f3pia de vetores. Esses conceitos s\u00e3o fundamentais, pois constituem a base para a manipula\u00e7\u00e3o de dados em grande escala.</p>"},{"location":"teoria/aula01/manipulacao-vetores/#inicializacao-de-vetores-declaracao-e-inicializacao","title":"Inicializa\u00e7\u00e3o de Vetores \u2192 Declara\u00e7\u00e3o e Inicializa\u00e7\u00e3o","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec1;                // Declara um vetor vazio de inteiros\n    std::vector&lt;int&gt; vec2(10);            // Declara um vetor de 10 inteiros inicializados com zero\n    std::vector&lt;int&gt; vec3(10, 5);         // Declara um vetor de 10 inteiros, todos inicializados com 5\n\n    // Exemplo de inicializa\u00e7\u00e3o de vetor com valores espec\u00edficos\n    std::vector&lt;int&gt; vec4 = {1, 2, 3, 4, 5};\n\n    // Imprime os elementos do vetor vec4\n    for (int val : vec4) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#acesso-e-modificacao-de-elementos","title":"Acesso e Modifica\u00e7\u00e3o de Elementos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Acessa elementos usando o operador []\n    std::cout &lt;&lt; \"Primeiro elemento: \" &lt;&lt; vec[0] &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Terceiro elemento: \" &lt;&lt; vec[2] &lt;&lt; std::endl;\n\n    // Acessa elementos usando o m\u00e9todo at()\n    std::cout &lt;&lt; \"Segundo elemento: \" &lt;&lt; vec.at(1) &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#modificacao-de-elementos","title":"Modifica\u00e7\u00e3o de Elementos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Modifica elementos usando o operador []\n    vec[0] = 10;\n    vec[2] = 30;\n\n    // Modifica elementos usando o m\u00e9todo at()\n    vec.at(1) = 20;\n\n    // Imprime os elementos modificados\n    for (int val : vec) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#iteracao-usando-loop","title":"Itera\u00e7\u00e3o Usando Loop","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Itera sobre os elementos usando um loop tradicional\n    for (size_t i = 0; i &lt; vec.size(); ++i) {\n        std::cout &lt;&lt; vec[i] &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#insercao-de-elementos","title":"Inser\u00e7\u00e3o de Elementos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Insere elementos no final do vetor\n    vec.push_back(6);\n    vec.push_back(7);\n\n    // Insere um elemento na posi\u00e7\u00e3o espec\u00edfica\n    vec.insert(vec.begin() + 2, 10); // Insere o valor 10 na terceira posi\u00e7\u00e3o\n\n    // Imprime os elementos ap\u00f3s a inser\u00e7\u00e3o\n    for (int val : vec) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#remocao-de-elementos","title":"Remo\u00e7\u00e3o de Elementos","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};\n\n    // Remove o \u00faltimo elemento\n    vec.pop_back();\n\n    // Remove um elemento na posi\u00e7\u00e3o espec\u00edfica\n    vec.erase(vec.begin() + 1); // Remove o segundo elemento\n\n    // Imprime os elementos ap\u00f3s a remo\u00e7\u00e3o\n    for (int val : vec) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#copiando-vetores","title":"Copiando Vetores","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    std::vector&lt;int&gt; vec1 = {1, 2, 3, 4, 5};\n\n    // Cria uma c\u00f3pia de vec1\n    std::vector&lt;int&gt; vec2 = vec1;\n\n    // Modifica a c\u00f3pia\n    vec2[0] = 10;\n\n    // Imprime os elementos dos dois vetores\n    std::cout &lt;&lt; \"vec1: \";\n    for (int val : vec1) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    std::cout &lt;&lt; \"vec2: \";\n    for (int val : vec2) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#contextos-uteis-para-hpc","title":"Contextos \u00dateis para HPC","text":"<p>Manipula\u00e7\u00f5es b\u00e1sicas de vetores s\u00e3o frequentemente utilizadas em HPC para inicializar e processar grandes conjuntos de dados. Aqui est\u00e3o alguns contextos \u00fateis:</p> <ol> <li>Inicializa\u00e7\u00e3o de Dados:<ul> <li>Vetores podem ser usados para armazenar dados de entrada para simula\u00e7\u00f5es ou c\u00e1lculos.</li> </ul> </li> <li>Opera\u00e7\u00f5es em S\u00e9rie:<ul> <li>Aplicar opera\u00e7\u00f5es matem\u00e1ticas b\u00e1sicas em todos os elementos de um vetor \u00e9 uma tarefa comum em HPC.</li> </ul> </li> <li>Armazenamento de Resultados Intermedi\u00e1rios:<ul> <li>Vetores s\u00e3o \u00fateis para armazenar resultados intermedi\u00e1rios em algoritmos iterativos.</li> </ul> </li> </ol>"},{"location":"teoria/aula01/manipulacao-vetores/#exemplo-uso-de-vector-com-classe-e-inline","title":"Exemplo: Uso de <code>Vector</code> com Classe e Inline","text":"<p>A utiliza\u00e7\u00e3o de classes para encapsular a l\u00f3gica de manipula\u00e7\u00e3o de vetores, junto com o uso de aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria e fun\u00e7\u00f5es <code>inline</code>, permite a cria\u00e7\u00e3o de estruturas de dados flex\u00edveis e de alto desempenho. Neste exemplo, implementaremos uma classe <code>Vector</code> que demonstrar\u00e1 esses conceitos.</p>"},{"location":"teoria/aula01/manipulacao-vetores/#conceitos-fundamentais","title":"Conceitos Fundamentais","text":"<p>Aloca\u00e7\u00e3o Din\u00e2mica de Mem\u00f3ria: A aloca\u00e7\u00e3o din\u00e2mica permite que a mem\u00f3ria para o vetor seja alocada em tempo de execu\u00e7\u00e3o, proporcionando flexibilidade na gest\u00e3o do tamanho do vetor. Utilizamos <code>new</code> para alocar mem\u00f3ria e <code>delete[]</code> para liber\u00e1-la, garantindo que o uso de mem\u00f3ria seja eficiente e controlado.</p> <p>Ponteiros: Os ponteiros s\u00e3o utilizados para manipular diretamente a mem\u00f3ria alocada dinamicamente. No nosso exemplo, <code>int* dados</code> \u00e9 um ponteiro para o array que armazenar\u00e1 os elementos do vetor.</p> <p>Fun\u00e7\u00f5es Inline: Fun\u00e7\u00f5es <code>inline</code> s\u00e3o usadas para otimizar o desempenho, especialmente em m\u00e9todos curtos e frequentemente chamados. A declara\u00e7\u00e3o <code>inline</code> sugere ao compilador que expanda o c\u00f3digo da fun\u00e7\u00e3o no local da chamada, reduzindo a sobrecarga de chamadas de fun\u00e7\u00e3o.</p> <p>Redimensionamento Din\u00e2mico: Redimensionar dinamicamente o vetor permite que ele cres\u00e7a conforme necess\u00e1rio. Implementamos um m\u00e9todo que duplica a capacidade do vetor quando necess\u00e1rio, copiando os dados existentes para um novo espa\u00e7o de mem\u00f3ria alocado.</p>"},{"location":"teoria/aula01/manipulacao-vetores/#implementacao-da-classe-vector","title":"Implementa\u00e7\u00e3o da Classe <code>Vector</code>","text":"<p>A seguir, apresentamos a implementa\u00e7\u00e3o detalhada da classe <code>Vector</code>, que inclui m\u00e9todos para inicializa\u00e7\u00e3o, acesso, modifica\u00e7\u00e3o, inser\u00e7\u00e3o e remo\u00e7\u00e3o de elementos, al\u00e9m de um m\u00e9todo para redimensionamento din\u00e2mico.</p> <pre><code>#include &lt;iostream&gt;\n\nclass Vector {\npublic:\n    Vector(int tamanho);                  // Construtor que inicializa o vetor\n    ~Vector();                            // Destrutor que libera a mem\u00f3ria alocada\n    void inicializa(int valor);           // M\u00e9todo para inicializar o vetor\n    inline int get(int index) const;      // M\u00e9todo inline para acessar um elemento\n    inline void set(int index, int valor); // M\u00e9todo inline para modificar um elemento\n    void inserir(int index, int valor);   // M\u00e9todo para inserir um elemento\n    void remover(int index);              // M\u00e9todo para remover um elemento\n    void imprime() const;                 // M\u00e9todo para imprimir o vetor\n    inline int tamanho() const;           // M\u00e9todo inline para obter o tamanho do vetor\n\nprivate:\n</code></pre>"},{"location":"teoria/aula01/manipulacao-vetores/#definicao-da-classe-vector","title":"Defini\u00e7\u00e3o da Classe <code>Vector</code>","text":"<p>Vamos adicionar fun\u00e7\u00f5es inline e algumas otimiza\u00e7\u00f5es para melhorar o desempenho onde for poss\u00edvel.</p> <ol> <li>Atributos:<ul> <li><code>int* dados</code>: Ponteiro para o array din\u00e2mico que armazena os elementos do vetor.</li> <li><code>int tam</code>: Tamanho atual do vetor.</li> <li><code>int capacidade</code>: Capacidade m\u00e1xima do vetor antes de precisar redimensionar.</li> </ul> </li> </ol> <pre><code>#include &lt;iostream&gt;\n\nclass Vector {\npublic:\n    Vector(int tamanho);                  // Construtor que inicializa o vetor\n    ~Vector();                            // Destrutor que libera a mem\u00f3ria alocada\n    void inicializa(int valor);           // M\u00e9todo para inicializar o vetor\n    inline int get(int index) const;      // M\u00e9todo inline para acessar um elemento\n    inline void set(int index, int valor); // M\u00e9todo inline para modificar um elemento\n    void inserir(int index, int valor);   // M\u00e9todo para inserir um elemento\n    void remover(int index);              // M\u00e9todo para remover um elemento\n    void imprime() const;                 // M\u00e9todo para imprimir o vetor\n    inline int tamanho() const;           // M\u00e9todo inline para obter o tamanho do vetor\n\nprivate:\n    int* dados;                           // Ponteiro para os dados do vetor\n    int tam;                              // Tamanho atual do vetor\n    int capacidade;                       // Capacidade m\u00e1xima do vetor\n    void redimensiona(int novaCapacidade); // M\u00e9todo para redimensionar o vetor\n};\n</code></pre> <ol> <li> <p>Construtor e Destrutor:</p> <ul> <li> <p><code>Vector(int tamanho)</code>: Inicializa o vetor com o tamanho especificado e aloca mem\u00f3ria dinamicamente.</p> <pre><code>Vector::Vector(int tamanho)\n    : tam(tamanho), capacidade(tamanho), dados(new int[tamanho]) {}\n</code></pre> </li> <li> <p><code>~Vector()</code>: Libera a mem\u00f3ria alocada para evitar vazamentos de mem\u00f3ria.</p> <pre><code>Vector::~Vector() {\n    delete[] dados; // Libera a mem\u00f3ria alocada\n}\n</code></pre> </li> </ul> </li> <li> <p>M\u00e9todos B\u00e1sicos:</p> <ul> <li> <p><code>inicializa(int valor)</code>: Inicializa todos os elementos do vetor com o valor especificado.</p> <pre><code>void Vector::inicializa(int valor) {\n    for (int i = 0; i &lt; tam; ++i) {\n        dados[i] = valor; // Inicializa cada elemento do vetor com o valor especificado\n    }\n}\n</code></pre> </li> <li> <p><code>get(int index) const</code>: M\u00e9todo inline para acessar um elemento na posi\u00e7\u00e3o especificada.</p> <pre><code>inline int Vector::get(int index) const {\n    if (index &gt;= 0 &amp;&amp; index &lt; tam) {\n        return dados[index]; // Retorna o elemento na posi\u00e7\u00e3o especificada\n    } else {\n        std::cerr &lt;&lt; \"\u00cdndice fora do intervalo!\" &lt;&lt; std::endl;\n        return -1; // Valor de erro\n    }\n}\n</code></pre> </li> <li> <p><code>set(int index, int valor)</code>: M\u00e9todo inline para modificar um elemento na posi\u00e7\u00e3o especificada.</p> <pre><code>inline void Vector::set(int index, int valor) {\n    if (index &gt;= 0 &amp;&amp; index &lt; tam) {\n        dados[index] = valor; // Modifica o elemento na posi\u00e7\u00e3o especificada\n    } else {\n        std::cerr &lt;&lt; \"\u00cdndice fora do intervalo!\" &lt;&lt; std::endl;\n    }\n}\n</code></pre> </li> <li> <p><code>inserir(int index, int valor)</code>: Insere um elemento na posi\u00e7\u00e3o especificada.</p> <pre><code>void Vector::inserir(int index, int valor) {\n    if (index &gt;= 0 &amp;&amp; index &lt;= tam) {\n        if (tam &gt;= capacidade) {\n            redimensiona(2 * capacidade); // Redimensiona o vetor se necess\u00e1rio\n        }\n        for (int i = tam; i &gt; index; --i) {\n            dados[i] = dados[i - 1]; // Move os elementos para a direita\n        }\n        dados[index] = valor; // Insere o novo elemento\n        tam++; // Incrementa o tamanho do vetor\n    } else {\n        std::cerr &lt;&lt; \"\u00cdndice fora do intervalo!\" &lt;&lt; std::endl;\n    }\n}\n</code></pre> </li> </ul> </li> <li> <p><code>remover(int index)</code>: Remove um elemento na posi\u00e7\u00e3o especificada.</p> <pre><code>void Vector::remover(int index) {\n    if (index &gt;= 0 &amp;&amp; index &lt; tam) {\n        for (int i = index; i &lt; tam - 1; ++i) {\n            dados[i] = dados[i + 1]; // Move os elementos para a esquerda\n        }\n        tam--; // Decrementa o tamanho do vetor\n    } else {\n        std::cerr &lt;&lt; \"\u00cdndice fora do intervalo!\" &lt;&lt; std::endl;\n    }\n}\n</code></pre> </li> <li> <p><code>imprime() const</code>: Imprime todos os elementos do vetor.</p> <pre><code>void Vector::imprime() const {\n    for (int i = 0; i &lt; tam; ++i) {\n        std::cout &lt;&lt; dados[i] &lt;&lt; \" \"; // Imprime cada elemento do vetor\n    }\n    std::cout &lt;&lt; std::endl;\n}\n</code></pre> </li> <li> <p><code>tamanho() const</code>: M\u00e9todo inline para obter o tamanho atual do vetor.</p> <pre><code>inline int Vector::tamanho() const {\n    return tam; // Retorna o tamanho atual do vetor\n}\n</code></pre> </li> <li> <p><code>redimensiona(int novaCapacidade)</code>: Redimensiona o vetor para a nova capacidade especificada, alocando nova mem\u00f3ria e copiando os dados existentes.</p> <pre><code>void Vector::redimensiona(int novaCapacidade) {\n    int* novoDados = new int[novaCapacidade]; // Aloca nova mem\u00f3ria\n    for (int i = 0; i &lt; tam; ++i) {\n        novoDados[i] = dados[i]; // Copia os dados antigos\n    }\n    delete[] dados; // Libera a mem\u00f3ria antiga\n    dados = novoDados; // Atualiza o ponteiro para os novos dados\n    capacidade = novaCapacidade; // Atualiza a capacidade do vetor\n}\n</code></pre> </li> </ol>"},{"location":"teoria/aula01/manipulacao-vetores/#uso-da-classe-vector","title":"Uso da Classe <code>Vector</code>","text":"<ol> <li> <p>Inicializa\u00e7\u00e3o e Impress\u00e3o:</p> <ul> <li>Criamos um vetor de tamanho 5 e inicializamos todos os elementos com 0.</li> <li> <p>Imprimimos o vetor inicializado.</p> <pre><code>int main() {\n    Vector vec(5); // Cria um vetor de tamanho 5\n    vec.inicializa(0); // Inicializa todos os elementos com 0\n\n    std::cout &lt;&lt; \"Vetor inicializado: \";\n    vec.imprime(); // Imprime o vetor inicializado\n</code></pre> </li> </ul> </li> <li> <p>Modifica\u00e7\u00e3o:</p> <ul> <li> <p>Modificamos o terceiro elemento para 10 e imprimimos o vetor.</p> <pre><code>    vec.set(2, 10); // Modifica o terceiro elemento para 10\n    std::cout &lt;&lt; \"Ap\u00f3s modificar o terceiro elemento para 10: \";\n    vec.imprime(); // Imprime o vetor ap\u00f3s a modifica\u00e7\u00e3o\n</code></pre> </li> </ul> </li> <li> <p>Inser\u00e7\u00e3o:</p> <ul> <li> <p>Inserimos o valor 20 na terceira posi\u00e7\u00e3o e imprimimos o vetor.</p> <pre><code>    vec.inserir(2, 20); // Insere o valor 20 na terceira posi\u00e7\u00e3o\n    std::cout &lt;&lt; \"Ap\u00f3s inserir 20 na terceira posi\u00e7\u00e3o: \";\n    vec.imprime(); // Imprime o vetor ap\u00f3s a inser\u00e7\u00e3o\n</code></pre> </li> </ul> </li> <li> <p>Remo\u00e7\u00e3o:</p> <ul> <li> <p>Removemos o segundo elemento e imprimimos o vetor.</p> <pre><code>    vec.remover(1); // Remove o segundo elemento\n    std::cout &lt;&lt; \"Ap\u00f3s remover o segundo elemento: \";\n    vec.imprime(); // Imprime o vetor ap\u00f3s a remo\u00e7\u00e3o\n</code></pre> </li> </ul> </li> <li> <p>Tamanho:</p> <ul> <li> <p>Imprimimos o tamanho atual do vetor.</p> <pre><code>    std::cout &lt;&lt; \"Tamanho do vetor: \" &lt;&lt; vec.tamanho() &lt;&lt; std::endl; // Imprime o tamanho do vetor\n\n    return 0;\n}\n</code></pre> </li> </ul> </li> </ol> <p>Neste exemplo, usamos aloca\u00e7\u00e3o din\u00e2mica de mem\u00f3ria e ponteiros para criar e manipular vetores em C++ usando classes e objetos. Tamb\u00e9m adicionamos fun\u00e7\u00f5es inline para melhorar o desempenho em opera\u00e7\u00f5es comuns como acesso e modifica\u00e7\u00e3o de elementos.</p>"},{"location":"teoria/aula01/memoria-dinamica/","title":"Aloca\u00e7\u00e3o de Mem\u00f3ria Din\u00e2mica","text":"<p>A aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica \u00e9 uma pr\u00e1tica que permite aos programadores alocar e desalocar mem\u00f3ria durante a execu\u00e7\u00e3o do programa. Quando lidamos com grandes volumes de dados e opera\u00e7\u00f5es computacionalmente intensivas, a gest\u00e3o eficiente da mem\u00f3ria \u00e9 crucial para o desempenho e a escalabilidade das aplica\u00e7\u00f5es.</p> <p>Em C++, a mem\u00f3ria din\u00e2mica \u00e9 gerenciada usando os operadores <code>new</code> e <code>delete</code> para alocar e desalocar mem\u00f3ria, respectivamente.</p>"},{"location":"teoria/aula01/memoria-dinamica/#exemplo-1-alocacao-e-manipulacao-de-matrizes-dinamicas","title":"Exemplo 1: Aloca\u00e7\u00e3o e Manipula\u00e7\u00e3o de Matrizes Din\u00e2micas","text":"<p>Vamos considerar um exemplo de aloca\u00e7\u00e3o din\u00e2mica de uma matriz e sua utiliza\u00e7\u00e3o em opera\u00e7\u00f5es de HPC.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\nusing namespace std::chrono;\n\nint main() {\n    int N = 1000; // Tamanho da matriz\n\n    // Aloca mem\u00f3ria para uma matriz din\u00e2mica\n    int** matriz = new int*[N];\n    for (int i = 0; i &lt; N; ++i) {\n        matriz[i] = new int[N];\n    }\n\n    // Inicializa a matriz com valores\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            matriz[i][j] = i + j;\n        }\n    }\n\n    // Realiza uma opera\u00e7\u00e3o de soma simples na matriz\n    auto inicio = high_resolution_clock::now();\n    long long soma = 0;\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            soma += matriz[i][j];\n        }\n    }\n    auto fim = high_resolution_clock::now();\n    auto duracao = duration_cast&lt;milliseconds&gt;(fim - inicio).count();\n\n    cout &lt;&lt; \"Soma de todos os elementos: \" &lt;&lt; soma &lt;&lt; endl;\n    cout &lt;&lt; \"Tempo de execu\u00e7\u00e3o: \" &lt;&lt; duracao &lt;&lt; \"ms\" &lt;&lt; endl;\n\n    // Libera a mem\u00f3ria alocada para a matriz\n    for (int i = 0; i &lt; N; ++i) {\n        delete[] matriz[i];\n    }\n    delete[] matriz;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/memoria-dinamica/#alocacao-da-matriz","title":"Aloca\u00e7\u00e3o da Matriz:","text":"<ul> <li><code>int** matriz = new int*[N];</code> aloca mem\u00f3ria para um array de ponteiros.</li> <li>O loop <code>for</code> interno aloca mem\u00f3ria para cada linha da matriz.</li> <li>Inicializa\u00e7\u00e3o e Opera\u00e7\u00f5es:<ul> <li>A matriz \u00e9 inicializada com a soma dos \u00edndices.</li> <li>Realiza uma opera\u00e7\u00e3o de soma em todos os elementos da matriz, medindo o tempo de execu\u00e7\u00e3o.</li> </ul> </li> <li>Desaloca\u00e7\u00e3o da Mem\u00f3ria:<ul> <li>A mem\u00f3ria alocada para cada linha \u00e9 liberada usando <code>delete[]</code>.</li> <li>A mem\u00f3ria alocada para o array de ponteiros \u00e9 liberada usando <code>delete[]</code>.</li> </ul> </li> </ul>"},{"location":"teoria/aula01/memoria-dinamica/#alocacao-de-memoria-com-stdvector","title":"Aloca\u00e7\u00e3o de Mem\u00f3ria com <code>std::vector</code>","text":"<p>Usar <code>std::vector</code> \u00e9 uma alternativa eficiente e segura para a aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica manual em C++. <code>std::vector</code> gerencia automaticamente a mem\u00f3ria, reduzindo o risco de vazamentos de mem\u00f3ria e outros erros.</p>"},{"location":"teoria/aula01/memoria-dinamica/#exemplo-com-stdvector","title":"Exemplo com <code>std::vector</code>","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\nusing namespace std::chrono;\n\nint main() {\n    int N = 1000; // Tamanho da matriz\n\n    // Aloca mem\u00f3ria para uma matriz din\u00e2mica usando std::vector\n    vector&lt;vector&lt;int&gt;&gt; matriz(N, vector&lt;int&gt;(N));\n\n    // Inicializa a matriz com valores\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            matriz[i][j] = i + j;\n        }\n    }\n\n    // Realiza uma opera\u00e7\u00e3o de soma simples na matriz\n    auto inicio = high_resolution_clock::now();\n    long long soma = 0;\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            soma += matriz[i][j];\n        }\n    }\n    auto fim = high_resolution_clock::now();\n    auto duracao = duration_cast&lt;milliseconds&gt;(fim - inicio).count();\n\n    cout &lt;&lt; \"Soma de todos os elementos: \" &lt;&lt; soma &lt;&lt; endl;\n    cout &lt;&lt; \"Tempo de execu\u00e7\u00e3o: \" &lt;&lt; duracao &lt;&lt; \"ms\" &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/memoria-dinamica/#consideracoes-de-desempenho-em-hpc","title":"Considera\u00e7\u00f5es de Desempenho em HPC","text":"<ol> <li>Localidade de Dados:<ul> <li>A localidade de refer\u00eancia \u00e9 importante para o desempenho da cache. Matrizes alocadas dinamicamente podem ter menor localidade de refer\u00eancia do que matrizes est\u00e1ticas ou <code>std::vector</code>, especialmente se cada linha for alocada separadamente.</li> </ul> </li> <li>Fragmenta\u00e7\u00e3o de Mem\u00f3ria:<ul> <li>A aloca\u00e7\u00e3o din\u00e2mica pode levar \u00e0 fragmenta\u00e7\u00e3o de mem\u00f3ria, especialmente se a mem\u00f3ria for alocada e desalocada frequentemente. Isso pode ser mitigado usando pools de mem\u00f3ria ou alocadores personalizados.</li> </ul> </li> <li>Parallelismo:<ul> <li>Aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica pode introduzir sobrecarga em ambientes paralelos devido \u00e0 necessidade de sincroniza\u00e7\u00e3o. Em HPC, \u00e9 comum usar t\u00e9cnicas avan\u00e7adas para gerenciar a aloca\u00e7\u00e3o de mem\u00f3ria de forma eficiente em ambientes paralelos.</li> </ul> </li> </ol> <p>A aloca\u00e7\u00e3o de mem\u00f3ria din\u00e2mica \u00e9 uma pr\u00e1tica fundamental em C++ que permite gerenciar a mem\u00f3ria de forma flex\u00edvel durante a execu\u00e7\u00e3o do programa. No contexto de HPC, a gest\u00e3o eficiente da mem\u00f3ria \u00e9 crucial para o desempenho e a escalabilidade das aplica\u00e7\u00f5es. Usar t\u00e9cnicas como aloca\u00e7\u00e3o manual com <code>new</code> e <code>delete</code> ou aloca\u00e7\u00e3o autom\u00e1tica com <code>std::vector</code> pode ajudar a escrever c\u00f3digo eficiente e seguro.</p>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/","title":"Sobrecarga de Fun\u00e7\u00f5es em C++","text":"<p>Sobrecarga de fun\u00e7\u00f5es \u00e9 um recurso da linguagem C++ que permite definir m\u00faltiplas fun\u00e7\u00f5es com o mesmo nome, mas com diferentes listas de par\u00e2metros. Isso significa que voc\u00ea pode ter v\u00e1rias fun\u00e7\u00f5es que realizam tarefas semelhantes, mas aceitam diferentes tipos ou n\u00fameros de argumentos.</p> <p>No contexto de HPC, a sobrecarga de fun\u00e7\u00f5es pode ser usada para otimizar opera\u00e7\u00f5es em diferentes tipos de dados (por exemplo, opera\u00e7\u00f5es em inteiros, floats e doubles) sem duplicar o c\u00f3digo. Isso pode ajudar a escrever c\u00f3digo mais limpo e eficiente.</p>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/#regras-para-sobrecarga-de-funcoes","title":"Regras para Sobrecarga de Fun\u00e7\u00f5es","text":"<p>Para que duas ou mais fun\u00e7\u00f5es sejam sobrecarregadas corretamente, elas devem ser diferentes em pelo menos um dos seguintes aspectos:</p> <ol> <li>N\u00famero de par\u00e2metros: As fun\u00e7\u00f5es devem ter um n\u00famero diferente de par\u00e2metros.</li> <li>Tipo de par\u00e2metros: As fun\u00e7\u00f5es devem ter tipos diferentes de par\u00e2metros.</li> </ol> <p>A sobrecarga de fun\u00e7\u00f5es n\u00e3o pode ser feita apenas com base no tipo de retorno das fun\u00e7\u00f5es.</p>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/#exemplo-basico-de-sobrecarga-de-funcoes","title":"Exemplo B\u00e1sico de Sobrecarga de Fun\u00e7\u00f5es","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;string&gt;\n\n// Fun\u00e7\u00e3o que imprime um inteiro\nvoid imprimir(int valor) {\n    std::cout &lt;&lt; \"Inteiro: \" &lt;&lt; valor &lt;&lt; std::endl;\n}\n\n// Fun\u00e7\u00e3o que imprime um float\nvoid imprimir(float valor) {\n    std::cout &lt;&lt; \"Float: \" &lt;&lt; valor &lt;&lt; std::endl;\n}\n\n// Fun\u00e7\u00e3o que imprime uma string\nvoid imprimir(std::string valor) {\n    std::cout &lt;&lt; \"String: \" &lt;&lt; valor &lt;&lt; std::endl;\n}\n\nint main() {\n    imprimir(10);          // Chama a fun\u00e7\u00e3o que imprime um inteiro\n    imprimir(3.14f);       // Chama a fun\u00e7\u00e3o que imprime um float\n    imprimir(\"Hello\");     // Chama a fun\u00e7\u00e3o que imprime uma string\n\n    return 0;\n}\n</code></pre> <p>Neste exemplo, a fun\u00e7\u00e3o <code>imprimir</code> \u00e9 sobrecarregada para aceitar diferentes tipos de argumentos: <code>int</code>, <code>float</code> e <code>std::string</code></p> <p>Vamos considerar um exemplo de sobrecarga de fun\u00e7\u00f5es para calcular o produto escalar de vetores de diferentes tipos.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\n// Fun\u00e7\u00e3o para calcular o produto escalar de vetores de inteiros\nint produtoEscalar(const std::vector&lt;int&gt;&amp; v1, const std::vector&lt;int&gt;&amp; v2) {\n    int produto = 0;\n    for (size_t i = 0; i &lt; v1.size(); ++i) {\n        produto += v1[i] * v2[i];\n    }\n    return produto;\n}\n\n// Fun\u00e7\u00e3o para calcular o produto escalar de vetores de floats\nfloat produtoEscalar(const std::vector&lt;float&gt;&amp; v1, const std::vector&lt;float&gt;&amp; v2) {\n    float produto = 0.0f;\n    for (size_t i = 0; i &lt; v1.size(); ++i) {\n        produto += v1[i] * v2[i];\n    }\n    return produto;\n}\n\n// Fun\u00e7\u00e3o para calcular o produto escalar de vetores de doubles\ndouble produtoEscalar(const std::vector&lt;double&gt;&amp; v1, const std::vector&lt;double&gt;&amp; v2) {\n    double produto = 0.0;\n    for (size_t i = 0; i &lt; v1.size(); ++i) {\n        produto += v1[i] * v2[i];\n    }\n    return produto;\n}\n\nint main() {\n    std::vector&lt;int&gt; v1_int = {1, 2, 3};\n    std::vector&lt;int&gt; v2_int = {4, 5, 6};\n\n    std::vector&lt;float&gt; v1_float = {1.0f, 2.0f, 3.0f};\n    std::vector&lt;float&gt; v2_float = {4.0f, 5.0f, 6.0f};\n\n    std::vector&lt;double&gt; v1_double = {1.0, 2.0, 3.0};\n    std::vector&lt;double&gt; v2_double = {4.0, 5.0, 6.0};\n\n    std::cout &lt;&lt; \"Produto Escalar (int): \" &lt;&lt; produtoEscalar(v1_int, v2_int) &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Produto Escalar (float): \" &lt;&lt; produtoEscalar(v1_float, v2_float) &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Produto Escalar (double): \" &lt;&lt; produtoEscalar(v1_double, v2_double) &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/#sobrecarga-de-funcoes-e-templates","title":"Sobrecarga de Fun\u00e7\u00f5es e Templates","text":"<p>Outra abordagem para lidar com opera\u00e7\u00f5es semelhantes em diferentes tipos de dados \u00e9 o uso de templates de fun\u00e7\u00f5es. Templates podem ser usados para evitar a necessidade de sobrecarregar fun\u00e7\u00f5es manualmente para cada tipo de dado.</p>"},{"location":"teoria/aula01/sobrecarga-de-funcoes-C%2B%2B/#exemplo-de-template-de-funcao","title":"Exemplo de Template de Fun\u00e7\u00e3o","text":"<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\n// Template de fun\u00e7\u00e3o para calcular o produto escalar de vetores\ntemplate &lt;typename T&gt;\nT produtoEscalar(const std::vector&lt;T&gt;&amp; v1, const std::vector&lt;T&gt;&amp; v2) {\n    T produto = 0;\n    for (size_t i = 0; i &lt; v1.size(); ++i) {\n        produto += v1[i] * v2[i];\n    }\n    return produto;\n}\n\nint main() {\n    std::vector&lt;int&gt; v1_int = {1, 2, 3};\n    std::vector&lt;int&gt; v2_int = {4, 5, 6};\n\n    std::vector&lt;float&gt; v1_float = {1.0f, 2.0f, 3.0f};\n    std::vector&lt;float&gt; v2_float = {4.0f, 5.0f, 6.0f};\n\n    std::vector&lt;double&gt; v1_double = {1.0, 2.0, 3.0};\n    std::vector&lt;double&gt; v2_double = {4.0, 5.0, 6.0};\n\n    std::cout &lt;&lt; \"Produto Escalar (int): \" &lt;&lt; produtoEscalar(v1_int, v2_int) &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Produto Escalar (float): \" &lt;&lt; produtoEscalar(v1_float, v2_float) &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Produto Escalar (double): \" &lt;&lt; produtoEscalar(v1_double, v2_double) &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre> <p>A sobrecarga de fun\u00e7\u00f5es em C++ permite a defini\u00e7\u00e3o de m\u00faltiplas fun\u00e7\u00f5es com o mesmo nome, mas com diferentes listas de par\u00e2metros. Isso melhora a legibilidade, manuten\u00e7\u00e3o e facilidade de uso do c\u00f3digo. No contexto de HPC, a sobrecarga de fun\u00e7\u00f5es pode ser usada para otimizar opera\u00e7\u00f5es em diferentes tipos de dados, evitando duplica\u00e7\u00e3o de c\u00f3digo e melhorando a efici\u00eancia. Alternativamente, templates de fun\u00e7\u00f5es podem ser usados para alcan\u00e7ar resultados similares com menos c\u00f3digo.</p>"},{"location":"teoria/aula01/uso-de-constantes/","title":"Const Correctness em HPC","text":"<p>Const Correctness (uso de constantes) \u00e9 um conceito em C++ que garante que os dados n\u00e3o sejam modificados quando n\u00e3o deveriam ser. Usar <code>const</code> corretamente pode melhorar a legibilidade do c\u00f3digo, evitar erros e permitir otimiza\u00e7\u00f5es pelo compilador. </p>"},{"location":"teoria/aula01/uso-de-constantes/#usos-comuns-de-const","title":"Usos Comuns de <code>const</code>","text":""},{"location":"teoria/aula01/uso-de-constantes/#1-variaveis-locais","title":"1. Vari\u00e1veis Locais","text":"<p>Declarar vari\u00e1veis locais como <code>const</code> se voc\u00ea n\u00e3o pretende modificar o valor delas.</p> <pre><code>const int valor = 10;\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#2-parametros-de-funcao","title":"2. Par\u00e2metros de Fun\u00e7\u00e3o","text":"<p>Usar <code>const</code> em par\u00e2metros de fun\u00e7\u00e3o para garantir que os argumentos n\u00e3o sejam modificados.</p> <pre><code>void imprimeValor(const int valor) {\n    std::cout &lt;&lt; \"Valor: \" &lt;&lt; valor &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#3-ponteiros-e-referencias","title":"3. Ponteiros e Refer\u00eancias","text":"<p>Declarar ponteiros e refer\u00eancias como <code>const</code> para garantir que os dados apontados ou referenciados n\u00e3o sejam alterados.</p> <pre><code>void imprimeValor(const int* ptr) {\n    std::cout &lt;&lt; \"Valor: \" &lt;&lt; *ptr &lt;&lt; std::endl;\n}\n\nvoid imprimeValor(const int&amp; ref) {\n    std::cout &lt;&lt; \"Valor: \" &lt;&lt; ref &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#4-metodos-de-classe","title":"4. M\u00e9todos de Classe","text":"<p>Declarar m\u00e9todos como <code>const</code> para garantir que eles n\u00e3o modifiquem o estado do objeto.</p> <pre><code>class Ponto {\npublic:\n    Ponto(int x, int y) : x(x), y(y) {}\n\n    int getX() const { return x; }\n    int getY() const { return y; }\n\nprivate:\n    int x, y;\n};\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#exemplo-multiplicacao-de-matrizes-com-const-correctness","title":"Exemplo: Multiplica\u00e7\u00e3o de Matrizes com Const Correctness","text":"<p>Vamos considerar um exemplo de multiplica\u00e7\u00e3o de matrizes onde aplicamos const correctness para garantir que os dados de entrada n\u00e3o sejam modificados.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n\nusing namespace std;\nusing namespace std::chrono;\n\n// Fun\u00e7\u00e3o para multiplicar duas matrizes com const correctness\nvoid multiplicaMatriz(const vector&lt;vector&lt;int&gt;&gt;&amp; A, const vector&lt;vector&lt;int&gt;&gt;&amp; B, vector&lt;vector&lt;int&gt;&gt;&amp; C) {\n    int N = A.size();\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            C[i][j] = 0;\n            for (int k = 0; k &lt; N; ++k) {\n                C[i][j] += A[i][k] * B[k][j];\n            }\n        }\n    }\n}\n\nint main() {\n    int N = 100; // Tamanho da matriz\n    vector&lt;vector&lt;int&gt;&gt; A(N, vector&lt;int&gt;(N, 1));\n    vector&lt;vector&lt;int&gt;&gt; B(N, vector&lt;int&gt;(N, 1));\n    vector&lt;vector&lt;int&gt;&gt; C(N, vector&lt;int&gt;(N, 0));\n\n    auto inicio = high_resolution_clock::now();\n\n    // Chama a fun\u00e7\u00e3o de multiplica\u00e7\u00e3o de matrizes\n    multiplicaMatriz(A, B, C);\n\n    auto fim = high_resolution_clock::now();\n    auto duracao = duration_cast&lt;milliseconds&gt;(fim - inicio).count();\n\n    cout &lt;&lt; \"Tempo de multiplica\u00e7\u00e3o de matrizes: \" &lt;&lt; duracao &lt;&lt; \"ms\" &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre>"},{"location":"teoria/aula01/uso-de-constantes/#const-correctness-em-classes","title":"Const Correctness em Classes","text":"<p>No contexto de HPC, classes frequentemente encapsulam dados e opera\u00e7\u00f5es. Garantir const correctness em m\u00e9todos de classe \u00e9 essencial.</p>"},{"location":"teoria/aula01/uso-de-constantes/#exemplo-classe-de-matriz-com-metodos-const","title":"Exemplo: Classe de Matriz com M\u00e9todos Const","text":"<pre><code>class Matriz {\npublic:\n    Matriz(int N) : data(N, vector&lt;int&gt;(N, 0)) {}\n\n    const vector&lt;int&gt;&amp; operator[](int index) const {\n        return data[index];\n    }\n\n    vector&lt;int&gt;&amp; operator[](int index) {\n        return data[index];\n    }\n\n    void imprime() const {\n        for (const auto&amp; linha : data) {\n            for (int valor : linha) {\n                cout &lt;&lt; valor &lt;&lt; \" \";\n            }\n            cout &lt;&lt; endl;\n        }\n    }\n\nprivate:\n    vector&lt;vector&lt;int&gt;&gt; data;\n};\n\nint main() {\n    Matriz matriz(3);\n\n    matriz[0][0] = 1;\n    matriz[1][1] = 2;\n    matriz[2][2] = 3;\n\n    cout &lt;&lt; \"Matriz:\" &lt;&lt; endl;\n    matriz.imprime();\n\n    return 0;\n}\n</code></pre> <p>Aplicar const correctness pode prevenir erros e permitir otimiza\u00e7\u00f5es adicionais pelo compilador. Usar <code>const</code> de maneira apropriada em vari\u00e1veis, par\u00e2metros de fun\u00e7\u00e3o, ponteiros, refer\u00eancias e m\u00e9todos de classe \u00e9 uma pr\u00e1tica recomendada para escrever c\u00f3digo robusto e eficiente.</p>"},{"location":"teoria/aula02/","title":"Contextos e Curiosidades","text":"<p>O que \u00e9 um Supercomputador?</p> <p>El Capitan atualmente, o Supercomputador mais r\u00e1pido do mundo!</p> <p>Santos Dumont o Supercomputador BR que vamos usar no projeto 2!</p> <p>LNCC - Laborat\u00f3rio Nacional de Computa\u00e7\u00e3o Ci\u00eantifica</p> <p>SINAPAD -  Sistema Nacional de Processamento de Alto Desempenho </p>"},{"location":"teoria/aula02/#o-que-e-hpc","title":"O que \u00e9 HPC?","text":"<p>High-Performance Computing (HPC) refere-se ao uso de supercomputadores e clusters de computadores para resolver problemas computacionalmente complexos. HPC \u00e9 essencial em campos como ci\u00eancia, engenharia e finan\u00e7as, onde grandes volumes de dados precisam ser processados rapidamente.</p>"},{"location":"teoria/aula02/#top-500","title":"TOP 500","text":"<p>Supercomputador Fugaku https://spectrum.ieee.org/japans-fugaku-supercomputer-is-first-in-the-world-to-simultaneously-top-all-high-performance-benchmarks</p> <p>O TOP 500 \u00e9 uma lista semestral que classifica os 500 supercomputadores mais poderosos do mundo com base no benchmark LINPACK, que mede a capacidade de resolver sistemas de equa\u00e7\u00f5es lineares. A lista \u00e9 um indicador importante do progresso em tecnologia de supercomputa\u00e7\u00e3o. Varia\u00e7\u00f5es da lista incluem:</p> <ul> <li>Green500: Classifica supercomputadores pela efici\u00eancia energ\u00e9tica.</li> <li>Graph500: Mede o desempenho em tarefas de an\u00e1lise de gr\u00e1ficos.</li> <li>HPCG: Avalia supercomputadores usando um benchmark alternativo ao LINPACK, mais representativo de cargas de trabalho reais em HPC.</li> </ul>"},{"location":"teoria/aula02/#que-tipo-de-problema-e-computacionalmente-complexo","title":"Que tipo de problema \u00e9 computacionalmente complexo?","text":"<p>Problemas computacionalmente complexos exigem grande capacidade de processamento e mem\u00f3ria para serem resolvidos eficientemente. Exemplos incluem:</p> <ul> <li>Simula\u00e7\u00f5es clim\u00e1ticas</li> <li>Modelagem molecular</li> <li>Processamento de grandes conjuntos de dados (Big Data)</li> <li>An\u00e1lise gen\u00f4mica</li> <li>Renderiza\u00e7\u00e3o de gr\u00e1ficos em alta resolu\u00e7\u00e3o</li> <li>Aprendizado de m\u00e1quina e intelig\u00eancia artificial</li> </ul>"},{"location":"teoria/aula02/#o-que-e-um-supercomputador","title":"O que \u00e9 um supercomputador?","text":"<p>Um supercomputador \u00e9 um sistema computacional de alto desempenho projetado para processar grandes volumes de dados e realizar c\u00e1lculos complexos muito rapidamente. Ele consiste em milhares de n\u00f3s de computa\u00e7\u00e3o interconectados, cada um contendo m\u00faltiplos processadores, grande quantidade de mem\u00f3ria e armazenamento r\u00e1pido.</p>"},{"location":"teoria/aula02/#o-que-e-um-cluster","title":"O que \u00e9 um Cluster?","text":"<p>Um cluster \u00e9 um conjunto de computadores (n\u00f3s) conectados que trabalham juntos como se fossem um \u00fanico sistema. Cada n\u00f3 em um cluster \u00e9 um computador independente, mas o sistema inteiro \u00e9 gerenciado para atuar em conjunto, distribuindo tarefas e compartilhando recursos.</p>"},{"location":"teoria/aula02/#qual-a-diferenca-de-um-supercomputador-para-um-cluster","title":"Qual a diferen\u00e7a de um supercomputador para um cluster?","text":"<p>A principal diferen\u00e7a entre um supercomputador e um cluster est\u00e1 na integra\u00e7\u00e3o e desempenho:</p> <ul> <li>Supercomputador: Um sistema integrado de alto desempenho projetado especificamente para computa\u00e7\u00e3o intensa. Possui uma arquitetura otimizada e interconex\u00f5es de alta velocidade.</li> <li>Cluster: S\u00e3o computadores independentes conectados para trabalhar juntos. Pode ser composto por hardware de mercado e geralmente \u00e9 mais flex\u00edvel e expans\u00edvel.</li> </ul> <p>OBS: Muitos supercomputadores modernos s\u00e3o de fato clusters, utilizando milhares de n\u00f3s interconectados para alcan\u00e7ar um desempenho extremamente alto.</p>"},{"location":"teoria/aula02/#cluster-franky","title":"Cluster Franky","text":"<p>Cluster Franky - Laborat\u00f3rio de Redes e Supercomputa\u00e7\u00e3o do Insper </p> <p>Nosso objetivo \u00e9 preparar voc\u00ea com as habilidades necess\u00e1rias para utilizar sistemas de HPC em situa\u00e7\u00f5es reais. Inspirado no supercomputador Santos Dumont, o Cluster Franky oferece um ambiente robusto e seguro para realizar simula\u00e7\u00f5es complexas e an\u00e1lises de grandes volumes de dados.</p>"},{"location":"teoria/aula02/#como-o-sistema-funciona","title":"Como o Sistema Funciona","text":"<p>Para que voc\u00ea compreenda melhor como o Cluster Franky opera, veja a figura abaixo que detalha a arquitetura do sistema:</p> <p></p>"},{"location":"teoria/aula02/#1-conexao-e-autenticacao","title":"1. Conex\u00e3o e Autentica\u00e7\u00e3o","text":"<p>O processo de intera\u00e7\u00e3o com o Cluster Franky come\u00e7a quando voc\u00ea se conecta ao Cluster via SSH atrav\u00e9s da rede do Insper, em seguida, voc\u00ea ser\u00e1 direcionado ao Login Node, que serve como o ponto de entrada para o cluster. Para acessar o sistema, \u00e9 necess\u00e1rio passar por um processo de autentica\u00e7\u00e3o usando pares de chaves p\u00fablicas e privadas, configurados previamente por nossa equipe t\u00e9cnica.</p>"},{"location":"teoria/aula02/#2-envio-e-gerenciamento-de-tarefas-jobs","title":"2. Envio e Gerenciamento de Tarefas (Jobs)","text":"<p>Uma vez autenticado, voc\u00ea interage com o cluster atrav\u00e9s do Slurm. O Slurm \u00e9 respons\u00e1vel por gerenciar a execu\u00e7\u00e3o das tarefas que voc\u00ea submete, distribuindo-as eficientemente pelos recursos de computa\u00e7\u00e3o dispon\u00edveis, que s\u00e3o divididos em:</p> <ul> <li>N\u00f3 de Computa\u00e7\u00e3o CPU: Composto por cinco n\u00f3s, cada um com 24 threads e 64 GB de RAM.</li> <li>N\u00f3 de Computa\u00e7\u00e3o GPU: Composto por quatro n\u00f3s, cada um equipado com uma GPU NVIDIA A1000 com 8GB de VRAM, uma CPU com 64 GB de RAM e 32 threads.</li> <li>N\u00f3 de Computa\u00e7\u00e3o Monstr\u00e3o: Composto por um n\u00f3 equipado com 4 GPU NVIDIA V100 com 32GB de VRAM, uma CPU com 1TB de RAM e 20 threads</li> </ul> <p>Os daemons de controle cada n\u00f3 de computa\u00e7\u00e3o gerencia a execu\u00e7\u00e3o das tarefas, garantindo que os recursos sejam alocados de forma otimizada. Isso significa que, independentemente de voc\u00ea estar executando simula\u00e7\u00f5es simples ou tarefas intensivas de processamento de dados, o sistema est\u00e1 configurado para maximizar a efici\u00eancia e minimizar o tempo de execu\u00e7\u00e3o.</p>"},{"location":"teoria/aula02/#3-armazenamento-e-gestao-de-dados","title":"3. Armazenamento e Gest\u00e3o de Dados","text":"<p>Durante suas atividades, voc\u00ea deve utilizar a pasta SCRATCH para armazenar temporariamente os arquivos e dados necess\u00e1rios para suas tarefas. \u00c9 importante lembrar que essa pasta \u00e9 destinada ao armazenamento tempor\u00e1rio, portanto, certifique-se de salvar seus dados em um local seguro ap\u00f3s concluir suas atividades.</p> <p>O sistema de arquivos atual do Cluster Franky utiliza o NFS (Network File System), que facilita o acesso aos dados entre os n\u00f3s de computa\u00e7\u00e3o. No futuro, planejamos migrar para o sistema de arquivos Lustre, que oferecer\u00e1 maior efici\u00eancia e melhor desempenho no manuseio de grandes volumes de dados.</p>"},{"location":"teoria/aula02/#porque-usar-o-cluster-franky","title":"Porque usar o Cluster Franky?","text":"<p>Utilizar o Cluster Franky oferece v\u00e1rios benef\u00edcios que v\u00e3o prepar\u00e1-lo para desafios reais em HPC:</p> <ul> <li> <p>Experi\u00eancia Pr\u00e1tica em HPC: Ao trabalhar com o Cluster Franky, voc\u00ea ter\u00e1 a oportunidade de realizar tarefas que simulam cen\u00e1rios reais encontrados em supercomputadores como o Santos Dumont. Isso inclui a execu\u00e7\u00e3o de simula\u00e7\u00f5es complexas, a otimiza\u00e7\u00e3o de recursos e o uso inteligente das ferramentas dispon\u00edveis.</p> </li> <li> <p>Desenvolvimento de Habilidades T\u00e9cnicas: Aprender a utilizar ferramentas avan\u00e7adas como o Slurm e a interagir com ambientes de computa\u00e7\u00e3o distribu\u00edda ir\u00e1 equip\u00e1-lo com habilidades t\u00e9cnicas valiosas, amplamente aplic\u00e1veis em diversas \u00e1reas de pesquisa e ind\u00fastria.</p> </li> <li> <p>Prepara\u00e7\u00e3o para o Mundo Real: A experi\u00eancia adquirida com o Cluster Franky ser\u00e1 um diferencial no mercado de trabalho, pois voc\u00ea estar\u00e1 familiarizado com pr\u00e1ticas e tecnologias utilizadas em sistemas de HPC de ponta.</p> </li> </ul> <p>O Cluster Franky n\u00e3o \u00e9 apenas uma ferramenta de aprendizado; \u00e9 uma porta de entrada para o mundo da computa\u00e7\u00e3o de alto desempenho. Aproveite essa oportunidade para expandir seus conhecimentos, experimentar e se preparar para enfrentar desafios de HPC. Se precisar de ajuda ou tiver d\u00favidas, procure um de n\u00f3s!</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/","title":"Cluster Franky","text":"<p>Nosso objetivo \u00e9 preparar voc\u00ea com as habilidades necess\u00e1rias para utilizar sistemas de HPC em situa\u00e7\u00f5es reais. Inspirado no supercomputador Santos Dumont, o Cluster Franky oferece um ambiente robusto e seguro para realizar simula\u00e7\u00f5es complexas e an\u00e1lises de grandes volumes de dados.</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#como-o-sistema-funciona","title":"Como o Sistema Funciona","text":"<p>Para que voc\u00ea compreenda melhor como o Cluster Franky opera, veja a figura abaixo que detalha a arquitetura do sistema:</p> <p></p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#1-conexao-e-autenticacao","title":"1. Conex\u00e3o e Autentica\u00e7\u00e3o","text":"<p>O processo de intera\u00e7\u00e3o com o Cluster Franky come\u00e7a quando voc\u00ea se conecta ao Cluster via SSH atrav\u00e9s da rede do Insper, em seguida, voc\u00ea ser\u00e1 direcionado ao Login Node, que serve como o ponto de entrada para o cluster. Para acessar o sistema, \u00e9 necess\u00e1rio passar por um processo de autentica\u00e7\u00e3o usando pares de chaves p\u00fablicas e privadas, configurados previamente por nossa equipe t\u00e9cnica.</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#2-envio-e-gerenciamento-de-tarefas-jobs","title":"2. Envio e Gerenciamento de Tarefas (Jobs)","text":"<p>Uma vez autenticado, voc\u00ea interage com o cluster atrav\u00e9s do Slurm. O Slurm \u00e9 respons\u00e1vel por gerenciar a execu\u00e7\u00e3o das tarefas que voc\u00ea submete, distribuindo-as eficientemente pelos recursos de computa\u00e7\u00e3o dispon\u00edveis, que s\u00e3o divididos em:</p> <ul> <li>N\u00f3 de Computa\u00e7\u00e3o CPU: Composto por cinco n\u00f3s, cada um com 24 threads e 64 GB de RAM.</li> <li>N\u00f3 de Computa\u00e7\u00e3o GPU: Composto por um n\u00f3s, equipado com uma GPU NVIDIA 1080 Ti, 16 GB de RAM e 8 threads.</li> </ul> <p>Os daemons de controle cada n\u00f3 de computa\u00e7\u00e3o gerencia a execu\u00e7\u00e3o das tarefas, garantindo que os recursos sejam alocados de forma otimizada. Isso significa que, independentemente de voc\u00ea estar executando simula\u00e7\u00f5es simples ou tarefas intensivas de processamento de dados, o sistema est\u00e1 configurado para maximizar a efici\u00eancia e minimizar o tempo de execu\u00e7\u00e3o.</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#3-armazenamento-e-gestao-de-dados","title":"3. Armazenamento e Gest\u00e3o de Dados","text":"<p>Durante suas atividades, voc\u00ea deve utilizar a pasta SCRATCH para armazenar temporariamente os arquivos e dados necess\u00e1rios para suas tarefas. \u00c9 importante lembrar que essa pasta \u00e9 destinada ao armazenamento tempor\u00e1rio, portanto, certifique-se de salvar seus dados em um local seguro ap\u00f3s concluir suas atividades.</p> <p>O sistema de arquivos atual do Cluster Franky utiliza o NFS (Network File System), que facilita o acesso aos dados entre os n\u00f3s de computa\u00e7\u00e3o. No futuro, planejamos migrar para o sistema de arquivos Lustre, que oferecer\u00e1 maior efici\u00eancia e melhor desempenho no manuseio de grandes volumes de dados.</p>"},{"location":"teoria/cluster-Franky/cluster-Franky/#porque-usar-o-cluster-franky","title":"Porque usar o Cluster Franky?","text":"<p>Utilizar o Cluster Franky oferece v\u00e1rios benef\u00edcios que v\u00e3o prepar\u00e1-lo para desafios reais em HPC:</p> <ul> <li> <p>Experi\u00eancia Pr\u00e1tica em HPC: Ao trabalhar com o Cluster Franky, voc\u00ea ter\u00e1 a oportunidade de realizar tarefas que simulam cen\u00e1rios reais encontrados em supercomputadores como o Santos Dumont. Isso inclui a execu\u00e7\u00e3o de simula\u00e7\u00f5es complexas, a otimiza\u00e7\u00e3o de recursos e o uso inteligente das ferramentas dispon\u00edveis.</p> </li> <li> <p>Desenvolvimento de Habilidades T\u00e9cnicas: Aprender a utilizar ferramentas avan\u00e7adas como o Slurm e a interagir com ambientes de computa\u00e7\u00e3o distribu\u00edda ir\u00e1 equip\u00e1-lo com habilidades t\u00e9cnicas valiosas, amplamente aplic\u00e1veis em diversas \u00e1reas de pesquisa e ind\u00fastria.</p> </li> <li> <p>Prepara\u00e7\u00e3o para o Mundo Real: A experi\u00eancia adquirida com o Cluster Franky ser\u00e1 um diferencial no mercado de trabalho, pois voc\u00ea estar\u00e1 familiarizado com pr\u00e1ticas e tecnologias utilizadas em sistemas de HPC de ponta.</p> </li> </ul> <p>O Cluster Franky n\u00e3o \u00e9 apenas uma ferramenta de aprendizado; \u00e9 uma porta de entrada para o mundo da computa\u00e7\u00e3o de alto desempenho. Aproveite essa oportunidade para expandir seus conhecimentos, experimentar e se preparar para enfrentar desafios de HPC. Se precisar de ajuda ou tiver d\u00favidas, procure um de n\u00f3s!</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/","title":"Contextualizando o HPC","text":""},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-hpc","title":"O que \u00e9 HPC?","text":"<p>High-Performance Computing (HPC) refere-se ao uso de supercomputadores e clusters de computadores para resolver problemas computacionalmente complexos. HPC \u00e9 essencial em campos como ci\u00eancia, engenharia e finan\u00e7as, onde grandes volumes de dados precisam ser processados rapidamente.</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#top-500","title":"TOP 500","text":"<p>Supercomputador Fugaku Fonte:https://spectrum.ieee.org/japans-fugaku-supercomputer-is-first-in-the-world-to-simultaneously-top-all-high-performance-benchmarks</p> <p>O TOP 500 \u00e9 uma lista semestral que classifica os 500 supercomputadores mais poderosos do mundo com base no benchmark LINPACK, que mede a capacidade de resolver sistemas de equa\u00e7\u00f5es lineares. A lista \u00e9 um indicador importante do progresso em tecnologia de supercomputa\u00e7\u00e3o. Varia\u00e7\u00f5es da lista incluem:</p> <ul> <li>Green500: Classifica supercomputadores pela efici\u00eancia energ\u00e9tica.</li> <li>Graph500: Mede o desempenho em tarefas de an\u00e1lise de gr\u00e1ficos.</li> <li>HPCG: Avalia supercomputadores usando um benchmark alternativo ao LINPACK, mais representativo de cargas de trabalho reais em HPC.</li> </ul>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#que-tipo-de-problema-e-computacionalmente-complexo","title":"Que tipo de problema \u00e9 computacionalmente complexo?","text":"<p>Problemas computacionalmente complexos exigem grande capacidade de processamento e mem\u00f3ria para serem resolvidos eficientemente. Exemplos incluem:</p> <ul> <li>Simula\u00e7\u00f5es clim\u00e1ticas</li> <li>Modelagem molecular</li> <li>Processamento de grandes conjuntos de dados (Big Data)</li> <li>An\u00e1lise gen\u00f4mica</li> <li>Renderiza\u00e7\u00e3o de gr\u00e1ficos em alta resolu\u00e7\u00e3o</li> <li>Aprendizado de m\u00e1quina e intelig\u00eancia artificial</li> </ul>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-um-supercomputador","title":"O que \u00e9 um supercomputador?","text":"<p>Monstr\u00e3o - Supercomputador do Insper Fonte:https://www.insper.edu.br/noticias/conhece-o-monstrao-saiba-mais-sobre-o-supercomputador-do-insper/</p> <p>Um supercomputador \u00e9 um sistema computacional de alto desempenho projetado para processar grandes volumes de dados e realizar c\u00e1lculos complexos muito rapidamente. Ele consiste em milhares de n\u00f3s de computa\u00e7\u00e3o interconectados, cada um contendo m\u00faltiplos processadores, grande quantidade de mem\u00f3ria e armazenamento r\u00e1pido.</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-um-cluster","title":"O que \u00e9 um Cluster?","text":"<p>Cluster Franky - Laborat\u00f3rio de Redes e Supercomputa\u00e7\u00e3o do Insper</p> <p>Um cluster \u00e9 um conjunto de computadores (n\u00f3s) conectados que trabalham juntos como se fossem um \u00fanico sistema. Cada n\u00f3 em um cluster \u00e9 um computador independente, mas o sistema inteiro \u00e9 gerenciado para atuar em conjunto, distribuindo tarefas e compartilhando recursos.</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#qual-a-diferenca-de-um-supercomputador-para-um-cluster","title":"Qual a diferen\u00e7a de um supercomputador para um cluster?","text":"<p>A principal diferen\u00e7a entre um supercomputador e um cluster est\u00e1 na integra\u00e7\u00e3o e desempenho:</p> <ul> <li>Supercomputador: Um sistema integrado de alto desempenho projetado especificamente para computa\u00e7\u00e3o intensa. Possui uma arquitetura otimizada e interconex\u00f5es de alta velocidade.</li> <li>Cluster: S\u00e3o computadores independentes conectados para trabalhar juntos. Pode ser composto por hardware de mercado e geralmente \u00e9 mais flex\u00edvel e expans\u00edvel.</li> </ul> <p>OBS: Muitos supercomputadores modernos s\u00e3o de fato clusters, utilizando milhares de n\u00f3s interconectados para alcan\u00e7ar um desempenho extremamente alto.</p>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-preciso-saber-para-utilizar-o-cluster","title":"O que \u00e9 preciso saber para utilizar o Cluster?","text":"<p>Para utilizar um cluster eficientemente, \u00e9 importante entender:</p> <ul> <li>Acesso e Conex\u00e3o: Como se conectar ao cluster e configurar as credenciais de acesso.</li> <li>Gerenciamento de Recursos: Como usar o sistema de gerenciamento de SLURM para submeter e monitorar jobs.</li> <li>Sistema de Arquivos: Navega\u00e7\u00e3o e uso do sistema de arquivos do cluster.</li> <li>Compila\u00e7\u00e3o e Execu\u00e7\u00e3o: Compilar c\u00f3digo e executar programas no ambiente do cluster.</li> <li>Paraleliza\u00e7\u00e3o: Como paralelizar c\u00f3digo usando bibliotecas como OpenMP e MPI.</li> </ul>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#o-que-e-preciso-saber-para-resolver-problemas-em-hpc","title":"O que \u00e9 preciso saber para resolver problemas em HPC?","text":"<p>Para resolver problemas em HPC, \u00e9 essencial ter conhecimento em:</p> <ul> <li>Arquitetura de Computadores: Compreender a arquitetura do sistema, incluindo hierarquia de mem\u00f3ria e caches, para escrever c\u00f3digo eficiente.</li> <li>Otimiza\u00e7\u00e3o de C\u00f3digo: T\u00e9cnicas de otimiza\u00e7\u00e3o, uso eficiente da mem\u00f3ria, uso efici\u00eante do compilador.</li> <li>Profiling: Ferramentas e t\u00e9cnicas para identificar gargalos de desempenho e medir a efici\u00eancia do c\u00f3digo.</li> <li>Gerenciamento de Recursos: Usar ferramentas de gerenciamento como SLURM para alocar recursos adequadamente.</li> <li>Programa\u00e7\u00e3o Paralela: Usar OpenMP para paraleliza\u00e7\u00e3o em mem\u00f3ria compartilhada e MPI para mem\u00f3ria distribu\u00edda.</li> </ul>"},{"location":"teoria/contextualizando-hpc/contextualizando-HPC/#recursos-adicionais","title":"Recursos Adicionais","text":"<ul> <li>Documenta\u00e7\u00e3o do SLURM: SLURM User Guide</li> <li>Tutoriais de MPI: MPI Tutorial</li> <li>OpenMP: OpenMP Official Site</li> <li>Profiling Tools: Gprof, Valgrind</li> </ul>"}]}