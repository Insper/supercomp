# Guia de Pragmas OpenMP

### Fun√ß√µes da API OpenMP

* `omp_get_thread_num()` ‚Üí retorna o ID da thread.
* `omp_get_num_threads()` ‚Üí total de threads na regi√£o paralela.
* `omp_get_wtime()` ‚Üí cron√¥metro de alta resolu√ß√£o.
* `omp_get_max_threads()` ‚Üí n√∫mero m√°ximo de threads dispon√≠veis.
* `OMP_NUM_THREADS` ‚Üí n√∫mero de threads usadas no programa
* `OMP_SCHEDULE` ‚Üí define a pol√≠tica de escalonamento quando se usa `schedule(runtime)`

### Criando regi√µes paralelas

```cpp
#pragma omp parallel
{
    // c√≥digo aqui roda em paralelo (todas as threads executam)
}
```



### Paralelizando la√ßos (`for`)

```cpp
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    a[i] = b[i] + c[i];
}
```

* **Cl√°usula `schedule`**: define como dividir as itera√ß√µes entre threads

  * `schedule(static)` ‚Üí divide blocos iguais e fixos
  * `schedule(dynamic, chunk)` ‚Üí distribui em blocos de `chunk` de forma din√¢mica
  * `schedule(guided, chunk)` ‚Üí blocos come√ßam grandes e v√£o diminuindo
  * `schedule(runtime)` ‚Üí definido pela vari√°vel de ambiente `OMP_SCHEDULE`



###  Vari√°veis privadas e compartilhadas

```cpp
#pragma omp parallel for private(x) shared(y)
for (int i = 0; i < N; i++) {
    int x = i;        // cada thread tem sua c√≥pia
    y[i] = f(x);      // y √© vis√≠vel por todas
}
```

* `private(var)` ‚Üí cada thread cria sua pr√≥pria c√≥pia
* `shared(var)` ‚Üí todas as threads acessam a mesma vari√°vel



### Redu√ß√µes (somat√≥rios, produtos, etc.)

```cpp
double soma = 0.0;
#pragma omp parallel for reduction(+:soma)
for (int i = 0; i < N; i++) {
    soma += a[i];
}
```

* `+` ‚Üí soma (ex.: `soma += ...`)
* `*` ‚Üí produto (ex.: `prod *= ...`)
* `max` ‚Üí m√°ximo (ex.: encontra o maior valor)
* `min` ‚Üí m√≠nimo (ex.: encontra o menor valor)
* `&&` ‚Üí AND l√≥gico
* `||` ‚Üí OR l√≥gico
* `^`  ‚Üí XOR bit a bit



### Se√ß√µes paralelas

```cpp
#pragma omp parallel sections
{
    #pragma omp section
    tarefa1();

    #pragma omp section
    tarefa2();
}
```

* Divide blocos de c√≥digo independentes entre threads.



### √Åreas cr√≠ticas e exclus√£o m√∫tua

```cpp
#pragma omp critical
{
    contador++;
}
```

* Apenas **uma thread por vez** entra nesse bloco.
* √ötil para proteger atualiza√ß√µes em vari√°veis compartilhadas.



###  Diretiva `single`

```cpp
#pragma omp parallel
{
    #pragma omp single
    {
        std::cout << "Executado por apenas 1 thread\n";
    }
}
```

* Apenas **uma thread** executa esse trecho, mas as outras esperam.



### Barreira de sincroniza√ß√£o

```cpp
#pragma omp barrier
```

* Faz todas as threads esperarem umas pelas outras antes de seguir adiante.



Sim üôå al√©m das diretivas b√°sicas que j√° coloquei no guia, existem outras **muito usadas na pr√°tica** que valem a pena aparecer num material de refer√™ncia r√°pida para os alunos. Vou complementar a lista com as mais √∫teis/did√°ticas:



###  `#pragma omp parallel for collapse(n)`

O `collapse(n)` junta `n` loops aninhados em **um s√≥ loop paralelo**. Muito √∫til em matrizes e tensores.

```cpp
#pragma omp parallel for collapse(2)
for (int i = 0; i < N; i++) {
    for (int j = 0; j < M; j++) {
        A[i][j] = i + j;
    }
}
```


###  `#pragma omp task`
Permite criar **tarefas ass√≠ncronas** dentro de uma regi√£o paralela. Muito usado para grafos, √°rvores e pipelines.

```cpp
#pragma omp parallel
{
    #pragma omp single
    {
        #pragma omp task
        f1();

        #pragma omp task
        f2();

        #pragma omp taskwait   // sincroniza as tasks
    }
}
```


### `#pragma omp atomic`
Protege uma opera√ß√£o simples (ex.: incremento) de condi√ß√µes de corrida, com overhead menor que `critical`.


```cpp
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    #pragma omp atomic
    soma += a[i];
}
```




### `#pragma omp master` e `#pragma omp single nowait`

* `master`: s√≥ a thread 0 roda.
* `single`: apenas uma thread roda (n√£o necessariamente a 0).
* `nowait`: libera as threads de esperarem.

```cpp
#pragma omp parallel
{
    #pragma omp master
    { std::cout << "Apenas a thread master executa\n"; }

    #pragma omp single nowait
    { std::cout << "Uma thread qualquer executa e n√£o h√° barreira\n"; }
}
```



###  `#pragma omp simd`
For√ßa a vetoriza√ß√£o SIMD (Single Instruction Multiple Data). 
Pode ser combinado com `parallel for` ‚Üí `#pragma omp parallel for simd`.

```cpp
#pragma omp simd
for (int i = 0; i < N; i++) {
    c[i] = a[i] + b[i];
}
```



### Controlando vari√°veis

* `firstprivate(var)` ‚Üí cada thread ganha uma c√≥pia inicializada com o valor original.
* `lastprivate(var)` ‚Üí garante que, ao final, o valor da √∫ltima itera√ß√£o fique na vari√°vel global.
* `default(shared)` ‚Üí define pol√≠tica padr√£o de vari√°veis (bom para pegar erros!).




Documenta√ß√£o dispon√≠vel em [openmp.org](https://www.openmp.org/wp-content/uploads/OpenMP-4.5-1115-CPP-web.pdf)