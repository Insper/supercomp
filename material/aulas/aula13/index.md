
# Uma Introdu√ß√£o a CUDA

O **CUDA (Compute Unified Device Architecture)** √© o modelo de programa√ß√£o paralela desenvolvido pela **NVIDIA**.
Ele permite que desenvolvedores usem o poder das **GPUs** para acelerar aplica√ß√µes de alto desempenho, executando milhares de threads simultaneamente.

Em um **sistema HPC com SLURM**, como o Franky ou o SDumont, a execu√ß√£o de programas CUDA segue tr√™s etapas principais:

1. **Carregar o m√≥dulo CUDA** dispon√≠vel no cluster.
2. **Compilar o c√≥digo** com o compilador `nvcc`.
3. **Executar o bin√°rio** com o `srun` ou `sbatch`(solicitando uma GPU).

---

## Etapa 1 ‚Äî Preparando o ambiente

Para saber informa√ß√µes sobre as filas que voc√™ tem acesso

```bash
sacctmgr list user $USER -s format=partition%20,MaxJobs,MaxSubmit,MaxNodes,MaxCPUs,MaxWall
```

Dentro do seu diret√≥rio de trabalho `/scratch/insperhpc/seu_login/GPU/`:

```bash
mkdir /scratch/insperhpc/seu_login/GPU
cd /scratch/insperhpc/seu_login/GPU
```

Liste os m√≥dulos dispon√≠veis e carregue o CUDA:

```bash
module avail cuda
module load cuda/12.6_sequana
```

Verifique se o compilador CUDA est√° ativo:

```bash
nvcc --version
```

---

## Etapa 2 ‚Äî C√≥digo Base (CPU)

Vamos come√ßar com um programa simples em **C++** que soma os elementos de dois vetores na **CPU**.

Crie o arquivo:

```bash
nano exemplo_cpu.cpp
```

Cole o c√≥digo abaixo:

```cpp
#include <iostream>
#include <math.h>

// Fun√ß√£o que soma os elementos de dois vetores
void add(int n, float *x, float *y)
{
  for (int i = 0; i < n; i++)
      y[i] = x[i] + y[i];
}

int main(void)
{
  int N = 1<<20; // 1 milh√£o de elementos
  float *x = new float[N];
  float *y = new float[N];

  // Inicializa os vetores
  for (int i = 0; i < N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  // Executa a soma na CPU
  add(N, x, y);

  // Verifica erro
  float maxError = 0.0f;
  for (int i = 0; i < N; i++)
    maxError = fmax(maxError, fabs(y[i]-3.0f));

  std::cout << "Erro m√°ximo: " << maxError << std::endl;

  delete [] x;
  delete [] y;

  return 0;
}
```

Compile e execute localmente (sem GPU):

```bash
g++ exemplo_cpu.cpp -o ex_cpu
```

```bash
srun --partition=sequana_cpu_dev ./ex_cpu
```

Sa√≠da esperada:

```
srun: job 123456 queued and waiting for resources
srun: job 123456 has been allocated resources
Erro m√°ximo: 0
```

---

## Etapa 3 ‚Äî Migrando para GPU (CUDA)

Agora, vamos reescrever o mesmo c√≥digo para rodar **na GPU**.

Crie o arquivo:

```bash
nano exemplo1.cu
```

Cole o c√≥digo abaixo:

```cpp
#include <iostream>
#include <math.h>

// Kernel CUDA: soma os elementos de dois vetores
__global__
void add(int n, float *x, float *y)
{
  int index = blockIdx.x * blockDim.x + threadIdx.x;
  int stride = blockDim.x * gridDim.x;
  for (int i = index; i < n; i += stride)
    y[i] = x[i] + y[i];
}

int main(void)
{
  int N = 1<<20;
  float *x, *y;

  // Aloca Mem√≥ria Unificada ‚Äì acess√≠vel pela CPU e pela GPU
  cudaMallocManaged(&x, N*sizeof(float));
  cudaMallocManaged(&y, N*sizeof(float));

  // Inicializa vetores na CPU
  for (int i = 0; i < N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  // Configura√ß√£o da grade e dos blocos
  int blockSize = 256;
  int numBlocks = (N + blockSize - 1) / blockSize;

  // Lan√ßa o kernel na GPU
  add<<<numBlocks, blockSize>>>(N, x, y);

  // Aguarda a GPU terminar
  cudaDeviceSynchronize();

  // Verifica o erro m√°ximo
  float maxError = 0.0f;
  for (int i = 0; i < N; i++)
    maxError = fmax(maxError, fabs(y[i]-3.0f));

  std::cout << "Erro m√°ximo: " << maxError << std::endl;

  // Libera mem√≥ria
  cudaFree(x);
  cudaFree(y);

  return 0;
}
```

Compile com o `nvcc`:

```bash
nvcc exemplo1.cu -o ex1
```

---

## Etapa 4 ‚Äî Executando no n√≥ GPU com SLURM

Agora, vamos executar o bin√°rio **pedindo uma GPU** via `srun`:

```bash
srun --partition=sequana_gpu_dev --gres=gpu:1 ./ex1
```

üí° **Explica√ß√£o dos par√¢metros:**

| Op√ß√£o                         | Significado                  |
| ----------------------------- | ---------------------------- |
| `--partition=sequana_gpu_dev` | Escolhe a fila de GPU        |
| `--gres=gpu:1`                | Solicita 1 GPU               |
| `./ex1`                       | Executa o programa compilado |

Sa√≠da esperada:

```
srun: job 11402255 queued and waiting for resources
srun: job 11402255 has been allocated resources
Erro m√°ximo: 0
```

---

##  Explica√ß√£o do Kernel CUDA

At√© agora, vimos como executar um **kernel CUDA** com m√∫ltiplas *threads* dentro de **um √∫nico bloco**.
Mas as **GPUs modernas** s√£o compostas por **m√∫ltiplos processadores paralelos**, chamados **Streaming Multiprocessors (SMs)**.
Cada **SM** pode executar **v√°rios blocos de threads simultaneamente**.

Por exemplo:

* Uma **GPU Tesla P100 (arquitetura Pascal)** possui **56 SMs**.
* Cada SM pode manter at√© **2048 threads ativas**.
* Isso totaliza mais de **100 mil threads em execu√ß√£o paralela real**!

Para aproveitar todo esse paralelismo, precisamos **lan√ßar o kernel com m√∫ltiplos blocos**, e n√£o apenas um.


### O que √© uma *Grid* e o que √© um *Block*?

Em CUDA:

* Cada **bloco** (*block*) √© um grupo de threads que trabalham juntas e compartilham mem√≥ria local.
* O conjunto de todos os blocos forma uma **grade** (*grid*).

Portanto:

> Uma **grade** √© composta por **v√°rios blocos**, e cada **bloco** cont√©m v√°rias **threads**.

A GPU distribui esses blocos entre seus SMs, executando eles conforme h√° recursos dispon√≠veis.


### Configurando a Execu√ß√£o com M√∫ltiplos Blocos

Se temos `N` elementos (ex: 1 milh√£o) e queremos 256 threads por bloco,
precisamos calcular **quantos blocos** s√£o necess√°rios para cobrir todos os elementos.

O c√°lculo √© simples:

```cpp
int blockSize = 256;
int numBlocks = (N + blockSize - 1) / blockSize;
add<<<numBlocks, blockSize>>>(N, x, y);
```

* `blockSize` ‚Üí n√∫mero de threads por bloco (normalmente m√∫ltiplo de 32).
* `numBlocks` ‚Üí n√∫mero de blocos necess√°rios (arredondando para cima).
* `<<<numBlocks, blockSize>>>` ‚Üí diz ao CUDA quantos blocos e threads criar.

> Dessa forma, garantimos pelo menos **N threads** para processar todos os elementos.


### Calculando o √çndice Global de Cada Thread

Agora, dentro do *kernel*, precisamos adaptar o c√≥digo para que **cada thread saiba qual parte do vetor processar**.

CUDA fornece vari√°veis internas que ajudam nisso:

* `threadIdx.x` ‚Üí √≠ndice da thread dentro do bloco
* `blockIdx.x` ‚Üí √≠ndice do bloco dentro da grade
* `blockDim.x` ‚Üí n√∫mero de threads por bloco
* `gridDim.x` ‚Üí n√∫mero total de blocos

O √≠ndice global √© calculado assim:

```cpp
int index = blockIdx.x * blockDim.x + threadIdx.x;
```

Esse c√°lculo √© **padr√£o em CUDA**, porque √© o permite mapear cada thread a uma posi√ß√£o √∫nica no vetor.


### Percorrendo Grandes Vetores com *Grid-Stride Loop*

Mesmo com muitos blocos, √†s vezes o n√∫mero de threads **ainda √© menor que N**.
Para lidar com isso, usamos um padr√£o chamado **grid-stride loop**:

```cpp
int stride = blockDim.x * gridDim.x;
for (int i = index; i < n; i += stride)
    y[i] = x[i] + y[i];
```

**O que isso faz:**

* `stride` representa o n√∫mero total de threads ativas na GPU.
* Cada thread processa m√∫ltiplos elementos separados por esse intervalo.
* Assim, mesmo que `N` seja muito grande, todas as posi√ß√µes do vetor s√£o tratadas.

---

### Kernel completo com m√∫ltiplos blocos

```cpp
#include <iostream>
#include <math.h>

// Kernel CUDA para somar dois vetores usando m√∫ltiplos blocos
__global__
void add(int n, float *x, float *y)
{
  int index  = blockIdx.x * blockDim.x + threadIdx.x; // √≠ndice global da thread
  int stride = blockDim.x * gridDim.x;                // salto entre itera√ß√µes

  for (int i = index; i < n; i += stride)
    y[i] = x[i] + y[i];
}

int main(void)
{
  int N = 1<<20; // 1 milh√£o de elementos
  float *x, *y;

  // Mem√≥ria unificada (CPU + GPU)
  cudaMallocManaged(&x, N*sizeof(float));
  cudaMallocManaged(&y, N*sizeof(float));

  // Inicializa√ß√£o dos vetores
  for (int i = 0; i < N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  // Configura√ß√£o da execu√ß√£o
  int blockSize = 256;
  int numBlocks = (N + blockSize - 1) / blockSize;

  // Lan√ßamento do kernel
  add<<<numBlocks, blockSize>>>(N, x, y);

  // Sincroniza√ß√£o
  cudaDeviceSynchronize();

  // Verifica√ß√£o do resultado
  float maxError = 0.0f;
  for (int i = 0; i < N; i++)
    maxError = fmax(maxError, fabs(y[i]-3.0f));

  std::cout << "Erro m√°ximo: " << maxError << std::endl;

  cudaFree(x);
  cudaFree(y);
  return 0;
}
```

Vers√£o com prints did√°ticos 
```cpp
#include <iostream>
#include <math.h>
#include <cuda_runtime.h>

// Kernel CUDA para somar dois vetores usando m√∫ltiplos blocos
__global__
void add(int n, float *x, float *y)
{
  // Calcula o √≠ndice global e o salto entre itera√ß√µes
  int index  = blockIdx.x * blockDim.x + threadIdx.x;
  int stride = blockDim.x * gridDim.x;

  // Imprime informa√ß√µes das primeiras threads de cada bloco
  if (threadIdx.x == 0) {
    printf("Bloco %d ativo com %d threads (index inicial global = %d)\n",
           blockIdx.x, blockDim.x, index);
  }

  // Cada thread processa m√∫ltiplos elementos separados por 'stride'
  for (int i = index; i < n; i += stride) {
    if (i < 10 && blockIdx.x == 0 && threadIdx.x < 5) {
      printf("[Thread %d | Bloco %d] somando x[%d]=%.1f + y[%d]=%.1f\n",
             threadIdx.x, blockIdx.x, i, x[i], i, y[i]);
    }
    y[i] = x[i] + y[i];
  }
}

int main(void)
{
  int N = 1<<20; // 1 milh√£o de elementos
  float *x, *y;

  std::cout << "=== Inicializando mem√≥ria unificada ===" << std::endl;
  cudaMallocManaged(&x, N*sizeof(float));
  cudaMallocManaged(&y, N*sizeof(float));

  // Inicializa√ß√£o dos vetores
  std::cout << "=== Inicializando vetores x e y ===" << std::endl;
  for (int i = 0; i < N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  // Configura√ß√£o da execu√ß√£o
  int blockSize = 256;
  int numBlocks = (N + blockSize - 1) / blockSize;

  std::cout << "=== Configura√ß√£o do kernel ===" << std::endl;
  std::cout << "N√∫mero total de elementos: " << N << std::endl;
  std::cout << "Threads por bloco (blockSize): " << blockSize << std::endl;
  std::cout << "N√∫mero de blocos (numBlocks): " << numBlocks << std::endl;
  std::cout << "Threads totais (gridDim*blockDim): "
            << numBlocks * blockSize << std::endl;
  std::cout << "=======================================" << std::endl;

  // Lan√ßamento do kernel
  add<<<numBlocks, blockSize>>>(N, x, y);

  // Sincroniza√ß√£o
  cudaDeviceSynchronize();

  std::cout << "\n=== Kernel finalizado, verificando resultados ===" << std::endl;

  // Verifica√ß√£o do resultado
  float maxError = 0.0f;
  for (int i = 0; i < N; i++)
    maxError = fmax(maxError, fabs(y[i]-3.0f));

  std::cout << "Erro m√°ximo: " << maxError << std::endl;

  // Mostra os primeiros 10 resultados
  std::cout << "\n=== Amostra dos primeiros 10 valores de y ===" << std::endl;
  for (int i = 0; i < 10; i++)
    std::cout << "y[" << i << "] = " << y[i] << std::endl;

  cudaFree(x);
  cudaFree(y);
  std::cout << "\n=== Execu√ß√£o completa ===" << std::endl;

  return 0;
}

```



### Visualiza√ß√£o do Modelo

| N√≠vel  | Identificador | Exemplo | Fun√ß√£o                 |
| ------ | ------------- | ------- | ---------------------- |
| Thread | `threadIdx.x` | 0‚Äì255   | Uma linha de execu√ß√£o  |
| Bloco  | `blockIdx.x`  | 0‚Äì4095  | Agrupa 256 threads     |
| Grade  | `gridDim.x`   | 4096    | Agrupa todos os blocos |

Cada thread calcula:

```
index = blockIdx.x * blockDim.x + threadIdx.x
```

e acessa `y[index]`.

### Compilando e executando no HPC

No seu ambiente:

```bash
module load cuda/12.6_sequana
nvcc add_grid.cu -o add_grid
srun --partition=sequana_gpu_dev --gres=gpu:1 ./add_grid
```

Sa√≠da esperada:

```
srun: job 11402255 queued and waiting for resources
srun: job 11402255 has been allocated resources
Erro m√°ximo: 0
```

### Conceitos-chave dessa etapa

| Conceito                                  | Explica√ß√£o                                               |
| ----------------------------------------- | -------------------------------------------------------- |
| **Streaming Multiprocessor (SM)**         | Unidade de processamento paralela da GPU                 |
| **Grid**                                  | Conjunto de blocos lan√ßados na GPU                       |
| **Block**                                 | Grupo de threads que compartilham mem√≥ria local          |
| **Grid-Stride Loop**                      | T√©cnica para percorrer grandes vetores com menos threads |
| **blockIdx.x * blockDim.x + threadIdx.x** | F√≥rmula padr√£o de indexa√ß√£o CUDA                         |

## Exerc√≠cios:

1. Teste outros tamanhos de vetor.
2. Modifique o n√∫mero de blocos e threads para observar o impacto.
3. Adicione medi√ß√µes de tempo com as fun√ß√µes CUDA (`cudaEventRecord`).
4. Teste kernels com mais dimens√µes.


## Se quiser aprender mais

1. Explore a [documenta√ß√£o do CUDA Toolkit](https://docs.nvidia.com/cuda/index.html).
   Veja o [Guia R√°pido de Instala√ß√£o](https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html) e o [Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html).
2. Teste o uso de `printf()` dentro do kernel para imprimir `threadIdx.x` e `blockIdx.x`.
3. Experimente `threadIdx.y`, `threadIdx.z` e `blockIdx.y`.
   Descubra como definir grids e blocos em m√∫ltiplas dimens√µes.
4. Leia sobre a [Unified Memory no CUDA 8](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/) e o mecanismo de migra√ß√£o de p√°ginas da arquitetura Pascal.



obs: Material adaptado do Deep Learning Institute NVIDIA e do NVIDIA Teaching kit - Accelerated Computing

```
